\documentclass[journal]{IEEEtran}

\usepackage[OT1]{fontenc} 
\usepackage{cite}
\usepackage{array}
\usepackage{textcomp}
\usepackage{color}
\usepackage{colortbl}
\usepackage{diagbox} 
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage{subfigure}
\usepackage{stfloats}
\usepackage{url}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{arydshln}
\usepackage{slashbox}
\usepackage{makecell}
\usepackage{rotating}
\usepackage{threeparttable}
\usepackage[colorlinks=true,linkcolor=blue]{hyperref}
\usepackage{pifont}
\usepackage{amssymb}%花体字母加粗
\usepackage{mathrsfs}%花体字母
\usepackage{amsfonts}
\usepackage{bm}
\DeclareMathOperator*{\argmin}{argmin}
%\usepackage[justification=centering]{caption}
%\newcommand{\textbf}{}
%\usepackage{titlesec} %自定义多级标题格式的宏包
%\titleformat{\section}[block]{\large}{\arabic{section}.}{1em}{\centering}[]
%\titleformat{\subsection}[block]{\large\itshape}{\arabic{section}.\arabic{subsection}.}{4pt}{}[]
%\titleformat{\subsubsection}[block]{\normalsize\itshape}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}.}{4pt}{}[]
%%\titleformat{\paragraph}[runin]{\normalsize\bfseries}{}{4pt}{}[]
%\titleformat{\paragraph}[block]{\normalsize\itshape}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}.\arabic{paragraph}.}{4pt}{}[]
%\titleformat{\textbf}[runin]{\normalsize\bfseries}{}{4pt}{}[]
%%\titlespacing*{\subsection} {0pt}{15pt}{5pt}
%\titlespacing*{\subsubsection}{0pt}{4pt}{4pt}
%\titlespacing*{\paragraph} {4pt}{3pt}{3pt}
%\titlespacing*{\textbf} {4pt}{0pt}{10pt}

% correct bad hyphenation here
% \hyphenation{op-tical net-works semi-conduc-tor}
%
%
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}

%________________________________color define_______________________________________
\definecolor{r00}{RGB}{255, 255, 255}
\definecolor{r01}{RGB}{255, 253, 253}
\definecolor{r02}{RGB}{255, 252, 252}
\definecolor{r03}{RGB}{255, 251, 251}
\definecolor{r04}{RGB}{255, 250, 250}
\definecolor{r05}{RGB}{255, 249, 249}
\definecolor{r06}{RGB}{255, 247, 247}
\definecolor{r07}{RGB}{255, 246, 246}
\definecolor{r08}{RGB}{255, 245, 245}
\definecolor{r09}{RGB}{255, 244, 244}
\definecolor{r10}{RGB}{255, 243, 243}
\definecolor{r11}{RGB}{255, 241, 241}
\definecolor{r12}{RGB}{255, 240, 240}
\definecolor{r13}{RGB}{255, 239, 239}
\definecolor{r14}{RGB}{255, 238, 238}
\definecolor{r15}{RGB}{255, 237, 237}
\definecolor{r16}{RGB}{255, 235, 235}
\definecolor{r17}{RGB}{255, 234, 234}
\definecolor{r18}{RGB}{255, 233, 233}
\definecolor{r19}{RGB}{255, 232, 232}
\definecolor{r20}{RGB}{255, 231, 231}
\definecolor{r21}{RGB}{255, 229, 229}
\definecolor{r22}{RGB}{255, 228, 228}
\definecolor{r23}{RGB}{255, 227, 227}
\definecolor{r24}{RGB}{255, 226, 226}
\definecolor{r25}{RGB}{255, 225, 225}
\definecolor{r26}{RGB}{255, 223, 223}
\definecolor{r27}{RGB}{255, 222, 222}
\definecolor{r28}{RGB}{255, 221, 221}
\definecolor{r29}{RGB}{255, 220, 220}
\definecolor{r30}{RGB}{255, 219, 219}
\definecolor{r31}{RGB}{255, 217, 217}
\definecolor{r32}{RGB}{255, 216, 216}
\definecolor{r33}{RGB}{255, 215, 215}
\definecolor{r34}{RGB}{255, 214, 214}
\definecolor{r35}{RGB}{255, 213, 213}
\definecolor{r36}{RGB}{255, 211, 211}
\definecolor{r37}{RGB}{255, 210, 210}
\definecolor{r38}{RGB}{255, 209, 209}
\definecolor{r39}{RGB}{255, 208, 208}
\definecolor{r40}{RGB}{255, 207, 207}
\definecolor{r41}{RGB}{255, 205, 205}
\definecolor{r42}{RGB}{255, 204, 204}
\definecolor{r43}{RGB}{255, 203, 203}
\definecolor{r44}{RGB}{255, 202, 202}
\definecolor{r45}{RGB}{255, 201, 201}
\definecolor{r46}{RGB}{255, 199, 199}
\definecolor{r47}{RGB}{255, 198, 198}
\definecolor{r48}{RGB}{255, 197, 197}
\definecolor{r49}{RGB}{255, 196, 196}
\definecolor{r50}{RGB}{255, 195, 195}
\definecolor{r51}{RGB}{255, 193, 193}
\definecolor{r52}{RGB}{255, 192, 192}
\definecolor{r53}{RGB}{255, 191, 191}
\definecolor{r54}{RGB}{255, 190, 190}
\definecolor{r55}{RGB}{255, 189, 189}
\definecolor{r56}{RGB}{255, 187, 187}
\definecolor{r57}{RGB}{255, 186, 186}
\definecolor{r58}{RGB}{255, 185, 185}
\definecolor{r59}{RGB}{255, 184, 184}
\definecolor{r60}{RGB}{255, 183, 183}
\definecolor{r61}{RGB}{255, 181, 181}
\definecolor{r62}{RGB}{255, 180, 180}
\definecolor{r63}{RGB}{255, 179, 179}
\definecolor{r64}{RGB}{255, 178, 178}
\definecolor{r65}{RGB}{255, 177, 177}
\definecolor{r66}{RGB}{255, 175, 175}
\definecolor{r67}{RGB}{255, 174, 174}
\definecolor{r68}{RGB}{255, 173, 173}
\definecolor{r69}{RGB}{255, 172, 172}
\definecolor{r70}{RGB}{255, 171, 171}
\definecolor{r71}{RGB}{255, 169, 169}
\definecolor{r72}{RGB}{255, 168, 168}
\definecolor{r73}{RGB}{255, 167, 167}
\definecolor{r74}{RGB}{255, 166, 166}
\definecolor{r75}{RGB}{255, 165, 165}
\definecolor{r76}{RGB}{255, 163, 163}
\definecolor{r77}{RGB}{255, 162, 162}
\definecolor{r78}{RGB}{255, 161, 161}
\definecolor{r79}{RGB}{255, 160, 160}
\definecolor{r80}{RGB}{255, 159, 159}
\definecolor{r81}{RGB}{255, 157, 157}
\definecolor{r82}{RGB}{255, 156, 156}
\definecolor{r83}{RGB}{255, 155, 155}
\definecolor{r84}{RGB}{255, 154, 154}
\definecolor{r85}{RGB}{255, 153, 153}
\definecolor{r86}{RGB}{255, 151, 151}
\definecolor{r87}{RGB}{255, 150, 150}
\definecolor{r88}{RGB}{255, 149, 149}
\definecolor{r89}{RGB}{255, 148, 148}
\definecolor{r90}{RGB}{255, 147, 147}
\definecolor{r91}{RGB}{255, 145, 145}
\definecolor{r92}{RGB}{255, 144, 144}
\definecolor{r93}{RGB}{255, 143, 143}
\definecolor{r94}{RGB}{255, 142, 142}
\definecolor{r95}{RGB}{255, 141, 141}
\definecolor{r96}{RGB}{255, 139, 139}
\definecolor{r97}{RGB}{255, 138, 138}
\definecolor{r98}{RGB}{255, 137, 137}
\definecolor{r99}{RGB}{255, 136, 136}
\definecolor{red}{RGB}{0, 0, 0}
\definecolor{red2}{RGB}{255, 0, 0}

%________________________________color define_______________________________________

\begin{document}
\title{\LARGE \bf
	Understanding the Challenges When 3D Semantic Segmentation Faces Class Imbalanced and OOD Data}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Yancheng~Pan,~\IEEEmembership{Member,~IEEE,}
	    Fan~Xie,~\IEEEmembership{Member,~IEEE,}
		Huijing~Zhao,~\IEEEmembership{Member,~IEEE}
	
\thanks{This work was supported in part by the NSFC under
	Grant 61973004. Yancheng Pan and Huijing Zhao are with
	the Key Laboratory of Machine Perception (MOE), School of AI, Peking
	University, Beijing 100084, China (e-mail: panyancheng@pku.edu.cn; zhaohj@pku.edu.cn). Fan Xie is with the School of EECS, Peking
	University, Beijing 100084.}

}% <-this % stops a space


\markboth{IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,~Vol.~?, No.~?, ??~????}%
{Shell \MakeLowercase{\textit{et al.}}: IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS}

% make the title area
\maketitle

%Experimental studies with both quantitative analysis by cross-correlating metrics and visualization analysis at feature space are conducted to gain a deeper understanding of the performance of state-of-the-art 3DSS models facing class imbalanced and OOD data, which is crucial towards real-world deployment.

\begin{abstract}
	
3D semantic segmentation (3DSS) is an essential process in the creation of a safe autonomous driving system. However, deep learning models for 3D semantic segmentation often suffer from the class imbalance problem and out-of-distribution (OOD) data. In this study, we explore how the class imbalance problem affects 3DSS performance and whether the model can detect the category prediction correctness, or whether data is ID (in-distribution) or OOD. For these purposes, we conduct two experiments using three representative 3DSS models and five trust scoring methods, and conduct both a confusion and feature analysis of each class. Furthermore, a data augmentation method for the 3D LiDAR dataset is proposed to create a new dataset based on SemanticKITTI and SemanticPOSS, called AugKITTI. We propose the wPre metric and TSD for a more in-depth analysis of the results, and follow are proposals with an insightful discussion. Based on the experimental results, we find that:  (1) the classes are not only imbalanced in their data size but also in the basic properties of each semantic category. (2) The intraclass diversity and interclass ambiguity make class learning difficult and greatly limit the models' performance, creating the challenges of semantic and data gaps. (3) The trust scores are unreliable for classes whose features are confused with other classes. For 3DSS models, those misclassified ID classes and OODs may also be given high trust scores, making the 3DSS predictions unreliable, and leading to the challenges in judging 3DSS result trustworthiness. All of these outcomes point to several research directions for improving the performance and reliability of the 3DSS models used for real-world applications.

\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
3D LiDAR, semantic segmentation, OOD detection, class imbalance
\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
%\IEEEpeerreviewmaketitle




\section{Introduction}

\IEEEPARstart{S}{emantic} segmentation \cite{yu2018methods}\cite{lateef2019survey} is a fundamental perception task that finds semantically interpretable categories of each unit of scene data. The unit can be an image pixel \cite{yu2018methods} or 3D point \cite{yuxing2019review}. A fine-grained semantic understanding is essential for an autonomous agent to navigate safely and smoothly in complex driving scenes. 3D LiDAR sensors are currently popular devices for mobile robots \cite{patz2008practical} and autonomous driving systems \cite{li2016vehicle}\cite{chen2017multi} and can capture realistic images of the surroundings with rich 3D geometric shapes. Semantic segmentation using 3D LiDAR data as input (3D semantic segmentation, 3DSS), has been widely studied, and deep learning techniques have made promising progress in this task in recent years \cite{yuxing2019review}\cite{yulan2019review}.

Deep models require a large amount of training data. The performance limitation caused by insufficient training data is called ``the data hungry effect'' \cite{marcus2018deep}. As described in \cite{gao2021we}, 3DSS studies that use deep learning techniques suffer severe data hunger problems, where 3D LiDAR datasets of real-world scenes are very limited and the class imbalance (also called the long-tail) problem is one of the key issues. Class imbalance is a common problem in machine learning and has been extensively studied \cite{buda2018systematic}, which means that the model could not be sufficiently learned for classes with a few samples. The class imbalance problem is even more severe for 3D LiDAR datasets due to the data acquisition method and the proportion of scene objects acquired in the real world. Although some studies have addressed alleviating the influence of a class imbalance during model training \cite{haixiang2017learning}, there has been no rigorous study pertaining to the following question: \textit{How does the class imbalance problem affect 3DSS models' performance?} 

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.4]{fig-1-1.pdf}
	\vspace{-3mm}
	\caption{A brief interpretation of  the challenges of 3D semantic segmentation: The class imbalance problem and the existence of OOD data. We will explore how the class imbalance problem affects 3DSS performance and whether the model can detect the category prediction correctness, ID or OOD. (3DSS: 3D semantic segmentation)}
	\label{fig:logic}
	\vspace{-4mm}
\end{figure}

Out-of-distribution (OOD) data are another key issue when deploying an AI system in the real world \cite{marcus2018deep}\cite{hendrycks2016baseline}. The problem is very severe for safety-critical applications such as autonomous driving, where some of the categories are unseen or rare in the datasets but need to be handled in the system \cite{koopman2017autonomous}. OOD detection has also been studied as a general problem in machine learning \cite{salehi2021unified}. However, the task is more difficult when 3DSS is faced with the dual challenges from class imbalances and OOD data, where the model could show a high confidence for wrong predictions \cite{nguyen2015deep} on either the object's semantic class or the judgment of its in-distribution (ID) or OOD. Compared with the bulk of efforts for improving 3DSS and OOD detection accuracies, far less attention is paid to understanding when the agent is uncertain. With an intent towards real-world deployment, it is important to ask:
\textit{Can the model be aware of its unsureness? Can the model detect whether the category prediction is correct or not? Can the model detect whether the input sample is ID or OOD?}

Fig. \ref{fig:logic} illustrates the key issues addressed in this research. With a focus on a deeper understanding of the challenges 3DSS models face with class imbalance and OOD data, two experiments are conducted to seek answers to the above questions. Experiment 1 studies 3DSS models' performance on a class-imbalanced dataset, where three 3DSS models, PointNet++ \cite{qi2017pointnet++}, Cylinder3D \cite{zhou2020cylinder3d} and RandLA-Net\cite{hu2019randla}, represent the popular and state-of-the-art models in the literature, and are trained and tested on a class imbalanced dataset, SemanticKITTI \cite{behley2019semantickitti}. Experiment 2 studies whether the model is aware of its unsureness when facing class imbalances and OOD data. Considering \textit{people} and \textit{rider} as OOD, the data from SemanticPOSS \cite{pan2020semanticposs} are augmented to SemanticKITTI \cite{behley2019semantickitti}, and a new dataset AugKITTI is developed. 3DSS models are trained on SubKITTI (SemanticKITTI without \textit{people} and \textit{rider}) while tested on AugKITTI. Softmax confidence \cite{hendrycks2016baseline}, data uncertainty and model uncertainty \cite{kendall2017uncertainties} \cite{malinin2019uncertainty}, ODIN \cite{liang2017enhancing} and Mahalanobis distance \cite{lee2018simple} are used as the trust scores to predict whether the classification result is correct or wrong, or whether the data are ID or OOD. To the best of our knowledge, this is the first work to provide an in-depth analysis of how class imbalance and OOD data affect 3DSS model performances with insightful analyses and discussions.

Experimental results show that although the scale of the training data is a key factor, model performance could be greatly affected by intraclass diversity and interclass ambiguity. Hard classes are found, that even with large training samples, have difficulty achieving a high classification accuracy or are easily confused with others. Through feature space analyses, it is understood that semantic and data gaps are among the underlying reasons. Facing the dual challenges of class imbalance and OOD, the model has difficulty predicting whether the classification result is correct or wrong or whether the data is ID or OOD. With the current trust scoring methods, a low trust score could be yielded by either OOD or ID for a wrong classification result, whereas a high trust score could also be given by an insufficiently trained model on wrong predictions. 

The main research contributions of this work are as follows:

\begin{enumerate}
	\item Experimental studies with both a quantitative analysis with cross-correlating metrics and a visualization analysis of the feature space are conducted to gain a deeper understanding of the performance of the state-of-the-art 3DSS models processing class imbalanced and OOD data, which is crucial for real-world deployments.
	
	\item A 3D LiDAR dataset augmentation method is developed. SemanticPOSS has rich data on dynamic objects, while SemanticKITTI describes mostly static scenes. A new dataset is generated by augmenting the data for the dynamic objects of SemanticPOSS to SemanticKITTI, which reduces dataset bias. Additionally, more realistic datasets for OOD studies are generated by exploiting the bias of the existing datasets.
	
	\item New metrics are proposed to address the class imbalance issue in evaluating model performance, and we demonstrate that the traditional metrics are not sufficient and that the new metrics are required for appropriately evaluating 3DSS and OOD detection performance in cases where the class models are not sufficiently learnt.
	
	\item We engage in an insightful discussion of the key issues to better understand the challenges of class imbalance and OOD data for the 3DSS task. We highlight potential topics for future works to improve the agent's awareness of the correctness or wrongness of the results and whether the data is ID or OOD.
	
\end{enumerate}

The structure of this paper is as follows. Section \ref{sec:2} reviews the existing research for 3DSS models, class imbalance and the trust scores used for failure detection and OOD detection. Section \ref{sec:3} introduces the flow of 3DSS and the datasets and models used for our experiments. Section \ref{sec:4} provides an analysis of Experiment 1, which evaluates the performances of the 3D semantic segmentation models trained on a class-imbalanced dataset. Section \ref{sec:5} provides an analysis of Experiment 2 to explore the performances of the trust scores applied to class-imbalanced datasets, which is followed by a discussion on future topics and potential solutions in Section \ref{sec:6}. 

%\IEEEPARstart{I}{n} the field of autonomous driving, 3D LiDAR sensor has become an essential device to perceive environment. 3D point cloud semantic segmentation is a core task for driving scene understanding and has been widely researched. Recently, with the development of deep learning methods, a lot of deep neural network models \cite{yulan2019review} have been proposed and brought great progress in 3D semantic segmentation tasks. However, deep models face several challenges in 3D semantic segmentation task due to the complexity of real-world LiDAR point cloud, such as class imbalance, and out-of-distribution (OOD) data.

%Class imbalance is an ubiquitous problem in real-world 3D LiDAR point cloud datasets, which is also called the long tail problem. As shown in Fig. [], the class number of SemanticKITTI \cite{behley2019semantickitti} dataset has a long tail distribution: most points belong to a few dominant classes while only a small part of data belong to other minor classes. Deep neural network models perform relatively poorly on these minor classes. Some studies \cite{haixiang2017learning} have aimed to alleviate the influence of class imbalance while model training. Besides, out-of-distribution (OOD) data is another problem in driving scene understanding and OOD detection \cite{hendrycks2016baseline} is also a research topic in deep learning domain. Deep models often suffer input samples which never appear in training data, namely the out-of-distribution data. For the safety of autonomous driving system, class imbalance and OOD data brings two huge challenges for present 3D semantic segmentation algorithm:
%
%\begin{itemize}
%	\item \textit{C1}: Classes of few samples are learned insufficiently by models.
%	
%	\item \textit{C2}: Classes of few samples are hard to distinguish with OOD data.
%\end{itemize}
%
%A brief interpretation of the two challenges for 3D semantic segmentation are shown in Fig. \ref{fig:logic}. In this paper, we try to deeply analyze the two challenges by seeking to answer the following questions:
%
%
%\begin{itemize}
%	\item \textit{Q1}: What are the performance of 3D semantic segmentation models trained on class-imbalanced datasets?
%	
%	\item \textit{Q2}: What are the performance of OOD detectors for 3D semantic segmentation task on class-imbalanced datasets?
%	
%	\item \textit{Q3}: What are the underlying reasons of these performances?
%\end{itemize}

% We provide an in-depth and quantized analysis of the influence of class imbalance, OOD data for real-world 3D semantic segmentation. We use state-of-the-art models \cite{qi2017pointnet++}\cite{zhou2020cylinder3d} training on public 3D point cloud datasets to evaluate the performance on each class and OOD detection ability of these models, and try to analyze the underlying reasons for experimental results by feature space analysis.

%To answer these questions, we create a class-imbalanced dataset with OOD data by combining SemanticKITTI \cite{behley2019semantickitti} and SemanticPOSS \cite{pan2020semanticposs} dataset, choose two represented methods PointNet++ \cite{qi2017pointnet++} and Cylinder3D \cite{zhou2020cylinder3d} trained on the dataset, and observe how prediction mistakes distribute for each class. Next, we use several OOD detection methods Softmax Confidence \cite{hendrycks2016baseline}, data uncertainty and model uncertainty \cite{kendall2017uncertainties} \cite{malinin2019uncertainty}, ODIN \cite{liang2017enhancing}, Mahalanobis Distance \cite{lee2018simple}, and evaluate OOD detection ability by AUROC. Furthermore, we analyze the feature distribution extracted by models and correlate to the input point clouds, aiming to understand why models perform differently when training on class-imbalanced datasets.

%The main contribution of this paper is a deep understanding of the models' performances to challenges of imbalance class and OOD data for 3D semantic segmentation task. The experiments, in-depth analysis can help 3D semantic segmentation models improve the performance and safety for real-world applications, and the insightful discussion can provide some novel views and potential topics in future works.

\section{Related Work} \label{sec:2}

%\begin{figure}[t]
%	\centering
%	\includegraphics[scale=0.38]{fig-2-dataset.pdf}
%	\caption{Data size of each class in (a) SemanticKITTI (b) SemanticPOSS, both of which reflect the class imbalance of data.}
%	\label{fig:2-dataset}
%	\vspace{-4mm}
%\end{figure}

\subsection{3D semantic segmentation models}

3DSS has been extensively studied in the literature to gain a precise understanding of complex scenarios, such as autonomous driving and robotics applications.
In recent years, great progress has been made in methods using deep learning techniques \cite{yulan2019review}\cite{gao2021we}, of which much of the pioneering work can be traced back to PointNet\cite{qi2017pointnet} and PointNet++\cite{qi2017pointnet++}, which provides the base network architectures for 3DSS.
3D data can be represented in different formats. Based on these formats, 3DSS models scaled up to DNN models are generally divided into point-based, image-based and voxel-based methods \cite{gao2021we}.
Point-based methods take raw point clouds as input and output pointwise labels. These types of methods, such as \cite{engelmann2017exploring}\cite{jiang2018pointsift}\cite{engelmann2018know}\cite{chen2019lsanet} \cite{zhiheng2019pyramnet}\cite{thomas2019kpconv}\cite{wu2019pointconv},\cite{hu2019randla} introduce special computation modules for local feature aggregation of 3D point clouds.
Voxel-based methods \cite{huang2016point}\cite{tchapmi2017segcloud}\cite{rethage2018fully}\cite{graham20183d}\cite{zhang2018efficient} \cite{zhou2020cylinder3d} partition 3D space into a number of voxels to convert the point clouds into a structured data format and then apply an encoder-decoder architecture for feature extraction. 
In addition, image-based methods \cite{wu2018squeezeseg}\cite{zhang2018liseg}\cite{wang2018pointseg}\cite{dewan2019deeptemporalseg}
\cite{wu2019squeezesegv2} \cite{milioto2019rangenet++} \cite{xu2020squeezesegv3} project point clouds into 2D images and apply 2D semantic segmentation models to predict semantic labels. 
In the following experiments, we choose PointNet++ \cite{qi2017pointnet++} to represent the earlier pioneering models and RandLA-Net \cite{hu2019randla} and Cylinder3D \cite{zhou2020cylinder3d} to represent the state-of-the-art point-based and voxel-based models, respectively.

%\subsection{3D semantic segmentation}
%
%The problem definition of 3DSS is to predict the pre-defined semantic categories of every points for a given input point cloud. Recently, a number of deep neural network models using for 3DSS have been proposed.
%% Fully Convolutional Network (FCN) \cite{long2015fully} and U-Net \cite{ronneberger2015u} architecture are the base network structure for segmentation. However, different from 2D image data structure, 3D point cloud is unordered and distributed in a continuous space. 
%PointNet\cite{qi2017pointnet} and PointNet++\cite{qi2017pointnet++} are the pioneering works for an end-to-end 3D point cloud processing, which provide a base network architecture for 3DSS. To improve the 3DSS performance, lots of deep models using different data format have been proposed to enhance the ability of feature representation. 
%Point-based methods takes raw point cloud as input and output point-wise labels. This type of methods such as \cite{engelmann2017exploring}\cite{jiang2018pointsift}\cite{engelmann2018know}\cite{chen2019lsanet} \cite{zhiheng2019pyramnet}\cite{thomas2019kpconv}\cite{wu2019pointconv}\cite{hu2019randla} introduce special computation modules for local feature aggregation of 3D point cloud. Voxel-based methods \cite{huang2016point}\cite{tchapmi2017segcloud}\cite{rethage2018fully}\cite{graham20183d}\cite{zhang2018efficient} \cite{zhou2020cylinder3d} partition 3D space to a number of voxels to convert point clouds into an structured data format, and apply an encoder-decoder architecture for feature extraction. Besides, image-based methods \cite{wu2018squeezeseg}\cite{zhang2018liseg}\cite{wang2018pointseg}\cite{dewan2019deeptemporalseg}
%\cite{wu2019squeezesegv2} \cite{milioto2019rangenet++} \cite{xu2020squeezesegv3} project point clouds into 2D images, and apply some 2D semantic segmentation models to predict semantic labels. We refer to \cite{yulan2019review}\cite{gao2021we} for a recent summary of these methods.
%However, although these 3DSS models have made a great progress on 3DSS task, few of these models pay much attention to the classes with insufficient samples and the OOD data, which are also important problem in practical application.

%\subsection{3D LiDAR dataset}

\subsection{Class imbalance problem}
Class imbalance reflects that some specific classes have far fewer samples in the training data than others, limiting models' performance for these small classes.
It is a common problem in training deep learning models for real-world applications and has been studied extensively in the literature \cite{johnson2019survey}\cite{zhang2021deep}. 
Many researchers have focused on analysing the imbalanced model performance caused by an imbalanced training data size \cite{hensman2015impact}\cite{buda2018systematic} \cite{ghosh2021combined}, and methods such as data resampling \cite{menardi2014training}\cite{pouyanfar2018dynamic} or loss reweighting \cite{lin2017focal}\cite{cui2019class} have been developed to alleviate the problem. These methods have also been used to address the class imbalance problem for 3DSS models \cite{chen2020compositional}.

As discussed in \cite{gao2021we}, the number and physical size of each object class vary in real-world scenarios. Therefore, in 3D LiDAR datasets, \textit{road}, \textit{building} and \textit{plants} make up a large proportion of the data, whereas \textit{people} and \textit{rider} are rare and thus difficult to model. Furthermore, in 3D LiDAR sensing, the point density of the objects closer to the sensor is much higher than that of the objects farther away, which aggravates the class imbalance problem in 3D LiDAR datasets.
Annotating the 3D LiDAR dataset is the result of a trade-off between labour cost and data size. Semantic categories cannot be defined in too much detail, thereby reducing the difficulty of manual annotation and ensuring that the amount of data in each category can meet the needs of model training.
For this reason, some objects have the same semantic labels but different morphological shapes, while some objects are similar in data but have different semantics definitions.
Therefore, in the current 3D LiDAR dataset, classes are imbalanced not only in terms of their data size but also in terms of their heterogeneous properties, a scenario that has not been studied in the literature.

%\subsection{Class imbalance}
%Class imbalance is a common problem in deep learning models for real-world application, reflected by some specific classes have much fewer examples than other classes in the training dataset, which limits model performance in these minor classes. Some studies \cite{hensman2015impact}\cite{buda2018systematic} \cite{ghosh2021combined} focus on analyzing how class imbalance influence the performance of deep learning models for image classification task. In addition, a number of researches try to alleviate the class imbalance problem by data re-sampling \cite{menardi2014training}\cite{pouyanfar2018dynamic} or loss re-weighting \cite{lin2017focal}\cite{cui2019class}. A comprehensive review of these methods is provided in \cite{johnson2019survey}\cite{zhang2021deep}. Several methods are proposed to deal with the class imbalance problem for 3DSS such as \cite{chen2020compositional}. 
%
%However, there is still lack of studies that give a systematic analysis of the influence on 3DSS models caused by class imbalance, most studies on class imbalance problem are based on image classification and segmentation task. On the other hand, most analysis of class imbalance problem focus on the imbalance caused by data size, but pay less attention to the nature of semantic category, such as the intra-class diversity and inter-class ambiguity.

\subsection{OOD and the open-world learning problem}
Learning models for autonomous driving and robotics applications need to address the open-world problem \cite{sehwag2019analyzing}, which requires the models to deal with both the seen (ID) and unseen (OOD) objects in the training datasets.
OOD detectors \cite{salehi2021unified} have been developed as an auxiliary module combined with the main task model for this purpose.
Several mainstream methods for OOD detection have been developed.
The methods are broadly divided into two groups based on whether they need an additional dataset that contains OOD examples.
Outlier Exposure methods \cite{hendrycks2018deep}\cite{papadopoulos2021outlier} use an auxiliary dataset to represent OOD data when training models to teach the model better representations for OOD detection. 
However, for many applications, it is not possible to predefine OOD data, making these approaches unsuitable.
Reconstruction methods \cite{xia2015learning}\cite{ruff2018deep} learn to map the training data to the hypersphere of the feature space and maps the OOD data outside the hypersphere. 
However, the unseen OODs could be very diverse, and guaranteeing them outside the hypersphere remains an open issue.
Trust scoring methods are the most popular methods and are studied in this research.
They utilize a trust score metric to assess the reliability of the main task model's results and classifies the ID/OOD by thresholding the scores.
Many trust score metrics have been developed in the literature \cite{hendrycks2016baseline} \cite{liang2017enhancing} \cite{lee2018simple} \cite{malinin2019uncertainty} \cite{lakshminarayanan2016simple}, which will be detailed in the next subsection. 
However, in this type of approach, OOD detection is not an independent task, and the performance is strongly related to the capabilities of the main task model.
Can OOD be detected by trust scoring the results of a 3DSS model that is trained on class imbalanced data? Research is needed.

%\subsection{OOD Detection}
%Deep neural networks often face input test data whose distribution is far from the training data in real-world applications, i.e., out-of-distribution (OOD) data. OOD detection is to detect whether an input sample is OOD, which is essential for deploying deep learning models in safety applications. In most research, OOD data is considered to be the samples which semantically different from the training data categories. 
%
%The most commonly used methods for OOD detection is trust scoring approaches, which use a designed trust scores to measure the difference between input test data and training data distribution, such as Softmax confidence \cite{hendrycks2016baseline}, ODIN \cite{liang2017enhancing}, Mahalanobis Distance (MD) \cite{lee2018simple}, uncertainty \cite{malinin2019uncertainty} based on Monte Carlo Dropout \cite{gal2016dropout} or Deep Ensemble \cite{lakshminarayanan2016simple}. In addition, Outlier Exposure methods \cite{hendrycks2018deep}\cite{papadopoulos2021outlier} use an auxiliary dataset to represent OOD data when training models, to teach the model better representations for OOD detection. Reconstruction methods \cite{xia2015learning}\cite{ruff2018deep} learn to map the training data into a hypersphere of the feature space and map OOD data outside the hypersphere. A comprehensive review of OOD detection methods is provided in \cite{salehi2021unified}. However, although there are studies of OOD detection for image classification \cite{hendrycks2016baseline}\cite{hendrycks2018deep}\cite{ruff2018deep} and semantic segmentation \cite{oberdiek2020detection}\cite{xia2020synthesize}\cite{chan2021entropy}, studies of OOD detection for 3DSS task are much fewer.

\subsection{Trust scores}
Knowing when a deep model's result is trustful and when the model is uncertain is of great importance in many safety-critical applications.
To this end, many trust score metrics have been developed, such as Softmax confidence \cite{hendrycks2016baseline}, ODIN \cite{liang2017enhancing}, Mahalanobis distance (MD) \cite{lee2018simple}, uncertainty \cite{malinin2019uncertainty} based on Monte Carlo dropout \cite{gal2016dropout} and deep ensemble \cite{lakshminarayanan2016simple}.
By thresholding these trust scores, OOD data \cite{hendrycks2016baseline} \cite{liang2017enhancing} \cite{lee2018simple} or model failures \cite{jiang2018trust}\cite{guo2017calibration} are detected.

In the literature, there are no universally recognized names for trust scores or for the thresholding methods on the trust scores.
We borrow the word {\it trust score} from \cite{jiang2018trust}, and we name {\it trust scoring} for the group of threshold methods on trust scores.
In the second experiment of the paper, we sequentially concatenate trust scoring with 3DSS to analyse the performance of the above trust scores on three tasks, namely, detecting ID/OOD, correct/wrong without OOD and correct/wrong with OOD. The focus is to understand the challenges when facing class imbalanced and OOD data, and we present our findings in the following sections.

%\subsection{Trust scores}
%Trust score is a value representing the confidence or reliability measurement of the deep network prediction, such as the commonly used Softmax confidence. It is often used to do failure detection or OOD detection. Failure detection is to detect whether the predicted category output by deep models is correct or wrong, which is also critical for safety applications as OOD detection. Some methods \cite{jiang2018trust}\cite{guo2017calibration} are proposed to improve the performance of failure detection. 
%
%Some challenges are exist for trust scoring approaches to detect wrongly category prediction or OOD input data. For example, deep models sometimes give a high confidence when wrongly classifying an unknown input data into a specific known class \cite{nguyen2015deep}, which may cause potential safety hazard in real-world application. In this work we pay attention to different trust scores using for failure and OOD detection and evaluate the performance of these scores in 3DSS task. 

\section{Methodology} \label{sec:3}
In this section, we introduce the flow of 3D semantic segmentation, datasets and the methods used for our experiments.
% and how we design experiments to seek the answer of three questions mentioned in the beginning.

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.58]{fig-3-1.pdf}
	\vspace{-3mm}
	\caption{Flow of 3DSS with OOD data. (3DSS: 3D Semantic Segmentation)}
	\label{fig:flow}
	\vspace{-4mm}
\end{figure}

%\begin{figure}[t]
%	\centering
%	\includegraphics[scale=0.26]{fig-3-model.pdf}
%	\caption{Network architecture of (a) PointNet++ (b) RandLA-Net (c) Cylinder3D.}
%	\label{fig:model}
%	\vspace{-4mm}
%\end{figure}

\begin{figure*}[t]
	\centering
	\includegraphics[scale=0.39]{fig-data-aug.pdf}
	\vspace{-2mm}
	\caption{The process to generate test frames by combining scenes from SemanticKITTI and \textit{people}, \textit{rider} instances from SemanticPOSS.}
	\label{fig:data aug}
	\vspace{-4mm}
\end{figure*}

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.32]{fig-data-aug2.pdf}
	\vspace{-6mm}
	\caption{Schematic diagram of the process to interpolate points on target LiDAR frames.}
	\label{fig:data aug2}
	\vspace{-4mm}
\end{figure}

A typical 3DSS model takes 3D point clouds $x$ as input, passes them to an end-to-end 3DSS model $f$, and outputs pointwise semantic labels $y$, as shown in Fig. \ref{fig:flow}. The 3DSS model requires a trust score $g$ to judge whether the category prediction is correct or to judge whether the input sample is ID or OOD. The trust score function $g$ takes the output probability vector or the feature vector given by model $f$ as input and outputs the judgment $z$. In our experiments, we focus on exploring the different performances using different 3DSS models $f$ and trust scores $g$.

\subsection{3D semantic segmentation models}
We use three baseline models in our experiment, PointNet++ \cite{qi2017pointnet++}, RandLA-Net \cite{hu2019randla} and Cylinder3D \cite{zhou2020cylinder3d}.% The network architectures of the three models are shown in Fig. \ref{fig:model}.

PointNet++ is a pioneering model in the field of deep neural networks used for 3D point cloud processing. It takes raw point clouds as input, uses PointNet \cite{qi2017pointnet} as a local feature extractor, and introduces multiscale grouping approaches to learn features from multiple scales. We take PointNet++ as a representative traditional 3DSS model in our experiment. 

RandLA-Net and Cylinder3D are recently proposed state-of-the-art methods for 3DSS tasks using different formats of input data. RandLA-Net is a point-based 3DSS model and uses random point sampling instead of a more complex point selection approach to reduce the computation and memory cost. In addition, a novel local feature aggregation module is proposed to increase the receptive field for each 3D point, which preserves the geometric details of the point cloud.

Cylinder3D is a voxel-based 3DSS model that uses a cylindrical partition instead of a common rectangular partition when performing voxelization and extracts voxel features by a simplified PointNet. A 3D U-Net architecture is used to process the 3D representation. In addition, the asymmetrical residual block is designed to meet the requirements of cuboid objects and to reduce the computational cost of 3D convolutions. According to the 3DSS performances in the SemanticKITTI \cite{behley2019semantickitti} benchmark, both RandLA-Net and Cylinder3D achieve high mIoU scores. We take RandLA-Net and Cylinder3D as representative state-of-the-art 3DSS models in our experiment. 

%We will use the three models to explore the similarities and differences of 3DSS performances, failure and OOD detection ability when training on class-imbalanced datasets.

\subsection{Trust scores}
The trust scoring approach uses a specific score $g(x)$ to judge whether input $x$ is an OOD sample or the category prediction is wrong. If given a threshold value $\delta$, the output of the trust scoring process $z$ is given by:

\begin{equation}
z = 
\left\{
\begin{array}{lr}
0, {\rm if \quad} g(x)\leq \delta &  \\
1, {\rm if \quad} g(x)>\delta &  
\end{array} \label{eq:gx}
\right. 
\end{equation}

We use several widely used scores for failure detection and OOD detection in our experiment, Softmax confidence \cite{hendrycks2016baseline}, uncertainty \cite{malinin2019uncertainty}, ODIN \cite{liang2017enhancing} and MD \cite{lee2018simple}. 

The Softmax confidence $conf(x)$ is the output of the Softmax layer and is the most common score used to detect failure and OOD, and is given by:

\begin{equation}
conf(x) = \max_c p_c(x) = \max_c \frac{\exp (f_c(x))}{\sum_{i=1}^{C} \exp (f_i(x))}
\end{equation}

where $p_c(x)$ is the prediction probability of class $c$, $f_c(x)$ is the last layer output of the network of class $c$ and $C$ is the number of classes. 

Uncertainty is a score to evaluate how certain the model predictions are, which can also be used for failure and OOD detection. In addition, uncertainty can be divided into data uncertainty $du(x)$ and model uncertainty $mu(x)$ to distinguish between the uncertainty caused by data ambiguity and model disagreement. Data uncertainty can be quantized by prediction entropy, and model uncertainty can be quantized by mutual information \cite{malinin2019uncertainty}, which are given by:

\begin{equation}
\begin{array}{lr}
du(x) = \mathbb{E}_M[H(\bm{p}(x))] = -\mathbb{E}_M[\sum_{c=1}^{C} p_i(x) \log p_c(x)] & \\
mu(x) = H(\mathbb{E}_M[\bm{p}(x)]) - \mathbb{E}_M[H(\bm{p}(x))] &
\end{array}
\end{equation}

where $H$ is the prediction entropy and $\mathbb{E}_M$ is the expectation for all the models distributed in the model space, which can be estimated by Monte Carlo dropout \cite{gal2016dropout} or deep ensemble \cite{lakshminarayanan2016simple}. 

ODIN \cite{liang2017enhancing} applies temperature scaling to the Softmax confidence using a temperature scaling parameter $T$:

\begin{equation}
temp(x) = \max_c \frac{\exp (f_c(x)/T)}{\sum_{i=1}^{C} \exp (f_i(x)/T)}
\end{equation}

Mahalanobis distance \cite{lee2018simple} is a distance measure in feature space:

\begin{equation}
md(x) = \min_c (\bm{f}(x) - \bm{\mu}_c)^{T} \bm{\Sigma}^{-1} (\bm{f}(x) - \bm{\mu}_c)
\end{equation}

where $\bm{\mu}_c$ is the mean vector of class $c$ and $\bm{\Sigma}$ is the covariance matrix of the training samples in feature space.

In our experiment, we try to explore the failure and OOD detection performance of these scores for the 3DSS models trained on the class-imbalanced datasets.

%\begin{table*}[b]
%	\centering
%	\renewcommand{\arraystretch}{1.2}
%	\caption{Setup of experiments.}
%	\begin{tabular}{m{9em}|m{24em}|m{24em}}
%		\hline \rule{0pt}{20pt} 
%		& \makebox[15em][s]{\shortstack[l]{Experiment 1\\ model performance evaluation.}}
%		& \makebox[15em][s]{\shortstack[l]{Experiment 2\\ OOD detection using different scores and models.}}
%		\\ \hline
%		Purpose & Train models on a class-imbalanced dataset, and compare models’ performances on different classes. & Train models on a class-imbalanced dataset, compare the OOD detection performance of different thresholding scores and models. \\ \hline
%		Question to explore & \textit{Q1}: What are the performance of 3D semantic segmentation models trained on class-imbalanced datasets? & \textit{Q2}: Can OOD data be detected if 3D semantic segmentation models are trained on class-imbalanced datasets? \hspace{60pt} \textit{Q3}: What is the relationship between model performance and OOD detection ability? \\ \hline
%		Train set & UnpeopledKITTI & UnpeopledKITTI \\ \hline
%		Test set & UnpeopledKITTI & AugmentedKITTI \\ \hline
%		Model & PointNet++, Cylinder3D & PointNet++, Cylinder3D \\ \hline
%		OOD detection score & / & Softmax confidence, data uncertainty, model uncertainty, ODIN, MD  \\ \hline
%		%Result & Table \ref{tab:5}, Fig. \ref{fig:11}, Fig. \ref{fig:12}(a) & Table \ref{tab:6}, Fig. \ref{fig:13}, Fig. \ref{fig:12}(b) & Table \ref{tab:7}, Fig. \ref{fig:14}(a) \\ \hline
%		%Result & Table \ref{tab:5}, Fig. \ref{fig:12}(a) & Table \ref{tab:6}, Fig. \ref{fig:12}(b) & Table \ref{tab:7}, Fig. \ref{fig:14}(a) \\ \hline
%	\end{tabular}
%	\label{tab:exp}
%	\vspace{-3mm}
%\end{table*}

%\subsection{Evaluation metric}
%
%For model performance, we use Intersection over Union (IoU) as evaluation metric. Assume that $FN_{c}$,$FP_{c}$,$TN_{c}$,$TP_{c}$ denote the number of false negative, false positive, true negative, and true positive predictions of class $c$, the IoU of class $c$ is given by
%
%\begin{equation}
%IoU_{c} = \frac{TP_{c}}{TP_{c}+FP_{c}+FN_{c}}.
%\end{equation}
%
%And for OOD detection, we use Area Under the Receiver Operating Characteristic curve (AUROC) to evaluate the performance of OOD detectors as most research used. The $x$-axis of ROC curve is False Positive Rate (FPR) and the $y$-axis is True Positive Rate (TPR), which is given by
%
%\begin{equation}
%TPR_{c} = \frac{TP_{c}}{TP_{c}+FN_{c}}, \quad FPR_{c} = \frac{FP_{c}}{FP_{c}+TN_{c}},
%\end{equation}
%
%where $TP_{c}$ means the number of OOD points whose confidence are lower than a given threshold value $\delta$. With the increase of $\delta$, $TPR_{c}$ and $FPR_{c}$ will both increase and form the ROC curve. AUROC is the area under ROC curve, indicating the performance of OOD detectors. The advantage of AUROC is that it can prevent paying more attention to dominant classes when data is imbalance, which is suitable for our experiments.

\subsection{Dataset Augmentation}
Due to the difficulty in manual point-level labelling of 3D LiDAR point clouds, there is a lack of large-scale 3D LiDAR datasets used for 3DSS tasks \cite{gao2021we}. 
Driving scene point clouds collected by vehicle-mounted LiDAR such as nuScenes \cite{caesar2019nuscenes}, SemanticKITTI \cite{behley2019semantickitti}, and SemanticPOSS \cite{pan2020semanticposs} are commonly used for understanding driving scenes. However, the above widely used public 3D datasets have a large difference in the data size of the different classes. Fig. \ref{fig:data num} shows the data size of the popular and largest dataset, SemanticKITTI, which  reflects the class imbalance problem.

We use SemanticKITTI in Experiment 1 to study how the class imbalance dataset affects the 3DSS performance. However, there is no publicly available dataset for a study of OOD in a 3DSS task.
To find a dataset for Experiment 2 on whether the model is aware of its unsureness when facing class imbalanced and OOD data, a dataset augmentation method is developed. SemanticKITTI contains few samples of \textit{people} and \textit{rider}, whereas SemanticPOSS describes scenes populated with these dynamic objects. Considering \textit{people} and \textit{rider} as OOD, the frames of SemanticKITTI that have no \textit{people} and \textit{rider} are extracted to compose a dataset \textbf{SubKITTI} for training, while the remaining frames of SemanticKITTI are augmented by the instances of \textit{people} and \textit{rider} of SemanticPOSS to generate a new dataset \textbf{AugKITTI} for testing.

Fig. \ref{fig:data aug} illustrates the flow of the dataset augmentation. SemanticPOSS is used as an auxiliary dataset that provides instances, while SemanticKITTI is a source dataset that provides LiDAR frames. An instance dataset is first generated by assembling all the instances of SemanticPOSS. Here, an instance is a 3D point cloud at the LiDAR sensor's coordinate system (i.e. LiDAR frame). Given a LiDAR frame $k$ of SemanticKITTI, an instance $s$ is sampled, and the 3D point cloud is projected to the LiDAR frame on their own coordinates. Augmentation can only be conducted if the projected space is on the road and not occupied by other objects. Fig. \ref{fig:data aug} illustrates the procedure of augmenting instance $s$ with LiDAR frame $k$. For each instance, a billboard mask is generated describing a region of the projected 3D point cloud on a 2D plane, which is orthogonal to the LiDAR beam of the 3D point cloud's center point. The billboard mask of an instance can be generated once. Given LiDAR frame $k$ and instance $s$, for any point $p_i$ of the LiDAR frame, if it is occluded by the billboard mask of $s$, a new point $p_i'$ is interpolated on the 3D point cloud of the instance and replaces the original $p_i$.

Although the data augmentation method is motivated by the OOD study in this research, it is a general method for generating augmented 3D point clouds, which can also be used to reduce the dataset bias between different 3D datasets. In addition, the proposed method can be applied to datasets with different sensor characteristics, e.g., transferring instances collected by a 32-line LiDAR to a 64-line LiDAR dataset. In this way, we create an augmented dataset with a certain number of \textit{people}; \textit{rider} samples and other classes have the same distribution as the training set. The data size of each class of AugKITTI is shown in Table \ref{tab:dataset2}.

%Because the existing point clouds datasets are not used for OOD detection, we create two special datasets \textbf{SemanticKITTI-PR} and \textbf{AugmentedKITTI} for network training and testing based on SemanticKITTI \cite{behley2019semantickitti} and SemanticPOSS \cite{pan2020semanticposs}. Semantic label \textit{people} and \textit{rider} will be considered to be unknown OOD classes in our experiments. The dataset called SemanticKITTI-PR is consist of about 10000 frames without \textit{people} and \textit{rider} from SemanticKITTI. 

%However, SemanticKITTI is lack of scenes with a lot of \textit{people} while the scenes of SemanticPOSS is much different from SemanticKITTI, which means it is not reasonable to take only SemanticKITTI or SemanticPOSS as test set. In order to better evaluate the OOD detection performance, we generate a test set called AugmentedKITTI by combining scenes from SemanticKITTI and \textit{people}, \textit{rider} instances from SemanticPOSS. Because the LiDAR sensors used for the two datasets are different, we create the test set by the following steps to form augmented frames which conform to the physical laws:

%\begin{enumerate}
%	\item Create an instance set by aggregating the \textit{people} and \textit{rider} instances from SemanticPOSS.
%	
%	\item For a given SemanticKITTI frame, randomly choose an instance from the set and judge whether the instance can be put into the frame.
%	
%	\item If the chosen instance is on road and empty space in the SemanticKITTI frame, generate a mask according to the contour of the instance. 
%	
%	\item Interpolate LiDAR points to the mask, and delete original LiDAR points which are occluded by the mask.
%	
%\end{enumerate}

%The process of augmented frames generating is shown in Fig. \ref{fig:data aug}. 

%In total 11 classes are used for experiments, and the data size of each class is shown in Table \ref{tab:dataset2}, which indicates the class imbalance of datasets. 

%For a qualitative analysis, we divided the 11 classes into big, middle, small and OOD classes according to the order of magnitudes of each class data size on training set: classes with more than 10M are big classes, between 1M and 10M are middle classes, less than 1M are small classes and \textit{people}, \textit{rider} are OOD classes.

%In total 11 classes are used for experiments: \textit{road}, \textit{plants}, \textit{building}, \textit{fence}, \textit{car}, \textit{trunk}, \textit{pole}, \textit{sign}, \textit{bike}, \textit{people}, and \textit{rider}. 

%\subsection{Experimental setup}
%To systematic analyze the relationship of class imbalance, model performance, and OOD detection, three experiments shown in Table \ref{tab:exp}, are designed. We seek the answer of \textit{Q1} by Experiment 1 and \textit{Q2},\textit{Q3} by Experiment 2. And for \textit{Q4} we give a feature space analysis to find the underlying reasons of the phenomena in the two experiments.
%
%In these experiments, single frame of SemanticKITTI is used as input, not overlapped frames. 11 classes are used for testing: \textit{road}, \textit{plants}, \textit{building}, \textit{fence}, \textit{car}, \textit{trunk}, \textit{pole}, \textit{sign}, \textit{bike}, \textit{people}, and \textit{rider}. All models are trained for 32 epochs using Adam optimizer with learning rate 0.001. Besides, we use class weights calculated by \cite{cui2019class} with $\beta$ = 0.9 when training models to alleviate the effect of class imbalance in a degree. And temperature scaling parameter $T$ is 1000 for ODIN \cite{liang2017enhancing}.

\begin{table*}[b]
	\centering
	\renewcommand{\arraystretch}{1.3}
	\caption{Data size of each class on SemanticKITTI for training and testing in our experiments, and training weights of each class.}
	\begin{tabular}{c|ccccc|cc|cc|cc}
		\hline
		scale & \multicolumn{5}{c|}{Large}    & \multicolumn{2}{c|}{Middle}    & \multicolumn{4}{c}{Small}    \\ \hline
		class & road(ro)    & plants(pl)    & building(bu)    & fence(fe)   & car(ca)    & trunk(tr)  & pole(po) & sign(si) &  bike(bi) & people(pe) & rider(ri)\\ \hline	
		SemanticKITTI (train) & 730.27M & 522.39M & 268.33M & 143.17M & 98.19M & 12.43M & 5.78M & 1.19M & 1.12M & 0.569M & 0.386M  \\
		SemanticKITTI (test) & 154.65M & 145.94M & 56.88M & 12.64M & 33.59M & 5.51M & 1.67M & 0.381M & 0.594M & 0.477M & 0.329M  \\ \hline
		Training weights & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.36 & 2.19 & 8.48 & 8.98 & 17.19 & 25.09 \\
		\hline
	\end{tabular}	
	\label{tab:dataset}
	\vspace{-3mm}
\end{table*}

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.64]{fig-4-exp.pdf}
	\vspace{-4mm}
	\caption{Setup of Experiment 1: Evaluate the performances of 3DSS models trained on a class-imbalanced dataset.}
	\label{fig:exp1}
	\vspace{-4mm}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.26]{fig-4-class.pdf}
	\vspace{-3mm}
	\caption{Class definition for our experiments.}
	\label{fig:4-class}
	\vspace{-4mm}
\end{figure}

\section{Performance of 3DSS Facing Class Imbalanced Data} \label{sec:4}

%\begin{figure*}[b]
%	\centering
%	\includegraphics[scale=0.5]{fig-misclassification.pdf}
%	\caption{Misclassification statistic of PointNet++ and Cylinder3D. The horizontal axis is classes sorted by data size, the vertical axis is error rate, and different color blocks show how much samples are misclassified to the corresponding class.}
%	\label{fig:misclassification}
%	\vspace{-4mm}
%\end{figure*}

\subsection{Experimental setup}
In this section, we evaluate the performances of 3D semantic segmentation models trained on a class-imbalanced dataset, as shown in Fig. \ref{fig:exp1}. 
We train and test models on the SemanticKITTI dataset, and some morphologically similar classes are merged in the experiment, as shown in Fig. \ref{fig:4-class}. There are a total of 11 classes for model training, and we simply use the first two letters of class names to denote these classes. The data size of each class is shown in Table \ref{tab:dataset}. For a qualitative analysis, we divided the 11 classes into \textit{large}, \textit{middle}, and \textit{small} classes according to the order of magnitude of each class data size on the training set. %: classes with more than 10M are big classes, between 1M and 10M are middle classes, less than 1M are small classes.

Three 3D semantic segmentation models PointNet++, RandLA-Net and Cylinder3D are used in the experiment, and all the models are trained for 32 epochs using a weighted cross-entropy loss given by:

\vspace{-3mm}
\begin{equation}
L = -\frac{1}{N} \sum_{c=0}^K \sum_{y_{i}=c} w_c{\bm h}_i^T \log{ {\bm p}_i} \label{eq:loss}
\end{equation}

where $N$ is the total number of samples used for the loss calculation, $K$ is the number of classes, $w_c$ is the weight of class $c$, $y_{i}$ is the ground truth of sample $i$, ${\bm h}_i$ is the ground truth one-hot vector of sample $i$, and ${\bm p}_i$ is the output probability of sample $i$. We use class weights calculated by \cite{cui2019class}, which are given by:

\vspace{-3mm}
\begin{equation}
w_c = \frac{1-\beta}{1-\beta^{N_c}}  \label{eq:w}
\end{equation}

where $N_c$ is the data size of class $c$ and $\beta$ = 0.9 when training models. The weights of classes are shown in the last line of Table \ref{tab:dataset}. The Adam optimizer with a learning rate of 0.001 is used for network optimization.

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.5]{fig-data-num.pdf}
	\vspace{-6mm}
	\caption{(a) Training data size and model performances on SemanticKITTI dataset. (b) Scatter plot of Iou of PointNet++ and Cylinder3D, which divides the classes into three groups.}% The result shows that model performances have a positive relationship with data size.}
	\label{fig:data num}
	\vspace{-4mm}
\end{figure}

\begin{figure*}[t]
	\centering
	\includegraphics[scale=0.36]{fig-loss-curve.pdf}
	\vspace{-4mm}
	\caption{Training loss curve of each class using (a) PointNet++, (b) RandLA-Net, (c) Cylinder3D. And test loss curve of each class using (d) PointNet++, (e) RandLA-Net, (f) Cylinder3D.}
	\label{fig:loss curve}
	\vspace{-4mm}
\end{figure*}

%We use ${\rm IoU}$ as model performance metric and analyze the relationship between IoU and data size of each class. Next, we analyze the training and test loss curve of each class to explore the learning differences on different classes. And we use confusion matrix to analyze the confusion among classes. A new metric called weighted precision (${\rm wPre}$) is proposed to measure the prediction performance which can avoid the prediction bias due to class imbalance. Finally, T-SNE method is used for a feature space analysis.

%In this section we try to evaluate the performances of 3D semantic segmentation models trained on class-imbalanced dataset, as shown in Fig. \ref{fig:exp1}. We train and test models on the SemanticKITTI dataset, and compare models’ performances on different classes. Three 3D semantic segmentation models PointNet++, RandLA-Net and Cylinder3D are used in the experiment, and all models are trained for 32 epochs using Adam optimizer with learning rate 0.001. Besides, we use class weights calculated by \cite{cui2019class} with $\beta$ = 0.9 when training models, which are shown in the last line of Table \ref{tab:dataset}.

\subsection{Experimental results}

%\begin{figure*}[b]
%	\centering
%	\includegraphics[scale=0.5]{fig-4-2.pdf}
%	\caption{Comparison of AUROC using Softmax confidence and ODIN. The 3DSS models are Cylinder3D (a) and PointNet++ (b). The arrow is from AUROC of Softmax confidence to ODIN. }
%	\label{fig:4-2}
%	\vspace{-4mm}
%\end{figure*}

Here, the traditional evaluation metrics of \textbf{intersection over union} (\textbf{IoU}), \textbf{precision} (\textbf{Pre}) and \textbf{recall} (\textbf{Rec}) are used to analyse and evaluate the model performance of each semantic category.
Hereinafter, we denote $|y_{_{GT}}=c|$ as the number of points whose ground truth (GT) labels are equal to class $c$ and $|y_{_{PD}}=c|$ as the number of points predicted (PD) to class $c$.
The IoU, Pre and Rec of class $c$ are estimated as follows:

\vspace{-1mm}
\begin{equation}
{\rm IoU}(c) = \frac{|y_{_{GT}}=c \land y_{_{PD}}=c|}{|y_{_{GT}}=c|+|y_{_{PD}}=c|-|y_{_{GT}}=c \land y_{_{PD}}=c|}
\end{equation}
\vspace{-5mm}
\begin{eqnarray}
{\rm Pre}(c) &=& \frac{|y_{_{GT}}=c \land y_{_{PD}}=c|}{|y_{_{PD}}=c|}\\
{\rm Rec}(c) &=& \frac{|y_{_{GT}}=c \land y_{_{PD}}=c|}{|y_{_{GT}}=c|}
\end{eqnarray}

The model performance of each class and the number of data points in training are shown in Fig. \ref{fig:data num}(a). State-of-the-art methods such as Cylinder3d and RandLA-Net significantly improve the overall performance of the model compared to the earlier method PointNet++.
From Fig. \ref{fig:data num}(b), it can be found that the classes can be divided into three groups.
The classes in the first group demonstrate excellent performance in all the models, which are marked as {\it simple} classes, and interestingly, they are all the large-scale classes.
The classes in the second group achieve great performance improvements in the state-of-the-art models, which are marked as {\it simple-with-effort} classes. In this group, \textit{people} and \textit{rider} are small-scale classes, while \textit{car} is a large-scale class. Interestingly, these classes are objects that have regular sizes and shapes. This may be the reason why they outperform other classes with more data samples.
The classes in the third group are hard ones, which demonstrate unsatisfactory performances in all models, and are marked as {\it hard} classes. This group contains the large-scale class \textit{fence}, the middle-scale classes \textit{pole} and \textit{trunk}, and the small-scale classes \textit{bike} and \textit{sign}. The models of these classes are hard to be learnt no matter on a small or large set of training data, and fewer performance improvements are found in the models.

%For model performances, we use Intersection over Union (IoU) as evaluation metric. For a unified expression, we denote $|y_{_{GT}}=c|$ as the number of points belonging to class $c$, and $|y_{_{PD}}=c|$ as the number of points classified as class $c$. Assume that $FN(c)$,$FP(c)$,$TN(c)$,$TP(c)$ denote the number of false negative, false positive, true negative, and true positive predictions of class $c$, the IoU of class $c$ is given by
%
%\vspace{-4mm}
%\begin{equation}
%\hspace{-5mm}
%\begin{aligned}
%IoU(c) &= \frac{TP(c)}{TP(c)+FP(c)+FN(c)} \\
%&= \frac{|y_{_{GT}}=c \land y_{_{PD}}=c|}{|y_{_{GT}}=c|+|y_{_{PD}}=c|-|y_{_{GT}}=c \land y_{_{PD}}=c|}.
%\end{aligned}
%\end{equation}
%
%Training data size and model performances on SemanticKITTI dataset are shown in Fig. \ref{fig:data num}. The results show the influence of class imbalance on model performance. In Fig. \ref{fig:data num} the data size of training set is obviously imbalance, while IoU of some small classes evidently drop with the decrease of data size, reflecting that models cannot learn these classes sufficiently. In addition, performances of PointNet++ almost have a total positive relationship with data size, and PointNet++ can hardly classify small class such as \textit{people}, \textit{rider} and \textit{bike} correctly, which shows that PointNet++ is more sensitive to the influence of class imbalance.

%and using different class weights when training cannot totally eliminate the impact of class imbalance.

We also find the influence of class imbalance reflected by the loss curve. We visualize the cross-entropy loss curve of class $c$ given by:

\vspace{-1mm}
\begin{equation}
L(c) = -\frac{1}{N_c}\sum_{y_{i}=c} {\bm h}_i^T \log{ {\bm p}_i}
\end{equation}

where $N_c$ is the data size of class $c$, $y_{i}$ is the ground truth of sample $i$, ${\bm h}_i$ is the ground truth one-hot vector of sample $i$ and ${\bm p}_i$ is the output probability of sample $i$.
As shown in Fig. \ref{fig:loss curve}, we discriminate between semantic classes by the colour and different data scales of the classes by line type. We find that the training loss curve of the simple classes converges faster and lower than the hard classes. In the test loss curves, we observe that simple classes retain a low and smooth loss value, whereas the curves of simple-with-effort and hard classes are relatively high and zigzag. Compared with the test loss of PointNet++, the loss of simple-with-effort classes \textit{people}, \textit{rider}, \textit{car} are evidently reduced when using RandLA-Net or Cylinder3D, whereas the loss of hard classes are not significantly reduced, indicating the learning difficulty of these classes.

Based on the above results and observations, we can conclude that apart from the size of the training data, the nature of each semantic class could be another key factor that greatly affects the model performance; that is, the classes are not only imbalanced on their data size but also on the basic properties of each semantic class.

\begin{figure*}[t]
	\centering
	\includegraphics[scale=0.33]{fig-confusion-mat.pdf}
	\vspace{-4mm}
	\caption{Confusion matrix of (a) PointNet++, (b) RandLA-Net, (c) Cylinder3D. The labels	of each row represent the ground truth, and the labels of each column represent the prediction results. Recall (Rec) is the diagonal and weighted precision (wPre) is the diagonal dividing the sum of each column. (GT: ground truth, PD: predictions, build.: building.)}
	\label{fig:confusion mat}
	\vspace{-4mm}
\end{figure*}

\begin{figure*}[t]
	\centering
	\includegraphics[scale=0.46]{fig-iou-with-npre-pre.pdf}
	\vspace{-6mm}
	\caption{(a) Wrong prediction to others classes using Cylinder3D. (b) Wrong prediction from other classes using Cylinder3D. (c) wPre vs. IoU scatter plot using Cylinder3D training and testing on SemanticKITTI. (d) Pre vs. IoU scatter plot using Cylinder3D training and testing on SemanticKITTI. (GT: ground truth, PD: predictions.)}
	\label{fig:4-f}
	\vspace{-2mm}
\end{figure*}

\begin{figure*}[t]
	\centering
	\includegraphics[scale=0.5]{fig-feature-exp1.pdf}
	\vspace{-3mm}
	\caption{T-SNE plot of 200 random sampled points from SemanticKITTI test frames using Cylinder3D. Some classes show intraclass diversity such as \textit{plants}. And some classes are confused due to the interclass ambiguity, such as \textit{trunk} and \textit{pole}, \textit{people} and \textit{rider}.}
	\label{fig:feature-exp1}
	\vspace{-4mm}
\end{figure*}


%In training loss curves of PointNet++, loss of \textit{people}, \textit{rider} and \textit{bike} cannot converge causing it nearly learn nothing about these classes, reflecting that models with lower classification ability will suffer class imbalance problem more severely. For RandLA-Net and Cylinder3D, they learn all classes validly as the training loss curves converge successfully. However, when using the two models in validation set, validation loss of \textit{bike}, \textit{sign} are much higher than big classes, indicating that small classes are more easily to be overfitted.

\subsection{Confusion analysis}

Fig. \ref{fig:confusion mat} shows the confusion matrixes of the three models. Each value $p(r,c)$ on row $r$ and column $c$ of the confusion matrix is estimated by:

\vspace{-1mm}
\begin{equation}
p(r,c) = \frac{|y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|}
\end{equation}

which indicates the ratio of points whose ground truth labels are $r$ but classified to $c$. Therefore, the diagonal values $p(c,c)$ equal the recall for class $c$, i.e., ${\rm Rec}(c) = p(c,c)$.
In addition to the diagonal values, the values in each row $r$ compose a vector of \textbf{wrong prediction ratios} (\textbf{WPR}) that describes how data points of the ground truth class $r$ are misclassified to other classes $c \ne r$. Similarly, the values in each column $c$ compose a vector of \textbf{be confused ratio} (\textbf{BCR}) that describes how data points of other ground truth class $r \ne c$ are misclassified to the predictive class $c$.

With the confusion matrix of Cylinder3D in Fig. \ref{fig:confusion mat}(c), the WPR and BCR vectors are generated and shown in Fig. \ref{fig:4-f}(a-b).
The class \textit{plants} demonstrates excellent performance on IoU, Pre and Rec
in all models in Fig. \ref{fig:data num}, and its data points have a very small part misclassified to other classes, as shown in Fig. \ref{fig:4-f}(a).
However, interestingly, the data points of the other classes have a large ratio predicted to \textit{plants} by mistake, meaning that \textit{plants} is a class that is easily confused.
This tendency for imprecision has been omitted in the literature.
To this end, this research proposes a new metric called \textbf{weighted precision} (\textbf{wPre}) by reshaping the precision metric as follows.

Let $\mathbf{\sim {\rm Pre}}=1-{\rm Pre}$ be the negation of precision; we have

\begin{equation}
\mathbf{\sim {\rm Pre}}(c) = \frac{\sum_{r \ne c}|y_{_{GT}}=r \land y_{_{PD}}=c|}{\sum_{r}|y_{_{GT}}=r \land y_{_{PD}}=c|}
\end{equation}

For a small-scale class $r$, even the wrong predictions occupy large proportions in its ground truth set, and the absolute point number is small compared to larger classes; hence, it has little impact in the evaluation. To balance the impacts from the classes of different scales, a new metric is developed by a weighting on the data size of the ground truth class.

\begin{eqnarray}
\mathbf{\sim {\rm wPre}}(c) &=& \frac{\sum_{r \ne c}|y_{_{GT}}=r \land y_{_{PD}}=c|/|y_{_{GT}}=r|}{\sum_{r}|y_{_{GT}}=r \land y_{_{PD}}=c|/|y_{_{GT}}=r|} \nonumber \\
&=& \frac{\sum_{r \ne c} p(r,c)}{\sum_{r} p(r,c)} = \sum_{r \ne c}\frac{1}{\eta_c}p(r,c)
\end{eqnarray}

where $\eta_c = \sum_{r} p(r,c)$ is a factor to normalize each column vector of the confusion matrix to 1, and $\mathbf{\sim {\rm wPre}}(c)$ is the sum of the normalized non-diagonal values in column $c$, which describes how easily class $c$ can be confused. Similarly, we have

\begin{equation}
{\rm wPre}(c) = 1-[\mathbf{\sim {\rm wPre}}(c)] = \frac{1}{\eta_c}p(c,c)
\end{equation}

By cross correlating IoU with the weighted precision metrics wPre of each class in Fig. \ref{fig:4-f}(c), three groups are shown in these classes, high-accuracy and hard to be confused, high-accuracy but easy to be confused, and low-accuracy but hard to be confused. For comparison, Fig. \ref{fig:4-f}(d) cross correlates IoU with the traditional precision metrics Pre, which failed to reflect such a property.

%Next, let us take a deeper look at the confusion among classes. Fig. \ref{fig:confusion mat} shows the prediction results of each class using the three models. The $r$-th row and the $c$-th column of the confusion matrix is given by

%\vspace{-1mm}
%\begin{equation}
%p(r,c) = \frac{|y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|}.
%\end{equation}
%
%Notice that the denominator of the confusion matrix cell is the number of points belonging to each class, and diagonal is recall of each class. From the confusion matrix, we can observe that models perform well in classifying big classes such as \textit{road}, \textit{building}, \textit{plants}, but perform not well in small classes such as \textit{sign}, \textit{people}. How these small classes be misclassified to other classes? It can be found that the color of columns of \textit{plants} are evidently deeper than other columns in confusion matrices, which indicates that \textit{plants} is easy to be misclassified from small classes.
%
%We use recall (REC) and normalized precision (nPRE) to analyze how model misclassify a class to other classes for 3D semantic segmentation. In confusion matrix, recall is the diagonal cells and normalized precision is the diagonal cells division by the sum of corresponding column, which are given by

% We define Wrong Prediction Ratio (WPR) and Be Confused Ratio (BCR) to analyze how model misclassify a class to other classes for 3D semantic segmentation. In confusion matrix, WPR is the sum of each row except diagonal and BCR is the sum of each column except diagonal, which are given by

%\vspace{-4mm}
%\begin{equation}
%WPR(r) = \sum_{c \ne r} p(r,c) = \frac{\sum_{c \ne r} |y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|},
%\end{equation}
%
%\vspace{-4mm}
%\begin{equation}
%BCR(c) = \sum_{r \ne c} p(r,c) = \sum_{r \ne c} \frac{|y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|}.
%\end{equation}

%\vspace{-3mm}
%\begin{equation}
%REC(r) = p(r,r) = \frac{|y_{_{GT}}=r \land y_{_{PD}}=r|}{|y_{_{GT}}=r|},
%\end{equation}
%
%\vspace{-3mm}
%\begin{equation}
%nPRE(c) = \frac{p(c,c)}{\sum_{r} p(r,c)} = \frac{1}{\eta} \frac{|y_{_{GT}}=c \land y_{_{PD}}=c|}{|y_{_{GT}}=c|},
%\end{equation}
%
%where $\eta$ is the sum of the $c$-th column
%
%\vspace{-3mm}
%\begin{equation}
%\eta = \sum_{r} p(r,c) = \sum_{r} \frac{|y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|},
%\end{equation}
%
%Compared with the traditional definition of precision (PRE), normalized precision can be considered as precision re-weighted by the data number of corresponding class. The traditional definition of precision is given by
%
%\vspace{-3mm}
%\begin{equation}
%PRE(c) = \frac{|y_{_{GT}}=c \land y_{_{PD}}=c|}{|y_{_{PD}}=c|}.
%\end{equation}
%
%The traditional definition of precision cannot reflect what percentage of small classes be misclassfied to others because precision value pay more attention to dominant classes. A visual comparison is shown in Fig. \ref{fig:4-f}(a) and (b). An evident difference between Fig. \ref{fig:4-f}(a) and (b) is the points of \textit{plants}, it has a very high precision but low normalized precision. The reason is that \textit{plants} is a big class and the absolute quantity of correct \textit{plants} prediction is much more than other classes. However, A considerable proportion of small classes is misclassfied to \textit{plants}, which can be reflected by the confusion matrices and Fig. \ref{fig:4-f}(b). But if we only consider traditional precision value, we will ignore the misclassification situation of small classes.
%
%%In Fig. \ref{fig:4-f}(a) the precision vs. recall scatter plot cannot reflect what percentage of small classes be classfied to others because precision value pay more attention to dominant classes. If we only consider precision value, we will ignore the misclassification situation of small classes. Fig. \ref{fig:4-f}(b) is WPR vs. BCR scatter plot using Cylinder3D training and testing on SemanticKITTI, which directly indicates the classification performances of each class.
%
%%where $|y_{_{GT}}=c|$ means the number of points that belongs to class $c$. 
%We next analyze how easy a class to be misclassified to other classes, and how easy a class to be misclassified from other classes. A detailed statistic is shown in Fig. \ref{fig:4-f}(c)(d), where the horizontal axis is classes sorted by data size. The different color blocks of Fig. \ref{fig:4-f}(c) show how much points are misclassified to the corresponding class according to a row of confusion matrix except diagonal.%, which is called Wrong Prediction Ratio (WPR) and given by
%
%%\vspace{-4mm}
%%\begin{equation}
%%\begin{aligned}
%%WPR(r) & = \sum_{c \ne r} p(r,c) = \frac{\sum_{c \ne r} |y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|} \\
%% &= 1-REC(r) .
%%\end{aligned}
%%\end{equation}
%
%And the different color blocks of Fig. \ref{fig:4-f}(d) show how much points are misclassified from the corresponding class according to a column of confusion matrix except diagonal.%, which is called Be Confused Ratio (BCR) and given by
%
%%\vspace{-4mm}
%%\begin{equation}
%%\begin{aligned}
%%BCR(c) &= \frac{1}{\eta} \sum_{r \ne c} p(r,c) = \frac{1}{\eta} \sum_{r \ne c} \frac{|y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|} \\
%% &= 1-nPRE(r) .
%%\end{aligned}
%%\end{equation}
%
%We can find that misclassification often occur from small classes to big classes in Fig. \ref{fig:4-f}(c). For big classes, \textit{fence} is also easy to be misclassified to others. Further, misclassification often occur in a specific big class, such as \textit{plants}. We can find in Fig. \ref{fig:4-f}(d) the pillar of \textit{plants} is much higher than other classes, showing it is most likely to be misclassified from other classes. The reason may be that the feature of \textit{plants} are very diverse and complex, which will be deeper explored in feature space analysis.

%Compared with the widely-used evaluation scores recall and precision, WPR and BCR are more suitable for analysis of results on class imbalanced dataset. Recall and precision are given by

%WPR is the opposite concept of recall while BCR can be considered as re-weighted precision evaluation, which can prevent precision value being influenced by prediction bias. The biggest difference between BCR and precision is the denominator of the formula. In a qualitative perspective, BCR describes whether other classes are easy to be misclassified to a specific class while precision describes whether model prediction is accurate. A visual comparison is shown in Fig. \ref{fig:4-f}(a) and (b). In Fig. \ref{fig:4-f}(a) the precision vs. recall scatter plot cannot reflect what percentage of small classes be classfied to others because precision value pay more attention to dominant classes. If we only consider precision value, we will ignore the misclassification situation of small classes. Fig. \ref{fig:4-f}(b) is WPR vs. BCR scatter plot using Cylinder3D training and testing on SemanticKITTI, which directly indicates the classification performances of each class. WPR has a negative relationship with data size, and small classes are easily be classified into \textit{plants}, causing higher BCR of \textit{plants}. 

\subsection{Feature analysis}

%[Description of feature analysis.]

Model performances are relevant to the feature description of models. Some experimental results using Cylinder3D are notable; large class \textit{plants} is easier to be confused compared with other large classes, while small classes \textit{people} and \textit{rider} have a relatively satisfactory performance. Therefore, we analyse the feature distribution of different classes, as shown in Fig. \ref{fig:feature-exp1}. 

We find that the proposed wPre metric can appropriately evaluate the feature confusion in the presence of the class imbalance. As mentioned in the previous sections, the IoU, Pre and Rec of class \textit{plants} are all high. However, the features of plants in Fig. \ref{fig:feature-exp1} are severely confused with other class features, which is not reflected by traditional metrics. In contrast, the wPre of \textit{plants} is very low because of the reweighting of the precision metric by class data size, which shows a better estimation of feature confusion.

In Fig. \ref{fig:feature-exp1}, confusion of the different classes can be easily observed; we find that the points of large classes \textit{road}, \textit{car} distribute far away from other classes, while \textit{fence}, \textit{plants} are confused. This result can explain the performance differences among classes in our experiment and the influence of class imbalance. The feature confusion of the different classes also reflects the classification confusion in Fig. \ref{fig:4-f}(a-b).

Two noticeable phenomena, intraclass diversity and interclass ambiguity, are reflected in Fig. \ref{fig:feature-exp1}. Some classes have various features, causing high intraclass diversity and learning difficulty. A prominent example is the feature distribution of \textit{plants} in Fig. \ref{fig:feature-exp1}, where we find that feature points of \textit{plants} can be divided into two parts. The right-up part corresponds to the points of the crown, and the other part corresponds to the roadside shrub. The morphological features of \textit{plants} can be extremely varied, which leads to a high intraclass diversity, and other classes that are not learned sufficiently are more likely to be misclassified to \textit{plants}. By contrast, classes such as \textit{road}, \textit{people}, and \textit{rider} have relatively consistent features, making them easier to learn.

On the other hand, some  of the different classes have similar features, causing interclass ambiguity and feature confusion. As shown in the right part of Fig. \ref{fig:feature-exp1}, two feature points of \textit{trunk} and \textit{pole} are close in feature space due to their similar columnar features. Similarly, \textit{people} and \textit{rider} show very similar geometrical features and are close in the feature space. The reason for confusion is the interclass ambiguity, namely, the feature similarity of these classes.

From the feature space analysis, we can give a systematic summary. Some classes have various features, while some different classes have similar features, causing these samples to be misclassified or hard to distinguish from other classes. The intraclass diversity and interclass ambiguity determine the learning difficulty of the classes and greatly affects model performance.

\begin{table*}[b]
	\centering
	\renewcommand{\arraystretch}{1.3}
	\caption{Data size of each class on SubKITTI and AugKITTI, and training weights of each class.}
	\begin{tabular}{c|ccccc|cc|cc|cc}
		\hline
		scale & \multicolumn{5}{c|}{Large}    & \multicolumn{2}{c|}{Middle}    & \multicolumn{2}{c|}{Small}    & \multicolumn{2}{c}{OOD}  \\ \hline
		class & road(ro)    & plants(pl)    & building(bu) & fence(fe)   & car(ca)    & trunk(tr)  & pole(po) & sign(si) &  bike(bi) & people(pe) & rider(ri)\\ \hline	
		SubKITTI (train) & 491.66M & 385.99M & 159.58M & 107.45M & 55.32M & 7.23M & 3.59M & 0.801M & 0.644M & 0 & 0  \\
		%UnpeopledKITTI (test) & 43.65M & 35.85M & 14.12M & 9.93M & 4.91M & 0.623M & 0.319M & 0.069M & 0.064M & 0 & 0  \\
		AugKITTI (test) & 42.48M & 36.07M & 22.62M & 15.98M & 2.71M & 0.479M & 0.447M & 0.082M & 0.027M & 2.49M & 1.21M  \\ \hline
		Training weights & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.87 & 3.17 & 12.36 & 15.33 & / & / \\
		\hline
	\end{tabular}	
	\label{tab:dataset2}
	\vspace{-3mm}
\end{table*}

%Now we can give an answer for the question mentioned in the beginning: \textbf{the existing 3D semantic segmentation models perform not well for small classes when training and testing on a class imbalanced dataset.} The specific reasons are as follows:
%
%\begin{itemize}
%	\item Class with insufficient data cannot be learnt by models well, reflecting by slow converge speed of loss curve.
%	
%	\item Model with limited classification ability will suffer class imbalance more severely.
%	
%	\item Some specific classes such as \textit{plants} are very diverse and complex, causing misclassification often occur from small classes to these big classes.	
%\end{itemize}

%\subsection{OOD detection using different scores}
\section{Performance of Trust Scores Facing Class Imbalanced and OOD Data} \label{sec:5}

%\begin{figure*}[b]
%	\centering
%	\includegraphics[scale=0.48]{fig-4-3.pdf}
%	\caption{(a)(b) Comparison of AUROC using PointNet++ and Cylinder3D. The thresholding scores are Softmax confidence (a) and ODIN (b). The arrow is from AUROC of PointNet++ to Cylinder3D. (c)(d) ID/OOD AUROC vs. IoU of ODIN using PointNet++ (c) and Cylinder3D (d). The result shows that OOD detection ability have a positive relationship with model performance.}
%	\label{fig:4-3}
%	\vspace{-4mm}
%\end{figure*}

\subsection{Experimental setup}

%In this subsection we try to seek whether OOD data can be detected using confidence or other thresholding scores if 3D semantic segmentation models are trained on class-imbalanced datasets. We evaluate two type of AUROC on AugmentedKITTI dataset, right/wrong AUROC and ID/OOD AUROC, to evaluate the ability of thresholding scores to distinguish whether the prediction is right and the input sample is ID. The differences of the two type of AUROC is the definition of negative sample. When calculating right/wrong AUROC, all of the points that predicted labels are not equal to ground truth will be considered as negative samples (wrong samples). When calculating ID/OOD AUROC, all of the points that belong to \textit{People} and \textit{rider} will be considered as negative sample (OOD sample). 

In this section, we evaluate the failure and OOD detection performances of trust scores using 3DSS models trained on class-imbalanced datasets, as shown in Fig. \ref{fig:exp2}. We train models on the SubKITTI dataset and test models on the AugKITTI dataset. The data size of each class is shown in Table \ref{tab:dataset2}. Compared with Experiment 1, \textit{people} and \textit{rider} are considered to be OOD classes.% For a qualitative analysis, we divided the 11 classes into big, middle,

Three 3D semantic segmentation models PointNet++, RandLA-Net and Cylinder3D are used in the experiment, and all the models are trained for 32 epochs using the weighted cross-entropy loss given by Equation (\ref{eq:loss}) and the Adam optimizer with a learning rate of 0.001. In addition, we use the class weights given by Equation (\ref{eq:w}) with $\beta$ = 0.9 when training the models, which are shown in the last line of Table \ref{tab:dataset2}.

Five trust scoring approaches, Softmax confidence, data uncertainty, model uncertainty, ODIN and MD, are used in the experiment. For data uncertainty and model uncertainty, we use the Monte Carlo dropout \cite{gal2016dropout} with the number of forward passes $M$ = 5 and the dropout probability $p$ = 0.25 as a commonly used setup \cite{ovadia2019can}. For ODIN, we use the temperature parameter $T$ = 1000.

%We use AUROC as failure and OOD detection performance metric and analyze the score reliability of each predictive class. Next, we visualize the results by plotting Trust score distribution (TSD), and TPR, FPR, wPre are used to provide a comprehensive analysis. Finally, T-SNE method is used for a feature space analysis.

%\textbf{Purpose}: Evaluate the performances of trust scores using for 3DSS models trained on class-imbalanced dataset, as shown in Fig. \ref{fig:exp2}. 
%
%\textbf{Dataset}: We train models on the SubKITTI dataset, and test models on the AugKITTI dataset. The data size of each class is shown in Table \ref{tab:dataset2}.
%
%\textbf{3DSS Model}: Three 3D semantic segmentation models PointNet++, RandLA-Net and Cylinder3D are used in the experiment, and all models are trained for 32 epochs using cross-entropy loss and Adam optimizer with learning rate 0.001. Besides, we use class weights calculated by \cite{cui2019class} with $\beta$ = 0.9 when training models, which are shown in the last line of Table \ref{tab:dataset2}.
%
%\textbf{Trust scoring approach}: Five Trust scoring approaches Softmax confidence, data uncertainty, model uncertainty, ODIN and MD are used in the experiment. For data uncertainty and model uncertainty, we use Monte Carlo Dropout \cite{gal2016dropout} with ensemble degree $M$ = 5.
%
%\textbf{Evaluation and analysis method}: We use normalized AUROC (nAUROC) as failure and OOD detection performance metric and analyze the score reliability of each predictive class. We use predictive classes distribution diagram to visualize the results, and normalized TPR (nTPR), normalized precision (nPRE), normalized AUROC (nAUROC) are used to help to provide a comprehensive analysis. Finally, T-SNE method is used for a feature space analysis.

%In this section we try to evaluate the performances of trust scores using for 3DSS models trained on class-imbalanced dataset, as shown in Fig. \ref{fig:exp2}. 
%We train models on the SubKITTI dataset, and test models on the AugKITTI dataset. Three 3DSS models PointNet++, RandLA-Net and Cylinder3D are used in the experiment, and all models are trained for 32 epochs using Adam optimizer with learning rate 0.001. Besides, we use class weights calculated by \cite{cui2019class} with $\beta$ = 0.9 when training models, which are shown in the last line of Table \ref{tab:dataset}. For data uncertainty and model uncertainty, we use Monte Carlo Dropout with ensemble degree $M$ = 5.
%We train and test models on the SemanticKITTI dataset, and compare models’ performances on different classes. Three 3D semantic segmentation models PointNet++, RandLA-Net and Cylinder3D are used in the experiment, and all models are trained for 32 epochs using Adam optimizer with learning rate 0.001. Besides, we use class weights calculated by \cite{cui2019class} with $\beta$ = 0.9 when training models.

%\begin{table*}[t]
%	\centering
%	\renewcommand{\arraystretch}{1.2}
%	\caption{ID/OOD AUROC of every predicted class using different thresholding scores.}
%	\begin{tabular}{c|c|ccccccccc|c}
%		\hline
%		model   & score &  road   & plants & building & fence & car & trunk & pole & sign & bike  & total \\ \hline
%		\multirow{5}{*}{PointNet++} & confidence & 75.7 & 79.0 &82.9 &69.5 &47.8 &43.4 &58.8 &/ &/ & 71.5  \\
%		& data uncertainty & 76.0 & 81.5 &85.4 &73.3 &53.6 &46.7 &59.1 &/ &/ & 73.9 \\
%		& model uncertainty & 75.8 & 71.6 &73.5 &60.4 &57.8 &68.6 &37.2 &/ &/ & 69.5  \\
%		& ODIN & 90.1 & 77.2 &75.6 &62.8 &65.1 &71.7 &65.1 &/ &/ & 76.2  \\
%		& MD & 89.5 & 85.4 &76.0 &75.4 &65.6 &62.7 &59.6 &/ &/ & 77.1  \\ 
%		\hline
%		\multirow{5}{*}{Cylinder3D} & confidence & 92.1 & 84.8 &92.8 &73.5 &84.2 &76.9 &92.0 &91.7 &45.9 & 74.6  \\
%		& data uncertainty & 91.9 & 86.7 &95.8 &74.3 &84.6 &77.5 &93.6 &92.3 &47.9 & 78.5  \\
%		& model uncertainty & 92.4 & 85.9 &94.3 &78.3 &85.3 &78.6 &90.1 &89.2 &51.8 & 80.1  \\
%		& ODIN & 92.3 & 84.3 &91.2 &77.6 &88.6 &79.9 &89.6 &95.2 &49.2 & 81.3  \\
%		& MD & 92.3 & 86.4 &91.7 &74.3 &86.9 &78.4 &89.1 &96.3 &69.1 & 82.8  \\
%		\hline
%	\end{tabular}	
%	\label{tab:auroc}
%\end{table*}

%\begin{table*}[b]
%	\centering
%	\renewcommand{\arraystretch}{1.2}
%	\caption{average value of thresholding scores of every predicted class.}
%	\begin{tabular}{c|c|ccccccccc}
%		\hline
%		model   & score &  road   & plants & building & fence & car & trunk & pole & sign & bike   \\ \hline
%		\multirow{5}{*}{PointNet++} & confidence ($\times 10^{-1}$) & 8.22 & 6.43 &7.08 &4.11 &5.36 &4.60 &2.68 &/ &/   \\
%		& data uncertainty ($\times 10^{-1}$) & 4.97 & 10.57 &8.63 &14.52 &12.62 &14.78 &17.67 &/ &/ \\
%		& model uncertainty ($\times 10^{-2}$) & 2.36 & 3.85 &4.90 &6.73 &4.11 &10.18 &11.143 &/ &/  \\
%		& ODIN ($\times 10^{-2}$) & 8.40 & 8.37 &8.38 &8.36 &8.36 &8.34 &8.34 &/ &/   \\
%		& MD ($\times 10^{-7}$) & 1.40 & 1.95 &2.21 &2.40 &3.17 &3.93 &8.58 &/ &/  \\ 
%		\hline
%		\multirow{5}{*}{Cylinder3D} & confidence ($\times 10^{-1}$) & 9.75 & 9.12 &8.93 &7.97 &9.26 &8.63 &9.16 &9.25 &6.41  \\
%		& data uncertainty ($\times 10^{-1}$) & 0.71 & 2.51 &3.71 &5.20 &1.99 &3.53 &2.44 &2.26 &8.70   \\
%		& model uncertainty ($\times 10^{-2}$) & 0.61 & 2.07 &3.22 &4.25 &4.59 &8.19 &5.52 &6.50 &21.76  \\
%		& ODIN ($\times 10^{-2}$) & 8.49 & 8.46 &8.43 &8.44 &8.48 &8.46 &8.46 &8.48 &8.40 \\
%		& MD ($\times 10^{-7}$) & 2.85 & 5.19 &2.83 &5.41 &11.68 &18.31 &16.52 &17.69 &41.39   \\
%		\hline
%	\end{tabular}	
%	\label{tab:avg}
%\end{table*}

\subsection{Experimental result}

Given a 3DSS model $f$ and a trust score $g$, a $g(x) \in [0,1]$ can be estimated for each data point $x$ based on the output of $f$.
Ideally, a high $g(x)$ indicates that the model $f$ is confident in its results, while a lower value indicates that the model is uncertain about its results.
Discriminating whether the predicted semantic class is correct or wrong, or whether the data are ID or OOD is a binary decision, which has usually been made by thresholding $g(x)$ using formula (\ref{eq:gx}).

Before examining the experimental results, let us first define three class sets: ID/correct ($\mathcal{A}_{ID.co}$), ID/wrong ($\mathcal{A}_{ID.wr}$) and OOD ($\mathcal{A}_{OOD}$).
$\mathcal{A}_{ID.co}$ and $\mathcal{A}_{ID.wr}$ contain both of the ID classes that appeared in the training data.
For each predicted class $c_{_{PD}}$, the former has a single class $\mathcal{A}_{ID.co}=\{c_{_{GT}}=c_{_{PD}}\}$, while the latter are the rest $\mathcal{A}_{ID.wr}=\{c_{_{GT}} \neq c_{_{PD}}\}$.
$\mathcal{A}_{OOD}$ are OOD classes that are not known in training and thus are not included in the predicted label set. In this experiment, the OOD classes are \textit{rider} and \textit{people}.

This study addresses three tasks that differ only in the definition of their true and false class sets.
Task 1 - I/O, discriminating whether the data are ID or OOD. For this task, we define the true class set as $\mathcal{A}^{I/O}=\mathcal{A}_{ID.co} \cup \mathcal{A}_{ID.wr}$ and the false class set as $\mathcal{\bar{A}}^{I/O}=\mathcal{A}_{OOD}$.
Task2 - C/W and Task3 - C/W with OOD, discriminating whether the predicted semantic class is correct or wrong, where the two tasks vary in whether OOD are addressed.
Both tasks share the same true class set that is $\mathcal{A}^{C/W}=\mathcal{A}_{ID.co}$.
They have different false class sets, which are $\mathcal{\bar{A}}^{C/W}=\mathcal{A}_{ID.wr}$ and $\mathcal{\bar{A}}^{C/W with OOD}=\mathcal{A}_{ID.wr} \cup \mathcal{A}_{OOD}$ for Task 2 and Task 3, respectively.

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.54]{fig-5-exp.pdf}
	\vspace{-3mm}
	\caption{Setup of Experiment 2: Evaluate the performances of trust scores using 3DSS models trained on class-imbalanced datasets. (I/O: ID/OOD. C/W: Correct/Wrong. SubKITTI: SemanticKITTI without OOD data. AugKITTI: SemanticKITTI with augmented OOD data. OOD data: people, rider. )}
	\label{fig:exp2}
	\vspace{-4mm}
\end{figure}

\begin{figure*}[t]
	\centering
	\includegraphics[scale=0.33]{fig-5-auroc.pdf}
	\vspace{-4mm}
	\caption{AUROC of different models and trust scores for (a) Task1 - I/O, (b) Task2 - C/W, (c) Task3 - C/W with OOD.}
	\label{fig:auroc}
	\vspace{-4mm}
\end{figure*}

\begin{figure*}[b]
	\centering
	\includegraphics[scale=0.46]{fig-5-distrib-eg.pdf}
	\vspace{-7mm}
	\caption{(a) An example of a trust score distribution (TSD) matrix ($\times 10^{-1}$) (b) An example of the TSD according to the matrix. From top to bottom, the horizontal bands are sequentially the classes of $\mathcal{A}_{ID.co}$, $\mathcal{A}_{ID.wr}$ and $\mathcal{A}_{OOD}$}
	\label{fig:distrib-eg}
	\vspace{-4mm}
\end{figure*}

\begin{figure*}[t]
	\centering
	\includegraphics[scale=0.41]{fig-5-distrib.pdf}
	\vspace{-4mm}
	\caption{TSD of 9 ID classes using Cylinder3D and Softmax confidence. \textit{Road} and \textit{sign} demonstrate perfect examples, whereas \textit{bike}, \textit{plants}, \textit{fence} and \textit{building} demonstrate examples of the worst performance.}
	\label{fig:distrib}
	\vspace{-4mm}
\end{figure*}

%\begin{figure*}[t]
%	\centering
%	\includegraphics[scale=0.4]{fig-5-roc.pdf}
%	\caption{The nTPR, nTPR, nROC curve, and nPRE using Cylinder3D and Softmax confidence.}
%	\label{fig:roc}
%	\vspace{-4mm}
%\end{figure*}

%\begin{figure}[t]
%	\centering
%	\includegraphics[scale=0.28]{fig-5-iouroc.pdf}
%	\caption{The nTPR, nTPR, nROC curve, and nPRE using Cylinder3D and Softmax confidence.}
%	\label{fig:iouroc}
%	\vspace{-4mm}
%\end{figure}

\begin{figure*}[t]
	\centering
	\includegraphics[scale=0.46]{fig-5-iocw.pdf}
	\vspace{-4mm}
	\caption{(a) per-class AUROC of the three tasks. (b) per-class TPR with $\delta$ = 0.9 of the three tasks. (c) per-class FPR with $\delta$ = 0.9 of the three tasks. Per-class AUROC and wPre for (d) Task1, (e) Task2, (f) Task2 vs Task3. }
	\label{fig:iocw}
	\vspace{-4mm}
\end{figure*}

\begin{figure*}[t]
	\centering
	\includegraphics[scale=0.58]{fig-feature-exp2.pdf}
	\vspace{-4mm}
	\caption{T-SNE plot of 200 random sampled points from AugKITTI using Cylinder3D. (a) Feature points of ID classes. (b) Feature points of \textit{car}, \textit{sign}, \textit{trunk}, \textit{pole}, \textit{road} and OOD classes. (c) Feature points of \textit{plants}, \textit{fence}, \textit{building}, \textit{bike} and OOD classes.}
	\label{fig:feature-exp2}
	\vspace{-4mm}
\end{figure*}

Here, the traditional evaluation metric of the \textbf{area under the receiver operating characteristic curve} (\textbf{AUROC}) is used to analyse and evaluate the trust scoring performance.
A receiver operating characteristic (ROC) curve is first plotted with the \textbf{true positive ratio} (\textbf{TPR}) and \textbf{false positive ratio} (\textbf{FPR}) for the vertical and horizontal axes, and the area under the ROC curve is estimated to evaluate the performance. For a predicted class $c$ and a given threshold $\delta$, TPR and FPR are estimated as follows:

\begin{eqnarray}
{\rm TPR}(c,\delta) = \frac{{\rm TP}(c,\delta)}{{\rm TP}(c,\delta)+{\rm FN}(c,\delta)}\\
{\rm FPR}(c,\delta) = \frac{{\rm FP}(c,\delta)}{{\rm FP}(c,\delta)+{\rm TN}(c,\delta)}
\end{eqnarray}

Given the true and false class sets, $\mathcal{A}^*$ and $\mathcal{\bar{A}}^*$, where $*$ represents the task, we have:
\begin{eqnarray}
{\rm TP}(c,\delta) = \sum_{r\in \mathcal{A}^*} { |y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) > \delta|}\\
{\rm TN}(c,\delta) = \sum_{r\in \mathcal{\bar{A}}^*} {|y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) \le \delta|}\\
{\rm FP}(c,\delta) = \sum_{r\in \mathcal{\bar{A}}^*} { |y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) > \delta|} \label{eq:fp}\\
{\rm FN}(c,\delta) = \sum_{r\in \mathcal{A}^*} {|y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) \le \delta|} 
\end{eqnarray}

The AUROC of all 3DSS models $f$, and the trust scores $g$, on three different tasks are plotted in Fig. \ref{fig:auroc}. We discriminate between the models by colour, trust scores by line type and tasks by subfigures.
It can be found that for each task, lines of the same colour are cluttered, revealing that the model performance is the dominant factor as compared to the trust score methods.

For each model, all trust scoring methods demonstrate a similar overall performance.
The performance of PointNet ++ for each class is related to data size to some extent, where there are no data in \textit{sign} and \textit{bike} from PointNet++ because none of the test points is predicted to be \textit{sign} and \textit{bike} by PointNet++.
The general tendency is that the larger the data size, the higher the AUROC value, which means that OOD detection also suffers from the class imbalance.

On the other hand, the state-of-the-art models, Cylinder3D and RandLA Net, have greatly improved the performance of all classes.
However, the performance is not equivalent. For example, \textit{sign} and \textit{bike} are both small classes and have very poor performance on PointNet++. Although \textit{sign} presents superior performance on Cylinder3D, the improvement of \textit{bike} is limited, and the AUROC values on all three tasks are unsatisfactory.
This phenomenon suggests that in these tasks, different properties of the classes may have a greater impact on performance than the data size imbalances. Some classes are hard because they are easily confused with OOD data or other classes.

%——————————————————————

%For a comprehensive analysis of the performance of trust scores, we use predictive classes distribution diagram to visualize the results, and some quantized evaluation scores such as normalized TPR (nTPR), normalized precision (nPRE), and normalized AUROC (nAUROC). An example of distribution diagram is shown in Fig. \ref{fig:distrib-eg}(a), where the trust score distribution of a specific predictive class is stacked with different colors according to the ground truth. If given two adjacent threshold values $\delta_1$ and $\delta_2$, the height of the distribution diagram in corresponding interval $(\delta_1,\delta_2]$ with predictive class $c$ is given by
%
%\vspace{-1mm}
%\begin{equation}
%h(c,\delta_1,\delta_2) = \sum_r { \frac{|y_{_{GT}}=r \land y_{_{PD}}=c \land \delta_1<t(x) \le \delta_2|}{|y_{_{GT}}=r|} }.
%\end{equation}
%
%Notice that we also re-weighted the by the distribution by data number of corresponding class, which is similar as the evaluation of experiment 1. And the distribution diagrams of 9 classes using Cylinder3D and Softmax confidence in experiment 2 are shown in Fig. \ref{fig:distrib}. We will evaluate the ability of trust scores to distinguish ID and OOD (ID/OOD), correct and wrong (C/W) using the distribution diagrams and some quantized evaluation scores.
%
%For OOD detection we can use $TP_{IO}(c,\delta)$, $TN_{IO}(c,\delta)$, $FP_{IO}(c,\delta)$, $FN_{IO}(c,\delta)$ denote the number of false negative, false positive, true negative, and true positive judgment of ID or OOD with predictive class $c$ and threshold $\delta$, which can be represented by the areas in the distribution diagram, as shown in Fig. \ref{fig:distrib-eg}(b) and given by
%
%\vspace{-3mm}
%\begin{equation}
%TP_{IO}(c,\delta) = \sum_{r\in \mathcal{A}_{ID}} { \frac{|y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) > \delta|}{|y_{_{GT}}=r|} },
%\end{equation}
%
%\vspace{-3mm}
%\begin{equation}
%TN_{IO}(c,\delta) = \sum_{r\in \mathcal{A}_{OOD}} { \frac{|y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) \le \delta|}{|y_{_{GT}}=r|} },
%\end{equation}
%
%\vspace{-3mm}
%\begin{equation}
%FP_{IO}(c,\delta) = \sum_{r\in \mathcal{A}_{OOD}} { \frac{|y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) > \delta|}{|y_{_{GT}}=r|} },
%\end{equation}
%
%\vspace{-3mm}
%\begin{equation}
%FN_{IO}(c,\delta) = \sum_{r\in \mathcal{A}_{ID}} { \frac{|y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) \le \delta|}{|y_{_{GT}}=r|} },
%\end{equation}
%
%where $\mathcal{A}_{ID}$, $\mathcal{A}_{OOD}$ is the set of ID classes and OOD classes. Using these variables we can define nTPR, nFPR to evaluate how ID and OOD be discriminated with trust scores changing, which is given by
%
%\vspace{-3mm}
%\begin{equation}
%nTPR_{IO}(c,\delta) = \frac{TP_{IO}(c,\delta)}{TP_{IO}(c,\delta)+FN_{IO}(c,\delta)},
%\end{equation}
%
%\vspace{-3mm}
%\begin{equation}
%nFPR_{IO}(c,\delta) = \frac{FP_{IO}(c,\delta)}{FP_{IO}(c,\delta)+TN_{IO}(c,\delta)}.
%\end{equation}
%
%And similar as experiment1, we use nPRE to evaluate how prediction accuracy change with trust scores changing, which is given by
%
%\vspace{-3mm}
%\begin{equation}
%nPRE_{IO}(c,\delta) = \frac{TP_{IO}(c,\delta)}{TP_{IO}(c,\delta)+FP_{IO}(c,\delta)}.
%\end{equation}
%
%Using nTPR as $y$-axis and nFPR as $x$-axis we can plot a normalized Receiver Operating Characteristic curve (nROC). In nROC curve nTPR is a function of nFPR, and we denote this function as $nTPR_{IO}^{(c)}(nFPR_{IO}^{(c)})$. The Area Under nROC curve (nAUROC) is often used to evaluate the ability of the trust scores to distinguish whether the input is ID or OOD, which is given by
%
%\vspace{-3mm}
%\begin{equation}
%nAUROC_{IO}(c) = \int_0^1{nTPR_{IO}^{(c)}(nFPR_{IO}^{(c)}) {\rm d}(nFPR_{IO}^{(c)})} .
%\end{equation}
%
%The evaluation approach of failure detection is similar as OOD detection. The difference is only in the different definition of TP, FP, TN, FN, as shown in Fig. \ref{fig:distrib-eg}(c). In addition, we calculate two condition of the failure detection: considering OOD data and ignoring OOD data. If considering OOD data, \textit{people} and \textit{rider} will be considered as wrong prediction. And if ignoring OOD data, \textit{people} and \textit{rider} will be excluded from statistics. The nTPR, nTPR, nROC curve, and nPRE using Cylinder3D and Softmax confidence in experiment 2 are shown in Fig. \ref{fig:roc}.
%
%%For failure detection and OOD detection, we use Area Under the Receiver Operating Characteristic curve (AUROC) to evaluate the performance of trust scores as most research used. The $x$-axis of ROC curve is False Positive Rate (FPR) and the $y$-axis is True Positive Rate (TPR), which are given by
%
%%\begin{equation}
%%TPR(c) = \frac{TP(c)}{TP(c)+FN(c)}, FPR(c) = \frac{FP(c)}{FP(c)+TN(c)} 
%%\end{equation}
%
%%\begin{equation}
%%TPR_{c} = \frac{TP_{c}}{TP_{c}+FN_{c}}, \quad FPR_{c} = \frac{FP_{c}}{FP_{c}+TN_{c}},
%%\end{equation}
%
%%We evaluate two type of AUROC on AugmentedKITTI dataset, right/wrong AUROC and ID/OOD AUROC, to evaluate the ability of thresholding scores to distinguish whether the prediction is right and the input sample is ID. The differences of the two type of AUROC is the definition of positive sample. When calculating right/wrong AUROC, all of the points that predicted labels are equal to ground truth will be considered as positive samples (right samples). The FPR and TPR are given by
%%
%%\begin{equation}
%%\begin{array}{lr}
%%{\rm right/wrong \quad} TPR_{c} = \frac{|y_{_{GT}}=y_{_{PD}}=c \land t(x)> \delta|}{|y_{_{GT}}=y_{_{PD}}=c|}, & \\
%%{\rm right/wrong \quad} FPR_{c} = \frac{|y_{_{GT}}\ne y_{_{PD}}=c \land t(x)>\delta|}{|y_{_{GT}}\ne y_{_{PD}}=c|}. &
%%\end{array}
%%\end{equation}
%%
%%\begin{equation}
%%\begin{array}{lr}
%%{\rm right/wrong \quad} TPR_{c} = \frac{|y_{_{GT}}=y_{_{PD}}=c \land t(x)> \delta|}{|y_{_{GT}}=y_{_{PD}}=c|}, & \\
%%{\rm right/wrong \quad} FPR_{c} = \frac{\sum_{r\ne c}\frac{|y_{_{GT}}=r \land y_{_{PD}}=c\land t(x)> \delta|}{|y_{_{GT}}=r|}}{\sum_{r\ne c}\frac{|y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|}}. &
%%\end{array}
%%\end{equation}
%%
%%where $t(x)$ is a thresholding score and $\delta$ is a given threshold value. Similarly, when calculating ID/OOD AUROC, all of the points that not belong to \textit{people} and \textit{rider} will be considered as positive sample (ID sample). The FPR and TPR are given by
%%
%%\begin{equation}
%%\begin{array}{lr}
%%{\rm ID/OOD \quad} TPR_{c} = \frac{|y_{_{GT}}\in ID \land y_{_{PD}}=c \land t(x)> \delta|}{|y_{_{GT}}\in ID \land y_{_{PD}}=c|}, & \\
%%{\rm ID/OOD \quad} FPR_{c} = \frac{|y_{_{GT}}\in OOD \land y_{_{PD}}=c \land t(x)> \delta|}{|y_{_{GT}}\in OOD \land y_{_{PD}}=c|}. &
%%\end{array}
%%\end{equation}
%%
%%\begin{equation}
%%\begin{array}{lr}
%%{\rm ID/OOD \quad} TPR_{c} = \frac{\sum_{r\in ID}\frac{|y_{_{GT}}=r \land y_{_{PD}}=c\land t(x)> \delta|}{|y_{_{GT}}=r|}}{\sum_{r\in ID}\frac{|y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|}}, & \\
%%{\rm ID/OOD \quad} FPR_{c} = \frac{\sum_{r\in OOD}\frac{|y_{_{GT}}=r \land y_{_{PD}}=c\land t(x)> \delta|}{|y_{_{GT}}=r|}}{\sum_{r\in OOD}\frac{|y_{_{GT}}=r \land y_{_{PD}}=c|}{|y_{_{GT}}=r|}}. &
%%\end{array}
%%\end{equation}
%
%%With the increase of $\delta$, $TPR_{c}$ and $FPR_{c}$ will both increase and form the ROC curve. AUROC is the area under ROC curve, indicating the performance of OOD detectors. The advantage of AUROC is that it can prevent paying more attention to dominant classes when data is imbalance, which is suitable for our experiments.
%
%The ID/OOD nAUROC results of Experiment 2 are shown in Table \ref{tab:auroc}. We evaluate nAUROC of every predicted class, where no data in \textit{sign} and \textit{bike} of PointNet++ because none of the test points is predicted to \textit{sign} and \textit{bike} by PointNet++. From Table \ref{tab:auroc} we can find that nAUROC varies among different classes, which means OOD detection also suffer from class imbalance. 
%In addition, nAUROC of Cylinder3D predictions is higher than PointNet++ for all scores and all classes, indicating that model performance also influence the validity of trust scores. For a deeper comparison, we plot IoU vs. nAUROC of each class using PointNet++ and Cylinder3D in Fig. \ref{fig:iouroc}, we can find that points of classes are mostly distributed nearby the red line, which means OOD detection ability have a positive relationship with model performance.
%%However, the performance of OOD detection does not entirely have a positive relationship with data size. \textit{Sign} predicted by Cylinder3D has 91.7\% AUROC but \textit{bike} only has 45.9\% using confidence, because OOD classes are more likely to be confused with \textit{bike} than \textit{sign}, which will be further explained by feature space analysis. But in summary, big classes are much stable and robust for OOD detection.
%
%If we focus on the different trust scoring approaches, we can find that compared with Softmax confidence, using uncertainty, ODIN or MD can improve OOD detection ability in a degree. However, the nAUROC of these scores is also relevant to confidence. The higher performance confidence has, the higher performance other scores will have, which means the validity of confidence can indicate the OOD detection ability of other scores. Therefore, we use Cylinder3D and Softmax confidence as trust score to give a deeper analysis of the confusion among different classes in next part.
%
%%The most arrows in Fig. \ref{fig:4-1} are pointing to the upper right, which indicates ODIN improves both right/wrong and ID/OOD AUROC in a degree. In Table \ref{tab:auroc} the total AUROC of uncertainty, ODIN and MD is little higher than baseline confidence.  In summary, \textbf{All of the thresholding scores for OOD detection also suffer from class imbalance.} 
%
%Several phenomena can be summarized:
%
%\begin{itemize}
%	\item OOD detection performances have a positive relationship with model performances.
%	
%	\item Classes with higher classification performances also have better OOD detection performances.
%	
%	\item OOD detection performances of trust scores such as uncertainty, ODIN or MD have a positive relationship with Softmax confidence.
%\end{itemize}
%
%However, from Fig. \ref{fig:iouroc}(b) we can also find that some points of classes are relatively far from the red line such as \textit{sign} and \textit{pole}. These exceptions can be explained by different features description of classes, which determine the confusion degree between known classes and OOD classes, and will be deeper explored in feature space analysis.
%We suppose that features of classes are another factor which influence OOD detection ability. Therefore, we analyze features description of different classes in next part to seek the underlying reason why model performance and OOD detection vary with different classes.

%In previous part we find that both classification performances and OOD detection performances have a positive relationship with class data size. In this subsection we try to explore the relationship between model classification performance and OOD detection ability. As shown in Table \ref{tab:auroc} and Fig. \ref{fig:4-3}(a)(b), AUROC of Cylinder3D predictions is higher than PointNet++ for all scores and all classes. Both Right/Wrong AUROC and ID/OOD AUROC evidently improve from PointNet++ to Cylinder3D. For a deeper comparison, we plot IoU vs. AUROC of each class using PointNet++ and Cylinder3D in Fig. \ref{fig:4-3}(c)(d), we can find that points of classes are mostly distributed nearby the red line, which means OOD detection ability have a positive relationship with model performance.
%
%%We also gives the average value of thresholding scores for each class in Table \ref{tab:avg}. The thresholding scores to detect OOD data by indicating the prediction confidence, which ought to give low confidence on unknown data and high confidence on learned data. However, small classes often get low confidence score because they are not learned by model sufficiently. We can see in Table \ref{tab:avg} the PointNet++ prediction confidences on small classes are same or even lower than OOD classes, which means model have not learned small classes and causes it hard to detect OOD data. This shows why OOD detection ability is influenced by model performance.
%
%By the previous analysis, the conclusion is obvious: \textbf{OOD detection ability have a positive relationship with model classification performance.} Several phenomena reflect this conclusion:
%
%\begin{itemize}
%	\item Models with higher classification performances also have better OOD detection performances.
%	
%	\item For a specific model, classes with higher classification performances also have better OOD detection performances.
%	
%	\item The average value of thresholding scores are relevant to classification performance.
%\end{itemize}


\subsection{Confusion analysis}

In this section, we choose the results of Cylinder3d with the Softmax confidence for further in-depth analysis as shown in Fig. \ref{fig:distrib}. 
We begin by examining the distribution of the $g(x)$ values of each predicted category.

\subsubsection{Trust score distribution (TSD)}

Given a sequence of monotonically increasing values $\{\delta_0,...,\delta_i,...,\delta_n\}$ with $\delta_0=0$ and $\delta_n=1$, a measure is defined below.

\begin{equation}
q(r,c,\delta_i) = \frac{|y_{_{GT}}=r \land y_{_{PD}}=c \land \delta_i<g(x) \le \delta_{i+1}|}{|y_{_{GT}}=r|}
\end{equation}

The numerator of the right-hand term counts the number of points whose ground truth label is $r$ while classified to $c$ with a trust score $g(x) \in (\delta_i,\delta_j]$.
In fact, $\sum_{i}^{n-1} q(r,c,\delta_i) = p(r,c)$.

Corresponding to the confusion matrix in Fig. \ref{fig:confusion mat}, each column vector of a predicted class $c$ can be extended to a \textbf{trust score distribution} (\textbf{TSD}) matrix, where each row $r$ is for a ground truth class, each column is for $\delta_i$, each matrix value is $q(r,c,\delta_i)$, and the sum of row $r$ is $p(r,c)$. Taking ${\rm PD}=$ \textit{plants} as an example, a matrix is shown in Fig. \ref{fig:distrib-eg}(a) and plotted in the mode of the stacked area chart in Fig. \ref{fig:distrib-eg}(b), where horizontal bands of a TSD are ordered. From top to bottom, they are sequentially the classes of $\mathcal{A}_{ID.co}$, $\mathcal{A}_{ID.wr}$ and $\mathcal{A}_{OOD}$.
The TSD of each predicted class $c$ is plotted in Fig. \ref{fig:distrib}.
Each horizontal band of a TSD depicts an $g(x)$ distribution for a certain ground truth class $r$ and predicted class $c$ with the area equal to $p(r,c)$.

In Fig. \ref{fig:distrib}, \textit{road} and \textit{sign} demonstrate perfect examples, where the data predicted for these classes almost fall in the top horizontal band, $\mathcal{A}_{ID.co}$ data.
The TSD of \textit{car} looks similar. However, there are many OOD data predicted as \textit{car}, which fall in the bottom horizontal bands, and some have very high trust scores.
The performance of \textit{trunk} and \textit{pole} are not bad too, and they are almost $\mathcal{A}_{ID.co}$ data, while their trust scores span wider ranges.
\textit{Bike}, \textit{plants}, \textit{fence} and \textit{building} demonstrate examples of the worst performance, where many $\mathcal{A}_{ID.co}$ data have lower trust scores than those of $\mathcal{A}_{ID.wr}$ and $\mathcal{A}_{OOD}$. With such distributions, it is difficult to discriminate between ID/OOD or correct/wrong by thresholding on the trust scores.


\subsubsection{Per-class AUROC for three tasks}

We extract the results of Cylinder3d with a Softmax confidence in Fig. \ref{fig:iocw} and cross-correlate the per-class AUROC of the three tasks in Fig. \ref{fig:iocw}(a).
The horizontal axis is for Task 1 - I/O, while the vertical axis compares Task 2 - C/W and Task 3 - C/W with OOD.
Two dotted lines are manually drawn at AUROC=0.7 for analysis. It can be found that for the data predicted as \textit{bike}, it is difficult to discriminate whether it is an ID or OOD. Comparing its performance on Task 2 and Task 3, it is found that \textit{bike} is easily affected by OOD.
In fact, the data of ID class \textit{bike} and OOD class \textit{rider} have similar properties, which makes them confusing.
This phenomenon suggests that the performance of OOD detection and the influence of OOD data need to be addressed with the confusion properties of the classes.

On the other hand, for those predicted as \textit{sign}, it is difficult to discriminate whether the predicted semantic class is correct or wrong, no matter whether OOD exists.
However, this result contradicts what we discussed earlier, where \textit{sign} demonstrates perfect TSD examples. We further analyse the results below.

\subsubsection{Threshold on trust scores}

%An ideal trust score should provide reliable prediction when it is high. So we are also interested in how model performances are influenced by wrong prediction and OOD with a high thresholding trust scores $\delta$. We analyze TPR and FPR with $\delta=0.9$ as the base of trust score evaluation.
%Fig. \ref{fig:iocw}(b) shows TPR results.

%AUROC is estimated as the area under the ROC curve plotted with ${\rm TPR}$ and ${\rm FPR}$ for vertical and horizontal axes.
%Given a sequence of $\{\delta_i\}$, thresholding trust scores on each $\delta_i$, a set of 2D points $\{({\rm TPR}(\delta_i),{\rm FPR}(\delta_i))\}$ is found to plot a ROC curve. 

An ideal trust score should provide a reliable prediction when it is high. Therefore, we are also interested in how model performance is influenced by an incorrect prediction and an OOD with high thresholding trust scores $\delta$. We analyse TPR and FPR with $\delta=0.9$ as the basis of a trust score evaluation.
Fig. \ref{fig:iocw}(b) shows the TPR results.

Since Task 2 and Task 3 share the same true class set, their per-class TPRs are the same, exhibiting a nearly linear trend.
Similar to the results of TSD, \textit{bike}, \textit{fence} and \textit{building} are the worst three performers, while \textit{road}, \textit{car}, \textit{pole} and \textit{sign} are among the top groups.
However, the FPR results in Fig. \ref{fig:iocw}(c) also contradict what we discussed earlier, where \textit{bike}, \textit{fence} and \textit{building} have very low FPRs for all three tasks, whereas \textit{road} and \textit{sign} have high values.
By examining the formula (\ref{eq:fp}), we found that some classes have very small FP and TN, as exhibited in Fig. \ref{fig:distrib}, and even a small FP could yield a high FPR. This is the main reason for the contradictory results in Fig. \ref{fig:iocw}(a) and (c). 
If classes are highly imbalanced, the metrics TPR and FPR may not properly and sufficiently evaluate the model performance of each class, which shows the need to combine them with a metric on precision.

\subsubsection{Per-class AUROC and wPre}

By incorporating the trust score, the wPre metrics in the previous section are extended below to evaluate the reliability of a model prediction.

\begin{equation}
{\rm wPre}(c,\delta) = \frac{{\rm wTP}(c,\delta)}{{\rm wTP}(c,\delta)+{\rm wFP}(c,\delta)}.
\end{equation}

where
\begin{eqnarray}
{\rm wTP}(c,\delta) = \sum_{r\in \mathcal{A}^*} { \frac{|y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) > \delta|}{|y_{_{GT}}=r|} }\\
{\rm wFP}(c,\delta) = \sum_{r\in \mathcal{\bar{A}}^*} { \frac{|y_{_{GT}}=r \land y_{_{PD}}=c \land t(x) > \delta|}{|y_{_{GT}}=r|} }
\end{eqnarray}

Cross correlating AUROC with wPre and $\delta$=0.9, we evaluate the performance for Task 1, Task 2 and Task 2 vs Task 3 in Fig. \ref{fig:iocw}(d-f), respectively. 
We obtain the following findings. For Task 1, \textit{car}, \textit{plants} and \textit{bike} have poor precisions, and \textit{bike} has the worst performance in discriminating between ID and OOD data due to the interclass ambiguity. For Task 2, \textit{plants} and \textit{fence} have poor precisions, whereas \textit{sign} has difficulty in discriminating between correct or wrong predictions of the semantic classes. In the case that OOD data exist in Task 3, \textit{car}, \textit{plants} and \textit{bike} are the most affected.

%______________

%We next analyze how classes are confused with each other focusing on Fig. \ref{fig:distrib} and Fig. \ref{fig:roc}. As we summarized in experiment 1, \textit{plants} and \textit{fence} are easy confused with other classes, which is also evidently reflected by the distribution diagram. In Fig. \ref{fig:distrib} some classes show a unimodal distribution such as \textit{road}, \textit{car}, \textit{sign}, indicating a high reliability when given high confidence. And OOD data is often be classified as \textit{plants}, \textit{car} or \textit{bike}, which is influenced by model classification performance and feature similarity.
%
%An ideal trust score should provide reliable prediction when it is high. So we first explore how model performances are influenced by wrong prediction and OOD data with $\delta >0.9$, as shown in Fig. \ref{fig:iocw}(a). It is easy to understand the nPRE of C/W considering OOD data is the lowest line. As we compare C/W considering OOD and C/W ignoring OOD, we can find nPRE evidently improves for \textit{car} and \textit{bike}, indicating these classes are easier to be influenced by OOD data. As we compare C/W considering OOD and ID/OOD, we can find nPRE evidently improves for \textit{plants} and \textit{fence}, indicating these classes suffer wrong prediction more severely. 
%
%We also need to analyze the ability of trust scores to distinguish ID/OOD and C/W, as shown in Fig. \ref{fig:iocw}(b). For OOD detection we can find that \textit{bike}, \textit{plants}, and \textit{fence} are hard to distinguish with OOD classes. The reason may be feature confusion with our defined OOD classes, which will be discussed in feature space analysis. For failure detection most classes reflect few difference between considering OOD and ignoring OOD, where bike is suffer the influence of OOD data obviously. The C/W nAUROC is low for \textit{sign}, \textit{bike}, and \textit{fence}, meaning that the ability to distinguish C/W is relevant to the classification performances.

%\begin{figure}[t]
%	\centering
%	\includegraphics[scale=0.52]{fig-iou roc.pdf}
%	\caption{IoU vs. confidence AUROC of each class using Cylinder3D. The result shows that OOD detection ability have a positive relationship with model performance.}
%	\label{fig:iou roc}
%	\vspace{-4mm}
%\end{figure}

\subsection{Feature space analysis}

%Experimental results show that although the scale of training data is a key factor, model performance could be greatly affected by intra-class diversity and inter-class ambiguity. Hard classes are found that even with large training samples, they could be hard to achieve high classification accuracy or easy to be confused with others. 
%Through feature space analysis, it is understood that semantic and sensory gap are among the underlying reasons. 
%On the other hand, facing dual challenges of class imbalance and OOD, the model is difficult to predict whether the classification result is correct or wrong, or whether the data is an ID or OOD. With the current trust scoring methods, low trust score could be yielded by either OOD or an ID of wrong classification result, whereas high trust score could be given by an insufficiently trained model on wrong predictions too. 

The validity of trust scores, namely, the failure detection and OOD detection abilities, are also relevant to the feature description of the models. We have found that \textit{bike}, \textit{plants}, and \textit{fence} are hard to distinguish from OOD classes in the experimental results. Therefore, we analyse the feature distribution of OOD classes and ID classes, as shown in Fig. \ref{fig:feature-exp2}.

The OOD detection performance is affected by the feature confusion between the predictive class and the OOD data. Similar to Experiment 1, the feature distribution of classes also determines the OOD detection performance. As we define \textit{people} and \textit{rider} as OOD classes, ID classes such as \textit{plants} and \textit{bike} have feature confusion with OOD classes to a degree, making it difficult to distinguish the OOD data. This result can explain the ID/OOD AUROC differences in our experiment.

We also find that the proposed TSD analysis can appropriately evaluate the feature confusion, failure and OOD detection performances. As illustrated in Fig. \ref{fig:distrib}, \textit{bike}, \textit{plants}, \textit{fence} and \textit{building} demonstrate examples of the worst performance, which corresponds to Fig. \ref{fig:feature-exp2}(c), where features of these classes are easily confused with OOD classes. In contrast, features of \textit{road}, \textit{sign}, \textit{pole} are far away from the OOD classes, whereas \textit{car} is slightly confused with the OOD classes, which also corresponds to the TSD analysis.

In addition, trust scores are not reliable for classes whose features are confused with other classes. Using wPre with $\delta$=0.9, as shown in Fig. \ref{fig:iocw}(d-f), we find that plants have poor precisions in all three tasks, which means that the reliability of \textit{plants} prediction is limited even though it gives a high confidence value. The features of \textit{plants} are severely confused with other classes in Fig. \ref{fig:feature-exp2}(a)(c), which explains the results. In addition, if features are confused with OOD classes, they will be influenced by OOD data more easily. As our analysis shows  in Fig. \ref{fig:iocw}(f), \textit{car}, \textit{plants} and \textit{bike} are most affected by OOD, while their features are also confused with OOD classes to different degrees.

From the feature space analysis, we can give a systematic summary. The validity of trust scores is also greatly affected by feature confusion among classes, which makes failure detection and OOD detection more challenging.

%- \textbf{Feature vectors of OOD classes are likely to have small norm.} In feature space, feature vectors of OOD classes distribute nearby the origin of coordinates.

\section{Discussion} \label{sec:6}

\subsection{The class imbalance problem}

Real-world scenes are occupied with various objects in different proportions. Although \textit{people}, \textit{rider}, \textit{bike}, \textit{sign}, etc. occupy small proportions in the scenes, and subsequently with 3D LiDAR data, precise perception of these objects is essential for an autonomous agent to traverse safely and smoothly in populated environments. However, due to the small number of data samples of these categories, their models could be under-trained, and their classification failure could be underestimated. Another factor that aggravates the class imbalance problem of 3D LiDAR datasets is the method of data measurement. The objects close to the sensor are measured with much higher point density than far objects. For autonomous driving applications, data are usually sensed from on-road viewpoints, yielding a very high percentage of LiDAR points on roads and nearby vegetation. This poses a huge challenge for training 3DSS models and evaluating performances that are truly meaningful to real-world applications. 

Class imbalance is a general problem in the deep learning domain. Although many methods have been developed, the class imbalance problem is far from being solved in 3DSS tasks. Model performance on small classes needs more attention, and studies to improve the performance of both large and small classes are needed. 


%Class imbalance has been known as a general problem in deep learning domain. Although a lot of methods have been proposed to alleviate the class imbalance, this problem cannot be totally eliminated in real-world application, such as driving-scene 3D semantic segmentation. The direct influence of class imbalance is the data insufficience of some classes, which causes poor classification and OOD detection performance of these classes. 

%To further overcome the problem, deep learning models are required to extract valid feature description of small classes. Some research directions can help, such as self-supervised learning [], few-shot learning []. However, these methods are still at an initial stage, and few studies apply these methods to 3D semantic segmentation task. 

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.33]{fig-6.pdf}
	\vspace{-3mm}
	\caption{Examples of intraclass diversity and interclass ambiguity.}
	\label{fig:6}
	\vspace{-4mm}
\end{figure}
     
\subsection{Intraclass diversity and interclass ambiguity}

Experimental results show that even for some classes having a large number of training samples, their model performance is unpleasant, e.g. hard to achieve high classification accuracy or are easy to confuse with others, such as \textit{fence} and \textit{plants}. On the other hand, even though some classes are trained on fewer samples, their model performance surpasses other classes, such as \textit{people} and \textit{rider}. Through feature space analysis, it is found that intraclass diversity and interclass ambiguity are among the main reasons, which reveals that there are large semantic and data gaps in the data. 

As illustrated in Fig. \ref{fig:6}, although some objects belong to the same semantic class, they may have various shapes, e.g., \textit{trunk} with straight and forked branches, \textit{plants} with nature and trimmed crowns. In these cases, the semantic category $y$ is the same, whereas the sensor data $x$ are very different, which yields a large semantic gap. Conversely, some objects are of different semantic categories, whereas due to partial observation, occlusion and/or low-resolution point sampling, their data could present similar features, such as \textit{people} and \textit{rider}, \textit{pole} and straight \textit{trunk} with its crown occluded. In these cases, the semantic category $y$ are different, whereas sensor data $x$ are very similar, which is called the data or sensory gap. Properly defining semantic classes is essential to reduce both the semantic and data gaps and leads to a fundamental solution to the intraclass diversity and interclass ambiguity problem. Unsupervised category discovery could be one of our future research topics.


%Deep models are required to deal with unseen objects and new scenes in real-world application, which means a valid uncertainty measure and OOD detector are indispensable. In our experiments, we find that the validity of confidence, uncertainty and the ability of OOD detector are relevant to the model performances. This result shows two direction to improve OOD detection: improve the performance of deep learning models, or design better uncertainty quantification.

%In addition, expect for OOD detection using confidence or uncertainty scores, there are some other methods such as GAN [], Auto Encoder []. There is also becoming a limitations in our experiments that not considered these methods. However, OOD detection using for 3D semantic segmentation task is an important topic but have not been adequately studied.

\subsection{Can 3DSS results be trusted}

For safety-critical applications such as autonomous driving, when compared to improving the overall statistical accuracy of 3DSS and/or OOD detection, it is more important to understand whether the current prediction results are trustworthy. Many metrics have been developed for such a purpose, where Softmax confidence, uncertainty, ODIN and Mahalanobis distance are among the most popular metrics, as discussed in earlier sections. These metrics use a 3DSS model's output at the intermediate or final layers and estimates a trust score on whether the prediction of semantic class is correct or whether it is an ID/OOD data. Many methods have been developed to find or calibrate metrics, such that a high score reflects that the model is confident of the result, whereas a low score shows that the model is unsure and thus could be either a wrong prediction on the semantic class or an unseen object in the training data (OOD). 

However, the performance of such trust scoring methods depends on both the metrics and the 3DSS model. Faced with the dual challenges of class imbalance and OOD data, the performance of a 3DSS model on each class could be much different, including both well-learnt and poorly-learnt classes. For the poorly-learnt classes, high trust scores could also be given on those wrong classified ID categories and OOD, making it hard to capture a correct understanding of the trustworthiness of the 3DSS results. A meticulous design of the metrics that addresses the 3DSS model's various performances on each semantic class is required, which may lead to a more pinpointed understanding of whether 3DSS results can be trusted. More studies are needed in the future.


%Semantic gap means human can recognize an object based on the prior knowledge which may not provided by the input data, whereas a machine does not, causing that different object may be confused with each other because of similar local features. For example, as shown in the right-up of Fig. \ref{fig:4-4}, points of a trunk, which looks very similar to points of a pole from the data appearance. Meanwhile, data gap is also existing in dataset, which means samples of a class may have very different features, such as the points of plants in the left of Fig. \ref{fig:4-4}.

%Semantic gap and data gap are also nonnegligible factors that influence model performance and OOD detection. How to define dataset classes scientifically is also worthy to be studied. On the other hand, the class definition differences among different 3D point cloud datasets bring great difficulties in developing a general category list for dataset sharing, which is required to be scientific studies at the communities' level.

\section{Conclusion and Future Work}

This work aims to explore the relationship among class imbalance, 3DSS model performance, failure and the OOD detection ability for 3D semantic segmentation tasks and to analyse the underlying reasons for these performances. For these purposes, we conduct two experiments and conduct both a confusion and feature analysis of each class. For experiments and analysis, we introduce a data augmentation method for the 3D LiDAR dataset, create the AugKITTI dataset based on SemanticKITTI and SemanticPOSS, and propose the ${\rm wPre}$ metric and a TSD for confusion analysis. The major findings from the above experimental studies are as follows:

\begin{enumerate}
	\item The classes are imbalanced not only in terms of their data size but also in terms of the basic properties of each semantic category. In other words, in addition to the training data size, the nature of each semantic class could be another key factor that greatly affects the model performance.
	
	\item The intraclass diversity and interclass ambiguity make class learning difficult and greatly limits model performance, causing the semantic and data gap challenge.
	
	\item Trust scores are unreliable for classes whose features are confused with other classes. For these classes, high trust scores could also be given on those wrongly classified ID classes and OOD, making the 3DSS predictions unreliable and creating a challenge of judging the 3DSS results to be trustful.
	
\end{enumerate}

For real-world 3D semantic segmentation with complex scenes, deep models are required to address the class imbalance problem, have an awareness when the model is uncertain and detect unseen objects. This work examines the performance of representative 3DSS models, and the results show that there are still challenges for real-world applications using deep learning models. From the experimental results, three directions can be explored for improving OOD detection, improving 3DSS model performance, designing thresholding scores, and alleviating the intraclass diversity and interclass ambiguity in training data. However, this study only considers a small portion of the 3DSS methods and trust scoring methods with manually chosen OOD classes. In the future, we would like to consider more types of failure and OOD detection methods and try to develop a practical failure and OOD detector for real-world 3D semantic segmentation task.


\bibliographystyle{IEEEtran}
\bibliographystyle{unsrt}
\bibliography{refs}

%\vspace{-16 mm}
%\begin{IEEEbiography}
%	[{\vspace{-10 mm}\includegraphics[width=1.0in,height=1.0in,clip,keepaspectratio]{bio-photos/bio-panyancheng}}]{Yancheng Pan}
%	received B.S. degree in computer science (machine intelligence) from Peking University, Beijing, China, in 2020, where he is currently pursuing the M.S. degree with the Key Laboratory of Machine Perception (MOE), Peking University.
%	His research interests include intelligent vehicles, computer vision, 3D LiDAR perception and uncertainty estimation.
%\end{IEEEbiography}

\vspace{-12 mm}
\begin{IEEEbiography}
	[{\vspace{-10 mm}\includegraphics[width=1.15in,height=1.15in,clip,keepaspectratio]{bio-photos/bio-panyancheng}}]{Yancheng Pan}
	received B.S. degree in Artificial Intelligence (artifical intelligence and technology) from Peking University, Beijing, China, in 2020, where he is currently pursuing the M.S. degree with the Key Laboratory of Machine Perception (MOE), Peking University.
	His research interests include intelligent vehicles, computer vision, 3D LiDAR perception and uncertainty estimation.
\end{IEEEbiography}

\vspace{-18 mm}
\begin{IEEEbiography}
	[{\vspace{-10 mm}\includegraphics[width=1.1in,height=1.1in,clip,keepaspectratio]{bio-photos/bio-xiefan}}]{Fan Xie}
	 is currently pursuing B.S. degree in Artificial Intelligence (artifical intelligence and technology) from Peking University, Beijing, China. His research interests include computer vision, deep learning, 3D LiDAR perception and uncertainty estimation.
\end{IEEEbiography}

\vspace{-18 mm}
\begin{IEEEbiography}
	[{\includegraphics[width=1.0in,height=1.0in,clip,keepaspectratio]{bio-photos/bio-zhaohuijing}}]{Huijing Zhao}
	received B.S. degree in computer science from Peking University in 1991. She obtained M.E. degree in 1996 and Ph.D. degree in 1999 in civil engineering from the University of Tokyo, Japan. From 1999 to 2007, she was a postdoctoral researcher and visiting associate professor at the Center for Space Information Science, University of Tokyo. In 2007, she joined Peking University as a tenure-track professor at the School of Electronics Engineering and Computer Science. She became an associate professor with tenure on 2013 and was promoted to full professor on 2020. She has research interest in several areas in connection with intelligent vehicle and mobile robot, such as machine perception, behavior learning and motion planning, and she has special interests on the studies through real world data collection.
\end{IEEEbiography}


% that's all folks
\end{document}

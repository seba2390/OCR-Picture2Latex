
\begin{algorithm}[t!]
   \caption{Iterative ROBD (iROBD)}
   \label{alg}
\begin{algorithmic}[1]
   \STATE {\bfseries Parameter:} $\lambda\ge0$
   \STATE Initialize a ROBD instance with $\lambda_1=\lambda$, $\lambda_2=0$
   \FOR{$t=1$ {\bfseries to} $T$}
   \STATE {\bfseries Input:} $h_t$, $v_{t-k}$
   \STATE Observe $f_{t-k}(y)=h_{t-k}(y-v_{t-k})$
   \STATE $\hat{y}_{t-k} = \mathrm{ROBD}(f_{t-k},\hat{y}_{t-k-p:t-k-1})$\label{line:6}
   \STATE Initialize a temporary sequence $s_{1:t}$
   \STATE $s_{1:t-k} \leftarrow \hat{y}_{1:t-k}$
    \FOR{$i=t-k+1$ {\bfseries to} $t$}
    \STATE $\Tilde{v}_i=\arg\min_v\min_yh_i(y-v)+\lambda c(y,s_{i-1:i-p})$
    \STATE Set $\Tilde{f}_i(y)=h_i(y-\Tilde{v}_i)$
    \STATE $s_i \leftarrow \mathrm{ROBD}(\Tilde{f}_i,s_{i-p:i-1})$
    \ENDFOR
   \STATE $y_t=s_t$
   \STATE {\bfseries Output:} $y_t$ (the action at time step $t$)
   \ENDFOR
w\end{algorithmic}
\end{algorithm}
The main contribution of this paper is the first competitive algorithm for online convex optimization with multi-step delay and nonlinear switching costs. We introduce a new algorithm, Iterative Regularized Online Balanced Descent (iROBD, see Algorithm \ref{alg}) that builds on ideas on ROBD and Optimistic ROBD in order to provide competitive guarantees in a significantly more general and challenging setting. The iROBD algorithm begins from $\hat{y}_{1:T}$, an oracle decision sequence from ROBD where there is no delay. Note that even though ROBD has two parameters $\lambda_1$ and $\lambda_2$, the latter is for practical implementation and redundant in theory. In this way, we use the setting where $\lambda_1=\lambda$ and $\lambda_2=0$, denoting this implementation as ROBD($\lambda$). The algorithmic goal is to make sure the actual decision sequence under delays $y_{1:T}$ stays close to the oracle one. Recall that at time step $t$, after observing $h_t,v_{t-k}$, the available information contains the perfect knowledge of hitting costs $f_{1:t-k}$ and the geometry of unknown hitting costs $f_{t-k+1:t}$, i.e., $h_{t-k+1:t}$. Therefore, the first step of iROBD is to recover what ROBD would do at time step $t-k$ as if it knew $f_{t-k}$ at that time (Line 6).
Given $\hat{y}_{1:t-k}$, the next step is to estimate unknown hitting costs $f_{t-k+1:t}$ (Line 7-13). To do this, iROBD initializes a temporary sequence $s_{1:t}$ which replicates the known part of the oracle sequence, i.e., $s_{1:t-k}=\hat{y}_{1:t-k}$. Then, iROBD iteratively estimates the unknown hitting costs optimistically (Line 9-13), i.e., for each $t-k+1\leq i\leq t$, it estimates the unknown hitting cost function such that running the ROBD algorithm on the temporary sequence would give the smallest cost. Note that, in the first loop $i=t-k+1$, the memory  $s_{i-1:i-p}$ is the same as the oracle sequence but, in later loops ($i=t-k+2,\cdots,t$), the memory contains estimations from previous iterations. After the last iteration ($i=t$), we take $s_t$ as the output action/decision (Line 14). \Cref{fig:temp_seq} depicts the evolution of $s_{1:t}$ in the iterative process.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.6\linewidth]{seq.drawio.pdf}
    \caption{The evolution of the sequence $s_{1:t}$ in iROBD.}
    \label{fig:temp_seq}
\end{figure}
We define some useful notations here. We use a superscript $^{(i)}$ to denote the decision of iROBD in the setting of $i$-step delay. For example, $y_t^{(k)}$ and $y_t^{(0)}$ are decisions of the algorithm at time $t$ in settings of $k$-step delay and no delay respectively. Note that $\hat{y}_t=y_t^{(0)}$ denotes the oracle decision of ROBD without delay. Similarly, $v_t^{(k)}$ is the estimation of the algorithm on the minimizer at time $t$ in the setting of $k$-step delay, while $v_t^{(0)}$ is that in the setting of no delay, that is, the exact minimizer $v_t$. For example, ${v}_t^{(1)}=\arg\min_v\min_yh_t(y-v)+\lambda c(y,y_{t-1:t-p}^{(0)})$, ${v}_t^{(2)}=\arg\min_v\min_yh_t(y-v)+\lambda c(y,y_{t-1}^{(1)},y_{t-2:t-p}^{(0)})$, and ${v}_t^{(3)}=\arg\min_v\min_yh_t(y-v)+\lambda c(y,y_{t-1}^{(2)},y_{t-2}^{(1)},y_{t-3:t-p}^{(0)})$ and so on. Therefore, we have $f_t^{(i)}(y)=h_t(y-v_t^{(i)})=f_t(y-v_t^{(i)}+v_t^{(0)})$ to be the estimated hitting cost of $i$-step-delay iROBD at time step $t$. And we can immediately get that $y_t^{(i)}=ROBD(f_t^{(i)},y_{t-1}^{(i-1)},y_{t-2}^{(i-2)},\cdots)$. Moreover, let $y_t^*$ denote the offline optimal decision at time step $t$. 

Additionally, the following notation also denote the hitting cost and switching cost: $H_t^{(i)}:=f_t(y_t^{(i)})$, and $M_t^{(i)}:=c(y_{t:t-p}^{(i)})$. Similarly, $H_t^{*}:=f_t(y_t^{*})$, and $M_t^{*}:=c(y_{t:t-p}^{*})$. Our goal is to bound the competitive ratio, i.e.,
\begin{align}
    % \min\limits_{y_1^{(k)}\cdots y_T^{(k)}}
    \frac{\sum_{t=1}^T\left(H_t^{(k)}+M_t^{(k)}\right)}{\sum_{t=1}^T\left(H_t^{*}+M_t^{*}\right)}.\notag
\end{align}

It is worth noting that this iterative estimation process is different than a one-shot optimistic approach on the whole trajectory (which is the most natural extension of the ideas in Optimistic ROBD to multi-step delay), where the online learner optimistically estimates the unknown hitting cost function $f_{t-k+1:t}$ jointly. Intuitively, this is because a per-step greedy policy does not follow the true optimal trajectory in hindsight. This difference, and in particular the iterative nature of the algorithm, is novel and is crucial to achieving a constant competitive ratio.

In the remainder of this section, we first show a general competitive bound on iROBD in the case of nonlinear switching cost and then we probe the tightness of the general bound by considering the special case of linear switching cost.



\subsection{Main Result: Nonlinear Switching Cost with Feedback Delay}

Our main result (\Cref{t.main}) shows that iROBD is a constant competitive algorithm under Lipschitz constraints on the nonlinear switching cost. Following the result we show that the dependence on delay and the nonlinear switching costs are both tight and that the Lipschitz constraints are necessary. 


\begin{theorem} \label{t.main}
Suppose the hitting costs are $m$-strongly convex and $l$-strongly smooth, and the switching cost is given by $c(y_{t:t-p})=\frac{1}{2}\|y_t-\delta(y_{t-1:t-p})\|^2$, where $\delta:\mathbb{R}^{d\times p}\to\mathbb{R}^d$. If there is a $k$-round-delayed feedback on the minimizers, and for any $1\le i\le p$ there exists a constant $L_i>0$, such that for any given $y_{t-1},\cdots,y_{t-i-1},y_{t-i+1},\cdots,y_{t-p}\in\mathbb{R}^d$, we have:
\begin{align}
    \|\theta(a)-\theta(b)\|\le L_i\|a-b\|,\forall a,b\in\mathbb{R}^d,\notag
\end{align}
where $\theta(x)=\delta(y_{t-1},\cdots,y_{t-i-1},x,y_{t-i+1},\cdots,y_{t-p})$, then the competitive ratio of iROBD($\lambda$) is bounded by 
\begin{align}
    O\left((l+2p^2L^2)^k\max\left\{\frac{1}{\lambda},\frac{m+\lambda}{m+(1-p^2L^2)\lambda}\right\}\right),\notag
\end{align}
where $L=\max_i\{L_i\}$, $\lambda>0$ and $m+(1-p^2L^2)\lambda>0$.
\end{theorem}

A detailed proof of \Cref{t.main} is given in \Cref{proofs}. \Cref{t.main} highlights the contrasting impact of memory, feedback, and nonlinear switching cost on the competitive ratio.  Interestingly, feedback delay ($k$) leads to an exponential degradation of the competitive ratio while memory ($p$) and the Lipschitz constant of the nonlinear switching cost ($L$) impact the competitive ratio only in a polynomial manner.

Our proof  exploits the iterative structure of the algorithm, and the key idea is to bound the estimation errors that accumulate from the iterations. Note that this is something that is not necessary in the proofs of competitive ratios in ROBD and Optimistic ROBD, e.g., see \citep{shi2020online}, and leads to significant challenges.

The crucial point about the theorem above is that the competitive ratio does not depend on the time horizon $T$ or the dimension $d$; it only depends on the delay, the memory structure, the convexity and smoothness of the cost functions, and the parameter the algorithm chooses. This means that iROBD is constant-competitive for OCO with feedback delay and structured memory.  It is also interesting to observe that the competitive ratio is exponential in the delay $k$, which highlights that the bound grows quickly as delay grows.  We show later that this is tight, which emphasizes the challenge delay creates for learning. 

The remainder of this section provides insight into the structure and tightness of \Cref{t.main}.  First, we highlight the case where the memory is of length one ($p=1$) and there is no delay.  This corresponds to SOCO with a nonlinear switching cost, a setting which has not been considered previously. The corollary below specializes \Cref{t.main} to this setting. Note that, because there is no delay, iROBD is simply ROBD.

\begin{corollary}\label{c.nonlinear} 
Suppose the hitting costs are $m$-strongly convex and the switching cost is given by $\frac{1}{2}\|y_t-y_{t-1}-\delta(y_{t-1})\|^2$, where $\delta:\mathbb{R}^d\to\mathbb{R}^d$. If there exists a constant $L$ such that
\begin{align}
     \|\delta(a)-\delta(b)\|\le L\|a-b\|,~\forall a,b\in\mathbb{R}^d,\notag
\end{align}
then the competitive ratio of ROBD($\lambda$) is upper bounded by
\begin{align}
     \max\left\{\frac{1}{\lambda},\frac{m+\lambda}{m-L(L+2)\lambda}\right\},\notag
\end{align}
where $\lambda>0$ and $m-L(L+2)\lambda>0$. If $\lambda = \frac{-(m+2L+L^2)+\sqrt{(m+2L+L^2)^2+4m}}{2}$, then the upper bound is \begin{align}
    \frac{1}{2}\left(1+\frac{2L+L^2}{m}+\sqrt{\left(1+\frac{2L+L^2}{m}\right)^2+\frac{4}{m}}\right).\notag
\end{align}
\end{corollary}


The result in the corollary is of particular interest because it is possible to construct a simple example showing a matching lower bound in this setting, highlighting the tightness of the analysis.  Thus, the optimality of ROBD, which has been proven previously for linear switching costs \citep{goel2019beyond}, extends to settings with nonlinear switching costs. Notice that setting of this corollary includes many practical applications, e.g., the drone example in \Cref{example:drone}.

\subsubsection{Globally or Locally Lipschitz}
To discuss the necessity of the Lipschitz assumptions on the function $\delta$ in \Cref{t.main} and \Cref{c.nonlinear}, we remark on the following two cases where the Lipschitz condition is violated globally or locally.

\begin{remark}\label{remark.1}
Consider hitting costs that are $m$-strongly convex and  switching costs given by $c(y_t,y_{t+1})=\frac{1}{2}\|y_t-y_{t-1}-\delta(y_{t-1})\|^2$, where $\delta:\mathbb{R}^d\to\mathbb{R}^d$. Then there exists a $\delta$ function with Lipschitz constant $L$ such that the competitive ratio of any online algorithm is lower bounded by 
\begin{align}
    \frac{1}{2}\left(1+\frac{2L+L^2}{m}+\sqrt{\left(1+\frac{2L+L^2}{m}\right)^2+\frac{4}{m}}\right),\notag
\end{align}
which exactly matches the upper bound in \Cref{c.nonlinear}. One achieves this bound by setting $\delta(y)=Ly$.  The derivation is included in Appendix \ref{appendix.remark1}. Note that the lower bound is of the order $L^2$. Thus, as $L$ becomes larger the competitive ratio grows unboundedly. So, if $\delta$ is very sensitive to small changes the competitive ratio can be very large.
\end{remark}

Note that if the Lipschitz constraint in \Cref{t.main} is not satisfied then one cannot hope to obtain a constant competitive guarantee for any algorithm, even if the magnitude of $\delta$ is arbitrarily small, as we highlight below.

Having talked about a very high global Lipschitz constant, next we are going to show that the competitive ratio would explode even when the Lipschitz constant is high in a very small interval. 

\begin{remark}\label{remark.2} Consider a $1$-dimensional setting ($d = 1$) with hitting cost $(y_t-v_t)^2$ and switching cost $(y_t-y_{t-1}-\delta(y_{t-1}))^2$, where 
\begin{align}
\delta(y)=\begin{cases}
\epsilon, & y\le n\epsilon \\
-\epsilon\cdot\sin\left(\frac{\pi}{\gamma\epsilon}y-\frac{n\pi}{\gamma}-\frac{\pi}{2}\right), & n\epsilon<y\le n\epsilon+\gamma\epsilon\\
-\epsilon, & y>n\epsilon+\gamma\epsilon
\end{cases}\notag    
\end{align}
with $n\in\mathbb{N}^+$ given in advance. Here, $\max_y|\delta(y)|=\epsilon$ and $\delta$ has Lipschitz constant $L=\frac{\pi}{\gamma}$, which can be unboundedly large when $\gamma$ is small.  In Appendix \ref{appendix.remark2} we show that the cost of any online algorithm is no smaller than $2\epsilon^2$ in this setting. Additionally, we show that the cost of the offline optimal is no larger than $3\gamma\epsilon^2$. Thus, the competitive ratio of any online algorithm is no smaller than $\frac{2}{3\gamma}$. By taking $\gamma$ arbitrarily small, the competitive ratio can become arbitrarily large. A detailed proof can be found in Appendix \ref{appendix.remark2}.
\end{remark}

Contrasting the \Cref{remark.1} and \Cref{remark.2}, we can see that the Lipschitz assumptions in \Cref{t.main} and \Cref{c.nonlinear} are necessary to get a bounded competitive ratio, not artificial consequences of the proof approach.

\subsection{Tightness: Linear Switching Cost}
To further explore the tightness of \Cref{t.main}, we now consider the special case of linear switching cost, i.e., where $\delta(y_{t-l:t-p})=\sum_{i=1}^pC_iy_{t-i}$.  In this setting, we can not only provide an upper bound on the performance of iROBD, but can also show a matching lower bound in terms of the dependency on delay.  

Note that the case of linear switching cost is also of interest in its own right. This case corresponds to online convex optimization with feedback delay and structured memory, i.e., $c(y_{t:t-p})=\frac{1}{2}\|y_t-\sum_{i=1}^pC_iy_{t-i}\|^2$, a setting that captures, for example, trajectory tracking problems in discrete time. Consider \Cref{eq:example-2} in Example 2 with $g(x_t)=0$, where a vehicle is tracking some moving object with locations $v_{1:T}$. At each time step $t$, the vehicle measures $v_t$ and takes a move $u_t$. Due to the communication and process delay from the sensor, the vehicle cannot accurately measure $v_t$ in time. Instead, $v_t$ is measured at time $t+k$. 

Our first result here is the following upper bound.

\begin{theorem}\label{t.delay}
Suppose the hitting costs are $m$-strongly convex and $l$-strongly smooth, and the switching cost is given by $c(y_{t:t-p})=\frac{1}{2}\|y_t-\sum_{i=1}^pC_iy_{t-i}\|^2$, where $C_i\in\mathbb{R}^{d\times d}$ and $\alpha=\sum_{i=1}^p\|C_i\|$. If there is a $k$-round feedback delay, then the competitive ratio of iROBD($\lambda$) is
\begin{align}
    O\left( (l+2\alpha^2)^k\max\left\{\frac{1}{\lambda},\frac{m+\lambda}{m+(1-\alpha^2)\lambda}\right\} \right),
\end{align}
where $\lambda>0$ and $m+(1-\alpha^2)\lambda>0$.
\end{theorem}

A proof of \Cref{t.delay} is given in Appendix \ref{appendix.delay}. The bound provided in this theorem resembles that in \Cref{t.main}, but with $C_i$ instead of $L$, making it tighter. Note that obtaining tighter results in this case requires a different proof technique. 

Like in the nonlinear setting, the result for linear switching cost also displays an exponential dependency on delay.  Thus, one may wonder if this dependence is a function of the algorithm or if it is fundamental.  The lower bound result that follows shows that it is fundamental.  

\begin{theorem} \label{t.exp_lowerbound}
Consider hitting costs that are both $m$-strongly convex and $m$-strongly smooth, and switching cost given by $c(y_t, y_{t-1}) = \frac{1}{2}\|y_t - \alpha y_{t-1}\|^2$. If there is a $k$-round feedback delay and $\alpha > 1$, then the competitive ratio of any online algorithm is lower bounded by $\frac{m (\alpha^{2k} - 1)}{\alpha^2 - 1}$.
\end{theorem}

In the study of no-regret online learning \emph{without} switching costs, delay influences regret bounds in a polynomial way, instead of exponentially~\citep{joulani2013online,shamir2017online}.  The contrast provided by the above result highlights that the existence of switching costs (which gives more power to the adversary) and the stronger metric (competitive ratio) makes the impact of delay significantly more dramatic. However, it is also interesting to note that the exponential impact of delay is consistent with what is proven \citep{yu2020competitive} for online control in linear systems, which gives a competitive ratio lower bound $\Omega(\|A\|^k)$ for online control with $k$ steps of delay.

Perhaps surprisingly, for the special case of $c(y_t, y_{t-1}) = \frac{1}{2}\|y_t - y_{t-1}\|^2$ it is possible to break through the exponential dependence on delay, as our final result of the section shows. This case corresponds to the original setting considered in the SOCO literature, e.g., \cite{goel2019online, goel2019beyond}, with the addition of feedback delay.

\begin{theorem}\label{t.poly_upperbound}
Consider hitting costs that are both $m$-strongly convex and $l$-strongly smooth, and the switching costs given by $c(y_t, y_{t-1}) = \frac{1}{2}\|y_t - y_{t-1}\|^2$. When there is a $k$-round feedback delay, there exists an online algorithm that is $poly(k)$-competitive.
\end{theorem}

In Sections \ref{proof.exp} and \ref{proof.poly}, we provide proofs of \Cref{t.exp_lowerbound} and \Cref{t.poly_upperbound} respectively.  
Deep connections between online optimization and online control have emerged in recent years.  However, the reductions developed in the literature to this point, e.g., \citep{goel2019beyond,shi2020online}, have applied only to limited control settings.  In particular, the most general result so far shows that Input-Disturbed Squared Regulators (IDSR) (\Cref{eq:example-1} with a special form of $w_t$: $w_t=B\Bar{w}_t$) can be reduced to online convex optimization with structured memory. Here, we highlight that the addition of feedback delay and nonlinear switching cost to online optimization with memory significantly expands the class of control problems which can be addressed.  We present two different reductions, one which focuses on linear dynamics and a second which focuses on nonlinear dynamics.  


\subsection{Linear Dynamics with Adversarial Disturbances}\label{Delay2OnlineControl}

Our first reduction connects online optimization with delay and memory to a class of linear dynamical system that is more general than possible via reductions in prior work, e.g., in~\citep{goel2019online,shi2020online}. Specifically, we consider 
\begin{equation}
\label{eq:example-1}
\begin{aligned}
    &\min_{u_t}\sum_{t=1}^{T} \frac{q_t}{2}\|x_t\|^2 + \sum_{t=0}^{T-1}\frac{1}{2}\|u_t\|^2 \\
    &\mathrm{s.t.~}\quad x_{t+1}=Ax_t+Bu_t+w_t,
\end{aligned}    
\end{equation}
where $(A,B)$ are in controllable canonical form and $w_t$ is a potentially adversarial disturbance. Note that in \citep{goel2019online} $B$ has to be invertible and \citep{shi2020online} only allows input disturbed systems (i.e., $x_{t+1}=Ax_t+B(u_t+w_t)$). 

\begin{algorithm}[t!]
   \caption{Reduction to OCO with Memory and Delay}
   \label{a.reduction}
\begin{algorithmic}[1]
   \STATE {\bfseries Input:} Transition matrix $A$ and control matrix $B$
   \STATE {\bfseries Solver:} OCO with memory $p$ and delay $p$ algorithm ALG
   \FOR{$t=0$ to $T-1$}
        \STATE {\bfseries Observe:} $x_t$ and $q_{t:t+p-1}$
        \IF{$t>0$}
            \STATE $w_{t-1}\leftarrow x_t-Ax_{t-1}-Bu_{t-1}$
            \STATE $\zeta_{t-1}\leftarrow\psi(w_{t-1})+\sum_{i=1}^pC_i\zeta_{t-1-i}$
        \ENDIF
        \STATE $f_t(y):=\frac{1}{2}\sum\limits_{i=1}^d\sum\limits_{j=1}^{p_i}q_{t+j}\left(y^{(i)}+\zeta_t^{(i)}+r(t+j,i,j)\right)^2$
        \STATE $h_t(y):=\frac{1}{2}\sum\limits_{i=1}^d\sum\limits_{j=1}^{p_i}q_{t+j}\left(y^{(i)}\right)^2$
        \STATE Work out $v_{t-p}\leftarrow\arg\min_vf_{t-p}(y)$
        \STATE Feed $v_{t-p}$ and $h_t$ into ALG
        \STATE Obtain the output of ALG, $y_t$
        \STATE $u_t\leftarrow y_t-\sum_{i=1}^pC_iy_{t-i}$
   \ENDFOR
\end{algorithmic}
\end{algorithm}

Algorithm \ref{a.reduction} presents a reduction from the control problem mentioned above to online convex optimization with structured memory and feedback delay leading to the following theorem. 

\begin{theorem}\label{t.reduction}
Consider the online control problem in \Cref{eq:example-1}. Assume the coefficients $q_{t:t+p-1}$ are observable at step $t$. It can be converted to an instance of OCO with structured memory and feedback delay using Algorithm \ref{a.reduction}. 
\end{theorem} 

A proof of \Cref{t.reduction} is given in Appendix \ref{appendix.reduction1}. This proof splits the disturbance into an input disturbance part, which can be dealt with using approaches in prior work, and a residual part, which leads to the $k$-round delay and requires a new analysis. From the details of the reduction in Algorithm \ref{a.reduction}  we can see that the cost function $f_t$ in the resulting online optimization has a term $r(t+p_i,i,p_i)$ in it, which involves $w_{t+p_i-1}$. Since $p=\max\{p_i\}$, we know that $f_t$ has a $w_{t+p-1}$, which is not revealed until step $t+p$ in our setting, resulting in a $p$-step feedback delay.

\iffalse
\begin{algorithm}[t!]
   \caption{Reduction to OCO with Memory and Delay}
   \label{a.reduction}
\begin{algorithmic}[1]
   \STATE {\bfseries Input:} Transition matrix $A$ and control matrix $B$
   \STATE {\bfseries Solver:} OCO with memory $p$ and delay $p$ algorithm ALG
   \FOR{$t=0$ to $T-1$}
        \STATE {\bfseries Observe:} $x_t$ and $q_{t:t+p-1}$
        \IF{$t>0$}
            \STATE $w_{t-1}\leftarrow x_t-Ax_{t-1}-Bu_{t-1}$
            \STATE $\zeta_{t-1}\leftarrow\psi(w_{t-1})+\sum_{i=1}^pC_i\zeta_{t-1-i}$
        \ENDIF
        \STATE $f_t(y):=\frac{1}{2}\sum\limits_{i=1}^d\sum\limits_{j=1}^{p_i}q_{t+j}\left(y^{(i)}+\zeta_t^{(i)}+r(t+j,i,j)\right)^2$
        \STATE $h_t(y):=\frac{1}{2}\sum\limits_{i=1}^d\sum\limits_{j=1}^{p_i}q_{t+j}\left(y^{(i)}\right)^2$
        \STATE Work out $v_{t-p}\leftarrow\arg\min_vf_{t-p}(y)$
        \STATE Feed $v_{t-p}$ and $h_t$ into ALG
        \STATE Obtain the output of ALG, $y_t$
        \STATE $u_t\leftarrow y_t-\sum_{i=1}^pC_iy_{t-i}$
   \ENDFOR
\end{algorithmic}
\end{algorithm}
\fi

Theorem \ref{t.delay} immediately implies that iROBD provides a constant-competitive online policy for the control problem, even against adversarial disturbances. We also show the state disturbed component of $w_t$ exactly corresponds to multi-round feedback delay in online optimization.  Further, since $cost(ALG)$ and $cost(OPT)$ remain unchanged, the reduction immediately provides competitive policies for the linear system with general adversarial disturbances, based on our constant-competitive algorithm iROBD. To state the result, we define:
\begin{align}
    &q_{min}=\min_{0\le t\le T-1,1\le i\le d}\sum_{j=1}^{p_i}q_{t+j},\notag\\
    &q_{max}=\max_{0\le t\le T-1,1\le i\le d}\sum_{j=1}^{p_i}q_{t+j}.\notag
\end{align}
%and we have the following corollary:

\begin{corollary}
Consider the online control problem in \Cref{eq:example-1}. Assume the coefficients $q_{t:t+p-1}$ are observable at step $t$. Let $\alpha=\sum_{i=1}^p\|{C_i}\|$. The competitive ratio of Algorithm \ref{a.reduction}, using iROBD($\lambda$) as the solver, is
\begin{align}
    O\left((q_{max}+2\alpha^2)^p\max\left\{\frac{1}{\lambda},\frac{q_{min}+\lambda}{q_{min}+(1-\alpha^2)\lambda}\right\}\right).\notag
\end{align}
\end{corollary}

Note that, in this corollary, due to the structure in $(A,B)$, the lengths of delay and memory are both $p$, which is also the same as the controllability index of $(A,B)$. 

\subsection{Nonlinear Dynamics with Delay and Time-varying Costs}

Our second reduction connects online optimization with delay and nonlinear switching cost to the following class of online nonlinear control problems:
\begin{equation}
\label{eq:example-2}
\begin{aligned}
    &\min_{u_t}\sum_{t=1}^{T} f_t(x_t) + \sum_{t=0}^{T-1}\frac{1}{2}\|u_t\|^2 \\
    &\mathrm{s.t.~}\quad x_{t+1}=Ax_t+u_t+g(x_t),
\end{aligned}    
\end{equation}
where $\{f_t\}_{t=1}^T$ is time-variant well-conditioned cost (e.g., trajectory tracking cost), and $g(x_t)$ is the nonlinear dynamics term. At time step $t$, only $f_{1:t-k}$ is known due to communication delays. Many robotic systems can be viewed as special cases of this form, such as pendulum dynamics and quadrotor dynamics~\citep{shi2019neural}. It is immediate to see that, by defining $y_t=x_t$, this online control problem can be converted into an online optimization problem with hitting cost $f_t$ and nonlinear switching cost $c(y_t,y_{t-1})=\frac{1}{2}\|y_t-Ay_{t-1}-g(y_{t-1})\|^2$. 

In this section we present a reduction from this class of online control to online convex optimization with nonlinear switching cost and feedback delay. The reduction implies that Theorem \ref{t.main} immediately gives that iROBD provides a constant-competitive online policy for the control problem, even against adversarial disturbances. 

\begin{remark}
    For simplicity of presentation we consider the trajectory tracking task $f_t(x_t)=\frac{1}{2}(x_t-v_t)^\top Q_t(x_t-v_t)$, where $\{v_t\}$ is the desired trajectory to track. However, the cost itself is not necessarily quadratic.  In fact, our algorithm works for general hitting costs $f_t$, if we know the minimizer and the geometry of the function. In other words, we need the parameters of the function to know its ``shape" and the minimizer to locate the function in the space. In this general setting, we just need to modify Line 4 to Line 6 in \Cref{a.reduction-2} to get the general form:
\begin{itemize}
    \item Line 4: Observe $x_t$, $v_t$ and the geometry of $f_t$. 
    \item Line 5: Set the exact $f_{t-k}$ by its geometry and minimizer $v_{t-k}$.
    \item Line 6: Set function $h_t$ by the same geometry as $f_t$ and minimizer at 0.
\end{itemize}
With this modification, the following results still hold.
\end{remark}

\begin{algorithm}[t!]
   \caption{Reduction to Online Optimization with Nonlinear Switching Cost and Delay}
   \label{a.reduction-2}
\begin{algorithmic}[1]
   \STATE {\bfseries Input:} Nonlinear function $g(x)$
   \STATE {\bfseries Solver:} Online optimization with delay $k+1$ and switching cost algorithm ALG
   \FOR{$t=0$ to $T-1$}
        \STATE {\bfseries Observe:} $x_t$, $v_{t-k}$ and $Q_t$
        \STATE Set $f_{t-k-1}(y)=\frac{1}{2}(y-v_{t-k})^TQ_{t-k}(y-v_{t-k})$
        \STATE Set $h_t(y)=\frac{1}{2}y^TQ_ty$
        \STATE $c(y,y_{t-1}):=\frac{1}{2}\|y-Ax_t-g(x_t)\|^2$
        \STATE Feed $f_{t-k-1}$, $h_t$ and $c(y,y_{t-1})$ into ALG
        \STATE Obtain the output of ALG, $y_t$
        \STATE $u_t\leftarrow y_t-Ay_{t-1}-g(y_{t-1})$
   \ENDFOR
\end{algorithmic}
\end{algorithm}

%Below is our result on the reduction:

\begin{theorem} \label{t.reduction2}
Consider the online control problem in \Cref{eq:example-2}. If $Q_t$ is observable at step $t$, and only the trajectory $v_{1:t-k}$ is known, i.e., there are $k$ steps of feedback delay, then it can be converted to an instance of online optimization with switching cost and feedback delay using \Cref{a.reduction-2}.
\end{theorem}


A proof of \Cref{t.reduction2} is given in Appendix \ref{appendix.reudction2}. The reduction in \Cref{a.reduction-2} results from observing that, after defining $y_t=x_t$, the online control problem in \Cref{eq:example-2} can be converted into an online optimization problem with hitting cost $f_t(y_t)=\frac{1}{2}(y_t-v_t)^TQ_t(y_t-v_t)$ and switching cost $c(y_t,y_{t-1})=\frac{1}{2}\|y_t-Ay_{t-1}-g(y_{t-1})\|^2$. Note that the nonlinear switching cost comes from the nonlinear dynamics, and the delayed feedback is coming from delayed information about the target trajectory $v_{1:t}$, i.e., only $v_{1:t-k}$ is known at time step $t$ due to communication delays.


Given that we have proven that iROBD is a constant competitive algorithm for online optimization with feedback delay and nonlinear switching costs, the reduction above immediately brings a competitive policy for class of online control problem with nonlinear dynamics and delay in \Cref{eq:example-2}. This is because $cost(ALG)$ and $cost(OPT)$ remain unchanged in the reduction. To state this formally, suppose the smallest and largest eigenvalue of positive definite matrix $Q_t$ is $\lambda_{min}(t)$ and $\lambda_{max}(t)$ respectively for $t=1,\cdots,T$. Further, define $\lambda_{min}=\min_{t}\{\lambda_{min}(t)\},~\lambda_{max}=\max_{t}\{\lambda_{max}(t)\}.$
Using this notation, we have the following corollary:

\begin{corollary}
    Consider the online control problem in \Cref{eq:example-2} where the $Q_t$ is observable at step $t$. If $\|Ax+g(x)-Ax'-g(x')\|\le L\|x-x'\|$ for any $x,x'\in\mathbb{R}^n$, then the competitive ratio of Algorithm \ref{a.reduction-2} using iROBD($\lambda$) as the solver is upper bounded by:
    \begin{align}
        O\left((\lambda_{max}+2L^2)^k\max\left\{\frac{1}{\lambda},\frac{\lambda_{min}+\lambda}{\lambda_{min}+(1-L^2)\lambda}\right\}\right).\notag
    \end{align}
\end{corollary}

This corollary implies that competitive control is more challenging when the system has more delay on the target trajectory (bigger $k$), when the cost functions are less smooth (larger $\lambda_{max}$), or if there are bad Lipschitz properties in the dynamics.  These qualitative observations are consistent with those from the robust control and nonlinear control literature~\citep{slotine1991applied,zhou1996robust}.
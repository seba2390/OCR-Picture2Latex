\subsection{Feeding Experiment}
\label{sec:experiment_hri_2016}

\graphicspath{{./}{./images_hri_2016/}}

% ====== Shared Autonomy User Study ======= %
%mean age 26.22, median 22

Building from the results of the grasping study (\cref{sec:experiment_rss_2015}), we designed a broader evaluation of our system. In this evaluation, we test our system in an eating task using a Kinova Mico robot manipulator. We chose the Mico robot because it is a commercially available assistive device, and thus provides a realistic testbed for assistive applications. We selected the task of eating for two reasons. First, eating independently is a real need; it has been identified as one of the most important tasks for assistive robotic arms~\citep{chung_2013}. Second, eating independently is hard; interviews with current users of assistive arms have found that people generally do not attempt to use their robot arm for eating, as it requires too much effort~\citep{herlant_2016}. By evaluating our systems on the desirable but difficult task of eating, we show how shared autonomy can improve over traditional methods for controlling an assistive robot in a real-world domain that has implications for people's quality of life.

We also extended our evaluation by considering two additional control methods: direct teleoperation and full robot autonomy. Direct teleoperation is how  assistive robot manipulators like the Mico are currently operated by users. Full autonomy represents a condition in which the robot is behaving ``optimally'' for its own goal, but does not take the user's goal into account. 

Thus, in this evaluation, we conducted a user study to evaluate four methods of robot control---our POMDP framework, a predict-then-act blending method~\citep{dragan_2013_assistive}, direct teleoperation, and full autonomy---in an assistive eating task. 

\subsubsection{Metrics}
\label{sec:experiment_hri_2016_metrics}
Our experiments aim to evaluate the effectiveness and user satisfaction of each method. % through objective and subjective measures.

\textbf{Objective measures.} We measure the objective efficiency of the system in four ways. \emph{Success rate} identifies the proportion of successfully completed trials, where success is determined by whether the user was able to pick up their intended piece of food. \emph{Total execution time} measures how long it took the participant to retrieve the food in each trial. \emph{Number of mode switches} identifies how many times participants had to switch control modes during the trial (\cref{fig:control_modes}). \emph{Total joystick input} measures the magnitude of joystick movement during each trial. The first two measures evaluate how effectively the participant could reach their goal, while the last two measures evaluate how much effort it took them to do so.

\textbf{Subjective measures.} We also evaluated user satisfaction with the system through subjective measures. After five trials with each control method, we asked users to respond to questions about each system using a seven point Likert scale. These questions, specified in \cref{sec:experiment_hri_2016_procedure}, assessed user preferences, their perceived ability to achieve their goal, and feeling they were in control. Additionally, after they saw all of the methods, we asked users to \emph{rank order} the methods according to their preference. 

\subsubsection{Hypotheses}
\label{sec:hypoths_feeding}

%possible hypoth - if there is a significant effect on success, there will also be a significant effect on rank

As in the previous evaluation, we are motivated by prior work that suggests that more autonomy leads to greater efficiency and accuracy for teleoperated robots~\citep{you_2011, leeper_2012, dragan_2013_assistive, hauser_2013, javdani_2015_rss}. We formulate the following hypotheses regarding the efficiency of our control methods, measured through objective metrics.

\newhypothset

\hypothcounter{Using methods with more autonomous assistance will lead to more successful task completions}{hypoth:feeding_1}

\hypothcounter{Using methods with more autonomous assistance will result in faster task completion}{hypoth:feeding_2}

\hypothcounter{Using methods with more autonomous assistance will lead to fewer mode switches}{hypoth:feeding_3}

\hypothcounter{Using methods with more autonomous assistance will lead to less joystick input}{hypoth:feeding_4}

Feeding with an assistive arm is difficult~\citep{herlant_2016}, and prior work indicates that users subjectively prefer more assistance when the task is difficult even though they have less control~\citep{you_2011, dragan_2013_assistive}. Based on this, we formulate the following hypotheses regarding user preferences, measured through our subjective metrics:

\hypothcounter{Participants will more strongly agree on feeling in control for methods with less autonomous assistance}{hypoth:feeding_5}

\hypothcounter{Participants will more strongly agree preference and usability subjective measures for methods with more autonomous assistance}{hypoth:feeding_6}

\hypothcounter{Participants will rank methods with more autonomous assistance above methods with less autonomous assistance}{hypoth:feeding_7}

Our hypotheses depend on an ordering of ``more'' or ``less'' autonomous assistance. The four control methods in this study naturally fall into the following ordering (from least to most assistance): direct teleoperation, blending, policy, and full autonomy. Between the two shared autonomy methods, policy provides more assistance because it creates assistive robot behavior over the entire duration of the trajectory, whereas blend must wait until the intent prediction confidence exceeds some threshold before it produces an assistive robot motion. %To evaluate the hypotheses listed above, we will assess whether the hypothesis holds for any pair of algorithms.

\subsubsection{Experimental Design}
\label{sec:experiment_hri_2016_design}

\begin{figure*}[t]
\centering
  \begin{subfigure}{0.240\textwidth}
    \includegraphics[width=1.0\textwidth, trim=200 0 700 0, clip=true]{Eating_shared_1.png}
    \caption{Detect}
    \label{subfig:study_1}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.240\textwidth}
    \includegraphics[width=1.0\textwidth, trim=200 0 700 0, clip=true]{Eating_shared_2.png}
    \caption{Align}
    \label{subfig:study_2}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.240\textwidth}
    \includegraphics[width=1.0\textwidth, trim=200 0 700 0, clip=true]{Eating_shared_3.png}
    \caption{Acquire}
    \label{subfig:study_3}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.240\textwidth}
    \includegraphics[width=1.0\textwidth, trim=200 0 700 0, clip=true]{Eating_shared_4.png}
    \caption{Serve}
    \label{subfig:study_4}
  \end{subfigure}
  \caption{Our bite grasping study. A plate with three bites of food was placed in front of users. (\subref{subfig:study_1}) The robot start by detecting the pose of all bites of food. (\subref{subfig:study_2}) The user then uses one of the four methods to align the fork with their desired bite. When the user indicates they are aligned, the robot automatically (\subref{subfig:study_3}) acquires and (\subref{subfig:study_4}) serves the bite.}
  \label{fig:study_ex}
\end{figure*}


To evaluate each robot control algorithm on a realistic assistive task, participants tried to spear bites of food from a plate onto a fork held in the robot's end effector (\cref{fig:study_ex}). For each trial, participants controlled the robot through a joystick and attempted to retrieve one of three bites of food on a plate.

Each trial followed a fixed bite retrieval sequence. First, the robot would move to a pose where its wrist-mounted camera could detect bites of food on the plate. This step ensured that the system was robust to bite locations and could operate no matter where on the plate the bites were located. While the camera captured and processed the scene to identify bite locations, we asked users to verbally specify which bite they wanted to retrieve\footnote{Users verbally specified which bite they wanted for all methods except autonomous, in which the algorithm selects the bite}, which allowed us to identify whether people were able to successfully retrieve their target bite. 

Next, participants used the joystick to position the robot's end effector so that the fork was directly above their target bite. Six DOF control was available in three modes of 2 DOF each (\cref{fig:control_modes}), and participants could switch between modes by pressing a button on the joystick. 

Once they had the fork positioned above their target bite, the participant prompted the robot to retrieve the bite by pressing and holding the mode switch button. The robot would then automatically move straight down to the height of the table, spearing the bite on the fork. Finally, the robot automatically served the bite. 



\subsubsection{Procedure}
\label{sec:experiment_hri_2016_procedure}

We conducted a within-subjects study with one independent variable (control method) that had four conditions (full teleoperation, blend, policy, and full autonomy). Because each participant saw all control methods, we counteract the effects of novelty and practice by fully counterbalancing the order of conditions. Each participant completed five trials for each condition for a total of 20 trials. The bite retrieval sequence described in \cref{sec:experiment_hri_2016_design} was the same in each trial across the four control conditions. The only difference between trials was the control method used for the alignment step, where the fork is positioned above the bite. We measure the metrics discussed in \cref{sec:hypoths_feeding} only during this step.

We recruited 23 able-bodied participants from the local community (11 male, 12 female, ages 19 to 59). After obtaining written consent, participants were given a brief overview of the feeding task, and told the robot may provide help or take over completely. Users then received instruction for teleoperating the system with modal control, and were given five minutes to practice using the robot under direct teleoperation. An eye tracking system was then placed on users for future data analysis, but participant gaze had no effect on the assistance provided by the robot.

As described in \cref{sec:experiment_hri_2016_design}, participants used a joystick to spear a piece of food from a plate on a fork held in the robot's end effector. The different control methods were never explained or identified to users, and were simply referred to by their order of presentation (e.g., ``method 1,'' ``method 2,'' etc.). After using each method, users were given a short questionnaire pertaining to that specific method. The questions were:
\begin{enumerate}
  \item ``I felt in \emph{control}''
  \item ``The robot did what I \emph{wanted}''
  \item ``I was able to accomplish the tasks \emph{quickly}''
  \item ``My \emph{goals} were perceived accurately''\label{question:accurately}
  \item ``If I were going to teleoperate a robotic arm, I would \emph{like} to use the system''
\end{enumerate}
These questions are identical to those asked in the previous evaluation (\cref{sec:experiment_rss_2015}), with the addition of question \ref{question:accurately}, which focuses specifically on the user's goals. Participants were also provided space to write additional comments. After completing all 20 trials, participants were asked to \emph{rank} all four methods in order of preference and provide final comments.

\subsubsection{Results}
\label{sec:results_feeding}
One participant was unable to complete the tasks due to lack of comprehension of instructions, and was excluded from the analysis. One participant did not use the blend method because the robot's finger broke during a previous trial. This user's blend condition and final ranking data were excluded from the analysis, but all other data (which were completed before the finger breakage) were used. Two other participants missed one trial each due to technical issues.


Our metrics are detailed in \cref{sec:experiment_hri_2016_metrics}. For each participant, we computed the task success rate for each method. For metrics measured per trial (execution time, number of mode switches, and total joystick input), we averaged the data across all five trials in each condition, enabling us to treat each user as one independent datapoint in our analyses. Differences in our metrics across conditions were analyzed using a repeated measures ANOVA with a significance threshold of $\alpha=0.05$. For data that violated the assumption of sphericity, we used a Greenhouse-Geisser correction. If a significant main effect was found, a post-hoc analysis was used to identify which conditions were statistically different from each other, with Holm-Bonferroni corrections for multiple comparisons. %compare all pairs of methods with Bonferonni corrections for multiple comparisons.


%sloppy command made it so f values didn't go into margins
\sloppy
\textbf{Success Rate} differed significantly between control methods $(F(2.33, 49.00)= 4.57, p = 0.011)$. Post-hoc analysis revealed that more autonomy resulted in significant differences of task completion between policy and direct $(p = 0.021)$, and a significant difference between policy and blend $(p=0.0498)$. All other comparisons were not significant. Surprisingly, we found that policy actually had a higher average task completion ratio than autonomy, though not significantly so. Thus, we found support \cref{hypoth:feeding_1} (\cref{subfig:trial_success}).

\textbf{Total execution time} differed significantly between methods $(F(1.89, 39.73) = 43.55, p < 0.001)$. Post-hoc analysis revealed that more autonomy resulted in faster task completion: autonomy condition completion times were faster than policy $(p=0.001)$, blend $(p < 0.001)$, and direct $(p < 0.001)$. There were also significant differences between policy and blend $(p < 0.001)$, and policy and direct $(p < 0.001)$. The only pair of methods which did not have a significant difference was blend and direct. Thus, we found support for \cref{hypoth:feeding_2} (\cref{subfig:time}).

\textbf{Number of mode switches} differed significantly between methods $(F(2.30, 48.39) = 65.16, p < 0.001)$. Post-hoc analysis revealed that more autonomy resulted fewer mode switches between autonomy and blend $(p < 0.001)$, autonomy and direct $(p < 0.001)$, policy and blend $(p < 0.001)$, and policy and direct $(p < 0.001)$. Interestingly, there was not a significant difference in the number of mode switches between full autonomy and policy, even though users cannot mode switch when using full autonomy at all. Thus, we found support for \cref{hypoth:feeding_3} (\cref{subfig:num_mode_switches}).

\textbf{Total joystick input} differed significantly between methods $(F(1.67, 35.14) = 65.35, p < 0.001)$. Post-hoc analysis revealed that more autonomy resulted in less total joystick input between all pairs of methods: autonomy and policy $(p < 0.001)$, autonomy and blend $(p < 0.001)$, autonomy and direct $(p < 0.001)$, policy and blend $(p < 0.001)$, policy and direct $(p < 0.001)$, and blend and direct $(p = 0.026)$. Thus, we found support for \cref{hypoth:feeding_4} (\cref{subfig:user_input}).

%\begin{figure}[t]
%\centering
%\begin{subfigure}{0.236\textwidth}
%  \includegraphics[clip=true]{Eating_Trial_Success_noxlabel.pdf}
%  \caption{Trial Success}
%  \label{subfig:trial_success}
%\end{subfigure}
%\,
%\begin{subfigure}{0.236\textwidth}
%  \includegraphics[clip=true]{Eating_Time_noxlabel.pdf}
%  \caption{Time}
%  \label{subfig:time}
%\end{subfigure}
%
%\begin{subfigure}{0.236\textwidth}
%  \includegraphics[clip=true]{Eating_Number_of_Mode_Switches_noxlabel.pdf}
%  \caption{Mode Switches}
%  \label{subfig:num_mode_switches}
%\end{subfigure}
%\,
%\begin{subfigure}{0.236\textwidth}
%  \includegraphics[clip=true]{Eating_Total_User_Input_noxlabel.pdf}
%  \caption{User Input}
%  \label{subfig:user_input}
%\end{subfigure}
%
%\begin{subfigure}{0.236\textwidth}
%  \includegraphics[clip=true]{Eating_Time_with_Assistance_noxlabel.pdf}
%  \caption{Assistance Ratio}
%  \label{subfig:assist_ratio}
%\end{subfigure}
%\begin{subfigure}{0.236\textwidth}
%  \includegraphics[clip=true]{Eating_Rank_noxlabel.pdf}
%  \caption{Method Rank}
%  \label{subfig:rank}
%\end{subfigure}
%\caption{Mean and standard deviation of each algorithm across all users of the (\subref{subfig:trial_success}) task completion ratio, (\subref{subfig:time}) total execution time, (\subref{subfig:num_mode_switches}) number of mode switches, (\subref{subfig:user_input}) total joystick input, (\subref{subfig:assist_ratio}) the ratio of time that robotic assistance was provided, and (\subref{subfig:rank}) the ranking as provided by each user, where 1 corresponds to the most preferred algorithm.}
%  \label{bar_results}
%\end{figure}


\begin{figure}[t]
\centering
\captionsetup[subfigure]{margin={0.7cm, 0pt}, aboveskip=0.5pt,belowskip=+5.pt}
\begin{subfigure}{0.238\textwidth}
  \includegraphics[clip=true]{Eating_Trial_Success_noxlabel_box.pdf}
  \caption{Trial Success}
  \label{subfig:trial_success}
\end{subfigure}
\hfill
\begin{subfigure}{0.242\textwidth}
  \includegraphics[clip=true]{Eating_Time_noxlabel_box.pdf}
  \caption{Time}
  \label{subfig:time}
\end{subfigure}

\begin{subfigure}{0.238\textwidth}
  \includegraphics[clip=true]{Eating_Number_of_Mode_Switches_noxlabel_box.pdf}
  \caption{Mode Switches}
  \label{subfig:num_mode_switches}
\end{subfigure}
\hfill
\begin{subfigure}{0.242\textwidth}
  \includegraphics[clip=true]{Eating_Total_User_Input_noxlabel_box.pdf}
  \caption{User Input}
  \label{subfig:user_input}
\end{subfigure}

\begin{subfigure}{0.238\textwidth}
  \includegraphics[clip=true]{Eating_Time_with_Assistance_noxlabel_box.pdf}
  \caption{Assistance Ratio}
  \label{subfig:assist_ratio}
\end{subfigure}
\hfill
\begin{subfigure}{0.242\textwidth}
  \includegraphics[clip=true]{Eating_Rank_noxlabel_box.pdf}
  \caption{Method Rank}
  \label{subfig:rank}
\end{subfigure}
\caption{Boxplots for each algorithm across all users of the (\subref{subfig:trial_success}) task completion ratio, (\subref{subfig:time}) total execution time, (\subref{subfig:num_mode_switches}) number of mode switches, (\subref{subfig:user_input}) total joystick input, (\subref{subfig:assist_ratio}) the ratio of time that robotic assistance was provided, and (\subref{subfig:rank}) the ranking as provided by each user, where 1 corresponds to the most preferred algorithm. Pairs that were found significant during post-analysis are plotted, where ${*}$ indicates $p<0.05$, ${*}{*}$ that $p<0.01$, and ${*}{*}{*}$ that $p<0.001$.}
 \label{fig:box_results}
\end{figure}





\begin{figure}[t]
  \centering
  \captionsetup[subfigure]{aboveskip=0.5pt,belowskip=+5.pt}
  \begin{subfigure}{0.47\textwidth}
    \includegraphics{Eating_Time_vs_Mode_Switches.pdf}
    \caption{Time vs. Mode Switches}
    \label{subfig:time_vs_mode_switch}
  \end{subfigure}
  \begin{subfigure}{0.47\textwidth}
    \includegraphics{Eating_Time_vs_User_Input.pdf}
    \caption{Time vs. Total Joystick Input}
    \label{subfig:time_vs_joystick}
  \end{subfigure}
  \caption{Time vs.\ user input in both the number of mode switches (\subref{subfig:time_vs_mode_switch}) and joystick input (\subref{subfig:time_vs_joystick}). Each point corresponds to the average for one user for each method. We see a general trend that trials with more time corresponded to more user input. We also fit a line so all points for all methods. Note that the direct teleoperation methods are generally above the line, indicating that shared and full autonomy usually results in less user input even for similar task completion time.}
  \label{fig:time_vs_user_inputs}
\end{figure}


\begin{figure}[t]
  \includegraphics{Eating_Assistance_Ratio_Interp.pdf}
  \caption{Ratio of the magnitude of the assistance to user input as a function of time. Line shows mean of the assistance ratio as a function of the proportion of the trajectory. Shaded array plots the standard error over users. We see that blend initially provides no assistance, as the predictor is not confident in the user goal. In contrast, policy provides assistance throughout the trajectory. We also see that policy decreases in assistance ratio over time, as many users provided little input until the system moved and oriented the fork near all objects, at which time they provided input to express their preference and align the fork.}
  \label{fig:assist_ratio_over_time}
\end{figure}

User reported subjective measures for the survey questions are assessed using a Friedman's test and a significance threshold of $p=0.05$. If significance was found, a post-hoc analysis was performed, comparing all pairs with Holm-Bonferroni corrections.

User agreement on \textbf{control} differed significantly between methods, $\xi^2(3) = 15.44, p<0.001$, with more autonomy leading to less feeling of control. Post-hoc analysis revealed that all pairs were significant, where autonomy resulting in less feeling of control compared to policy $(p<0.001)$, blend $(p=0.001)$, and direct $(p<0.001)$. Policy resulted in less feeling of control compared to blend $(p<0.001)$ and direct $(p=0.008)$. Blend resulted in less feeling of control compared to direct $(p=0.002)$. Thus, we found suppoert for \cref{hypoth:feeding_5}.

User agreement on preference and usability subjective measures sometimeses differed significantly between methods. User agreement on \textbf{liking} differed significantly between methods, $\xi^2(3) = 8.74, p=0.033$. Post-hoc analysis revealed that between the two shared autonomy methods (policy and blend), users liked the more autonomous method more $(p=0.012)$. User ability for achieving goals \textbf{quickly} also differed significantly between methods, $\xi^2{3} = 11.90, p=0.008$. Post-hoc analysis revelead that users felt they could achieve their goals more quickly with policy than with blend $(p=0.010)$ and direct $(p=0.043)$. We found no significant differences for our other measures. Thus, we find partial support for \cref{hypoth:feeding_6} (\cref{fig:survey_questions}).

\textbf{Ranking} differed significantly between methods, $\xi^2(3) = 10.31, p=0.016$. Again, post-hoc analysis revealed that between the two shared autonomy methods (policy and blend), users ranked the more autonomous one higher $(p=0.006)$. Thus, we find support for \cref{hypoth:feeding_7}. As for the like rating, we also found that on average, users ranked direct teleopration higher than both blend and full autonomy, though not significantly so (\cref{subfig:rank}).

%Subjective Control $\xi^2(3) = 15.44, p<0.001$.
%Subjective Goals $\xi^2(3) = 5.12, p=0.163$.
%Subjective Quickly $\xi^2{3} = 11.90, p=0.008$
%Subjective Want $\xi^2{3} = 7.243, p=0.065$



\begin{figure*}[t]
  \includegraphics[clip=true]{Eating_Survey_Questions_Box_Large.pdf}
  \caption{Boxplots for user responses to all survey question. See \cref{sec:experiment_hri_2016_procedure} for specific questions. Pairs that were found significant during post-analysis are plotted, where ${*}$ indicates $p<0.05$, ${*}{*}$ that $p<0.01$, and ${*}{*}{*}$ that $p<0.001$. We note that policy was perceived as quick, even though autonomy actually had lower task completion (\cref{subfig:time}). Additionally, autonomy had a very high variance in user responses for many questions, with users very mixed on if it did what they wanted, and achieved their goal. On average, we see that policy did better then other methods for most user responses.}
  \label{fig:survey_questions}
\end{figure*}






\subsubsection{Discussion}
The robot in this study was controlled through a 2 DOF joystick and a single button, which is comparable to the assistive robot arms in use today.

% Summarize results
As expected, we saw a general trend in which more autonomy resulted in better performance across all objective measures (task completion ratio, execution time, number of mode switches, and total joystick input), supporting \cref{hypoth:feeding_1}--\cref{hypoth:feeding_4}. We also saw evidence that autonomy decreased feelings of control, supporting \cref{hypoth:feeding_5}. However, it improved people's subjective evaluations of usability and preference, particularly between the shared autonomy methods (policy and blend), supporting \cref{hypoth:feeding_6} and \cref{hypoth:feeding_7}. Most objective measures (particularly total execution time, number of mode switches, and total joystick input) showed significant differences between all or nearly all pairs of methods, while the subjective results were less certain, with significant differences between fewer pairs of methods.

% Low task completion ratio
We can draw several insights from these findings. First, autonomy improves peoples' performance on a realistic assistive task by requiring less physical effort to control the robot. People use fewer mode switches (which require button presses) and move the joystick less in the more autonomous conditions, but still perform the task more quickly and effectively. For example, in the policy method, $8$ of our $22$ users did not use any mode switches for any trial, but this method yielded the highest completion ratio and low execution times. Clearly, some robot autonomy can benefit people's experience by reducing the amount of work they have to do.

% Benefit of alignment
Interestingly, full autonomy is not always as effective as allowing the user to retain some control. For example, the policy method had a slightly (though not significantly) higher average completion ratio than the full autonomy method. This appears to be the result of users fine-tuning the robot's end effector position to compensate for small visual or motor inaccuracies in the automatic bite localization process. Because the task of spearing relatively small bites of food requires precise end effector localization, users' ability to fine-tune the final fork alignment seems to benefit the overall success rate. Though some users were able to achieve it, our policy method isn't designed to allow this kind of fine-tuning, and will continually move the robot's end effector back to the erroneous location against the user's control. Detecting when this may be occurring and decreasing assistance would likely enhance people's ability to fine-tune alignment, and improve their task completion rate even further.


Given the success of blending in previous studies~\citep{li_2011, carlson_2012, dragan_2013_assistive, muelling_2015, gopinath_2016}, we were surprised by the poor performance of blend in our study. We found no significant difference for blending over direct teleopration for success rate, task completion time, or number of mode switches. We also saw that it performed the worst among all methods for both user liking and ranking. 
One possible explanation is that blend spent relatively little time assisting users (\cref{subfig:assist_ratio}). For this task, the goal predictor was unable to confidently predict the user's goal for $69\%$ of execution time, limiting the amount of assistance (\cref{fig:assist_ratio_over_time}). Furthermore, the difficult portion of the task---rotating the fork tip to face downward---occurred at the beginning of execution. Thus, as one user put it ``While the robot would eventually line up the arm over the plate, most of the hard work was done by me.'' In contrast, user comments for shared autonomy indicated that ``having help earlier with fork orientation was best.'' 
This suggests that the \emph{magnitude} of assistance was less important then assisting at a time that would have been helpful. And in fact, assisting only during the portion where the user could do well themselves resulted in additional frustration.

Although worse by all objective metrics, participants tended to prefer direct teleoperation over autonomy. This is not entirely surprising, given prior work where users expressed preference for more control~\cite{kim_2012}. However, for difficult tasks like this one, users in prior works tend to favor more assistance~\citep{you_2011, dragan_2013_assistive}. Many users commented that they disliked autonomy due to the lack of item selection, for example, ``While [autonomy] was fastest and easiest, it did not account for the marshmallow I wanted.'' Another user mentioned that autonomy ``made me feel inadequate.''


We also found that users responded to failures by blaming the system, even when using direct teleoperation. Of the eight users who failed to successfully spear a bite during an autonomous trial, five users commented on the failure of the algorithm. In contrast, of the 19 users who had one or more failure during teleoperation, only two commented on their own performance. Instead, users made comments about the system itself, such as how the system ``seemed off for some reason'' or ``did not do what I intended.'' One user blamed their viewpoint for causing difficulty for the alignment, and another the joystick. This suggests that people are more likely to penalize autonomy for its shortcomings than their own control. Interestingly, this was not the case for the shared autonomy methods. We find that when users had some control over the robot's movement, they did not blame the algorithm's failures (for example, mistaken alignments) on the system.



%quotes about shared auton
%I prefered the systems where the robot and I were working together to accomplish the task (shared rank 1)
%Having help earlier with fork orientation was best (system 2) and having no work at all (4) was slightly better then late help
%Having teh robot position the arm correctly and having me only control lateral movements made it easy to use
%Fast movements caused me to rush
%
%
%Auton:
%Even though [auton] is most effective at task - lack of choice makes it unlikable. [policy] was quickest and required least effort while still allowing food item choice
%Would prefer choice of which item
%While it was fastest and easiest, it did not account for the marshmallow I wanted, and it made me feel inadequate
%[Auton] was efficient but I didn't have a chance to control or pick food in my way
%
%Blend:
%Not recognizing my goals
%While the robot would eventually lineup the arm over the plate, most of the hard work was done by me
%[blend] had a lot of issues because the robot took actions not aligned with my goal
%




%Bonferroni corrected values
%\begin{table*}
%  \newcommand{\algoauton}{Auton}
%  \newcommand{\algopolicy}{Policy}
%  \newcommand{\algoblend}{Blend}
%  \newcommand{\algodirect}{Direct}
%  \centering
%  \newcommand{\sigresult}[1]{\bm{#1}}
%  \newcommand{\spssnoval}{\sigresult{<\!0.001}}
%  %\addtolength\tabcolsep{-2.2pt}
%  \begin{tabular}{|c|c|c|c|c|c|c|}
%    \hline
%    %Algorithm & Direct-Blend & Direct-Policy & Direct-Autonomy & Blend-Policy & Blend-Autonomy & Policy-Autonomy
%    Metric & \algoauton-\algopolicy & \algoauton-\algoblend & \algoauton-\algodirect & \algopolicy-\algoblend & \algopolicy-\algodirect & \algoblend-\algodirect \\
%    \hline
%    Success Rate & $1.000$ & $0.780$ & $0.345$ & $0.060$ & $\sigresult{0.021}$ & $1.000$ \\
%    Completion Time & $\sigresult{0.001}$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $1.000$ \\
%    Mode Switches & $0.251$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $0.426$ \\
%    Control Input & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\sigresult{0.026}$ \\
%    Like Rating& $0.630$ & $0.972$ & $1.000$ & $\sigresult{0.012}$ & $1.000$ & $0.431$ \\
%    Ranking & $0.174$ & $1.000$ & $1.000$ & $\sigresult{0.006}$ & $0.564$ & $1.000$ \\
%    \hline
%    \end{tabular} 
%    \caption{Post-Hoc p-value for every pair of algorithms for each hypothesis. For Success rate, completion time, mode switches, and total joystick input, results are from a repeated measures ANOVA. For like rating and ranking, results are from a Wilcoxon signed-rank test. All values reported with Bonferroni corrections. }
%    \label{tab:p_val_results_old}
% % \addtolength\tabcolsep{2.2pt}
%\end{table*}

%Holm-Bonferroni corrected values
%value for success rate of policy-blend: 0.049769999999999995
\begin{table*}
  \newcommand{\algoauton}{Auton}
  \newcommand{\algopolicy}{Policy}
  \newcommand{\algoblend}{Blend}
  \newcommand{\algodirect}{Direct}
  \newcommand{\sigresult}[1]{\bm{#1}}
  \newcommand{\spssnoval}{\sigresult{<\!0.001}}
  \newcommand{\nonsigresult}{\text{NS}}
  \centering
  %\addtolength\tabcolsep{-2.2pt}
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    %Algorithm & Direct-Blend & Direct-Policy & Direct-Autonomy & Blend-Policy & Blend-Autonomy & Policy-Autonomy
    Metric & \algoauton-\algopolicy & \algoauton-\algoblend & \algoauton-\algodirect & \algopolicy-\algoblend & \algopolicy-\algodirect & \algoblend-\algodirect \\
    \hline
    Success Rate & $\nonsigresult$ & $\nonsigresult$ & $\nonsigresult$ & $\sigresult{0.050}$ & $\sigresult{0.021}$ & $\nonsigresult$ \\
    Completion Time & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\nonsigresult$ \\
    Mode Switches & $\nonsigresult$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\nonsigresult$ \\
    Control Input & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\spssnoval$ & $\sigresult{0.004}$ \\
    Ranking & $\nonsigresult$ & $\nonsigresult$ & $\nonsigresult$ & $\sigresult{0.006}$ & $\nonsigresult$ & $\nonsigresult$ \\
    Like Rating& $\nonsigresult$ & $\nonsigresult$ & $\nonsigresult$ & $\sigresult{0.012}$ & $\nonsigresult$ & $\nonsigresult$ \\
    Control Rating& $\spssnoval$ & $\sigresult{.001}$ & $\spssnoval$ & $\spssnoval$ & $\sigresult{0.008}$ & $\sigresult{.002}$ \\
    Quickly Rating& $\nonsigresult$ & $\nonsigresult$ & $\nonsigresult$ & $\sigresult{0.010}$ & $\sigresult{0.043}$ & $\nonsigresult$ \\
    \hline
    \end{tabular} 
    \caption{Post-Hoc p-value for every pair of algorithms for each hypothesis. For Success rate, completion time, mode switches, and total joystick input, results are from a repeated measures ANOVA. For like rating and ranking, results are from a Wilcoxon signed-rank test. All values reported with Holm-Bonferroni corrections.}
    \label{tab:eating_p_val_results}
 % \addtolength\tabcolsep{2.2pt}
\end{table*}

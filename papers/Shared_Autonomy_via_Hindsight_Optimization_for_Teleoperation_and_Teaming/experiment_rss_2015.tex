\subsection{Grasping Experiment}
\label{sec:experiment_rss_2015}

Our first shared-control teleoperation user study evaluates two methods, our POMDP framework and a predict-then-act blending method~\citep{dragan_2013_assistive}, on the task of object grasping. This task appears broadly in teleoperation systems, appearing in nearly all applications of teleoperated robotic arms. Additionally, we chose this task for its simplicity, evaluating these methods on tasks where direct teleoperation is relatively easy.


\subsubsection{Metrics}
\label{sec:experiment_rss_2015_metrics}

Our experiment aims to evaluate the efficiency and user satisfaction of each method.

\textbf{Objective measures.} We measure the objective efficiency of the system in two ways. \emph{Total execution time} measures how long it took the participant to grasp an object, measuring the effectiveness in achieving the user's goal. \emph{Total joystick input} measures the magnitude of joystick movement during each trial, measuring the user's effort to achieve their goal.

\textbf{Subjective measures.} We also evaluated user satisfaction with the system through through a seven-point Likert scale survey. After using each control method, we asked users to rate if they would \emph{like to use} the method. After using both methods, we asked users which they \emph{preferred}.

\subsubsection{Hypotheses}
\label{sec:hypoths_rss_2015}

Prior work suggests that more autonomy leads to greater efficiency for teleoperated robots~\citep{you_2011, leeper_2012, dragan_2013_assistive, hauser_2013, javdani_2015_rss}. Additionally, prior work indicates that users subjectively prefer more assistance when it leads to more efficient task completion~\citep{you_2011, dragan_2013_assistive}. Based on this, we formulate the following hypotheses:
\newhypothset

\hypothcounter{Participants using the policy method will grasp objects significantly faster than the blend method}{hypoth:grasp_1}

\hypothcounter{Participants using the policy method will grasp objects with significantly less control input than the blend method}{hypoth:grasp_2}

\hypothcounter{Participants will agree more strongly on their preferences for the policy method compared to the blend method}{hypoth:grasp_3}


\subsubsection{Experiment Design}
\label{sec:experiment_rss_2015_design}

\begin{figure}[t]
\centering
\includegraphics[width=0.49\textwidth, trim=150 0 200 0, clip=true]{robot_exper_setup.JPG}
\caption{Our experimental setup for object grasping. Three objects - a canteen, block, and glass - were placed on the table in front of the robot in a random order. Prior to each trial, the robot moved to the configuration shown. Users picked up each object using each teleoperation system.}%For each trail, the user was told which of the three objects to pickup.}%They teleoperated the arm to a grasp pose, then pushed a button to close the hand.}
 \label{fig:exper_setup_rss_2015}
\end{figure} 


We set up our experiments with three objects on a table: a canteen, a block, and a cup (\cref{fig:exper_setup_rss_2015}). Users teleoperated a robot arm using two joysticks on a Razer Hydra system. The right joystick mapped to the horizontal plane, and the left joystick mapped to the height. A button on the right joystick closed the hand. Each trial consisted of moving from the fixed start pose, shown in \cref{fig:exper_setup_rss_2015}, to the target object, and ended once the hand was closed.



\subsubsection{Procedure}

We conducted a within-subjects study with one independent variable (control method) that had two conditions (policy, blend). We counteract the effects of novelty and practice by counterbalancing the order of conditions. Each participant grasped each object one time for each condition for a total of 6 trials.

We recruited 10 participants (9 male, 1 female), all with experience in robotics, but none with prior exposure to our system. To counterbalance individual differences of users, we chose a within-subjects design, where each user used both systems.

Users were told they would be using two different teleoperation systems, referred to as ``method1'' and ``method2''. Users were not provided any information about the methods. Prior to the recorded trials, users went through a training procedure: First, they teleoperated the robot directly, without any assistance or objects in the scene. Second, they grasped each object one time with each system, repeating if they failed the grasp. Users were then given the option of additional training trials for either system if they wished.

Users then proceeded to the recorded trials. For each system, users picked up each object one time in a random order. Users were told they would complete all trials for one system before the system switched, but were not told the order. However, it was obvious immediately after the first trail started, as the policy method assists from the start pose and blend does not. Upon completing all trials for one system, they were told the system would be switching, and then proceeded to complete all trials for the other system. If users failed at grasping (e.g. they knocked the object over), the data was discarded and they repeated that trial. Execution time and total user input were measured for each trial.

Upon completing all trials, users were given a short survey. For each system, they were asked for their agreement on a 1-7 Likert scale for the following statements:
\begin{enumerate}
  \item ``I felt in \emph{control}''
  \item ``The robot did what I \emph{wanted}''
  \item ``I was able to accomplish the tasks \emph{quickly}''
  \item ``If I was going to teleoperate a robotic arm, I would \emph{like} to use the system''
\end{enumerate}

They were also asked ``which system do you \emph{prefer}'', where $1$ corresponded to blend, $7$ to policy, and $4$ to neutral. Finally, they were asked to explain their choices and provide any general comments. %User averages for all questions are shown in \cref{fig:survey_means}.

\subsubsection{Results}

\begin{figure}[t]
 % \begin{subfigure}{0.1028\textwidth}
   \includegraphics{grasping_timeplot_box.pdf}
   %\caption{Mean}
 %\label{fig:time_compare}
 %\end{subfigure}
 \hfill
 %\begin{subfigure}{0.34\textwidth}
 %  \centering 
   %\includegraphics[trim=0 0 0 0, clip=true]{images/time_diff_error.pdf}
   \includegraphics[trim=0 0 0 0, clip=true]{grasping_time_diff_scatter_peruser.pdf}
  %\caption{Per-Trial Time Difference}
 %\label{fig:time_diffs}
 %\end{subfigure}

   \includegraphics{grasping_controlplot_box.pdf}
   \hfill
   %\includegraphics[trim=0 0 0 0, clip=true]{images/control_diff_error.pdf}
   \includegraphics[trim=0 0 0 0, clip=true]{grasping_control_diff_scatter_peruser.pdf}
   \caption{Task completion times and total input for all trials. On the left, box plots for each system. On the right, the time and input of blend minus policy, as a function of the time and total input of blend. Each point corresponds to one trial, and colors correspond to different users. We see that policy was faster $(p<0.01)$ and resulted in less input $(p<0.05)$. Additionally, the difference between systems increases with the time/input of blend.}
 \label{fig:time_control_plots}
 \end{figure}


\begin{figure}[t]
   \centering 
   \begin{subfigure}[b]{0.29\textwidth}
     \centering 
     \includegraphics[trim=0 0 0 0, clip=true]{grasping_Survey_Questions_box.pdf}
      \caption{ }
     \label{subfig:survey_means}
   \end{subfigure}
   \hfill
   \begin{subfigure}[b]{0.19\textwidth}
     \centering 
     \includegraphics[trim=0 0 0 0, clip=true]{grasping_pref_vs_like.pdf}
      \caption{ }
      \label{subfig:prev_vs_like}
   \end{subfigure}
   %\includegraphics[trim=0 0 0 0, clip=true]{images/survey_plot_means.pdf}
   \caption{(a) Means and standard errors from survey results from our user study. For each system, users were asked if they felt in \emph{control}, if the robot did what they \emph{wanted}, if they were able to accomplish tasks \emph{quickly}, and if they would \emph{like} to use the system. Additionally, they were asked which system they \emph{prefer}, where a rating of 1 corresponds to blend, and 7 corresponds to policy. We found that users agreed with feeling in control more when using the blend method compared to the policy method $(p<0.01)$. (b) The \emph{like} rating of policy minus blend, plotted against the \emph{prefer} rating. When multiple users mapped to the same coordinate, we plot multiple dots around that coordinate. Colors correspond to different users, where the same user has the same color in \cref{fig:time_control_plots}. }
 \label{fig:survey_means}
 \end{figure}



Users were able to successfully use both systems. There were a total of two failures while using each system - once each because the user attempted to grasp too early, and once each because the user knocked the object over. These experiments were reset and repeated.

We assess our hypotheses using a significance level of $\alpha=0.05$. For data that violated the assumption of sphericity, we used a Greenhouse-Geisser correction. If a significant main effect was found, a post-hoc analysis was used to identify which conditions were statistically different from each other, with Holm-Bonferroni corrections for multiple comparisons.

\textbf{Trial times} and \textbf{total control input} were assessed using a two-factor repeated measures ANOVA, using the assistance method and object grasped as factors. Both trial times and total control input had a significant main effect. We found that our policy method resulted in users accomplishing tasks more quickly, supporting \cref{hypoth:grasp_1} $(F(1,9)=12.98, p=0.006)$. Similarly, our policy method resulted in users grasping objects with less input, supporting \cref{hypoth:grasp_2} $(F(1,9)=7.76, p = 0.021)$. See \cref{fig:time_control_plots} for more detailed results.

%blend took on average $55\%$ longer than policy. 13.37s to 8.60s
%blend resulted in users applying $70\%$ more control on average. 124.92 to 73.33
%No significant effect was found on the trial run, and no interaction effects were found.

To assess \textbf{user preference}, we performed a Wilcoxon paired signed-rank test on our survey question asking if they would \emph{like} to use each system, and a Wilcoxon rank-sum test on the survey question of which system they \emph{prefer} against the null hypothesis of no preference (value of 4). There was no evidence to support \cref{hypoth:grasp_3}.

In fact, our data suggests a trend towards the opposite: that users prefer blend over policy. When asked if they would \emph{like} to use the system, there was a small difference between methods (blend: $M=4.90, SD=1.58$, policy: $M=4.10, SD=1.64)$. However, when asked which system they \emph{preferred}, users expressed a stronger preference for blend ($M=2.90, SD=1.76$). While these results are not statistically significant according to our Wilcoxon tests and $\alpha=0.05$, it does suggest a trend towards preferring blend. See \cref{fig:survey_means} for results for all survey questions.

%We found no evidence to support \textbf{H3}, where a Wilcoxon paired signed-rank test showed no significance. In fact, our data suggests a trend toward the opposite - that users prefer blend over policy. When asked if they would \emph{like} to use the system, there was a small difference between methods. However, when asked which system they preferred directly, users expressed a stronger preference for blend with a mean of $2.90$ on a 1-7 Likert scale. See \cref{fig:survey_means} for results for all survey questions.

We found this surprising, as prior work indicates a strong correlation between task completion time and user satisfaction, even at the cost of control authority, in both shared autonomy~\citep{dragan_2013_assistive, hauser_2013} and human-robot teaming~\citep{gombolay_2014} settings.\footnote{In prior works where users preferred greater control authority, task completion times were indistinguishable~\citep{kim_2012}.} Not only were users faster, but they recognized they could accomplish tasks more quickly (see \emph{quickly} in \cref{fig:survey_means}). One user specifically commented that  ``[Policy] took more practice to learn\ldots but once I learned I was able to do things a little faster. However, I still don't like feeling it has a mind of its own''. 


%other data: 
%wilcox control: (0.0, 0.0072125783459572193)
%wilcox quickly: (5.0, 0.23555891992407951)
%wilcox want: (5.0, 0.1247727360437228)
%wilcox tedious: (6.0, 0.68309139830960874)
%wilcox rating (16.5, 0.47130320504429746)
%wilcox compare(9.0, 0.098458502377584176)

Users agreed more strongly that they felt in \emph{control} during blend ($Z = -2.687$, $p = 0.007$). Interestingly, when asked if the robot did what they \emph{wanted}, the difference between methods was less drastic. This suggests that for some users, the robot's autonomous actions were in-line with their desired motions, even though the user did not feel that they were in control.

Users also commented that they had to compensate for policy in their inputs. For example, one user stated that ``[policy] did things that I was not expecting and resulted in unplanned motion''. This can perhaps be alleviated with user-specific policies, matching the behavior of particular users.


%Fundamentally, we seem to treat a user as a provider of goals, using their actions to infer intent an assist. However, the interface asks them to execute trajectories

Some users suggested their preferences may change with better understanding. For example, one user stated they ``disliked (policy) at first, but began to prefer it slightly after learning its behavior. Perhaps I would prefer it more strongly with more experience''. It is possible that with more training, or an explanation of how policy works, users would have preferred the policy method. We leave this for future work.




\subsubsection{Examining trajectories}

%We also look at traces of trajectories to determine why some users disliked the autonomous policy.

\begin{figure}[t]
  \centering
  \begin{subfigure}{0.233\textwidth}
    \centering 
    \includegraphics[trim=0 0 0 0, clip=true]{user_7_trial_5_eachdim.pdf}
    \caption{Blend}
    \label{fig:user7_blend}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.233\textwidth}
    \centering 
    \includegraphics[trim=0 0 0 0, clip=true]{user_7_trial_2_eachdim.pdf}
    \caption{Policy}
    \label{fig:user7_policy}
  \end{subfigure}
  \hfill
  \caption{User input and autonomous actions for a user who preferred policy assistance, using (\subref{fig:user7_blend})~blending and (\subref{fig:user7_policy})~policy for grasping the same object. We plot the user input, autonomous assistance with the estimated distribution, and what the autonomous assistance would have been had the predictor known the true goal. We subtract the user input from the assistance when plotting, to show the autonomous action as compared to direct teleoperation. The top 3 figures show each dimension separately. The bottom shows the dot product between the user input and assistance action. This user changed their strategy during policy assistance, letting the robot do the bulk of the work, and only applying enough input to correct the robot for their goal. Note that this user never applied input in the `X' dimension in this or any of their three policy trials, as the assistance always went towards all objects in that dimension.}
  \label{fig:user7}
\end{figure}

\begin{figure}[t]
  \centering
  \hfill
  \begin{subfigure}{0.233\textwidth}
    \centering 
    \includegraphics[trim=0 0 0 0, clip=true]{user_6_trial_0_eachdim.pdf}
    \caption{Blend}
    \label{fig:user6_blend}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.233\textwidth}
    \centering 
    \includegraphics[trim=0 0 0 0, clip=true]{user_6_trial_3_eachdim.pdf}
    \caption{Policy}
    \label{fig:user6_policy}
  \end{subfigure}
  \caption{User input and autonomous assistance for a user who preferred blending, with plots as in \cref{fig:user7}. The user inputs sometimes opposed the autonomous assistance (such as in the `X' dimension) for both the estimated distribution and known goal, suggesting the cost function didn't accomplish the task in the way the user wanted. Even still, the user was able to accomplish the task faster with the autonomous assistance then blending. }
  \label{fig:user6}
\end{figure}


Users with different preferences had very different strategies for using each system. Some users who preferred the assistance policy changed their strategy to take advantage of the constant assistance towards all goals, applying minimal input to guide the robot to the correct goal (\cref{fig:user7}). In contrast, users who preferred blending were often opposing the actions of the autonomous policy (\cref{fig:user6}). This suggests the robot was following a strategy different from their own.


%Comments:
%-People were startled during practice when robot started moving on its own. Some went through multiple trials of doing nothing until they interacted with the robot
%
%-Some users tended to ``fight'' the system. Other's worked with it.
%---Maybe show the user input trace, one for each?



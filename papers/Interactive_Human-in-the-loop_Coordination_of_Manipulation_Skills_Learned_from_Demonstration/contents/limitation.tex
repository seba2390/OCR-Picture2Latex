%========================================
\begin{figure}[t!]
    \centering
    \includegraphics[width=0.6\linewidth]{figures/single_demo.png}
    %--------------------
    \caption{Illustration of the generalization problem in Sec.~\ref{subsec:limit-few}. 
Given the single demonstration (in black), the retrieved trajectory (in blue) is significantly displaced w.r.t. the excepted trajectory (in green).}
    \label{fig:single_demo}
    %--------------------
    \vspace{-0.15cm}
\end{figure}
%========================================
%==============================
\section{Current Limitations}\label{sec:limitation}
In this section, we discuss three limitations of the current skill coordination methods that are built upon the TP-HSMM model in Sec.~\ref{subsec:tp-hsmm}. 
These limitations serve as the main motivation for the proposed solution in the subsequent section. 


%==============================
\subsection{Generalization from Very Few Demos}\label{subsec:limit-few}
As described in Sec.~\ref{subsec:tp-hsmm}, the TP-HSMM of a skill is computed as a parameterized average of \emph{all} demos. 
However, when only one or very few demos are provided (compared with the number of frames), 
the resulting model can have over-confident GMMs at different stages of the skill. 
One direct consequence is that the generalization to new scenarios is heavily biased towards this one demo.
As shown in Fig.~\ref{fig:single_demo} for a picking skill, the retrieved trajectory ends up between the new object pose and the demonstrated pose.
Even though this can be mitigated by adding new demos, 
it is still desirable to learn a reasonable model with very few demos,
especially for simple skills such as picking and dropping within free spaces.

%========================================
\begin{figure}[t!]
    \centering
    \includegraphics[width=0.45\linewidth]{figures/branch_gaussian_2p_box.png}
    \includegraphics[width=0.45\linewidth]{figures/branch_svm_2p_box.png}
    %--------------------
    \caption{
Comparison between branch selection based on the Gaussian preconditions (left) 
and the proposed selector (right), 
    for the bin-picking skill with 5 branches (four sides and the center). 
    Note that different colors indicate the predicted branches at that sample point (in dots),
 while the \emph{projected} training data are indicated as diamonds (left).}
    \label{fig:branch_compare}
    %--------------------
    \vspace{-0.15cm}
\end{figure}
%========================================

%==============================
\subsection{Multiple Branches for One Skill}\label{subsec:limit-branch}
Often there are multiple ways of executing the same skill under different scenarios (called \emph{branches}).
For instance, as shown in the experiment, there are five different ways of picking objects from a bin, i.e., approaching with different angles depending on the distances to each boundary.  
Our earlier work~\cite{rozo2020learning} proposed a learning algorithm for TP-HSMM with multiple branches, 
and moreover a precondition model that chooses the best branch based on the first GMMs of all branches.
However, this model requires a large number of demos to cover the area of interest 
and does not generalizes well to new scenarios.
This is mainly due to the usage of Gaussian clustering over few samples in high dimensions. 
Fig.~\ref{fig:branch_compare} illustrates one example of the bin-picking skill described earlier with 5 branches.
It can be seen that the precondition model from~\cite{rozo2020learning} can yield bad choices even close to the demonstrated scenes. 

%==============================
\subsection{Manual Conditioning in Task Graph}\label{subsec:manual-specification}
Lastly, as mentioned in Sec.~\ref{sec:introduction}, complex manipulation tasks often contain various sequences of skills to account for different scenarios. 
A high-level abstraction of such relations is often referred as task networks~\cite{hayes2016autonomously}.
In such networks, a valid plan evolves by transition from one skill to another until the task is solved. 
As shown in Fig.~\ref{fig:framework}, different sequences can share some common skills and one skill may appear several times in the same sequence. 
Even though the graph structure that encapsulates these sequences can be sketched easily, 
the \emph{conditions} on these transitions are particularly difficult and tedious to specify manually. 
Often it is required to modify these conditions whenever the workspace or the goal specification is changed. 

\section{Experimental Results And Discussion}
\label{sec:results}
The results presented in this section test the performance of the Autoencoder model. We evaluate our model using the performance metrics: accuracy, precision, recall, and F1 score, defined as follow: 

\vspace{-5mm}
\begin{align*}
    Accuracy &= \frac{TP+TN}{TP+TN+FP+FN}
\end{align*}
\vspace{-3mm}
\begin{align*}
    Precision &= \frac{TP}{TP+FP}
\end{align*}
\vspace{-3mm}
\begin{align*}
    Recall &= \frac{TP}{TP+FN}
\end{align*}
\vspace{-3mm}
\begin{align*}
    F1 ~Score &= 2 \times \frac{Precision \times Recall}{Precision + Recall}
\end{align*}

In our experiments, a \textit{positive} outcome means an abnormal activity was detected, whereas a negative outcome means a normal activity was detected.
True Positive (TP) refers to an abnormal activity that was correctly classified as abnormal. 
True Negative (TN) refers to a normal activity that was correctly classified as normal.
False Positive (FP) refers to a normal activity that was misclassified as abnormal.
and False Negative (FN) refers to an abnormal activity that was misclassified as normal.

The success of our model is based on measuring the reconstruction error that is produced by any given data point. Figure \ref{fig:recon} shows an example of reconstructed data overlaid the original data that was inserted into the model. %To be clear, the values shown in this graph are not measurements of the reconstruction loss that are shown in Figure \ref{fig:thresh}. This figure only shows the normalized temperature measurement from each data point, that is why they are not being represented in degrees.
In this figure, extremely severe dips in temperature denoted by the blue line (representing our original data) can be noticed. The data reconstructed by the model, represented by the red line, does not dip as much as the original data. This is because our model was not able to reconstruct these points accurately due to the fact that they are anomalies. The reconstruction loss (i.e. different between the original and the reconstructed data), where the model recognizes normal or abnormal behavior, is shown in Figure \ref{fig:thresh}. The figure shows a visualization of the mean-squared-error (MSE) generated by the model after it was given each data point within the test data set. The dotted red line denotes the threshold determined as mentioned in Section \ref{sec:ml-model}. Each data point's actual label is represented either by blue color to denote a normal behavior or red color to denote an anomaly and every data point that lies above the threshold was classified as anomalous. This figure illustrates our model's capability to detect the majority of anomalies by measuring the MSE produced by each data point.

Overall, as shown in Figure \ref{fig:aeresults}, our model was able to attain high performance with over $90\%$ in all metrics. The precision is lower than the recall metric which shows that the model produced slightly more false positives than false negatives. In a smart farming environment, a higher rate of false positives would not have a dramatic affect on the productivity of day to day operations and would ensure a higher number of anomalous situations are detected. A rather problematic situation would be if there were more false negatives than positives. A user would much prefer receiving an alert when nothing was wrong than not receiving an alert and enabling potential harm to occur to the crops and hardware. In the future, we hope to further decrease the number of false positives and negatives in order to fine-tune an overall more accurate model. This can be done by using more training samples.


% \begin{table}[!t]
%     \caption{Results}
%     \centering
%     \begin{tabular}{| c | c | c | c |}
%     \hline
%     Accuracy & Precision & Recall & F1\\ [0.5ex] % inserts table %heading
%     \hline
    
%     98.98\% & 90\% & 92.95\% & 91.45\% \\
    
%     \hline
%     \end{tabular}
%     \label{table:results}
% \end{table}

\begin{figure}[t!]
    \centering
    \includegraphics[width=8cm]{figures/aeresults-v2.png}
    \caption{Performance metrics for Autoencoder Model}
    \label{fig:aeresults}
\end{figure}


\section{Conclusion and Future Work}
\label{sec:conclusion}
Our approach has shown that smart farming anomaly detection can be done at an extremely accurate level by using an Autoencoder. Our approach would allow vast scalability by only requiring non-anomalous data for training. Greenhouses provide controlled environments that create consistent conditions for crops and data collection. Environments such as this are a perfect use case for our approach since the performance of an Autoencoder can drastically improve when provided with large amounts of non-anomalous data. Our approach shows that it may not be entirely necessary for machine learning professionals that are working on anomaly detection within smart farming to be highly concerned with developing models that are trained using labeled data that contains both normal and anomalous data. 

In the future, we will explore more anomaly detection models in order to optimize the system's performance. Once the best model has been selected, the architecture could be brought online to be used and tested with the added interactions of Internet connectivity. By bringing the system online we will have the ability to alert users of potential threats or anomalous behavior. These alerts could be coupled with actuators such as fertilization, watering, video monitoring, etc. The introduction of cameras can be ``used to calculate biomass development and fertilization status of crops" \cite{Walter6148}. They can also be used to allow the system-user to monitor their property from afar. We plan to introduce photo and video monitoring as one of our next steps to improve security and broaden our scope.

\section{Acknowledgements}
\label{sec:ack}
We thank TTU Shipley Farms for allowing to use greenhouse, and setup smart farm testbed. Dr. Brian Leckie and his group were instrumental in our system and early stages of data collection. We are thankful to Ms. Deepti Gupta to provide helpful guidance on dealing with time-series, correlated data and gave input on our model selection. This research is partially supported by the NSF Grant 2025682 at TTU.
\section{Time-Invariant Games}\label{sec:BR}
In this section, we provide sufficient conditions for Nash equilibrium convergence of the best response algorithm for time-invariant games. The best response algorithm in this case becomes 
\begin{align}\label{eq:BR:update}
    x_{i,t+1} = \mathop{\rm{arg min}}_{x_i \in \mathcal{X}_i} \mathcal{C}_{i} (x_i, x_{-i,t}).
\end{align} 
%
% We first show a useful lemma that lays the foundation for the subsequent analysis.
% %
%
%
\begin{proposition}\label{prop:BR}
Suppose that the game $\mathcal{G}$ is $m$-strongly monotone, and $\nabla_i \mathcal{C}_i(x_i,x_{-i})$ is $L$-Lipschitz continuous in $x_{-i}$ 
for every $x_i \in \mathcal{X}_i$, with parameter $m>L \sqrt{N-1}$. 
Then, the best response algorithm \eqref{eq:BR:update} satisfies that
\begin{align}\label{eq:BR:convergence}
    \left\| x_T - x^{*}\right\| \leq \rho^{T-1} \left\| x_1 - x^{*}\right\|,
\end{align}
where $\rho:= \frac{L\sqrt{N-1}}{m}$.
\end{proposition}
%
\begin{proof}
Applying the first order optimality condition to the cost function $\mathcal{C}_i$  at the optimal point $x_{i,t+1}$ and using the update rule \eqref{eq:BR:update}, we have that
%
\begin{align}\label{eq:BR_temp1}
    \langle \nabla_i \mathcal{C}_i (x_{i,t+1},x_{-i,t}),x_i - x_{i,t+1} \rangle \geq 0, \; \; \forall x_i \in \mathcal{X}_i.
\end{align}
%
Since the game is strongly monotone, we have that for all $x_i \in \mathcal{X}_i$,
\begin{align}\label{eq:BR_temp2}
    \langle \nabla_i \mathcal{C}_i (x_{i},x_{-i,t})- \nabla_i \mathcal{C}_i (x_{i,t+1},x_{-i,t}), x_i - x_{i,t+1} \rangle  \nonumber \\
    \geq m \left\| x_i -x_{i,t+1} \right\|^2,
\end{align}
%
which follows from the definition \eqref{eq:strong_monotone} by setting $x=(x_{i},x_{-i,t})$ and $x'=(x_{i,t+1},x_{-i,t})$.
Combining \eqref{eq:BR_temp2} with \eqref{eq:BR_temp1} and replacing $x_i$ with $x_i^{*}$, we get
\begin{align}\label{eq:BR_temp3}
    &m \left\| x_i^{*} -x_{i,t+1} \right\|^2  
    % \leq & \langle \nabla_i \mathcal{C}_i (x_{i}^{*},x_{-i,t})- \nabla_i \mathcal{C}_i (x_{i,t+1},x_{-i,t}), x_i^{*} - x_{i,t+1} \rangle   \nonumber \\
    \leq  \langle \nabla_i \mathcal{C}_i (x_{i}^{*},x_{-i,t}) , x_i^{*} - x_{i,t+1} \rangle .
\end{align}
Summing the both sides of inequality \eqref{eq:BR_temp3} over $i=1,\ldots,N$, we have that
%
\begin{align}\label{eq:BR_temp4}
    & \left\| x_{t+1} - x^{*} \right\|^2 
    \leq  \frac{1}{m} \sum_i \langle \nabla_i \mathcal{C}_i (x_{i}^{*},x_{-i,t}) , x_i^{*} - x_{i,t+1} \rangle \nonumber \\
    & \leq  \frac{1}{m} \sum_i \langle \nabla_i \mathcal{C}_i (x_{i}^{*},x_{-i,t}) - \nabla_i \mathcal{C}_i (x^{*}) , x_i^{*} - x_{i,t+1} \rangle \nonumber \\
    & \leq   \frac{1}{m} \sum_i L \left\| x_{-i,t} - x_{-i}^{*}\right\| \left\| x_{i}^{*} - x_{i,t+1}\right\| \nonumber \\
   & \leq   \frac{L\sqrt{N-1}}{m}   \left\| x_{t} - x^{*}\right\| \left\| x^{*} - x_{t+1}\right\|,
\end{align}
%
where the second inequality follows from the Nash equilibrium condition $\langle \nabla_i \mathcal{C}_i (x^{*}),x_i - x_{i}^{*} \rangle \geq 0 $, $\forall x_i \in \mathcal{X}_i$ and the third inequality is due to the Lipschitz continuous property of the function $\mathcal{C}_i$ in $x_{-i}$.
The last inequality follows from the Cauchy-Schwarz inequality.
Dividing the inequality \eqref{eq:BR_temp4} by $\left\| x_{t+1} - x^{*} \right\|$ yields 
\begin{align}\label{eq:BR_temp5}
    \left\| x_{t+1} - x^{*} \right\| \leq \frac{L \sqrt{N-1}}{m}\left\| x_{t} - x^{*} \right\|.
\end{align}
Note, if $\left\| x_{t+1} - x^{*} \right\| = 0$, then \eqref{eq:BR_temp5} holds trivially. Applying inequality \eqref{eq:BR_temp5} iteratively over $t=1,\ldots,T-1$ completes the proof.
\end{proof}
%
In what follows, we provide some intuition and explain the condition $m>L \sqrt{N-1}$.
First, suppose that $L_1$ is the Lipschitz constant of the function $ \nabla_i \mathcal{C}_i(x)$ with respect to $x$. From its definitions we conclude that $L\leq L_1$. Therefore, the Lipschitz constant $L_1$ provides an upper bound on the variation of the gradients and is always greater than the strongly monotone parameter $m$ which provides a lower bound, i.e., $m\leq L_1$. However, it is still possible to have $m>L \sqrt{N-1} $. For example, if $\mathcal{C}_i$ only depends on $x_i$, we have that $L = 0$ and thus the condition naturally holds as long as $m>0$.

On the other hand, consider the condition $m>L\sqrt{N-1}$ and rearrange the terms to get $L<\frac{m}{ \sqrt{N-1}}$. Recall that $L$ is the Lipschitz constant of the function $\nabla_i \mathcal{C}_i(x_i,x_{-i})$ with respect to $x_{-i}$, which can be interpreted as the maximum influence of the other agents' actions on agent $i$. The condition $L<\frac{m}{ \sqrt{N-1}}$ requires that this influence is small enough for the game to converge.  The presence of multiple agents ($N$ is large) reduces the upper bound on the influence of other agents' actions which , effectively, increases the difficulty of the game.



Note that \cite{facchinei201012} also provides a sufficient condition for convergence of the best response algorithm, that involves the spectral norm of a matrix composed of parameters related to the second-order partial derivative of the cost function.
%
In this work, we analyze the best response algorithm from a different perspective that relies on strong monotonicity to characterize  convergence.
In simple cases such as two-player potential games, it is easy to show that our condition is equivalent to the condition in \cite{facchinei201012}.
However, in general, strong monotonicity  provides a more intuitive condition for convergence. Finally, we experimentally show that when the condition $m>L\sqrt{N-1}$ does not hold, the best-response algorithm may lead to cycles. This result further validates the utility of the proposed condition. 

Proposition \ref{prop:BR} shows that the best response algorithm converges to the Nash equilibrium at an exponential rate. Indeed, it is a no-regret learning algorithm for each agent as well, as shown in the following proposition.

\begin{proposition}\label{prop:BR:no_regret}
Suppose that the game $\mathcal{G}$ is $m$-strongly monotone with parameter $m>L \sqrt{N-1}$, the cost $C_i(x_i,x_{-i})$ is $L_0$-Lipschitz continuous in $x_{-i}$ for every $x_i \in \mathcal{X}_i$, and the diameter of the convex set $\mathcal{X}_i$ is bounded by $D$, for all $i=1,\ldots,N$ Then, the static regret of the best response algorithm satisfies
\begin{align*}
    {\rm{SR}}_i(T) \leq  \sum_{t=1}^T \mathcal{C}_i(x_t) -  \sum_{t=1}^T \min_{x_i}\mathcal{C}_i(x_i,x_{-i,t}) = \mathcal{O}(1).
\end{align*}
\end{proposition}

\begin{proof}
The first inequality holds due to the fact that $\sum_{t=1}^T \min_{x_i}\mathcal{C}_i(x_i,x_{-i,t})\leq \min_{x_i}\sum_{t=1}^T \mathcal{C}_i(x_i,x_{-i,t})$.
% Let $y_i^{*} = \mathop{\rm{argmin}}_{x_i} \sum_{t=1}^T \mathcal{C}_i(x_i,x_{-i,t})$.
% %
% Recalling that $x_{i,t+1} = \mathop{\rm{arg min}}_{x_i} \mathcal{C}_i (x_i, x_{-i,t})$, we have that $\langle \nabla_i \mathcal{C}_i (x_{i,t+1},x_{-i,t}),y_i^{*}  - x_{i,t+1} \rangle \geq 0$. From the definition of regret in \eqref{eq:def:regret:game}, we have that 
% \begin{align*}
%     {\rm{SR}}_i(T) =& \sum_{t=1}^T \Big( \mathcal{C}_i(x_t) - \mathcal{C}_i(x_{i,t+1},x_{-i,t}) \nonumber \\
%     &+ \mathcal{C}_i(x_{i,t+1},x_{-i,t})  -  \mathcal{C}_i(y_i^{*},x_{-i,t})\Big) \nonumber \\
%     \leq & \sum_{t=1}^T \Big( \mathcal{C}_i(x_t) - \mathcal{C}_i(x_{i,t+1},x_{-i,t}) \Big) \nonumber \\
%     &+ \sum_{t=1}^T \langle \nabla_i \mathcal{C}_i(x_{i,t+1},x_{-i,t}),x_{i,t+1} - y_i^{*} \rangle \nonumber \\
%     \leq & \sum_{t=1}^T \Big( \mathcal{C}_i(x_t) - \mathcal{C}_i(x_{i,t+1},x_{-i,t}) \Big) ,
% \end{align*}
% where the first inequality is due to the convexity of the loss function $\mathcal{C}_i(x)$ with respect to $x_i$ and the second inequality follows from the necessary condition of optimality. 
Observe that $\mathcal{C}_i(x_{i,t+1},x_{-i,t})=\min_{x_i}\mathcal{C}_i(x_i,x_{-i,t})$ since $x_{i,t+1}=\mathop{\rm{arg min}}_{x_i \in \mathcal{X}_i} \mathcal{C}_{i} (x_i, x_{-i,t})$. Then, it follows that
%
\begin{align}\label{eq:BR_no_temp1}
    &{\rm{SR}}_i(T) \leq \sum_{t=1}^T \mathcal{C}_i(x_t) -  \sum_{t=1}^T \min_{x_i}\mathcal{C}_i(x_i,x_{-i,t}) \nonumber\\
    & = \sum_{t=1}^T \Big( \mathcal{C}_i(x_t)- \mathcal{C}_i(x_{t+1})+ \mathcal{C}_i(x_{t+1}) - \mathcal{C}_i(x_{i,t+1},x_{-i,t}) \Big) \nonumber \\
    & \leq \mathcal{C}_i(x_1) + \sum_{t=1}^T \Big(\mathcal{C}_i(x_{t+1}) - \mathcal{C}_i(x_{i,t+1},x_{-i,t}) \Big) \nonumber \\
    & \leq  \mathcal{C}_i(x_1) + L_0 \sum_{t=1}^T \left\|x_{-i,t+1} - x_{-i,t}\right\| \nonumber \\
    & \leq  \mathcal{C}_i(x_1) + L_0 \sum_{t=1}^T \left\|x_{t+1} - x_{t}\right\|,
\end{align}
where the second to the last inequality follows from the Lipschitz continuous property of the function $\mathcal{C}_i$ in $x$.
By virtue of \eqref{eq:BR:convergence} in Proposition 1, we have
\begin{align}\label{eq:BR_no_temp2}
    &\left\|x_{t+1} - x_{t}\right\|^2 = \left\|x_{t+1} -x^{*}+x^{*} -x_{t}\right\|^2 \nonumber \\
    &\leq  2 \left\|x_{t+1} -x^{*}\right\|^2 + 2 \left\|x^{*} -x_{t}\right\|^2 
    \leq  2(\rho^2+1)\left\|x_{t}-x^{*} \right\|^2.
\end{align}
Substituting the inequality \eqref{eq:BR_no_temp2} into \eqref{eq:BR_no_temp1}, we have 
\begin{align}\label{eq:BR_no_temp3}
    {\rm{SR}}_i(T) 
    \leq & \mathcal{C}_i(x_1) + L_0 \sum_{t=1}^T \sqrt{2(\rho^2+1)} \left\|x_{t} - x^{*}\right\|  \nonumber \\
    \leq &  \mathcal{C}_i(x_1) + L_0 \sqrt{2(\rho^2+1)} \sum_{t=1}^T \rho^t D \nonumber \\
    \leq & \mathcal{C}_i(x_1)+\frac{ DL_0 \sqrt{2(\rho^2+1)}} {1-\rho},
\end{align}
which completes the proof.
\end{proof}

Proposition \ref{prop:BR:no_regret} indeed provides a stronger bound than the static regret defined in \eqref{eq:def:regret:game}. Instead of comparing to a single best action in hindsight, it compares with a sequence of episode-wise best actions, which is equivalent to the dynamic regret with time-invariant cost functions. This strong result own itself to the best response algorithm.

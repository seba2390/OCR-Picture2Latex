\section{Introduction}\label{sec:introduction}

Designing polynomial-time approximation algorithms with worst-case
guarantees is one of the most common approaches to coping with
$NP$-hard optimization problems.  For many problems, even the
best-achievable worst-case guarantee (assuming $P \neq NP$) is too
weak to be immediately meaningful.
%\footnote{For an exercise in
 % futility, try to convince a practitioner to use an
  %algorithm on the grounds that it is a (worst-case) 2-approximation.}
Fortunately, it has been widely observed that most approximation
algorithms typically compute solutions that are much better than their
worst-case approximation guarantee would suggest
(e.g.~\cite{cormode2010set,rego2011traveling}).
%citation 1: http://dimacs.rutgers.edu/~graham/pubs/papers/ckw.pdf
%citation 2: http://www.sciencedirect.com/science/article/pii/S0377221710006065
Is there a mathematical explanation for this phenomenon?

% When faced with a computationally hard problem, we aim to design
% algorithms with good approximation guarantees in the \textit{worst
%   case}.  However, many real life instances have additional structure
% and many algorithms behave far better than what is theoretically
% predicted by their worst case analysis (probably the most famous such
% example is Dantzig's simplex algorithm for linear
% programming~\cite{spielman2001smoothed}). The
% \textit{beyond-worst-case} analysis of algorithms avoids the
% pessimistic viewpoint of a worst case analysis and explains
% theoretically the success of good (practical) algorithms on many
% instances encountered in real life data.

One line of work addresses this question by restricting attention to
instances that satisfy a {\em stability} condition, stating that there
should be a ``sufficiently prominent'' optimal solution.  
Such conditions are analogs of the ``large margin'' assumptions that are
often made in machine learning theory.
Such assumptions reflect the belief that the instances arising in
practice are ones that have a ``meaningful solution''.  For example,
if we run a clustering algorithm on a data set, it's because we're
expecting that a ``meaningful clustering'' exists.  
The hope is that
formalizing the assumption of a ``meaningful solution'' imposes
additional structure on an instance that provably makes the problem
easier than on worst-case instances.

Several such stability notions have been studied.
In this work, we focus on the most well-studied one, that of {\em
  perturbation-stability}
%Towards this direction, 
introduced by Bilu and Linial~\cite{bilu2012stable}.
% in the context of
%the Maximum Cut problem.
The idea behind the definition is that the optimal solution should be
robust to small changes in the input (e.g., the edge weights of a
graph).  For if this is not true, then a minor misspecification of the
data (which is often noisy in practice, anyways) can change the output of
the algorithm.  
In data analysis, one is certainly
hoping that the conclusions reached are not sensitive to small errors
in the data.
%
%introduced the notion of a \textit{stable instance} for graph
%optimization problems and argued that in many practical situations
%only sufficiently stable instances are of interest.  In particular,
%they argue that interesting instances should have stable solutions:
%the optimal solution should not change if we slightly perturb the
%input. For example, a clustering instance that is meaningful should
%have a solution that stands out; this solution should remain optimal,
%even if the edge weights are slightly inaccurate or noisy. 
An informal definition of $\gamma$-perturbation-stability (henceforth
simply {\em $\gamma$-stability}) is the following:
\begin{definition} [$\gamma$-stability] Given a weighted graph and an
  optimal solution $S^*$ for some problem, we say that the instance is
  {\em $\gamma$-stable} if $S^*$ remains the unique optimal solution, even
  when each edge weight is increased by an (edge-dependent) factor
  between~1 and~$\gamma$.
%any subset of the edge weights are increased by a factor of at most $\gamma$.
\end{definition}
Thus $1$-stability is equivalent to the assumption that the
optimal solution is unique.  The bigger the~$\gamma$, the stronger the
assumption (since there are fewer instances we are required to solve), and hence, the easier the problem.
%just asks for the optimum solution to be unique and as we increase this %parameter $\gamma$, the constraint on $S^*$ becomes more and more difficult to satisfy. 
The basic question is then \textbf{whether sufficiently stable
  instances of computationally hard problems are easier to
  solve}. 
%In particular, whether there exist algorithms that solve
%correctly and in polynomial time all sufficiently stable instances of
%some $NP$-hard problems or whether the approximation guarantee of an
%approximation algorithm improves when the input is stable. 
The ultimate goal is to determine the {\em stability threshold} of a
problem:
%Once we find that some $NP$-hard problems become easier to solve in
%%sufficiently stable instances, the second question is \textbf{what
%%is the 
the smallest value of $\gamma$ such that the problem is
  polynomial-time solvable on $\gamma$-stable instances.
%where the problem 
%threshold of stability needed to solve them exactly in polynomial time
%}. 
We note that there is no general connection between hardness of
approximation thresholds and stability thresholds of a
problem---depending on  the
problem, each could be larger than the other (e.g.,~\cite{balcan2015k}, where even though asymmetric $k$-center cannot be approximated to any
constant factor, it can be solved optimally under 2-stability).
%Two interesting and counterintuitive facts we would like to point out between %approximation and stability are the following:
%\begin{itemize}
%\item There exist problems that are hard to approximate within any constant %factor and yet we can exactly recover optimum even in 2-stable instances~\cite{balcan2015k}.
%
%\item An algorithm $A$ might have worse approximation guarantees than another %algorithm $B$ and yet require a smaller stability threshold for exact recovery~\cite{kleinberg2002approximation,makarychevSODA14,cualinescu1998improved}.
%\end{itemize}
Thus a good approximation algorithm need not recover an optimal
solution in stable instances, and conversely.\footnote{%
%It is easy to
%  see that there is no ``black-box'' connection between the two types
%  of thresholds.  
For a silly example, consider an algorithm that
  checks if an instance is stable (by brute-force), if so returns the
  optimal solution (computed by brute force), and if not returns a
  terrible solution.  Similarly, consider an $\alpha$-approximation
  algorithm that uses brute force to always output a suboptimal
  solution, in every instance where one   within $\alpha$ of optimal
  exists.  For more natural (and polynomial-time) examples,
  see~\cite{balcan2015k,makarychevSODA14}.}



%We prove that given a $p$-extendible independence set system $(X,\mathcal{I})$, where $X$ is our universe consisting of elements $e_i$, each having weight $w_i$ and $\I$ is the set of feasible (called independent) solutions, the standard greedy algorithm can recover exactly the optimum solution for the maximization problem $\max_{S\in \mathcal{I}}\sum_{e\in S} w_e$ if the system is $p$-stable. 


\subsection{Our Results}
%results and structure of the paper}

Two genres of algorithms that are frequently reported to perform much
better on ``real-world'' instances than in the worst case are {\em
  greedy algorithms} and {\em local search algorithms}.  The goal of
this paper is to systematically study these two types of algorithms
through the lens of perturbation-stability.  We carry this out for the
rich and well-motivated class of problems that concern maximizing a
monotone submodular set function subject to downward-closed
feasibility constraints (as in e.g.~\cite{lovasz1983submodular,
  nemhauser1978analysis, fisher1978analysis}).  Both greedy and local
search algorithms can be naturally defined for all problems in this
class.  Special cases include~\cite{mestre2006greedy} $k$-dimensional matching, asymmetric
traveling salesman, influence maximization~\cite{kempe2003maximizing},
welfare maximization in combinatorial auctions (with submodular
valuations)~\cite{lehmann2001combinatorial,vondrak2008optimal}, and so
on.

We organize our results along two different axes: whether the
objective function is additive or submodular, and according to the
``complexity'' of the feasibility constraints.  
For the latter, we use the classic notions of the intersection of
$p$ matroids (for a parameter $p$), the more general notion of
$p$-extendible systems (where a feasible solution can accommodate a
new element after deleting at most $p$ old ones), and the still
more general notion of $p$-systems (where the cardinality of maximal
independent sets can only differ by a $p$ factor).
\hyperref[table-results]{Figure \ref{table-results}} summarizes our main results.  
We also prove that all of our results are tight.

% Two natural questions that motivate our work on stability are:
% \textit{``how does Greedy perform on stable instances?"} and
% \textit{``are all local optima also global optima on stable
%   instances?"}. We prove positive stability and recovery results which
% mostly replicate the known approximation factors of Greedy and Local
% Search, however this analogy is not perfect. A summary of our results
% (old and {\color{red}new}) is presented in
% \hyperref[table-results]{Figure \ref{table-results}}.
\begin{figure}[h!]
	\centering
	\includegraphics[width=14cm,height=6cm]{TESTEPS}
        \caption{Summary of old and new results. 
On the left we have
          previous approximation results about greedy and local
          search          algorithms~\cite{korte1978analysis,nemhauser1978analysis,fisher1978analysis,
            reichel2007evolutionary} and our new local search
          approximation guarantees. (Each table entry indicates the
          worst-case approximation factor.)  On the right are our recovery
          results for greedy and local search algorithms, with each
          table entry indicating the smallest $\gamma$ such that the
          algorithm is optimal in every $\gamma$-stable instance.
All of the results are tight.}
	\label{table-results}
\end{figure}
%Observe the
%          differences between approximation and stability for the
%          different constraint systems. For all our results, there are
%          simple tight counterexamples.}

\hyperref[sec:additive]{Section \ref{sec:additive}} proves our results
for the greedy algorithm in the case of additive objective functions.
An interesting finding here is that for the most general set systems that
we consider ($p$-systems), the greedy algorithm can have an
infinite stability threshold, even though it is a good worst-case
approximation algorithm. In fact, this crucial difference between approximation and stability also led us to give a different characterization of the $p$-extendible systems. Another interesting differentiation between stability and approximation 
shows up in the case of a uniform matroid (cardinality constraints).

\hyperref[sec:submodular]{Section \ref{sec:submodular}} considers the greedy algorithm for
maximizing a monotone submodular function.  As all previous works on
perturbation-stability have considered only problems with additive
objective functions, here we need to formulate a notion of
perturbation-stability for submodular functions, which boils down to
defining the class of allowable perturbations of a submodular
function~$f$.  The ``sweet spot''---neither too restrictive nor too
permissive---turns out to be the set of perturbed
functions~$\tilde{f}$ such that: (i) $\tilde{f}$ is also monotone and
submodular; (ii) $\tilde{f}$ is a pointwise approximation of $f$
($\tilde{f}(S) \in [f(S),\gamma \cdot f(S)]$ for every $S$); and (iii)
the marginal value of an element~$j$ with respect to a set $S$ can
only go up (in $\tilde{f}$), and by at most $(\gamma-1)$ times the
stand-alone value of~$j$.\footnote{Each additional constraint on
allowable perturbations $\tilde{f}$ weakens the stability assumption, resulting in a harder
  problem.  For example, if one only assumes~(i) and~(ii) and
  not~(iii), then the problem becomes ``too easy'', and every
  $\alpha$-approximation algorithm automatically recovers the optimal
  solution in $\alpha$-stable instances.  If~(iii) is replaced by the
  stronger condition that all marginal values change by a factor in
  $[1,\gamma]$, the problem becomes ``too hard'', with no positive
  recovery results possible (essentially because zero marginal values
  in $f$ must stay zero in $\tilde{f}$).}  
This definition specializes to the usual one in
the special case of additive functions.  
%In data analysis applications
%where a submodular function is estimated from data
%(e.g.~\cite{backstrom2006group}), one would indeed hope to obtain
%results that are robust to perturbations of this type. 
Towards the end of this section, we also present an application for the welfare maximization problem, for which a weaker stability assumption is sufficient to guarantee recovery of the optimal allocation.

\hyperref[sec:local search]{Section~\ref{sec:local search}} identifies the smallest $\gamma$ such
that all local optima of $\gamma$-stable instances are also global
optima, with both additive and submodular functions.  A byproduct of
our results here is new tight worst-case approximation guarantees for
local search in $p$-extendible systems, which surprisingly were not
known previously.  The tight approximation guarantees are $p^2$ for
additive functions and $p^2+1$ for monotone submodular functions.

% our study on stability (\hyperref[sec:local
% search]{Section \ref{sec:local search}}), we prove that Local Search
% is a $p^2$-approximation for maximizing an additive function $f$ under
% a $p$-extendible system. If $f$ is monotone, submodular the ratio
% becomes $p^2+1$, extending an old result by Nemhauser et
% al.~\cite{nemhauser1978analysis, fisher1978analysis}. In the negative
% side, we prove that Local Search can behave arbitrarily bad for
% approximating solutions under $p$-systems. In terms of exact recovery
% on independence systems, we prove that local optima are indeed global
% optima for a stability threshold which needs to be exactly the same as
% the approximation \textit{worst-case} factor, thus revealing an
% interesting connection between approximation and stability. All of our
% results for Greedy and Local Search are tight.


% In more detail, in \hyperref[sec:additive]{Section \ref{sec:additive}}
% we prove that, for additive functions Greedy exactly recovers
% $p$-stable instances for $p$-extendible
% systems~\cite{mestre2006greedy} (famous problems like welfare
% maximization, $k$-dimensional Matching, Asymmetric Travelling Salesman
% Problem, weighted $\Delta$-Independent Set etc. are cases of
% extendible systems).  For $p$-systems, surprisingly, recovery is not
% possible, even though Greedy is a $p$-approximation and actually
% Greedy can fail even for arbitrarily stable instances. The failure on
% stable $p$-systems motivates the definition of \textit{hereditary}
% $p$-systems: these are $p$-systems that remain such, even after the
% deletion or contraction of elements. It turns out that this is an
% equivalent way of viewing the family of $p$-extendible systems
% (\hyperref[sec:hereditary]{Appendix~\ref{sec:hereditary}}). We then
% extend the \textit{Bilu-Linial} notion of stability for the case of
% submodular functions where we prove similar recovery results for
% Greedy (\hyperref[sec:submodular]{Section \ref{sec:submodular}}). 


\subsection{Further Related Work}

Perturbation-stability was defined by
Bilu and Linial~\cite{bilu2012stable} 
in the context of the \MaxCut\
problem.  Subsequent work on perturbation-stability
includes~\cite{bilu2012practically,makarychevSODA14,angelidakisSTOC17,balcan2012clustering,balcan2015k,awasthi2012center,reyzin2012data,mihalak2011complexity,balcan2010nash}.
Independently of
%We note that prior to the work of 
Bilu and Linial \cite{bilu2012stable}, Balcan, Blum and
Gupta~\cite{balcan2009approximate} introduced the related notion of
%and studied a somewhat similar but different notion of
\textit{approximation stability} in the context of clustering problems
like $k$-means and $k$-median.  
More technically distant analogs of these stability conditions (but
with similar motivation) were proposed by~\cite{ackerman2009clusterability,daniely2012clustering,ostrovsky2006effectiveness}; see
Ben-David~\cite{ben2015computational} for further discussion.
%see http://theory.stanford.edu/~tim/f14/l/l7.pdf for references
%for swamy, use https://www.math.uwaterloo.ca/~cswamy/papers/kmeans-journ.pdf


% .~\cite{garey2002computers}. In \MaxCut, we are given a weighted
% graph $G(V, E, w)$ on $n$ vertices and our goal is to find a cut
% $(S, V \setminus S)$ with the maximum weight of edges crossing
% it. Bilu and Linial~\cite{bilu2012stable} gave an algorithm that
% recovers $O(\sqrt{n\cdot \Delta})$-stable instances of \MaxCut\
% ($\Delta$: maximum degree of $G$). Following the work
% in~\cite{bilu2012stable} and in~\cite{bilu2012practically} for the
% \MaxCut\ problem, Makarychev et al.~\cite{makarychevSODA14} gave an
% exponential improvement over the previous results upon the stability
% needed in order to have recovery. They showed that the standard
% Goemans-Williamson~\cite{goemans1994879} SDP relaxation for \MaxCut\
% (with $\ell_2^2$-triangle inequalities) becomes integral when
% $\gamma=O(\sqrt{\log n}\log \log n)$ by revealing some interesting
% connections with metric embeddings and Bourgain's theorem and
% specifically with the distortion caused when embedding negative type
% metrics into $\ell_1$.

% In the same work, Makarychev et al. also study the classic NP-hard
% partitioning problem of finding the Minimum Multiway Cut with $k$
% terminals (see \cite{dahlhaus1994complexity, buchbinder2013simplex}
% for a summary of known results) and show how to recover 4-stable
% instances via an LP-relaxation. Only recently~\cite{angelidakisSTOC17}
% the recovery threshold was brought down to $2(1-\tfrac{1}{k})$. In the
% same work, they introduce the notion of \textit{metric perturbation
%   resilience} and they explore a wide class of clustering problems
% with natural center-based objectives (including $k$-means, $k$-median,
% $k$-center) providing algorithms for recovering 2-stable
% instances. The previous best bound was due to Balcan and
% Liang~\cite{balcan2012clustering} that recovered $(1+\sqrt{2})$-stable
% instances for center-based objectives. However, for the special case
% of asymmetric $k$-center, Balcan et al.~\cite{balcan2015k} showed that
% 2-stable instances can be recovered and that this result cannot be
% improved. Specifically, recovering even the symmetric $k$-center on
% $(2- \epsilon)$-stable instances is hard unless $NP = RP$.  Another
% surprising relationship between symmetric and asymmetric $k$-center
% instances is that unlike approximation ratio, for which symmetric
% $k$-center is easily solved to a factor of 2 but asymmetric $k$-center
% cannot be approximated to any constant
% factor~\cite{chuzhoy2005asymmetric,vishwanathan1996log}, both
% symmetric and asymmetric $k$-center can be recovered on 2-stable
% instances. This was, to the best of our knowledge, the first problem
% that is hard to approximate to any constant factor in the worst case,
% yet can be optimally solved in polynomial time on Bilu-Linial stable
% instances for a constant value of stability. The above imply there are
% unexpected, non-trivial results and interesting connections between
% approximation and recovery.

%later~\cite{awasthi2012center,balcan2012clustering,reyzin2012data}
%studied a related notion of \textit{perturbation resilience} for these
%center-based clustering problems.

% The authors
% of~\cite{bilu2012stable} focused on the \MaxCut\ problem, for which
% they showed that for stable instances, exact recovery of \MaxCut\ is
% possible. Since then, many results \cite{bilu2012stable,
%   awasthi2012center, balcan2009approximate, balcan2012clustering,
%   balcan2015k, bilu2012practically, makarychev2012approximation,
%   reyzin2012data} in this \textit{beyond-worst-case} analysis of
% algorithms are the exact recovery stable instances of the following
% problems: Minimum Multiway-Cut, \MaxCut\ and symmetric and asymmetric
% $k$-center, $k$-median and $k$-means. There are also results for
% stability in problems such as finding Nash
% equilibria~\cite{balcan2010nash} or the metric traveling salesman
% problem~\cite{mihalak2011complexity}.

% More precisely, in \cite{balcan2015k} the authors first prove that
% 2-stable instances of $k$-center can be recovered exactly in
% polynomial time and then they show that recovering symmetric
% $k$-center on ($2-\epsilon$)-stable instances is hard unless
% $NP = RP$. Surprisingly enough, unlike approximation ratio, for which
% symmetric $k$-center is easily solved to a factor of 2 but asymmetric
% $k$-center cannot be approximated to any constant
% factor~\cite{vishwanathan1996log, chuzhoy2005asymmetric}, both
% symmetric and asymmetric $k$-center can be solved optimally on
% 2-stable instances~\cite{balcan2015k}. This was the first problem that
% is hard to approximate to any constant factor in the worst case, yet
% can be optimally solved in polynomial time under just 2-stability and
% also the first tight result for any problem under Bilu-Linial
% stability, i.e., this was the first time the exact value of the
% threshold, for which the problem transitions from being $NP$-hard to
% efficiently computable was found.

% These findings suggest that thresholds for recovery and approximation can interchange both ways and so the concepts of approximation and stability are different. There are however interesting connections between the two concepts that yield interesting theoretical results: in~\cite{makarychevSODA14} the authors show that the recovery threshold for \MaxCut\ is the same as the approximation threshold for {\sc Sparest Cut}.

% %Finally, we note that although Bilu and Linial~\cite{bilu2012stable}
% %studied real-world clustering problems with \textit{meaningful}
% %solutions on weighted graphs when introducing their stability notion,
% %it is natural to ask a similar question when the function at hand is
% %not additive, but has the \textit{diminishing returns} property,
% i.e. it is submodular. Maximizing monotone and non-monotone submodular
% functions~\cite{lovasz1983submodular, nemhauser1978analysis,
%   fisher1978analysis, schrijver2002combinatorial,
%   buchbinder2014submodular, buchbinder2016constrained,
%   gupta2010constrained} has been widely studied in many different
% settings with applications in social networks analysis, influence
% maximization~\cite{kempe2003maximizing,mossel2007submodularity,
%   barbosa2015power, easley2010networks, chen2009efficient} and welfare
% maximization~\cite{lehmann2001combinatorial,
%   nisan2007computationally}, where greedy performs well and is
% tight~\cite{vondrak2008optimal, feige1998threshold}. However, in real
% world applications, we hardly ever know the \textit{exact} details of
% the submodular function we wish to maximize and we can only get
% estimates for it~\cite{backstrom2006group}. Even though the estimates
% might be just a distorted version of reality and wildly misspecified,
% we would like to have guarantees on the quality of solutions we
% produce. To do so, we may hope that, similarly to clustering,
% submodular functions are robust to noise, i.e. small perturbations
% won't affect their optimum solution. In this work, we also take a step
% towards introducing a sensible stability definition for submodular
% functions which is a generalization of the Bilu-Linial stability and
% proving tight positive recovery results for greedy and local search.





%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:

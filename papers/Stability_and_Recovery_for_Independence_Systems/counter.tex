\section{Counterexamples}\label{sec:counter}

Here are two simple counterexamples that prove the tightness of our Greedy recovery results and our Local Search approximation and recovery results:

\begin{itemize}
\item In the submodular case, we proved greedy recovers $(p+1)$-stable $p$-extendible systems. Here is a simple example of a matroid (1-extendible) where Greedy and Local Search fail to recover the optimal solution even though it is 2-stable (also notice that here, Greedy and Local Search give a 2-approximation):  Take $A_1=\{x,\epsilon_1\}, B_1=\{y\}, A_2=\{\epsilon_2\}, B_2=\{x\}$ as in~\cite{filmus2012power}. Assign $w(x)=w(y)=1$ and $w(\epsilon_1)=\epsilon, w(\epsilon_2)=\epsilon$ for some small $\epsilon>0$ (and so $w(A_1)=1+\epsilon$) and consider the partition matroid whose independent sets can only contain one of $\{A_i,B_i\}, i=1,2$. Observe that $\{A_1,A_2\}$ is a local optimum with value $1+2\epsilon$, whereas the global optimum is $\{B_1,B_2\}$ with value 2. Also notice that the same solution is produced by the Greedy algorithm and that the instance can be $(2-\epsilon')$-stable for any small $\epsilon'>0$.

\item Local Search is a $p^2$-approximation for $p$-extendible systems. Look at \hyperref[counter1]{Figure~\ref{counter1}} for a tight counterexample (just for simplicity, we have the $p=2$ case; it generalizes readily).
\end{itemize} 


\begin{figure}[h!]
	\centering
	\includegraphics[width=5cm,height=4cm]{IMAGE1}
        	\caption{Local Search is a 4-approximation for this 2-extendible system $(X,\I)$: Let $A=\{a_1,a_2\}$ be feasible and assign $w(a_1)=w(a_2)=1+\epsilon$ and $w(b_i)=2, \forall i\in\{1,2,3,4\}$. The constraints are: $a_1\cup B_1 \notin \I, a_2\cup B_2 \notin \I $, $a_i\cup B_j \in \I$ for $i\neq j$ and $A\cup b_i\notin \I,\forall i\in\{1,2,3,4\}$. Observe that $A$ is a local optimum ($(2,1)$-swaps) with value $2+2\epsilon$, whereas $B_1\cup B_2$ is the global optimum with value 8. Notice also that for the appropriate choice of $\epsilon$, this can be a $(4-\epsilon')$-stable instance for any small $\epsilon'$.}
	\label{counter1}
\end{figure}

\subsection{Cardinality Constraints}\label{sec:cardinality-counter}

Another interesting separation between approximation and stability happens for the case of cardinality constraints. A special case of submodular maximization on $p$-extendible systems is when we have a uniform matroid constraint where the only feasible solutions are those that have cardinality $k \ge 1$ ($\I=\{S\subseteq X: |S|\le k\}$). For this special case, recall that greedy is a $(1-\tfrac{1}{e})$-approximation (in fact, $1-(1-\tfrac{1}{k})^k$) and that this is tight \cite{feige1998threshold}. Regarding stability, we show that the stability threshold needed by greedy for recovery is at least $2-\tfrac{1}{k}$ and so $(1-\tfrac{1}{e})^{-1}$-stability is not enough, i.e. here the approximation threshold is strictly smaller than the stability threshold needed for recovery (see also \hyperref[fig:cardinality]{Figure~\ref{fig:cardinality}}).

\begin{proposition}
For submodular maximization under a uniform matroid ($\I=\{S: |S|\le k\},k\ge 1$), greedy cannot recover $\gamma$-stable instances if $\gamma<(2-\tfrac{1}{k})$.
\end{proposition}

\begin{proof}
The $(2-\tfrac{1}{k}-\delta)$-stable counterexample (for any small $\delta$) where greedy fails is the following: We have in total ($k+1$) elements: $x_1,x_2,\dots, x_k$ and a special element $e$. Denote $O=\{x_1,x_2,\dots, x_k\}$ and with $O_i$ any subset of $O$ with exactly $i$ elements. The function $f$ has: $f(O)=1, f_{O_i}(x_j)=\tfrac{1}{k}, \forall x_j\in O\setminus O_i,  f_{\{e\}\cup O_i}(x_j)=\tfrac{1}{k}(1-\tfrac{1}{k}), \forall x_j\in O\setminus O_i $ and $f(e)=\tfrac{1}{k}, f_{O_i}(e)=\tfrac{1}{k}-\tfrac{i}{k^2}$. Then Greedy first picks element $e$ (to break ties we could set $f(e)=\tfrac{1}{k}+\epsilon$) and then $k-1$ other elements $O_{k-1}\subseteq O$ (let $S=\{e\}\cup O_{k-1}$). However, the optimal solution is $O$ with $f(O)=1$ and greedy has value $1-(\tfrac{1}{k}-\tfrac{1}{k^2})$. Since $S\sm O=\{e\}$, any perturbation such that $\tilde{f}(S)\ge \tilde{f}(O)$ could only $\gamma$-perturb the value $f(e)$: $\tilde{f}(S)\ge \tilde{f}(O)\iff (\gamma-1)\tfrac{1}{k}\ge\tfrac{1}{k}-\tfrac{1}{k^2} \iff \gamma\ge (2-\tfrac{1}{k})$.
\end{proof}
\begin{figure}[h!]
	\centering
	\includegraphics[width=13cm,height=4cm]{IMAGE2}
        	\caption{This is the case for $k=2$ and $k=3$ (the area corresponds to marginal improvements). For $k=2$, there are three elements: $\{e,x_1,x_2\}$. $f(\{x_1,x_2\})=1$, so the optimal solution is $O=\{x_1,x_2\}$. We trick the greedy algorithm which first chooses $\{e\}$ that has slightly better marginal value. For exact recovery, a $\tfrac{3}{2}$-perturbation is needed, even though Greedy is a $\left(\tfrac{4}{3}\right)^{-1}$-approximation. Similarly, for $k=3$, the optimum is $O=\{x_1,x_2,x_3\}$, whereas Greedy picks $\{e,x_1,x_2\}$ and needs $\tfrac{5}{3}$-stability for recovery, even though it is $\left(\tfrac{19}{27}\right)^{-1}$-approximation. Note that stability thresholds need to be larger than the approximation factors.}
	\label{fig:cardinality}
\end{figure}




 

















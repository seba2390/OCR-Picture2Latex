\subsection{Online Pairwise Learning to Rank}
\label{sec_model}


\begin{figure}[t]
  \vspace{-2mm}
  \centering
  \includegraphics[width=\linewidth]{figures/PairRank_List.png}
  \Description[An illustration of \model{} model]{From document graph to block graph, and then the generated ranked list.}
  \caption{PairRank: pairwise explore and exploit by divide-and-conquer. Assume that the optimal ranking order among the 5 documents is $1 \succ 2 \succ 3 \succ 4 \succ 5$. At the current round $t$, the ranker is confident about its preference estimation between all the pairs expect $(1, 2), (3, 5), (4 ,5)$. In this example, the instantaneous regret of the first proposed ranked list is 3 and 2 in the second proposal.}
  \label{fig:model}
  \vspace{-2mm}
\end{figure}

The key in OL2R is to effectively explore the unknowns while providing high-quality results to the users, which is often referred to as the explore-exploit trade-off. In this work, we propose to directly train a pairwise model from its interactions with users and directly explore in the pairwise document ranking space via a divide-and-conquer strategy. The high-level idea of \model{} is illustrated in Figure \ref{fig:model}, and we explain its details in the following.


\subsubsection{Pairwise Learning to Rank}

We focus on the pairwise ranking models because of their advantageous effectiveness reported in prior offline LTR studies \cite{chapelle2011yahoo}, and their ability to tackle implicit feedback.
Specifically, we adopt a single layer RankNet model with a sigmoid activation function \cite{burges2010ranknet} as our pairwise ranker.
This choice is based on the promising empirical performance of RankNet and the feasibility of analyzing the resulting online solution's convergence. 
% We name the proposed algorithm as \model{} and describe its procedures in Algorithm \ref{algo:algo1}. 

In a single layer RankNet, the probability that a document $i$ is more relevant than document $j$ under query $q$ is computed as $\mathbb{P}(i \succ j | q) = \sigma({\bx^\top_i}\btheta - {\bx^\top_j}\btheta)$, where $\btheta \in \bR^d$ and $\Vert\btheta\Vert \leq Q$ is the model parameter and $\sigma(x)= {1}/({1 + \exp(-x)})$.
To simplify our notations, we use $\xij$ to denote $\bx_i - \bx_j$ in our subsequent discussions.

With the knowledge of $\btheta$, due to the monotonicity and transitivity of the sigmoid function, the ranking of documents in $\mathcal{X}$ can be uniquely determined by $\{{\bx^\top_1}\btheta, {\bx^\top_2}\btheta, \dots, {\bx^\top_{L}}\btheta\}$. Therefore, the key of learning a RankNet model is to estimate its parameter $\btheta$. As RankNet specifies a distribution on pairwise comparisons, the objective function for $\btheta$ estimation can be readily derived as the cross-entropy loss between the predicted pairwise distribution on documents and those inferred from user feedback till round $t$:
\small
\begin{align}
\label{eqn:loss}
    \mathcal{L}_t = \sum_{s=1}^t\sum_{(m, n) \in \mathcal{G}_{s}} & - \ymns \log\big(\sigma({\xmns}^\top\btheta)\big)  \\
    & - (1 - \ymns)\log\big(1 - \sigma({\xmns}^\top\btheta)\big) + \frac{\lambda}{2} \Vert\btheta\Vert^2 \nonumber 
\end{align}
\normalsize
where $\lambda$ is the L2 regularization coefficient, $\mathcal{G}_{s}$ denotes the set of document pairs that received different click feedback at round $s$, i.e., $\mathcal{G}_{s} = \{(m, n): c_m^{s} \neq c_n^{s}, \forall \tau(m) < \tau(n) \leq o_{s}\}$, $\ymns$ indicates whether the document $m$ is preferred over document $n$ in the click feedback, i.e., $\ymns = \frac{1}{2}(c_m^t - c_n^t) + \frac{1}{2}$~\cite{burges2010ranknet}. Due to the log-convexity of the loss function defined in Eq~\eqref{eqn:loss}, the global optimal solution $\hat{\btheta}_t$ at round $t$ exists and can be efficiently obtained by gradient descent. 
 
Online learning of RankNet boils down to the construction of $\{\mathcal{G}_{s}\}^T_{s=1}$ over time. However, the conventional practice of using all the inferred pairwise preferences from click feedback \cite{joachims2002optimizing,agichtein2006improving} imposes a higher risk in an online setting. In the presence of click noise (e.g., a user mistakenly clicks on an irrelevant document), pairing documents would cause a quadratically increasing number of noisy training instances, which impose strong negative impact on the quality of the learned ranker \cite{carvalho2008suppressing}. As the updated ranker is immediately executed, cascading of ranker deterioration is possible. 
%Specifically, one incorrect label of a single document will lead to many ``mis-labeled'' document pairwise preferences. Such negative impact is more severe in online setting as the clicks are known to be biased and noisy. 
To alleviate this deficiency, we propose to only use independent pairs inferred from the feedback, e.g., $\mathcal{G}_{s}^{ind} = \{(m, n): c_m^{s} \neq c_n^{s}, \forall (\tau_s(m), \tau_s(n)) \in D\}$, where $D$ represents the set of disjointed position pairs, for example, $D = \{(1, 2), (3, 4), ... (L-1, L)\}$. In other words, we will only use a subset of non-overlapping pairwise comparisons for our online ranker update. 

\subsubsection{Uncertainty Qualification}
\begin{figure}[t]
  %\vspace{-2mm}
  \centering
  \includegraphics[width=0.8\linewidth]{figures/CertainRankOrder.png}
  \Description[Comparison between certain and uncertain rank order]{How estimation uncertainty determines the certain and uncertain rank order.}
  \vspace{-2mm}
  \caption{Illustration of certain and uncertain rank orders.}
  \label{fig:certain_rank}
  \vspace{-2mm}
\end{figure}

As discussed in Section \ref{sec:problem}, $\hat{\btheta}_t$ is obtained based on the acquired feedback from what has been presented to the user, which is subject to various types of biases and noises \cite{joachims2005accurately,agichtein2006improving,joachims2007evaluating}. Hence, $\hat{\btheta}_t$ only reflects what the ranker knows so far; and it is vital to effectively explore the unknowns to complete its knowledge. In \model{}, we propose to explore in the pairwise document ranking space spanned by $\mathcal{X}_t$ under $q_t$, with respect to the current ranker's uncertainty about the pairwise comparisons.

Accurate quantification of the current ranker's uncertainty on pairwise preference estimation is the key to such exploration. The model estimation uncertainty is caused by the existence of click noise, i.e., $\Vert\hat{\btheta}_t - \btheta^*\Vert \neq 0$, where $\btheta^*$ is the underlying ground-truth model parameter. And this model estimation uncertainty directly leads to the uncertainty in the ranker's pairwise preference estimation. 
To quantify the source of uncertainty, we follow conventional click models to assume the clicks are independent of each other given the true relevance of documents, so as their noise \cite{joachims2005accurately,guo2009click,guo2009efficient}. As a result, the pairwise noise becomes the sum of noise from the two associated clicks. Because we only use the independent document pairs $\mathcal{G}^{ind}$, the pairwise noise is thus independent of each other in \model{} and the history of result serving, which directly leads to the following proposition.

\begin{proposition}
For any $t \geq 1$, $\forall (i, j) \in \mathcal{G}_t^{ind}$, define pairwise noise $\epsilon_{ij}^t = \yijt - \sigma(\xijt^\top\theta^*)$. For all $t \geq 1$, $\epsilon_{ij}^t$ is a sub-Gaussian random variable with $\mathbb{E}[\epsilon_{ij}^t| \mathcal{G}_{t-1}^{ind}, \{\epsilon^{t-1}\}, \dots, \mathcal{G}_{1}^{ind}, \{\epsilon^{1}\}] = 0$, where $\{\epsilon^t\} = \{\epsilon_{ij}^t, (i, j)\in\mathcal{G}_t^{ind}\}$
\end{proposition}

According to the property of sub-Gaussian random variables, such assumption can be easily satisfied in practice as long as the pointwise click noise follows a sub-Gaussian distribution. For example, the pointwise noise can be modeled as a binary random variable related to the document's true relevance under the given query, which follows $\frac{1}{2}$-sub-Gaussian distribution.

Therefore, based on the solution of Eq~(\ref{eqn:loss}), the uncertainty of the estimated pairwise preference $\sigma({\bx_{ij}^t}^\top \hat{\btheta}_t)$ by RankNet at round $t$ can be analytically bounded with a high probability, as shown in the following lemma.

\begin{lemma} (Confidence Interval of Pairwise Preference Estimation). At rount $t < T$, for any pair of documents $\bx_i^t$ and $\bx_j^t$ under query $q_t$, with probability at least $1 - \delta_1$, we have,
\begin{equation*}
    |\sigma({\xijt}^\top \hat{\btheta}_t) - \sigma({\xijt}^\top \btheta^*) | \leq \alpha_t\Vert\xijt\Vert_{\mathbf{M}_t^{-1}},
\end{equation*}
where $\alpha_t = ({2k_{\mu}}/{c_{\mu}}) \Big(\sqrt{R^2\log{({\det(\mathbf{M}_t)}/({\delta_1^2 \det(\lambda \mathbf{I})})})} + \sqrt{\lambda} Q\Big)$, $\mathbf{M}_t = \lambda \mathbf{I} + \sum_{s =1}^{t-1}\sum_{(m, n) \in \mathcal{G}^{ind}_{s}}\xmns\xmns^\top$, $k_{\mu}$ is the Lipschitz constant of the sigmoid link function $\sigma$, $c_{\mu} = \inf_{\btheta \in \bTheta} \dot{\sigma}(\bx^\top\btheta)$, with $\dot{\sigma}$ as the first derivative of $\sigma$, and $R$ is the sub-gaussian parameter for noise $\epsilon$.
\label{lemma:cb}
\end{lemma}

The detailed proof of Lemma~\ref{lemma:cb} can be found in the appendix. This lemma provides a tight high probability bound of the pairwise preference estimation uncertainty under a RankNet specified by $\hat\btheta_t$, which enables us to perform efficient pairwise exploration for model update. To better illustrate our exploration strategy based on the pairwise estimation uncertainty, we introduce the following definition on document pairs.

\begin{definition} (Certain Rank Order)
At any round $t < T$, the ranking order between document $i$ and $j$, denoted as $(i, j)$, is considered in a certain rank order if and only if $\sigma({\bx_{ij}^t}^\top\hat{\btheta}_t) - \alpha_{t}\Vert\bx_{ij}^t\Vert_{\mathbf{M}_t^{-1}} > \frac{1}{2}$.
\end{definition}

Intuitively, based on Lemma~\ref{lemma:cb}, if $(i, j)$ is in a certain rank order, with a high probability that the estimated preference (order) between document $i$ and $j$ is consistent with the ground-truth. 
For example, as shown in Figure~\ref{fig:certain_rank}, $\hat{\sigma}^t_{ij}$ and $\hat{\sigma}_{mn}^t$ represent the estimated pairwise preference on document pair $(i,j)$ and $(m,n)$ based on $\hat{\btheta}_t$, while $CB_{ij}^t$ and $CB_{mn}^t$ represent the corresponding confidence bound defined in Lemma~\ref{lemma:cb}, i.e., $CB_{ij}^t = \alpha_t\Vert\xijt\Vert_{\mathbf{M}_t^{-1}}$ and $CB_{mn}^t = \alpha_t\Vert\xmnt\Vert_{\mathbf{M}_t^{-1}}$. According to Lemma~\ref{lemma:cb},  we know that the ground-truth pairwise preferences, $\sigma_{ij}^*$ and $\sigma_{mn}^*$, lie within the corresponding confidence intervals with a probability at least $1 - \delta_1$, i.e., $\sigma_{ij}^* \in [\hat{\sigma}_{ij}^t - CB_{ij}^t, \hat{\sigma}_{ij}^t + CB_{ij}^t]$. 
In Figure~\ref{fig:certain_rank}, for pair $(m, n)$, the lower bound of its pairwise estimation, $\hat{\sigma}_{mn}^t - CB_{mn}^t$, is greater than $\frac{1}{2}$. This indicates that with a high probability $1 - \delta_1$, the estimated preference between document $m$ and $n$ is consistent with the ground-truth model $\btheta^*$; and thus there is no need to explore this pair. In contrast, with $\hat{\sigma}_{ij}^t - CB_{ij}^t < \frac{1}{2}$, the estimated order $(i \succ j)$ is still with uncertainty as the ground-truth model may present an opposite order; hence, exploration on this pair is necessary. 

We use $\mathcal{E}_{c}^t$ to represent the set of all certain rank orders at round $t$. Accordingly, the set of uncertain rank orders at round $t$ is defined as: $\mathcal{E}_{u}^t = \{(i, j) \in [L_t]^2: (i, j) \notin \mathcal{E}_c^t \wedge (j, i) \notin \mathcal{E}_c^t\}$. 

\subsubsection{Explore the Unknowns via Divide-and-Conquer}

\begin{algorithm}[t]
\caption{PairRank}
\label{algo:algo1}
    \textbf{Input:} $\lambda$, $\delta_1$, $\delta_2$
    Initialize $\mathbf{M}_0 = \lambda \mathbf{I}, \hat{\btheta}_1 = 0$
    \For{$t=1$ \KwTo $T$}{
        \text{Receive query $q_t$ and its corresponding candidate documents set} $\mathcal{X}_t = \{\bx_1^t, \bx_2^t, ..., \bx_{L_t}^t\}$. \\
        
        $\mathcal{E}_c^t = \{(i, j) \in [L_t]^2: \sigma({\bx_{ij}^t}^\top\mathbf{\hat{\btheta}}_{t-1}) - \alpha_{t-1}\Vert\bx_{ij}^t\Vert_{\mathbf{M}_{t-1}} > 1/2\}$ \\
        $\mathcal{E}_u^t = \{(i, j) \in [L_t]^2: (i, j) \notin \mathcal{E}_c^t \wedge (j, i) \notin \mathcal{E}_c^t\}$ \\
        \text{Construct ordered block list} $\mathcal{B}_t = \{\mathcal{B}_1^t, \mathcal{B}_2^t, ... \mathcal{B}_{d_t}^t\}$ \\
        % by $\mathcal{E}_c^t \text{ and } \mathcal{E}_u^t$. \\
        \text{Generate ranked list} $\tau_t = \{\pi(\mathcal{B}_1^t), \pi(\mathcal{B}_2^t), ... , \pi(\mathcal{B}_{d_t}^t) \}$  \\
        \text{Observe click feedback} ${C}_t$, and corresponding $o_t$. \\
        $\mathcal{G}_t^{ind} = \{(i, j) \in [o_t]^2: c_i^t \ne c_j^t \wedge (\tau_t(i), \tau_t(j)) \in D\}$. \\
        \text{Estimate $\hat{\theta}_t$ as the solution of Eq \eqref{eqn:loss}}. \\
        $\mathbf{M}_t = \mathbf{M}_{t-1} + \sum_{(i, j) \in \mathcal{G}_t^{ind}} \mathbf{x}_{ij}^t {\mathbf{x}_{ij}^t}^\top$.
    }
\end{algorithm}

With the aforementioned pairwise estimation uncertainty and the corresponding sets of certain and uncertain rank orders, i.e., $\mathcal{E}_c^t$ and $\mathcal{E}_u^t$, we can effectively explore the unknowns.
Intuitively, we only need to randomize the ranking of documents among which the model is still uncertain about their ranking orders, i.e., the uncertain rank orders, and therefore obtain feedback to further update the model (and reduce uncertainty). 
For example, in the document graph shown in Figure \ref{fig:model}, the solid lines represent certain rank orders, while the dash lines represent the uncertain rank orders. When generating the ranked list, we should randomly swap the order between document 1 and 2 (i.e., to explore) while preserving the order between document 1 and documents 3, 4, 5 (i.e., to exploit).

This naturally leads to a divide-and-conquer exploration strategy in the space of pairwise document comparisons. Specifically, we partition $\mathcal{X}_t$ into different parts (referred to as \textit{blocks} hereafter) based on $\mathcal{E}_c^t$ and $\mathcal{E}_{u}^t$ such that the ranking orders between any documents belonging to different blocks are certain, shown in the block graph in Figure~\ref{fig:model}. The ranked list can thus be generated by topological sort across blocks and random shuffling within each block. As the exploration is confined to the pairwise ranking space, it effectively reduces the exponentially sized action space to quadratic. 

Algorithm~\ref{algo:algo1} shows the detailed steps of \model{}. At round t, we first construct $\mathcal{E}_c^t$ and $\mathcal{E}_u^t$ according to the current mode $\hat{\btheta}_{t-1}$. Then, we create blocks of $\mathcal{X}_t$ according to the definition below.

\begin{definition} (Block)
At any round $t < T$, the block $\mathcal{B}$ is a set of documents that satisfy: 
\begin{enumerate}[nolistsep]
    \item $\forall i \in \mathcal{B}_d^t, (i, j) \in \mathcal{E}_c^t \text{ for any } j\in[L_t]\setminus \mathcal{B}_d^t.$ 
    \item $\nexists k \in [L_t] \setminus \mathcal{B}_d^t,  \text{for } i, j \in \mathcal{B}_d^t, (i, k) \in \mathcal{E}_t^c \wedge (k, j) \in \mathcal{E}_c^t$
\end{enumerate}
\end{definition}

Intuitively, each block is a subset of documents linked to each other by the \textit{uncertain rank order}. It can be viewed as a connected component in an undirected graph with documents as vertices and \textit{uncertain rank order} as edges under a given query. The connected components (blocks) can be found by linearly scanning through the vertices, based on breadth-first search or depth-first search if a vertex is not visited before. When the algorithm stops, each vertex (document) will be assigned to a connected component (block). Once the blocks are constructed, the order of the blocks can be obtained by topological sort (line 6). Let $\mathcal{B}_t = \{\mathcal{B}_1^t, \mathcal{B}_2^t, ... \mathcal{B}_{d_t}^t\}$ be the ordered block list for $\mathcal{X}_t$ at round $t$, the ranked list $\tau_t$ is generated as $\tau_t = \{\pi(\mathcal{B}_1^t), \pi(\mathcal{B}_1^t), ... , \pi(\mathcal{B}_{d_t}^t) \}$, where $\pi(\cdot)$ randomly permutes its input set as output.



To further improve exploration efficiency, we propose two options to generate the ranked list. As shown in Figure~\ref{fig:model}, the first ranked list is generated by randomly shuffling all documents within each block (referred to as random exploration), while in the second list, only the uncertain rank orders are shuffled, and the certain ones are preserved (referred to as conservative exploration). In our empirical studies, we observe such conservative exploration gives better improvement than random exploration, which further confirms the importance of efficient exploration in OL2R.
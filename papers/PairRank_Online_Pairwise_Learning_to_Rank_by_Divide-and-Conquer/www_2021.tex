\documentclass[sigconf]{acmart}
% \documentclass[draft]{acmart}

\usepackage[linesnumbered, ruled]{algorithm2e}
% \renewcommand{\baselinestretch}{0.99}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}  % for sub-figure
\usepackage{subcaption}  % for sub-figure
\usepackage{amsthm}
\usepackage{appendix}
\usepackage{mathtools}
\settopmatter{authorsperrow=4}


\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newcommand{\me}{\mathrm{e}}
\usepackage{enumitem}
\newenvironment{hproof}{%
  \renewcommand{\proofname}{Proof Sketch}\proof}{\endproof}

\def \bx {\mathbf{x}}
\def \xij {\mathbf{x}_{ij}}
\def \xijt {{\mathbf{x}_{ij}^t}}
\def \xjit {{\mathbf{x}_{ji}^t}}
\def \xijs {{\mathbf{x}_{ij}^s}}
\def \xmns {{\mathbf{x}_{mn}^s}}
\def \xmnt {{\mathbf{x}_{mn}^t}}
\def \ymns {{\mathbf{y}_{mn}^s}}
\def \ymnt {{\mathbf{y}_{mn}^t}}
\def \yijs {{\mathbf{y}_{ij}^s}}
\def \yijt {{\mathbf{y}_{ij}^t}}
\def \tp  {t^\prime}
\def \sub {\scriptscriptstyle}
\def \btheta {\boldsymbol{\theta}}
\def \bTheta {\boldsymbol{\Theta}}
\def \bR {\mathbb{R}}
\def \bM {\mathbf{M}}
\def \bZ {\mathbf{Z}}
\def \bU {\mathbf{U}}
\def \bG {\mathbf{G}}
\def \bSigma {\mathbf{\Sigma}}
% \renewcommand{\osum}[2]{\mathop{\sum{#2}}_{#1}}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}


%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2021}
\acmYear{2021} 
\acmConference[WWW '21]{Proceedings of the Web Conference 2021}{April 19--23, 2021}{Ljubljana, Slovenia}
\acmBooktitle{Proceedings of the Web Conference 2021 (WWW '21), April 19--23, 2021, Ljubljana, Slovenia}
\acmPrice{}
\acmDOI{10.1145/3442381.3449972}
\acmISBN{978-1-4503-8312-7/21/04}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}
%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{PairRank: Online Pairwise Learning to Rank by Divide-and-Conquer}
\newcommand{\model}{{PairRank}}


\author{Yiling Jia}
\affiliation{%
  \institution{University of Virginia}
  \city{Charlottesville}
  \state{VA}
  \country{USA}
}
\email{yj9xs@virginia.edu}

\author{Huazheng Wang}
\affiliation{%
  \institution{University of Virginia}
  \city{Charlottesville}
  \state{VA}
    \country{USA}
}
\email{hw7ww@virginia.edu}

\author{Stephen Guo}
\affiliation{%
  \institution{Walmart Labs}
  \city{Sunnyvale}
  \state{CA}
  \country{USA}
}
\email{sguo@walmartlabs.com}

\author{Hongning Wang}
\affiliation{%
  \institution{University of Virginia}
  \city{Charlottesville}
  \state{VA}
  \country{USA}
}
\email{hw5x@virginia.edu}


%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Online Learning to Rank (OL2R) eliminates the need of explicit relevance annotation by directly optimizing the rankers from their interactions with users. However, the required exploration drives it away from successful practices in offline learning to rank, which limits OL2R's empirical performance and practical applicability.
In this work, we propose to estimate a pairwise learning to rank model online. In each round, candidate documents are partitioned and ranked according to the model's confidence on the estimated pairwise rank order, and exploration is only performed on the uncertain pairs of documents, i.e., \emph{divide-and-conquer}.  
Regret directly defined on the number of mis-ordered pairs is proven, which connects the online solution's theoretical convergence with its expected ranking performance. Comparisons against an extensive list of OL2R baselines on two public learning to rank benchmark datasets demonstrate the effectiveness of the proposed solution.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002951.10003317.10003338.10003343</concept_id>
       <concept_desc>Information systems~Learning to rank</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10010070.10010071.10011194</concept_id>
       <concept_desc>Theory of computation~Regret bounds</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809.10010047.10010048</concept_id>
       <concept_desc>Theory of computation~Online learning algorithms</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809.10011254.10011257</concept_id>
       <concept_desc>Theory of computation~Divide and conquer</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Learning to rank}
\ccsdesc[500]{Theory of computation~Online learning algorithms}
\ccsdesc[500]{Theory of computation~Divide and conquer}
\ccsdesc[500]{Theory of computation~Regret bounds}

\keywords{Online learning to rank; divide and conquer; regret analysis}

\maketitle

\input{introduction}
\input{related}
\section{Method}
\input{problem}
\input{algorithm}
\input{regret}

\input{experiment}

\section{Conclusion}
Existing OL2R solutions suffer from slow convergence and sub-optimal performance due to inefficient exploration and limited optimization strategies. Motivated by the success of offline models, we propose to estimate a pairwise learning to rank model on the fly, named as \model{}. 
Based on the model's pairwise order estimation confidence, exploration is performed only on the pairs where the ranker is still uncertain, i.e., \emph{divide-and-conquer}. 
We prove a sub-linear upper regret bound defined on the number of mis-ordered pairs, which directly links \model{}'s convergence with classical ranking evaluations.  
Our empirical experiments support our regret analysis and demonstrate significant improvement of \model{} over several state-of-the-art OL2R baselines. 

Our effort sheds light on moving more powerful offline learning to rank solutions online. Currently, our work is based on a single layer RankNet for analysis purposes. Following recent efforts of convergence analysis in deep learning \cite{zhou2019neural}, it is possible to extend \model{} with deep ranking models and directly optimize rank-based metrics (such as NDCG). Furthermore, most OL2R solutions focus on population-level ranker estimation; thanks to the improved learning efficiency by \model{}, it is possible for us to study individual-level ranking problems, e.g., personalized OL2R.

\section{Acknowledgements}
We want to thank the reviewers for their insightful comments. This work is based upon work supported by National Science Foundation under grant IIS-1553568 and IIS-1618948, and Google Faculty Research Award.


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}

\appendix
\input{supplementary}

\end{document}
\endinput


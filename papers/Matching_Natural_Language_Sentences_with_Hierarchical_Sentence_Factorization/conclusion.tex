%!TEX root = main.tex
\section{Conclusion}
\label{sec:conclude}

In this paper, we propose a technique named \textit{Hierarchical Sentence Factorization} that is able to transform a sentence into a hierarchical factorization tree. Each node in the tree is a semantic unit consists of one or several words in the sentence and reorganized into the form of ``predicate-argument'' structure. Each depth in the tree factorizes the sentence into semantic units of different scales.
Based on the hierarchical tree-structured representation of sentences, we propose both an unsupervised metric and two supervised deep models for sentence matching tasks. On one hand, we design a new unsupervised distance metric, named \textit{Ordered Word Mover's Distance} (OWMD), to measure the semantic difference between a pair of text snippets.
% The new metric combines our sentence factorization algorithm with the Order-preserving Wasserstein Distance.
% Compared with the Word Mover's Distance (WMD) metric,
OWMD takes the sequential structure of sentences into account, and is able to handle the flexible syntactical structure of natural language sentences.
On the other hand, we propose the multi-scale Siamese neural network architecture which takes the multi-scale representation of a pair of sentences as network input and matches the two sentences at different granularities.

We apply our techniques to the task of text-pair similarity estimation and the task of text-pair paraphrase identification, based on multiple datasets. Our extensive experiments show that both the unsupervised distance metric and the supervised multi-scale Siamese network architecture can achieve significant improvement on multiple datasets using the technique of sentence factorization. 


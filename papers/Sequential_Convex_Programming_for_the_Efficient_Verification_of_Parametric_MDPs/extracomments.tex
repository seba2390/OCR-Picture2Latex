%\section{To be incorporated into intro}
%\subsection{Difficulty of NLP}
%General methods for nonconvex optimization fall into two categories: local, and global. 
%Global methods can guarantee optimality at a large computational cost. 
%They are practical only on small problems.
%
%sampling based methods (CE, MRAS),
%branch and bound~\cite{LW66},
%label-correcting,
%polynomial optimization~\cite{Las01,Par00}
%
%Local methods sacrifice optimality for computational efficiency.
%Relaxation and restriction,
%trust region,
%sequential convex programming,
%SQP (\tool{SNOPT})

%!TEX ROOT = ../centralized_vs_distributed.tex

\subsection{\titlecap{variance computation for discrete-time systems}}\label{app:disc-time-single-int-variance-explicit}

\myParagraph{Wiener--Kintchine Formula}
Given any fixed values of delay and feedback gains,
the steady-state variance $ \varx{\gpos}{I} $ or $ \varx{\gvel,\gpos}{II} $ of the decoupled subsystems can be computed numerically by
\begin{equation}\label{eq:disc-time-variance-integral}
	\dfrac{1}{2\pi}\int_{-\pi}^{+\pi}\dfrac{d\theta}{|h(\e^{j\theta})|^2},
\end{equation}
where the characteristic polynomial $ h(z) $
is~\eqref{eq:disc-time-single-int-characteristic-polinomial} or~\eqref{eq:disc-time-double-int-characteristic-polinomial}.

\myParagraph{\titlecap{single integrator model}}
The moment-matching method applied to the subsystem~\eqref{eq:disc-time-single-int-decoupled} yields 
a linear system of equations in the variables $ (\rho_0,...,\rho_\delayn) $,
where $ \rho_t \doteq \mathbb{E}[\xtilde{}{k}\xtilde{}{k\pm t}] $:
\begin{subequations}\label{eq:disc-time-single-int-moment-matching-eqs}
	\begin{align}
		\rho_0 &= \mathbb{E}[\xtilde{}{k+1}^2] = \rho_0 + \gpos^2\rho_0 + 1 - 2\gpos\rho_\delayn \label{eq:disc-time-single-int-first-moment-eq}\\
		\rho_1 &= \mathbb{E}[\xtilde{}{k+1}\xtilde{}{k}] = \rho_0 - \gpos\rho_\delayn \label{eq:disc-time-single-int-yule-walker-eqs-1}\\
		&\hspace{2mm}\vdots \nonumber \\
		\rho_\delayn &= \rho_{\delayn-1} - \gpos\rho_1, \label{eq:disc-time-single-int-yule-walker-eqs-2}
	\end{align}
\end{subequations}
where~\eqref{eq:disc-time-single-int-yule-walker-eqs-1}--\eqref{eq:disc-time-single-int-yule-walker-eqs-2} are the Yule-Walker equations.
%associated to the decoupled subsystem~\eqref{eq:disc-time-single-int-decoupled}.
System~\eqref{eq:disc-time-single-int-moment-matching-eqs}
can be written compactly as $ A^{(\tau)}\rho = e_1 $, where
$ \rho^\top = [\rho_0,\dots,\rho_{\delayn}]$,
$ e_1 $ is the canonical vector in $ \Real{\delayn+1} $ with nonzero first coordinate and $ A^{(\tau)}\in\Real{(\delayn+1)\times(\delayn+1)} $ with
\begin{equation}\label{eq:explicit-variance-matrix-A}
	A^{(\tau)} = \begin{bmatrix}
		-\gpos^2 &   		&     		& 		 &   	  & 2\gpos\\
		1 		 & -1 		&     		& 		 &    	  & -\gpos\\
		& 	\ddots	& \ddots	&  		 & \iddots&  \\
		& 			& 			&		 & 		  &  \\
		& 			& 			&		 & 		  &  \\
		& -\gpos	& 			& 		 & 1 	  & -1
	\end{bmatrix}.
\end{equation}
In particular, when $ \delayn $ is odd, the $ (\ceil{\nicefrac{\delayn}{2}} + 1) $-th row is
\begin{equation}\label{eq:app-explicit-variance-matrix-A-mid-row-odd}
	\left[\!\begin{array}{cccccccc}
		0 & \dots & 0 & 1 & -1-\gpos & 0 & \dots & 0
	\end{array}\!\right],
\end{equation}
while, when $ \delayn $ is even, the $ (\nicefrac{\delayn}{2} + 2) $-th row is
\begin{equation}\label{eq:app-explicit-variance-matrix-A-mid-row-even}
	\left[\!\begin{array}{cccccccc}
		0 & \dots & 0 & 1-\gpos & -1 & 0 & \dots & 0
	\end{array}\!\right].
\end{equation}
%where we highlight the dependence on the delay in view of the recursive characterization of $ \rho_0 $.
Notice that $ A^{(\tau)} $ is full rank for all $ \delayn \ge 1 $ and thus~\eqref{eq:disc-time-single-int-moment-matching-eqs} can be solved uniquely.
In particular, we are interested in the autocorrelation $ \rho_0 = \varx{\gpos}{I} $,
which is given by
the ratio between the minor associated with the top-left element of $ A^{(\tau)} $,
named $ n_\delayn \doteq M^{(\tau)}_{1,1} $, and the determinant $ d_\delayn \doteq \det(A^{(\tau)}) $.
Specifically, $ \rho_0 $ is a rational function in $ \gpos $
and can be computed in closed form by a symbolic solver
given any value of $ \delayn $.

Further, $ n_{\delayn} $ and $ d_{\delayn} $ can be computed %recursively via an inductive argument on the delay $ \delayn $, 
by leveraging the following nested structure of the matrix $ A^{(\delayn)} $:
\begin{equation}\label{eq:recursive-matrix}
	A^{(\delayn)} = \tikz[baseline=(M.west)]{%
		\node[matrix of math nodes,matrix anchor=west,left delimiter={[},right delimiter={]},ampersand replacement=\&] (M) {%
			-\gpos^2\&			\&			\&							\& 							\&						 \&	-2\gpos		\\
			1 	\& -1  		\&    		\&							\& 							\& 						 \&	  			\\
			\&  1  		\&  -1		\&	  						\&      					\& 						 \& -\gpos   	\\
			\&    		\&   1 		\& \textcolor{white}{t1}	\& 							\& 						 \&				\\
			\&			\&			\&							\& \tilde{A}^{(\delayn-4)}	\&						 \&				\\
			\& 			\&	  		\& 							\&	 						\& \textcolor{white}{t1} \&				\\
			\& 		    \&   -\gpos	\&							\&							\& 1					 \&	-1			\\
			\& 	-\gpos	\&	  		\&							\&							\&						 \&	1			\\			
		};
		\node[draw,fit=(M-3-3)(M-7-7),inner sep=-1pt] {};
		\node[draw,fit=(M-4-4)(M-6-6),inner sep=-1pt] {};
	},
\end{equation}
where $ \tilde{A}^{(\delayn)} $ is the submatrix of $ A^{(\delayn)} $ obtained by removing its first row and column
such that $ M^{(\delayn)}_{1,1} = \det(\tilde{A}^{(\delayn)}) $,
and the matrices $ \tilde{A}^{(\delayn-2)} $ and $ \tilde{A}^{(\delayn-4)} $ are framed in~\eqref{eq:recursive-matrix}.

The solution obeys the following recursive expression in $ \delayn $:
%\begin{prop}\label{prop:disc-time-single-int-variance-explicit}
\begin{subequations}\label{eq:disc-time-single-int-variance-explicit}
	\begin{gather}
		n_\delayn = \begin{dcases}
			(-1-\gpos)n_{\delayn-1} + \tilde{n}_{\delayn-1} & \mbox{if } \delayn \mbox{ odd}\\
			-(1-\gpos)n_{\delayn-1} - \gpos\tilde{n}_{\delayn-1} & \mbox{if }\delayn \mbox{ even},\\
		\end{dcases} \label{eq:disc-time-single-int-variance-explicit-numerator}\\
		\tilde{n}_{\delayn} = (2-\gpos^2)\tilde{n}_{\delayn-2} - \tilde{n}_{\delayn-4}, \label{eq:disc-time-single-int-variance-explicit-numerator-rem}\\
		d_\delayn = d_{\delayn-2} - \gpos^2\left(n_\delayn+n_{\delayn-2}\right), \label{eq:disc-time-single-int-variance-explicit-denominator}\\
		\tilde{n}_{-3} = -1+\gpos^2, \ \tilde{n}_{-2} = \gpos^2, \ \tilde{n}_{-1} = -1, \ \tilde{n}_0 = 0, \\
		n_{-1} = 0, \ n_0 = 1, \ d_{-1} = -2\gpos, \ d_0 = 2\gpos-\gpos^2.
	\end{gather}
\end{subequations}

\cref{eq:disc-time-single-int-variance-explicit} can be proved by an inductive argument
on the delay $ \delayn $.

\myParagraph{Numerator}
We demonstrate the formula for odd delays $ \delayn = 2k+1, k\in\mathbb{N} $.
The other case can be obtained similarly and is thus omitted. % in the interest of space.\\

Let us consider the submatrix $ \tilde{A}^{(\delayn)} \in\Real{\delayn\times\delayn} $
obtained by removing the first row and column of $ A $,
such that $ n_\delayn = \det(\tilde{A}^{(\delayn)}) $.
Replacing the $ (\floor{\nicefrac{\delayn}{2}}) $-th column with the sum of
$ (\floor{\nicefrac{\delayn}{2}}) $-th and $ (\ceil{\nicefrac{\delayn}{2}}) $-th columns yields
\begin{equation}\label{eq:numerator-1}
	\det\left(\tilde{A}^{(\delayn)}\right) = \left|\begin{array}{c|c|c}
		\tilde{A}_{11}^{(\delayn-1)} &  & \tilde{A}_{12}^{(\delayn-1)} \\
		\hline
		\begin{array}{ccc} \dots & 0 & -\gpos \end{array} & -1-\gpos & \\
		\hline
		\tilde{A}_{21}^{(\delayn-1)} & \begin{array}{c} 1 \\ 0 \\ \vdots \end{array} & \tilde{A}_{22}^{(\delayn-1)}
	\end{array}\right|,
\end{equation}
from which it follows $ n_\delayn = (-1-\gpos)n_{\delayn-1} - \det(R^{(\delayn)}) $ where $ R^{(\delayn)}\in\Real{(\delayn-1)\times(\delayn-1)} $
and the base case is $ n_1 = -1-\gpos $.
This expression corresponds to~\eqref{eq:disc-time-single-int-variance-explicit-numerator} with $ \tilde{n}_{\delayn-1} = -\det(R^{(\delayn)}) $.
Manipulations of the second term yield a further recursive expression for $ \tilde{n}_{\delayn-1} $.
Let us write
\begin{equation}\label{eq:numerator-2}
	\det\left(R^{(\delayn)}\right) =	\tikz[baseline=(M.west)]{%
		\node[matrix of math nodes,matrix anchor=west,left delimiter=|,right delimiter=|,ampersand replacement=\&] (M) {%
			-1 		\&    		\& 	  \& 	 			\& 				\&   		\& -\gpos\\
			1 		\& -1  		\&    \& 				\&  			\& -\gpos 	\&  \\
			\&  1  		\&  \textcolor{white}{t1}  \&       			\&    			\& 			\& \\
			\&    		\&    \& R^{(\delayn-4)}	\&	  			\& 			\& \\
			\& 			\&	  \&	 			\&	\textcolor{white}{t2}			\&			\&	\\
			\& \gpos    \&    \&				\&		1		\&	-1		\&	\\
			-\gpos	\& 			\&	  \&				\&				\& 	1		\& -1\\			
		};
		\node[draw,fit=(M-2-2)(M-6-6),inner sep=-1pt] {};
		\node[draw,fit=(M-3-3)(M-5-5),inner sep=-1pt] {};
	},
\end{equation}
where the two inner boxes highlight $ R^{(\delayn-2)} $ and $ R^{(\delayn-4)} $, respectively.
Straightforward calculations yield
\begin{multline}\label{eq:numerator-3}
	\det\left(R^{(\delayn)}\right) = \det\left(R^{(\delayn-2)}\right) + \\
	\gpos\tikz[baseline=(M.west)]{%
		\node[matrix of math nodes,matrix anchor=west,left delimiter=|,right delimiter=|,ampersand replacement=\&] (M) {%
			1 			\& -1  		\&    						\& 					\&  						\& -\gpos 	 \\
			\&  1  		\&  \textcolor{white}{t1}  	\&       			\&    						\& 			 \\
			\&    		\&    						\& R^{(\delayn-4)}	\&	  						\& 			 \\
			\& 			\&	  						\&	 				\&	\textcolor{white}{t2}	\&			 \\
			\& -\gpos   \&    						\&					\&		1					\&	-1		 \\
			-\gpos		\& 			\&	  						\&					\&							\& 	1		 \\			
		};
		\node[draw,fit=(M-1-2)(M-5-6),inner sep=-1pt] {};
		\node[draw,fit=(M-2-3)(M-4-5),inner sep=-1pt] {};
	}.
\end{multline}
The determinant in the second addend is computed as
\begin{equation}\label{eq:numerator-4}
	-\gpos\det\left(R^{(\delayn-2)}\right) + 
	\tikz[baseline=(M.west)]{%
		\node[matrix of math nodes,matrix anchor=west,left delimiter=|,right delimiter=|,ampersand replacement=\&] (M) {%
			1  		 \&  \textcolor{white}{t1}  \&       			\&    						\\
			\&    						\& R^{(\delayn-4)}	\&	  						\\
			\&	  						\&	 				\&	\textcolor{white}{t2}	\\
			-\gpos   \&    						\&					\&		1					\\
		};
		\node[draw,fit=(M-1-2)(M-3-4),inner sep=-1pt] {};
	},
\end{equation}
and the second addend in the above equation has the same structure as
the determinant in the second addend in~\eqref{eq:numerator-3}.
Thus, an easy inductive argument proves
\begin{multline}\label{eq:numerator-rem-recursive}
	\det\left(R^{(\delayn)}\right) = \det\left(R^{(\delayn-2)}\right) + \gpos\left(-\gpos\det\left(R^{(\delayn-2)}\right)\right.\\
	\left.-\gpos\det\left(R^{(\delayn-4)}\right) - \dots - \gpos\det\left(R^{(3)}\right)- \gpos\right),
\end{multline}
where the base case is $ \det\left(R^{(3)}\right) = -\gpos^2 $.
\cref{eq:disc-time-single-int-variance-explicit-numerator-rem} is retrieved by noting
\begin{multline}\label{eq:numerator-rem-recursive-1}
	\det\left(R^{(\delayn-2)}\right) - \left(1-\gpos^2\right)\det\left(R^{(\delayn-4)}\right) = \\
	\gpos\left(-\gpos\det\left(R^{(\delayn-6)}\right) - \dots -\gpos\right),
\end{multline}
and thus the tail of the infinite summation in~\eqref{eq:numerator-rem-recursive} can be replaced
by the left-hand term in~\eqref{eq:numerator-rem-recursive-1}.

\myParagraph{Denominator}
The denominator of $ \rho_0 $ is computed as the determinant of $ A $.
Let $ A^{(\delayn)} \doteq A $, from~\eqref{eq:explicit-variance-matrix-A} we get
\begin{multline}\label{eq:denominator-1}
	\det\left(A^{(\delayn)}\right) = -\gpos^2M_{1,1}^{(\delayn)} -\\
	2\gpos\tikz[baseline=(M.west)]{%
		\node[matrix of math nodes,matrix anchor=west,left delimiter=|,right delimiter=|,ampersand replacement=\&] (M) {%
			1 	\& -1  		\&    		\&							\& 							\& 						 \&	  			\\
			\&  1  		\&  -1		\&	  						\&      					\& 						 \& -\gpos   	\\
			\&    		\&   1 		\& \textcolor{white}{t1}	\& 							\& 						 \&				\\
			\&			\&			\&							\& \tilde{A}^{(\delayn-4)}	\&						 \&				\\
			\& 			\&	  		\& 							\&	 						\& \textcolor{white}{t1} \&				\\
			\& 		    \&   -\gpos	\&							\&							\& 1					 \&	-1			\\
			\& 	-\gpos	\&	  		\&							\&							\&						 \&	1			\\			
		};
		\node[draw,fit=(M-2-3)(M-6-7),inner sep=-1pt] {};
		\node[draw,fit=(M-3-4)(M-5-6),inner sep=-1pt] {};
	},
\end{multline}
where $ \tilde{A}^{(\delayn-2)} $ and $ \tilde{A}^{(\delayn-4)} $ are framed in the second addend above.
The latter can be computed as the following sum,
\begin{equation}\label{eq:denominator-2}
	\gpos M_{1,1}^{(\delayn-2)} + \tikz[baseline=(M.west)]{%
		\node[matrix of math nodes,matrix anchor=west,left delimiter=|,right delimiter=|,ampersand replacement=\&] (M) {%
			1  		\&  -1				\&	  						\&      								\& 							\\
			\&   1 				\& \textcolor{white}{t1}	\& 										\&							\\
			\&					\&							\& \tilde{A}^{(\delayn-4)}				\&							\\
			\&	  				\& 							\&	 									\& 	\textcolor{white}{t1}	\\
			\&   -\gpos			\&							\&										\& 1						\\
		};
		\node[draw,fit=(M-2-3)(M-4-5),inner sep=-1pt] {};
	},
\end{equation}
where the same structure is repeated recursively in the second addend above.
Thus, an easy inductive argument proves
\begin{equation}\label{eq:denominator-recursirve}
	d_\delayn = -\gpos^2n_\delayn - 2\gpos\left(\gpos n_{\delayn-2} + \gpos n_{\delayn-4} + \dots + \gpos n_1 + 1\right),
\end{equation}
where the base case is $ d_1 = -\gpos^2(-1-\gpos)-2\gpos $.
\cref{eq:disc-time-single-int-variance-explicit-denominator} is retrieved by noting
\begin{multline}\label{eq:denominator-recursirve-1}
	-2\gpos\left(\gpos n_{\delayn-2} + \gpos n_{\delayn-4} + \dots + 1\right) = \\
	-\gpos^2 n_{\delayn-2} -\gpos^2 n_{\delayn-2} - 2\gpos\left(\gpos n_{\delayn-4} + \dots + 1\right) = \\
	-\gpos^2 n_{\delayn-2} + d_{\delayn-2}.
\end{multline}

Given $ \delayn $,
convexity of $ \rho_0 $ in $ \gpos $ can be assessed by checking the sign
of the second derivative in the stability region.
This reduces to a system of inequalities
which can be solved, \eg by \texttt{solve\_rational\_inequalities} in Python.
The variance was proved strictly convex for all tried delays.

\myParagraph{\titlecap{double integrator model}}
The moment-matching system associated with~\eqref{eq:disc-time-double-int-decoupled}
has $ \delayn+2 $ variables $ (\rho_0,\dots,\rho_{\delayn+1}) $ and is composed of the following equations:
\begin{subequations}\label{eq:disc-time-double-int-moment-matching-eqs}
	\begin{align}
		\begin{split}
			\rho_0 &= (2-\gvel)^2\rho_0 + (1-\gvel)^2\rho_0 + \gvel^2\gpos^2\rho_0 + 1 \\
			&- 2(2-\gvel)(1-\gvel)\rho_1 - 2(2-\gvel)\gvel\gpos\rho_{\delayn+1} \\
			&+ 2(1-\gvel)\gvel\gpos\rho_\delayn
			\label{eq:disc-time-double-int-first-moment-eq}
		\end{split}\\
		\rho_1 &= (2-\gvel)\rho_0 - (1-\gvel)\rho_1 - \gvel\gpos\rho_{\delayn+1} \label{eq:disc-time-double-int-yule-walker-eqs-1}\\
		\rho_2 &= (2-\gvel)\rho_1 - (1-\gvel)\rho_0 - \gvel\gpos\rho_{\delayn}\\
		&\hspace{2mm}\vdots \nonumber \\
		\rho_{\delayn+1} &= (2-\gvel)\rho_\delayn - (1-\gvel)\rho_{\delayn-1} - \gvel\gpos\rho_1, \label{eq:disc-time-double-int-yule-walker-eqs-2}
	\end{align}
\end{subequations}
where~\eqref{eq:disc-time-double-int-yule-walker-eqs-1}--\eqref{eq:disc-time-double-int-yule-walker-eqs-2} are the Yule-Walker equations
associated with~\eqref{eq:disc-time-double-int-decoupled}.
Analogous considerations to the single-integrator model can be done in this case.
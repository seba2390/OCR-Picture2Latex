%!TEX ROOT = ../../centralized_vs_distributed.tex

\section{\titlecap{control design}}\label{sec:cont-time-single-int-control-design}

\done{
	\myParagraph{\titlecap{single integrator model}}
	\tcb{For system~\eqref{eq:cont-time-single-int-formation-model}
		\cref{prob:variance-minimization} amounts to}
	\begin{equation}\label{eq:cont-time-single-int-variance-minimization}
		k_1^*,\dots,k_n^* = \argmin_{\{k_\ell\}_{\ell=1}^n} \; \var(K),
	\end{equation}
	\tcb{and parameterization~\eqref{eq:cont-time-single-int-subsystem} allows to rewrite it as}
	\begin{equation}\label{eq:cont-time-single-int-variance-minimization-decoupled}
		k_1^*,\dots,k_n^* = \argmin_{\{k_\ell\}_{\ell=1}^n} \; \sum_{j = 2}^N \varx{\gpos_j}{I},
	\end{equation}
	%where the circulant matrix $ K $ is uniquely defined by its eigenvalues~\cite{circulant}
	with stability condition \tcb{given by}~\eqref{eq:cont-time-single-int-variance-condition}.
	%where $ \varx{\gpos} $ is defined in~\eqref{eq:cont-time-single-int-steady-state-variance}
	%and $ \sigma(K) $ \tcb{denotes} the spectrum of $ K $.
	%$ \gpos_M \doteq \max\gpos_j < \nicefrac{\pi}{(2\taun)} $.
	\tcb{Linear dependence of the eigenvalues of $ K $ on the feedback gains~\cite{circulant}
		and~\cref{lem:optimal-variance-explicit} guarantee convexity of optimization problem~\eqref{eq:cont-time-single-int-variance-minimization-decoupled}.}
	Thus, the optimal \tcb{feedback} gains can be computed efficiently.
	
	\begin{figure}
		\centering
		\includegraphics[width=.6\linewidth]{cost-comparison}
		\caption{Exact variance function~\eqref{eq:cont-time-single-int-steady-state-variance}
			%		used in the optimal design~\eqref{eq:cont-time-single-int-variance-minimization-decoupled}
			and its quadratic approximation. % used in~\eqref{eq:quadratic-approximation}.
		}
		\label{fig:cost-comparison}
	\end{figure}
	
	\tcb{To make analytical progress and gain intuition, we also consider the following approximation of~\eqref{eq:cont-time-single-int-variance-minimization-decoupled},}
	%\marginpar{\vspace{2cm}\tiny I tried to push this figure upwards so that it's closer to the approximated optimization problem. Hope this is enough to make the whole thing more readable.}
	\begin{equation}\label{eq:quadratic-approximation}
		\tilde{k}_1^*,\dots,\tilde{k}_n^* = \argmin_{\{k_\ell\}_{\ell=1}^n} \; \sum_{j=2}^N \left(\gpos_j-\opteig\right)^2,
	\end{equation}
	\tcb{which} squeezes the spectrum of $ K $ about the ``optimal" \tcb{eigenvalue $\opteig$. The variance $ \varx{\cdot}{I} $ can be approximated with a quadratic function around its minimum because it is strictly convex, differentiable in the stability region, and it blows up at the boundaries $ \{0,\nicefrac{\pi}{2}\} $, see~\autoref{fig:cost-comparison}.}
	\begin{prop}[Near-optimal proportional control]\label{prop:subopt-gain}
		The solution of \tcb{problem~\eqref{eq:quadratic-approximation} is determined by 
			\[
			\tilde{k}_\ell^* 
			\; \equiv \; 
			\tilde{k}^*
			\; \doteq \;
			\dfrac{\opteig}{2n+1}.
			\]}
	\end{prop}
	\begin{proof}
		The result follows by applying properties of the DFT to~\eqref{eq:quadratic-approximation}.
		\if0\mode
		See technical report~\cite{2021arXiv210900359B}.
		\else
		See Appendices C-D in the technical report~\cite{2021arXiv210110394B}.
		\fi
	\end{proof}
	\cref{prop:subopt-gain} \tcb{shows that spatially-constant feedback gains provide good performance even when spatially-varying feedback gains are allowed. According to~\cref{lem:optimal-variance-explicit}, the suboptimal gain $ \tilde{k}^*$ decreases with the delay $ \taun $ and with the number of agents involved in the feedback loops, thereby reflecting benefits of communication.
	}
	%\marginpar{\vspace{-3cm}\tiny As you correctly observed, the cost decoupling is possible even when the variance of the input is added. However, Luca S. preferred to remove this from the paper for now, and possibly add it if the reviewers ask explicitly about that. Still need to check that the regularized optimization in convex, but that's not difficult.}
	
	\iffalse
	\begin{rem}[Control regularization]
		\tcb{An additional} term may be included in~\eqref{eq:cont-time-single-int-variance-minimization} to penalize excessive \tcb{use of control effort.}
		However, \tcb{variance of control input} 
		cannot be decoupled like~\eqref{eq:cont-time-single-int-variance-minimization-decoupled}
		because of the cross-variances between neighbors,
		\begin{equation}\label{eq:control-input-variance}
			\red{\mathbb{E}\left[\lVert u(t) \rVert^2\right] = \tr{\mathbb{E}\left[x(t)x(t)^\top\right]K^2}}
		\end{equation}
		%		making the optimization \tcb{problem challenging} to solve.
		\tcb{Alternatively,} any norm of $ K $
		can be used to regularize the problem while allowing for the variance decoupling.
	\end{rem}
	\fi
	
	\iffalse
	\myParagraph{\titlecap{single integrator model}}
	In view of~\eqref{eq:cont-time-single-int-model},
	\cref{prob:variance-minimization} reads
	\begin{equation}\label{eq:cont-time-single-int-variance-minimization}
		\argmin_{\{k_\ell\}_{\ell=1}^n} \; \mathbb{E}\left[\lVert x_{\infty}\rVert^2\right]
	\end{equation}
	which, according to the decoupling~\eqref{eq:cont-time-single-int-subsystem},
	is equivalent to
	\begin{equation}\label{eq:cont-time-single-int-variance-minimization-decoupled}
		\argmin_{\{k_\ell\}_{\ell=1}^n} \; \sum_{\substack{\gpos\in\sigma(K)\\\gpos\neq0}} \varx{\gpos}
	\end{equation}
	where $ \varx{\gpos} $ is defined in~\eqref{eq:cont-time-single-int-steady-state-variance}
	and $ \sigma(K) $ is the spectrum of $ K $.
	The stability condition for the formation is $ \gpos_M < \nicefrac{\pi}{(2\taun)} $,
	where $ \gpos_M \doteq \max\sigma(K) $ is the spectral radius of $ K $.
	%\footnote{In general, the eigenvalues of a positive semi-definite symmetric matrix are convex spectral functions~\cite{borweinConvex}.}
	Optimization~\eqref{eq:cont-time-single-int-variance-minimization-decoupled} is convex in virtue of %the stability constraints~\eqref{eq:cont-time-single-int-variance-condition},
	~\cref{lem:optimal-variance-explicit}
	and being the eigenvalues of $ K $ linear in the feedback gains~\cite{circulant},
	%In particular,
	and therefore can be solved numerically.
	We also consider a quadratic approximation to achieve analytical intuition:
	\begin{equation}\label{eq:quadratic-approximation}
		\argmin_{\{k_\ell\}_{\ell=1}^n} \; \sum_{\substack{\gpos\in\sigma(K)\\\gpos\neq0}} \left(\gpos-\opteig\right)^2
	\end{equation}
	%where $ \opteig $ is the minimizer of $ \var{\cdot} $.
	In words,~\eqref{eq:quadratic-approximation} squeezes the spectrum of $ K $
	about the ``optimal" eigenvalue:
	this is reasonable
	because the variance $ \varx{\gpos} $ is strictly convex
	and differentiable in the stability region,
	and explodes at the boundaries.
	Thus, it can be approximated by a parabola about the minimum (see~\autoref{fig:cost-comparison}).
	\begin{prop}\label{prop:subopt-gain}
		The solution of~\eqref{eq:quadratic-approximation} is $ \tilde{k}_\ell^* \! \equiv \! \tilde{k}^* \! \doteq \! \dfrac{\opteig}{2n+1} $.
	\end{prop}
	\begin{proof}
		The result follows by applying properties of the DFT to~\eqref{eq:quadratic-approximation}.
		See Appendices C-D in~\cite{2021arXiv210110394B} for details.
	\end{proof}
	\cref{prop:subopt-gain} shows that %designing all equal gains is a good choice
	%even when multiple gains are allowed.
	the suboptimal gain $ \tilde{k}^* $ decreases with
	the delay $ \taun $, according to the
	latency-dependent stability condition~\eqref{eq:cont-time-single-int-variance-condition},
	and with the number of agents involved in the feedback loops.
	%which reflects the benefit of communication.
	
	\begin{rem}[Control regularization]
		Excessive input efforts may be penalized by design adding a suitable term in~\eqref{eq:cont-time-single-int-variance-minimization}.
		However, the input intensity $ \mathbb{E}[\lVert u(t)\rVert^2] $
		cannot be decomposed like~\eqref{eq:cont-time-single-int-variance-minimization-decoupled}
		because of the cross-variances between neighbors,
		making the optimization hard.
		Conversely, any norm of $ K $
		can serve to the purpose without affecting the problem convexity.
	\end{rem}
	\fi
}
\def\year{2021}\relax
%File: formatting-instructions-latex-2021.tex
%release 2021.2
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai21}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet} % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{ulem}

\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%\nocopyright
%PDF Info Is REQUIRED.
% For /Author, add all authors within the parentheses, separated by commas. No accents or commands.
% For /Title, add Title in Mixed Case. No accents or commands. Retain the parentheses.
\pdfinfo{
/Title (AAAI Press Formatting Instructions for Authors Using LaTeX -- A Guide)
/Author (AAAI Press Staff, Pater Patel Schneider, Sunil Issar, J. Scott Penberthy, George Ferguson, Hans Guesgen, Francisco Cruz, Marc Pujol-Gonzalez)
/TemplateVersion (2021.2)
} %Leave this
% /Title ()
% Put your actual complete title (no codes, scripts, shortcuts, or LaTeX commands) within the parentheses in mixed case
% Leave the space between \Title and the beginning parenthesis alone
% /Author ()
% Put your actual complete list of authors (no codes, scripts, shortcuts, or LaTeX commands) within the parentheses in mixed case.
% Each author should be only by a comma. If the name contains accents, remove them. If there are any LaTeX commands,
% remove them.

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai21.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash

\title{Distribution Matching for Rationalization}
\author{
    %Authors
    % All authors must be in the same font size and format.
    Yongfeng Huang\textsuperscript{\rm 2}\footnote{Work done during an internship at Recurrent AI}, Yujun Chen\textsuperscript{\rm 1}, Yulun Du\textsuperscript{\rm 1}, Zhilin Yang\textsuperscript{\rm 1}
    \\
}
\affiliations{
    %Afiliations
    \textsuperscript{\rm 1}Recurrent AI, Beijing \\
    \textsuperscript{\rm 2}Tsinghua University, Beijing\\
    %If you have multiple authors and multiple affiliations
    % use superscripts in text and roman font to identify them.
    %For example,

    % Sunil Issar, \textsuperscript{\rm 2}
    % J. Scott Penberthy, \textsuperscript{\rm 3}
    % George Ferguson,\textsuperscript{\rm 4}
    % Hans Guesgen, \textsuperscript{\rm 5}.
    % Note that the comma should be placed BEFORE the superscript for optimum readability
    % email address must be in roman text type, not monospace or sans serif
    huangyf17@tsinghua.org.cn, chenyujun@rcrai.com, duyulun@rcrai.com, kimi\_yang@rcrai.com\\ 

    % See more examples next
}
\iffalse
%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Single Author}
\author {
    % Author
    Author Name \\
}

\affiliations{
    Affiliation \\
    Affiliation Line 2 \\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name,\textsuperscript{\rm 1}
    Second Author Name, \textsuperscript{\rm 2}
    Third Author Name \textsuperscript{\rm 1} \\
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1} Affiliation 1 \\
    \textsuperscript{\rm 2} Affiliation 2 \\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi
\begin{document}

\maketitle

\begin{abstract}
The task of rationalization aims to extract pieces of input text as rationales to justify neural network predictions on text classification tasks. By definition, rationales represent key text pieces used for prediction and thus should have similar classification feature distribution compared to the original input text. However, previous methods mainly focused on maximizing the mutual information between rationales and labels while neglecting the relationship between rationales and input text. To address this issue, we propose a novel rationalization method that matches the distributions of rationales and input text in both the feature space and output space. Empirically, the proposed distribution matching approach consistently outperforms previous methods by a large margin. Our data and code are available\footnote{https://github.com/kochsnow/distribution-matching-rationality}.
\end{abstract}


\section{Introduction}
In many real-world NLP applications, interpretability is an important objective for model development because it is crucial for human users to understand, verify, and trust the machine predictions. Among other possibilities, rationalization is a learning paradigm that extracts key text pieces as rationales to justify and interpret model predictions \cite{lei2016rationalizing}. Specifically, \citet{lei2016rationalizing} uses a generator to selectively extract rationales from the original input, and a classifier is applied on the rationales to predict the classification labels. This can be viewed as a cooperative game between the generator and the classifier to maximize the mutual information between the rationales and the labels \cite{Chen2018LearningTE}. In other words, this is based on the desideratum that the extracted rationales are predictive of the classification labels. Different variants of rationalization methods have been proposed under this framework, which additionally consider other desiderata such as the dependency between labels, rationales, and the complement of rationales \cite{chang2019game,chang2020invariant,yu2019rethinking}.

In this work, we argue that it is crucial to incorporate the following desideratum into modeling---the rationales and the original full input text should have similar feature and output distributions when the same classifier is applied. By definition, rationales represent key text pieces that are actually used for predicting the labels. The definition has a two-folded implication. First, the rationales should have a similar feature distribution to the input text because intermediate feature representations directly reflect how the model processes natural language. Second, since ultimately the probability outputs are used for classification, the rationales should have a similar output distribution to the input text. For example, consider a review ``this is a great movie''. A well-trained sentiment classifier mainly uses the rationale ``great movie'' for prediction. When the classifier is applied, ``great movie'' and ``this is a great movie'' should have similar feature and output distributions.

However, the aforementioned prior has not been effectively leveraged in previous approaches. As a solution, we propose a novel distribution matching approach for rationalization. In the feature space, we impose a regularization term that minimizes the central moment discrepancy (CMD) \cite{Zellinger2017CentralMD} between the full input features and the rationale features. In the output space, a teacher-student distillation loss \cite{hinton2015distilling} is employed to minimize the cross entropy loss between the full input predictions and the rationale predictions. 
Our approach is a plug-and-play improvement that is applicable to different rationalization variants.

We evaluate the proposed distribution matching approach on widely-used rationalization benchmarks---the beer review dataset ~\cite{McAuley2012LearningAA} and hotel review dataset ~\cite{Bao2018DerivingMA}. We use the game-theoretic class-dependent model \cite{chang2019game} as our base model. Empirical results show that distribution matching substantially improves over the baseline and outperforms all considered previous methods. It is also observed that both feature space matching and output space matching contribute to the overall performance.

To summarize, our work makes the following four contributions: 
\begin{itemize}
    \item We analyze the rationalization framework and uncover the issue that existing approaches neglect the relationship between rationales and input text. 
    \item We propose to impose an inductive bias that rationales should have similar feature and output distributions with input text so as to improve the faithfulness of rationalization. 
    % \item We proposed to leverage two regularization terms. 
    \item We achieved state-of-the-art results with substantial gains on multiple settings. % From an application perspective, our empirical gains substantiate the significance of our technical advancement
\end{itemize}
    % We believe it is nontrivial to apply these techniques in the contextof rationalization. 

\section{Related Work}
\subsection{Interpretability}
There are multiple lines of research in the area of learning interpretable models for NLP tasks. Roughly, there are three categories---post-hoc explanation methods, extractive retionalization methods, and the self-explaining model-based approach.

\paragraph{Extractive Rationalization.}
Extractive rationalization selects pieces of text from the input to form rationales that justify the prediction. Multiple variants were proposed to improve over the original framework \cite{lei2016rationalizing}. \citet{chang2019game} introduced a game-theoretic framework where the rationale generator is dependent on the class labels. \citet{yu2019rethinking} employed a similar idea and additionally employed constraints on the complement of rationales. Other approaches were based on the information bottleneck \cite{paranjape2020information}, latent variable models \cite{Bastings2019InterpretableNP}, and  learning environment-invariant representations \cite{chang2020invariant}.  However, none of these previous methods consider the relationship between rationales and the full input in terms of feature distribution. 

Recently, a new benchmark \cite{deyoung2019eraser} was introduced with labeled rationales available for training. This enables directly finetuning pretrained models \cite{DBLP:journals/corr/abs-1802-05365,Radford2018ImprovingLU,Devlin2019BERTPO,Yang2019XLNetGA} to predict the rationales in an end-to-end fashion. However, in this work, we focus on the conventional unsupervised learning setting because rationale groundtruth is not available for most real-world tasks.


% ~\cite{lei2016rationalizing,chang2019game,yu2019rethinking}
% try to generate the rationale together with the classification. Methods in this thread try to find the most expressive word segments, which will severely influence model's confidence if segments being removed. 
% In this category, the ERASER benchmark was released recently as a standard interpretable benchmark~\cite{deyoung2019eraser}. The ERASER benchmark consists of several existing extractive retionalization methods like ~\cite{lei2016rationalizing,lehman2019inferring}.
% ~\cite{lei2016rationalizing} provides a generator to extract rationale and an predictor to consume the rationale and make the decision; 
% ~\cite{chang2019game} introduces the idea of game theory between labels and is capable of providing both factual and counterfactual rationales for given label; 
% ~\cite{yu2019rethinking} use an introspective generator to disentangle the information according to labels and extract the rationale for certain labels. 
% Besides, ~\cite{paranjape2020information} builds an information bottleneck based approach to extract concise rationales. 
% In general, most of these methods follow the generator-predictor framework using the generator to extract rationales. 

% Most predictors in the typical generator-predictor framework can only maximize the mutual information between the extracted rationales and labels. 
% However, the original text always contains richer semantic information and obtain better predicting accuracy. 
% While matching the distribution between the extracted rationales and original text can help rationale generator learn higher level semantic feature for clasification. 

\paragraph{Post-Hoc Explanation.}
The post-hoc methods do not require specific additional efforts during training and explainations are computed after training is finished. Most of these approaches invetsigate the gradient saliency in a trained neural network. For example, ~\citet{sundararajan2017axiomatic,smilkov2017smoothgrad,Bao2018DerivingMA} studied the integrated gradients of a model for interpretability.
% and obtained the interpretability for cross data source target.  is often simpler and can be ignored in the training phase. 

% % distribution can barely 

% from higher level 

% while ignores the rich information beneath the original text. 


% The framework calls for highly expressive rationale and 

\paragraph{Model-Based Approach.}
Another line of research focuses on developing models that self-explain the results. For example, module networks \cite{Andreas2016LearningTC} learn structures in addition to weights so that the learned structure can be used to interpret how the model processes and reasons over natural language. \citet{Johnson2017InferringAE} adapted the concept of module networks to the vision domain.

\subsection{Knowledge Distillation}

\citet{hinton2015distilling} proposed the teacher-student framework of knowledge distillation that transfers knowledge from a teacher model to a student model by optimizing the cross entropy loss. The most typical use case of knowledge distillation is model compression. A small model is distilled from a large pretrained model to achieve a more desirable complexity-effectiveness trade off \cite{Sanh2019DistilBERTAD,Jiao2019TinyBERTDB}. Knowledge distillation is also known to improve performance when the student model is of comparable size with the teacher model \cite{yim2017gift,furlanello2018born,wang2020knowledge} because it provides soft, continuous labels for more effective training. \cite{yoon2018invase} used knowledge distillation in selecting instance-wise features which is similar with rationalization.

\subsection{Learning Domain-Invariant Representations}

There are two main categories for learning domain-invariant representations---adversarial training and distribution matching. 
Adversarial training introduces an adversarial game where a discriminator learns to distinguish features extracted by an encoder \cite{Ganin2015UnsupervisedDA}. Distribution matching, on the other hand, is based on minimizing the distance between distributions in various forms \cite{Zellinger2017CentralMD,Gretton2006AKM,Li2015GenerativeMM}. 

\section{Distribution Matching for Rationalization}

In this section, we first introduce the standard rationalization framework \cite{lei2016rationalizing} and discuss our proposed method. Then we consider a more advanced rationalization variant (i.e., the game-theoretic approach introduced by \citet{chang2019game}) and discuss how to implement our framework on it.

\subsection{Preliminaries: The Rationalization Framework}

The input to the rationalization framework \cite{lei2016rationalizing} is a text sequence $\mathbf{x}=(x_1, x_2, \cdots, ,x_l)$ of length $l$, where each $x_i \in \mathcal{V}$ denotes the $i$-th token and $\mathcal{V}$ is the vocabulary. A generator $g$ is applied on $\mathbf{x}$ to obtain the rationale mask $\mathbf{z}$, i.e.,
\[
\mathbf{z} = g(\mathbf{x})
\]
where the rationale mask $\mathbf{z}$ is represented as a sequence of binary variables $\mathbf{z} = (z_1, z_2, \cdots, z_l)$. Each entry $z_i = 1$ means $x_i$ is selected as part of the rationales and $z_i = 0$ denotes the opposite. In other words, given the input text $\mathbf{x}$ and the mask $\mathbf{z}$, the rationale can be obtained as $\{x_i | z_i = 1\}$.

A classifier $c$ is applied on top of the rationale to obtain the model output distribution $\hat{p}(Y)$. Computationally, we use a lookup table to obtain the input embeddings $\mathbf{e}(\mathbf{x})$ and feed the masked embeddings to the classifier $c$ as follows:
\[
\hat{p}(Y) = c(\mathbf{z} \odot \mathbf{e}(\mathbf{x}))
\]
where $\odot$ denotes element-wise multiplication and $\hat{p}(Y)$ is a probability distribution over the classes.

Let $y$ be the groundtruth label in the label space $\mathcal{Y}$. The classification loss is written as a standard cross entropy loss:
\[
l_\text{cls} = - \log \hat{p}(Y = y)
\]

Additionally, it is desirable to control the sparsity and compactness of the rationales. To achieve this goal, the following regularization is applied:
\[
\Omega(\mathbf{z}) = \lambda_1 \|\mathbf{z}\|_1 + \lambda_2 \sum_{i = 2}^{l}|z_i - z_{i - 1}|
\]
with $\lambda_1$ and $\lambda_2$ being the coefficients.

The generator and the discriminator are jointly trained to minimize the overall loss function
\[
\min_{g, c} l_\text{cls} + \Omega(\mathbf{z}).
\]
Since $\mathbf{z}$ is discrete, the loss function is not differentiable w.r.t. the generator parameters. Methods like straight-through \cite{Bengio2013EstimatingOP} can be used for optimization.

% An ideal rationales should satisfy the conditions of sufficiency and compactness. The optimal objective of generator $G$ maximizes sufficiency  under the constraints of compactness. The sufficiency and compactness are defined as the following:
% \paragraph{sufficiency:}Rationales $\mathbf{x_z}$ ought to reach nearly the same prediction (target vector). 
% \begin{equation}
%     p_Y(\cdot|\mathbf{x_z}) = p_Y(\cdot|\mathbf{x})
% \end{equation}
% \paragraph{Compactness:}$\mathbf{x_z}$ should be sparse and coherent.
% \begin{equation}
%     \sum_{k} |z_k| <p
% \end{equation}
% \begin{equation}
%     \sum_{k} |z_k-z_{k-1}|< c
% \end{equation}



\subsection{Distribution Matching for Rationalization (DMR)}

Now we introduce our DMR method to improve rationalization based on distribution matching. Figure~\ref{fig:DMR_frame} illustrates the DMR model in comparison with the baseline RNP~\cite{lei2016rationalizing}. 

The underlying assumption and desideratum of our distribution matching approach is that the rationales and the original full input text should have similar feature and output distributions when the classifier is applied. Intuitively, interpreting model predictions is to explain how the classifier processes input information. Since rationales are to interpret and justify the predictions, when the input contains only the rationales, the classifier should learn features and make predictions in a very similar way compared to using the full original text as input. Based on this intuition, we propose to encourage similar distributions in both the feature and output spaces between the rationales and the full text input.

\begin{figure*}
    \centering
    \includegraphics[width=0.97\textwidth ]{cyj.pdf}
    \caption{Comparison of (a) the baseline RNP framework, and (b) our proposed DMR framework. We run the classifier on the full input text for feature matching, and also train a student classifier for output matching.}
    \label{fig:DMR_frame}
\end{figure*}

\subsubsection{Feature Space Matching}

The classifier $c$ can be instantiated as different models such recurrent neural networks \cite{Hochreiter1997LongSM}, convolutional networks \cite{Waibel1989PhonemeRU} and Transformers \cite{Vaswani2017AttentionIA}. Let $f$ be the function in classifier $c$ that maps word embeddings to network output features---e.g., the output of a max-pooling layer. Given a text sample $\mathbf{x}_i$ with rationale $\mathbf{z}_i$, it follows that $f(\mathbf{e}(\mathbf{x}_i))$ and $f(\mathbf{z}_i \odot \mathbf{e}(\mathbf{x}_i))$ are the features of the full input text and the rationales respectively. Denote these two features as $\mathbf{f}_i^x$ and $\mathbf{f}_i^z$ respectively.

Given a batch of $N$ training samples $\{\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_N\}$ with rationales $\{\mathbf{z}_1, \mathbf{z}_2, \cdots, \mathbf{z}_N\}$ computed by the generator $g$, we employ the classifier $c$ to compute features $\{\mathbf{f}_1^x, \mathbf{f}_2^x, \cdots, \mathbf{f}_N^x\}$ and $\{\mathbf{f}_1^z, \mathbf{f}_2^z, \cdots, \mathbf{f}_N^z\}$. A central moment discrepancy regularizer \cite{Zellinger2017CentralMD} is employed to match the distributions in the feature space:
\[
l_\text{fm} = \|\mathbf{E}_x - \mathbf{E}_z\|_2 + \sum_{k = 2}^K \|\mathbf{C}_k^x - \mathbf{C}_k^z\|_2
\]
with
\[
\mathbf{E}_x = \frac{1}{N} \sum_{i = 1}^N \mathbf{f}_i^x
\]
\[
\mathbf{C}_k^x = \frac{1}{N} \sum_{i = 1}^N (\mathbf{f}_i^x - \mathbf{E}_x)^k
\]
where $\mathbf{E}_x$ the is empirical expectation of the features, and $\mathbf{C}_k^x$ is $k$-th order central moments of the feature coordinates. $\mathbf{E}_z$ and $\mathbf{C}_k^z$ are defined in a similar way. In practice, we compute the central moments up to the fifth order, i.e., $K = 5$. It is assumed that the features are distributed in the interval $[0, 1]$---e.g., the output of the sigmoid function; in other cases, constants might be added before each term \cite{Zellinger2017CentralMD}.

The feature space matching loss $l_\text{fm}$ enforces the rationales and the full input to have similar feature distributions when the classifier $c$ is applied.

\subsubsection{Output Space Matching}

A straightforward method to add training signals in the output space is to use a normal classification loss as in \cite{lei2016rationalizing}. However, following \cite{hinton2015distilling}, we believe only a categorical label is not sufficient to provide useful training signals. Our goal is to ensure that the rationales and the full input have similar output distributions, so knowledge distillation \cite{hinton2015distilling} is used for distribution matching in the probability output space.

Specifically, we first pretrain a teacher classifier $c_t$ that maps the full input text to the probability space using a standard classification loss. Let $\hat{p}_t(Y) = c_t(\mathbf{e}(\mathbf{x}))$ be the teacher model distribution of sample $\mathbf{x}$. The output space matching loss is written as the cross entropy between the teacher distribution $\hat{p}_t(Y)$ and the student distribution $\hat{p}(Y)$:
\[
l_\text{om} = \sum_{y = 1}^{|\mathcal{Y}|} - \hat{p}_t(Y = y) \log \hat{p}(Y = y).
\]

\subsubsection{Overall Loss Function}
\label{ssub:overall}
The overall loss function is formulated as the weighted sum of the feature and output space matching losses, along with the normal rationalization losses, i.e.,
\[
\min_c l_\text{cls} + \lambda_3 l_\text{fm} + \lambda_4 l_\text{om}
\]
\[
\min_g l_\text{cls} + \Omega(\mathbf{z})
\]
where $\lambda_3$ and $\lambda_4$ are the coefficients of the loss terms. Note that we apply the matching losses only on the classifier and do not backpropagate the gradients of $l_\text{fm}$ and $l_\text{om}$ to the generator $g$. Also the regularizer $\Omega(\mathbf{z})$ only depends on the generator. Although gradients from discriminator $d$ are not directly passed to $g$, the generators essentially benefit from the losses. 
Since we measure the accuracy of rationale prediction, the results improve if and and only if the generators improve. Therefore, the generators benefit a lot from our two regularization terms (though in an indirect manner).

% In this work, we argue that it is crucial to incorporate the following desideratum into modeling---the rationales and the original full input text should have similar feature and output distributions when the same classifier is applied. By definition, rationales represent key text pieces that are actually used for predicting the labels. The definition has a two-folded implication. First, the rationales should have a similar feature distribution to the input text because intermediate feature representations directly reflect how the model processes natural language. Second, since ultimately the probability outputs are used for classification, the rationales should have a similar output distribution to the input text. For example, consider a review ``this is a great movie''. A well-trained sentiment classifier mainly uses the rationale ``great movie'' for prediction. When the classifier is applied, ``great movie'' and ``this is a great movie'' should have similar feature and output distributions.

% \subsection{The DMR Framework}

% \begin{figure*}
%     \centering
%     \includegraphics[width=0.9\textwidth ]{Framework.png}
%     \caption{(a)The RNP framework; (b) The DMR framework}
%     \label{fig:my_label}
% \end{figure*}

\subsection{Extensions and Implementation}
Our above derivation is based on the original rationalization framework \cite{lei2016rationalizing}. However, our approach is general and applicable to different backbone methods. In our preliminary study, we experimented with multiple variants that improve over the original method and found that the CAR framework \cite{chang2019game} works particularly well. The CAR framework feed ground-truth label to the generator and proposed the cooperative and adversarial game mechanism.

% The CAR framework feed ground-truth label to the generator to model the dependency between the label and the rationales, and the car framework consist of a classifier $c$, a factual generator $g_f$, and a counterfactual generator $g_c$ for each class, where the factual generator $g_f$ and the classifier $c$ play a standard cooperative game as before. The counterfactual generator $g_c$ takes data samples from the other class and plays an adversarial game with the classifier.

% The CAR framework makes a few major improvements:
% \begin{itemize}
%     \item During training, the ground-truth label is fed into the generator. This models the dependency between the label and the rationales.
%     \item Each class has a classifier $c$, a factual generator $g_f$, and a counterfactual generator $g_c$. The factual generator $g_f$ and the classifier $c$ play a standard cooperative game as before. The counterfactual generator $g_c$ takes data samples from the other class and plays an adversarial game with the classifier---maximizing the classification loss. See \cite{chang2019game} for detailed analysis on the game-theoretical properties.
% \end{itemize}

% Our proposed method is applicable to CAR although it is seemingly different from the original framework. 
% In the CAR framework, we similarly apply the feature and output distribution matching losses only on the classifier, which does not directly affect the gradients on the generators. 
% In our implementation, the DMR is implemented based on CAR. We treat the discriminators in the CAR as classifier and apply the two loss function on their outputs. The teacher classifier for each of the rationale group is added as well to CAR. 
% % \paragraph{Training Details:}

We adopt a two-stage training scheme in our implementation. In the first stage, the teacher classifier $c_t$ is pretrained on the full dataset. After pretraining the teacher classifier $c_t$, we jointly train the student classifiers and the generators using the aforementioned losses.

% Following \cite{chang2019game}, all the generators and classifiers in the DMR framework are composed of one word embedding layer, a bi-directional LSTM network, and one linear projection layer. The input to the generators are appended with the (factual or counterfactual) label as a one-hot vector. 


% In this training stage, student discriminator $d_z$ is fed with rationales $z$ generated by generators; the targets labels of $d_z$ includes hard label $y$ and soft labels $y_t$ provided by teacher discriminator $d_t$; $d_x$ is fed with text input $x$ and share the same parameters with $d_z$. While student discriminators aim to distinguish the ground truth labels of rationales, generator $g_t$ aims to convince student discriminators $d_z$ rationales $z$ belong to its class $t$. 

% \paragraph{Architecture design details:}


% \section{Experiment}
% \subsection{Datasets}
% To evaluate the performance of extracted rationales, we will use the multi-aspect beer and hotel datasets, which are commonly used in the field of rationalization. Following the data preprocessing procedure in~\cite{}, we will firstly preprocess both beer and hotel dataset into binary classification problems. The validate dataset will follow the same processing for 
% considering $\mathcal{X}$ datasets, which are all about binary classification. The first one is the multi-aspect beer 

% \subsection{Baselines}
% \begin{enumerate}
%     \item \textbf{RNP:} RNP is a generator-predictor framework proposed in ~\cite{}. The generator will select text segments as rationales, and the predictor will use the extracted segments to do the classification. The selection aims at maximizing the predictive accuracy of the predictors' output and is constrained to be both sparse and continuous. 
%     \item \textbf{CAR:} Another generator-predictor framework propoesd in . The generator and predictor serve the same purpose as RNP, while this method added another discriminator to judge whether given rationale is for positive or negative label. The method provide a class based rationale extraction method that can provide rationale for both positive and negative label. 
%     \item \textbf{3player:} The 3player is the improvement of RNP from Yu et al. \cite{}, which try to alleviate the degeneration problem of RNP. The model consist of three modules including the generator, the predictor and the complement predictor. The complement predictor tries to maximize the predictive accuracy from unselected words. Besides the MMI objective optimized between the generator and predictor, the generator also plays an adversarial game with the complement predictor, trying to minimize its performance.
%     \item \textbf{INVRAT:} 

% \end{enumerate}

% To seek for a pair comparison, the generator of all the mentioned methods will use the same architecture. The rationale predictor for all generator-predictor based methods use the same architecture. The proposed method use the same architecture for both teacher and student discriminators are the same as discriminator in .... The hidden state of all... In addition, the sparsity and continuity constraints follow the same form and adjust all methods to have same level of sparsity. 

% \subsection{Experiment Settings}




% \subsection{Results}

\begin{table*}[]
    \centering
    % Please add the following required packages to your document preamble:
% \usepackage{multirow}
\vspace{0.5cm}
\small
\begin{tabular}{c|cccc|cccc|cccc}
\hline%\hline
\multicolumn{1}{c|}{\multirow{2}{*}{Beer}} & \multicolumn{4}{c|}{Appearance}                               & \multicolumn{4}{c|}{Aroma}                                    & \multicolumn{4}{c}{Palate}                                   \\
\multicolumn{1}{c|}{}                      & S    & P             & R             & \multicolumn{1}{c|}{F} & S    & P             & R             & \multicolumn{1}{c|}{F} & S    & P             & R             & \multicolumn{1}{c}{F} \\ \hline
CAR                                        & 11.9 & 76.2          & 49.3          & 59.9                   & 10.3 & 50.3          & 33.3          & 40.1                   & 10.2 & \textbf{56.6} & 46.2          & 50.9                   \\
DMR (ours)                                        & 11.7 & \textbf{83.6} & \textbf{52.8} & \textbf{64.7}          & 11.7 & \textbf{63.1}          & \textbf{47.6}          & \textbf{54.3}                   & 10.7 & 55.8          & \textbf{48.1} & \textbf{51.7}          \\
\hline%\hline
\multirow{2}{*}{Hotel} & \multicolumn{4}{c|}{Location}                        & \multicolumn{4}{c|}{Service}                         & \multicolumn{4}{c}{Cleanliness}                      \\
                      & S    & P             & R             & F             & S    & P             & R             & F             & S    & P             & R             & F             \\ \hline
% RNP                   & 10.9 & 43.3          & 55.5          & 48.6          & 11.0 & 40.0          & 38.2          & 39.1          & 10.6 & 30.5          & 36.0          & 33.0          \\
CAR                   & 10.6 & 46.6          & 58.1          & 51.7          & 11.7 & 40.7          & 41.4          & 41.1          & 10.3 & 29.0          & 33.8          & 31.2          \\
DMR (ours)                   & 10.7 & \textbf{47.5} & \textbf{60.1} & \textbf{53.1} & 11.6 & \textbf{43.0} & \textbf{43.6} & \textbf{43.3} & 10.3 & \textbf{31.4} & \textbf{36.4} & \textbf{33.7} \\\hline
\end{tabular}

\caption{\normalsize Comparison with \emph{CAR} on both the beer review dataset and the hotel review dataset. S, P, R, and F1 represent the sparsity level, precision, recall, and F1 score respectively. We use the same (or similar) sparsity levels as previous work for fair comparison. All the baseline results are taken from \cite{chang2019game}.}
    \label{tab:table_game}
\end{table*}

%harden 
\begin{table*}[!ht]
    \centering
\small
    \begin{tabular}{c|cccc|cccc|cccc}
%\hline%\hline
% \multicolumn{1}{c|}{\multirow{2}{*}{Beer}} & \multicolumn{4}{c|}{Appearance}                               & \multicolumn{4}{c|}{Aroma}                                    & \multicolumn{4}{c}{Palate}                                   \\
% \multicolumn{1}{c|}{}                      & S    & P             & R             & \multicolumn{1}{c|}{F} & S    & P             & R             & \multicolumn{1}{c|}{F} & S    & P             & R             & \multicolumn{1}{c|}{F} \\ \hline
% CAR                                        & 11.9 & 76.2          & 49.3          & 59.9                   & 10.3 & 50.3          & 33.3          & 40.1                   & 10.2 & \textbf{56.6} & 46.2          & 50.9                   \\
% DMR (ours)                                        & 11.7 & \textbf{83.6} & \textbf{52.8} & \textbf{64.7}          & 11.7 & 63.1          & 47.6          & 54.3                   & 10.7 & 55.8          & \textbf{48.1} & \textbf{51.7}          \\ \hline
\hline%\hline
\multicolumn{1}{c|}{\multirow{2}{*}{Beer}} & \multicolumn{4}{c|}{Appearance}                               & \multicolumn{4}{c|}{Aroma}                                    & \multicolumn{4}{c}{Palate}                                   \\
\multicolumn{1}{c|}{}                      & S    & P             & R             & \multicolumn{1}{c|}{F} & S    & P             & R             & \multicolumn{1}{c|}{F} & S    & P             & R             & \multicolumn{1}{c}{F} \\ \hline
RNP                                        & 7.9  & 13.5          & 5.8           & 8.1                    & 8.4  & 30.3          & 15.3          & 20.3                   & 9.1  & 28.2          & 17.2          & 21.4                   \\
3PLAYER                                    & 7.9  & 15.8          & 6.8           & 9.5                    & 8.4  & 48.9          & 24.4          & 32.6                   & 9.1  & 14.2          & 8.5           & 10.7                   \\
INVRAT                                     & 7.9  & 49.5          & 20.9          & 29.3                   & 8.4  & 48.2          & 24.4          & 32.4                   & 9.1  & 32.8          & 20.0          & 24.9                   \\

DMR (ours)                                        & 7.9  & \textbf{80.1} & \textbf{34.7} & \textbf{48.6}          & 8.9  & \textbf{50.3}          & \textbf{28.9} & \textbf{36.7}          & 9.6  & \textbf{49.7} & \textbf{38.2} & \textbf{43.2}          \\ \hline
RNP                                        & 15.8 & 13.5          & 11.3          & 12.3                   & 16.8 & 34.3          & 34.2          & 34.3                   & 18.1 & 19.8          & 23.8          & 21.6                   \\
3PLAYER                                    & 15.8 & 15.6          & 13.5          & 14.5                   & 16.8 & 35.7          & 35.9          & 35.8                   & 18.1 & 20.7          & 24.9          & 22.6                   \\
INVRAT                                     & 15.8 & 58.0          & 49.6          & 53.5                   & 16.8 & 42.7          & 42.5          & 42.6                   & 18.1 & \textbf{44.0} & \textbf{52.8}          & \textbf{48.0}                   \\

DMR (ours)                                        & 15.7 & \textbf{61.5} & \textbf{52.0} & \textbf{56.4}          & 16.8 & \textbf{47.6} & \textbf{51.3} & \textbf{49.4}          & 15.7 & 39.4          & 49.7 & 44.0          \\ \hline
RNP                                        & 23.7 & 26.3          & 33.1          & 29.3                   & 25.2 & 40.0          & 60.1          & 48.0                   & 27.2 & 19.2          & 33.8          & 24.5                   \\
3PLAYER                                    & 23.7 & 12.6          & 15.9          & 14.0                   & 25.2 & 33.0          & 49.7          & 39.7                   & 27.2 & 22.0          & 39.3          & 28.2                   \\
    INVRAT                                     & 23.7 & 54.0          & \textbf{69.2}          & 60.7                   & 25.2 & 44.7 & 67.4          & 53.8                   & 27.2 & 26.5          & 46.9          & 33.9                   \\

DMR (ours)                                        & 21.2 & \textbf{58.9} & 67.4 & \textbf{62.9}          & 25.0 & \textbf{44.7}          & \textbf{71.8} & \textbf{55.1}          & 27.2 & \textbf{28.0} & \textbf{61.3} & \textbf{38.4}          \\ \hline
\end{tabular}
    \caption{\normalsize Comparsion with \emph{RNP}, \emph{3PLAYER} and \emph{INVRAT} on the beer review dataset. S, P, R, and F1 represent the sparsity level, precision, recall, and F1 score respectively. We use the same (or similar) sparsity levels as previous work for fair comparison. All the baseline results are taken from \cite{chang2020invariant}.}
    \label{tab:table_invariant}
\end{table*}

\begin{table*}[!t]
\centering
\small
\begin{tabular}{c|ccc|ccc|ccc}
\hline
\multicolumn{1}{l|}{} & \multicolumn{3}{c}{appearance} & \multicolumn{3}{c|}{aroma}     & \multicolumn{3}{c}{palate}                        \\
input                 & precision & recall  & f1-score & precision & recall  & f1-score & precision & recall  & f1-score                     \\ \hline
rationales            & 92.09   & 88.56 & 90.29  & 93.47   & 79.23 & 85.77  & 93.87   & 71.79 & \multicolumn{1}{c}{81.36} \\
full texts            & 91.54   & 91.88 & 91.71  & 94.34   & 79.26 & 86.15  & 94.52   & 70.08 & \multicolumn{1}{c}{80.49} \\ \hline
\end{tabular}
\centering
\caption{\normalsize Comparison of classification performances using rationales and full texts}
    \label{tab:rationales classification}
\end{table*}


\section{Experiments}
\subsection{Datasets}
% To evaluate the performance of extracted rationales, we will use the multi-aspect beer and hotel datasets, which are commonly used in the field of rationalization. Following the data preprocessing procedure in~\cite{}, we will firstly preprocess both beer and hotel dataset into binary classification problems. The validate dataset will follow the same processing for 
% consider X datasets, which are all about binary classification. The first one is the multi-aspect beer 
To evaluate the performance of our DMR framework, we use the multi-aspect beer and hotel datasets, which are commonly used in the field of rationalization.

\paragraph{Beer reviews:} The beer review dataset~\cite{McAuley2012LearningAA} is a multi-aspect sentiment classification dataset, where each review of a beer consists of a plain-text comment and ratings from three aspects including appearance, aroma and palate. 
% Comment text contains several sentences describing  the impression of one or multiple aspect of a beer, including appearance, aroma and palate. 
% To construct the setting of binary classification, we treat the reviews that have ratings $\leq 0.4$ as negative and those $\geq 0.6$ as positive. Thus the rating for each aspect is binary.  

% In addition, we use annotated test dataset in the beer review dataset to evaluate performance of our proposed rationalization method. 

\paragraph{Hotel reviews:} The hotel review dataset~\cite{Bao2018DerivingMA} is another multi-aspect  sentiment classification dataset. 
The dataset contains reviews of hotels from three aspects including location, cleanliness, and service. 
Each review also has a rating on a scale of 0-5 stars. 
% Similarly, we consider reviews with rating $>3$ as positive and the ones with rating $\leq 3$ as negative.

We preprocess both datasets in the same setting as~\cite{chang2019game} for fair comparison. 
% We use manually labeled rationales from~\cite{chang2019game} as groundtruth annotations to form the test set.
% The beer review test set has about 1,000 reviews with sentence-level annotations indicating which aspect a sentence belongs to, while the hotel review test set has 200 annotated reviews for each aspect. 

% The test dataset in hotel review uses manually labeled rationales as annotated by~\cite{chang2019game} and contains about 200 reviews with rationales explain the labeled rating for each aspect.




\subsection{Baselines}

We consider the following baselines for comparison in our experiments:
\begin{itemize}
    \item \textbf{RNP:} RNP is the original rationalization framework proposed in ~\cite{lei2016rationalizing}.
    The generator selects text segments as rationales, and the predictor is fed with rationales for label classification. 
    RNP aims to maximize the mutual information between
    rationales and labels and the rationales are constrained to be both sparse and continuous. 
    
    \item \textbf{3PLAYER:} The 3PLAYER method is an enhancement of RNP~\cite{yu2019rethinking}, which alleviates the degeneration problem of RNP by introducing an extra complement predictor. The complement predictor tries to maximize the predictive accuracy from unselected words and plays an adversarial game with generator. 
    % Compared to RNP,  The rationalization framework consist of three modules including generator, predictor and complement predictor. The complement predictor tries to maximize the predictive accuracy from unselected words and plays an adversarial game with generator. Meanwhile, MMI is still the optimal objective of the generator and predictor 
    
    \item \textbf{INVRAT:} INVRAT introduces a game-theoretic invariant criterion as the objective and aims to learn environment invariant representations~\cite{chang2020invariant}. 
    
    % INVRAT point out the fatal flaw of MMI objective only based on rationales, for MMI can not distinguish spurious correlations between the input features and the output. By using introducing a game-theoretic invariant rationalization criterion, INVRAT can filter out spurious correlations and improve the generalization of framework. 

    \item \textbf{CAR:} CAR proposes a game theoretic approach to class-wise selective rationalization~\cite{chang2019game}. The approach produces both positive and negative rationales. This is the direct baseline of our results because we use CAR as our backbone model.
    
    % , which is still based on generator-predictor framework.
% . Generators in the CAR produce both positive and negative rationales to challenge the predictors while predictors try to distinguish ground truth labels of rationales. In other word, CAR take the way of adversarial learning to drive generators to generate meaningful rationales. 
    % \item \textbf{DMR:} 
\end{itemize}

To seek for fair comparisons, the generators, the predictors, and the discriminators of all the baselines and our method use the same architecture as in the previous work \cite{chang2019game}. In addition, the sparsity and continuity constraints follow the same form and all methods are adjusted to have a comparable level of sparsity in the experiments. 
In our experiment, we implement our DMR framework directly based on the CAR model. 
% , one bi-direction LSTM layer and one linear projection layer and only vary in the input dimension of embedding layer and the hidden dimension of LSTM layer. 

Following previous work \cite{chang2019game}, the hidden unit size and the embedding dimension of the teacher discriminator are set as 100, while those of the generators and the student discriminator are set as 102 for two extra class label dimensions. 
% are appended to text embedding vector and hidden feature vector. 



\begin{table*}[!t]
\centering
\vspace{0.5cm}
\small
\begin{tabular}{c|cccc|cccc|cccc}
\hline%\hline
\multicolumn{1}{c|}{\multirow{2}{*}{Beer}} & \multicolumn{4}{c|}{Appearance}                               & \multicolumn{4}{c|}{Aroma}                                    & \multicolumn{4}{c}{Palate}                           \\
\multicolumn{1}{c|}{}                      & S    & P             & R             & \multicolumn{1}{c|}{F} & S    & P             & R             & \multicolumn{1}{c|}{F} & S    & P             & R             & F             \\ \hline
DMR                                        & 8.8  & \textbf{78.4} & \textbf{37.3} & \textbf{50.6}          & 8.8  & 48.7          & \textbf{27.6} & \textbf{35.3}          & 8.9  & \textbf{60.2} & \textbf{43.2} & \textbf{50.3} \\ 
~~ - fm                                 & 8.9  & 74.5          & 35.7          & 48.3                   & 8.4  & 49.5          & 26.7          & 34.7                   & 8.9  & 58.6          & 42.2          & 49.1          \\
~~ - fm\&om                           & 8.8  & 70.0          & 33.4          & 45.2                   & 7.7  & \textbf{50.2} & 24.8          & 33.2                   & 8.9  & 54.3          & 38.9          & 45.3          \\ \hline
DMR                                        & 12.3 & \textbf{82.6} & \textbf{55.0} & \textbf{66.1}          & 13.0 & \textbf{61.8} & \textbf{51.5} & \textbf{56.1}          & 11.5 & \textbf{55.8} & \textbf{51.6} & \textbf{53.6} \\ 
~~ - fm                                 & 12.4 & 77.0          & 51.5          & 63.5                   & 12.0 & 60.4          & 46.5          & 52.6                   & 12.3 & 51.3          & 50.5          & 50.9          \\
~~ - fm\&om                           & 12.3 & 74.5          & 49.6          & 59.6                   & 12.9 & 55.2          & 45.6          & 50.0                   & 12.1 & 50.6          & 49.1          & 49.8          \\\hline
DMR                                        & 16.0 & \textbf{72.8} & \textbf{63.0} & \textbf{67.5}          & 16.2 & 52.3          & \textbf{54.6} & \textbf{53.4}          & 16.4 & \textbf{45.2} & \textbf{59.5} & \textbf{51.4} \\ 
~~ - fm                                 & 16.0 & 69.0          & 59.7          & 64.0                   & 15.5 & \textbf{52.4} & 52.2          & 52.3                   & 16.0 & 38.4          & 49.4          & 43.2          \\
~~ - fm\&om                           & 16.0 & 63.9          & 55.4          & 59.4                   & 16.1 & 36.2          & 37.5          & 36.8                   & 16.3 & 37.7          & 49.3          & 42.7          \\\hline
DMR                                        & 24.0 & \textbf{57.7} & \textbf{74.7} & \textbf{65.1}          & 24.1 & \textbf{46.1} & \textbf{71.3} & \textbf{56.0}          & 23.8 & \textbf{36.6} & \textbf{70.2} & \textbf{48.1} \\ 
~~ - fm                                 & 23.9 & 54.1          & 69.9          & 61.0                   & 24.0 & 44.0          & 67.8          & 53.4                   & 24.0 & 29.8          & 57.4          & 39.2          \\
~~ - fm\&om                           & 23.9 & 53.9          & 69.7          & 60.8                   & 24.1 & 43.0          & 66.6          & 52.2                   & 23.9 & 28.5          & 54.8          & 37.5          \\\hline
\end{tabular}
\caption{\normalsize Ablation study. ``- fm'' means removing the feature space matching loss, and ``- fm\&om'' means removing both feature and output space matching losses.}
\label{tab:ablation_study}
\end{table*}

\begin{table*}[]
    \centering
\small
    % Please add the following required packages to your document preamble:
% \usepackage{multirow}

\begin{tabular}{c|cccc|cccc|cccc}
\hline%\hline
\multirow{2}{*}{Beer} & \multicolumn{4}{c|}{Appearance}                        & \multicolumn{4}{c|}{Aroma}                         & \multicolumn{4}{c}{Palate}                      \\
                      & S    & P             & R             & F             & S    & P             & R             & F             & S    & P             & R             & F             \\ \hline
DMR$_{CORAL}$                   & 11.9 & 79.0          & 50.8          & 61.9          & 11.7 & 60.3          & 45.2          & 51.6          & 10.1 & 47.0          & 38.0          & 42.0          \\
DMR$_{MMD}$                   & 11.7 & 81.0          & 51.4          & 62.9          & 11.5 & 50.0          & 36.9          & 42.4          & 10.6 & 44.5          & 38.0          & 41.0          \\
DMR (ours)                   & 11.7 & \textbf{83.6} & \textbf{52.8} & \textbf{64.7} & 11.7 & \textbf{63.1} & \textbf{47.6} & \textbf{54.3} & 10.7 & \textbf{55.8} & \textbf{48.1} & \textbf{51.7} \\\hline
\end{tabular}
\caption{\normalsize Comparison of Different Matching Loss Selected.}
    \label{tab:table_loss_sensitivity}
\end{table*}

\begin{figure}
    \centering
    \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=0.8\linewidth]{lambda_3.pdf}
    \caption{}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=0.8\linewidth]{lambda_4.pdf}
    \caption{}
    \end{subfigure}
    \caption{Parameter Sensitivity of $\lambda_3$ and $\lambda_4$}
    \label{fig:lambdas_sensitivity}
\end{figure}


\subsection{Quantitative Evaluation}

% In this section, we evaluate the performance of DMR and compare its performance against with state-of-the-art methods on the beer and the hotel review datasets. 
% % to evaluate the effectiveness of our method. 
% % Both datasets contain multiple aspects for each review sentences and each aspect is indicated by a single sentence with clear polarity. 
% We train our models using a balanced training dataset as in~\cite{chang2019game} and evaluate the performances on the test sets with human annotated rationales. 
% % with human annotated rationales. 
% To further compare with \emph{INVRAT} and \emph{3PLAYER}, we adjust the level of sparsity to obtain the same rationale lengths on the beer dataest as in~\cite{chang2020invariant}. 
% We evaluate the performance of rationalization methods by calculating the precision, recall and F1 scores between the extracted rationales and human labeled rationales, which follows the prior work.

% % We reported the precision, recall and F1 score of the extracted rationales.% \john{We repeated our experiments five times, and report the best performance. ??}. 
% Since previous work reported results with different sparsity levels \cite{chang2020invariant,chang2019game}, we reported our results under several sparsity levels for direct comparison with previous work, as shown in Table \ref{tab:table_beer}.
% In the first set, DMR achieves the best performance in both the appearance and the palate aspect, and outperforms the direct baseline CAR in the aroma aspect.
% % In the appearance aspect, DMR gains a significant margin over both CAR and RNP, while RNP obtains surprisingly high performance in the aroma aspect. 

% % By comparing generated rationales with human annotations,  
% % are calculated for evaluating the performance of rationalization methods. 

% % In Table~\ref{tab:table_beer}, we compare DMR with other methods on the beer review dataset. 
% % We compare DMR with other methods in two settings, fixed sparsity and variant sparsity. 


% % Comparing with RNP and CAR, DMR obtains the best performance in 
% In the last three sets, we vary the rationale lengths and set the sparsity level at 7.9, 15.8, 23.7 to match the experiment settings in~\cite{chang2020invariant}. DMR obtains the best performances in almost all metrics and sparsity combinations.
% % which demonstrates the effectiveness of distribution matching.
% % According to Table~\ref{tab:table_beer}, in all the sparsity settings, 


% % We only use the sparsity levels in~\cite{chang2019game} since INVRAT and 3PLAYER have not been evaluated on the hotel dataset. 
% % only shows the variant length result in beer dataset. 
% As presented in Table~\ref{tab:table_hotel}, DMR outperforms all state-of-the-art methods in all three aspects on the hotel review dataset. 
% Specially, DMR obtains substantial gains (more than 2 F1 points) over other methods on the cleanliness and the service aspects, while also outperforming CAR and RNP in the location aspect.
% On the hotel review dataset, there is not reported results available for INVRAT and 3PLAYER.
% % in the metric of F1 score, 
% % Besides, DMR perform better than DMR-w/o-fm again proving the advantage of matching distribution in the both output and feature space. We do not compare 

% We use rationales generated by DMR and original full texts to train classifiers with the same structure respectively. The classification results in the Table~\ref{tab:rationales classification} show that better rationalization does not substantially improve classification, but with our method, training a classifier on the rationales is able to achieve performance comparable to using full text.

% The results in Table~\ref{tab:table_beer} and ~\ref{tab:table_hotel} reveal the effectiveness of distribution matching. 
% Compared with existing approaches, DMR is able to extract more accurate rationales and the advantages can be extended to all sparsity levels. 
% % invariant to all help rationales find more accurate representations. 
% % Matching the distribution of input and rationales can greatly help the generators to predict the accurate rationales. 

% % the input texts have similar distribution as rationales extracted. 

% % Even though CAR or INVRAT can achieves slightly 
% % when comparing with invariant rationalization and 3 player methods, 

% % \subsection{Extracting Rationales with Variant Sparsity}

% % In many previous studies, sparsity constraint is critical for extracting effective rationales. Besides, as discussed in~\cite{chang2020invariant}, since the review of each aspect in the multi-aspect dataset is highly correlated, many baseline methods for rationale extraction performs much worse when using soft constraint rather than the hard constraint. As a result, \john{we introduce the hard constraint in our framework} and restricted the extracted rationale lengths with given number. We consider
% % the highlight lengths of 10, 20 and 30, and compare the generated rationales against the human annotations and report precision, recall and F1 score in Table~\ref{tab:table_invaraint}.
 
% % Please add the following required packages to your document preamble:

In this section, we evaluate the performance of DMR and compare its performance against with the state of arts methods on the beer and the hotel review datasets. 

 
% We compared our DMR with CAR on the both beer review dataset and hotel review dataset. 
We train our models using a balanced training dataset as in~\cite{chang2019game} and evaluate the performances on the test sets with human annotated rationales.
Since  rationales generated from CAR were based on ground truth label,  we also infer our rationales condition on true labels. As results shown in Table~\ref{tab:table_game}, DMR outperforms CAR in all aspects of two datasets.
% Specially, DMR obtains substantial gains (more than 4 F1 points) over CAR methods on the appearance and aroma aspects in the beer review dataset.
% and more than 2 F1 points over CAR on the cleanliness and the service aspects in hotel review dataset. 

To further compare with \emph{RNP}, \emph{INVRAT} and \emph{3PLAYER},  we adjust the sparsity levels to obtain the same rationale lengths on the beer dataset as in~\cite{chang2020invariant}. The data split and processing of the beer review dataset in ~\cite{chang2020invariant} are not available. 
% We believe CAR and RNP based approaches are also directly comparable. In fact, CAR and RNP both uses labels in the training phase, CAR uses the counterfactual training loss while RNP uses the standard classification loss. During test time, both RNP and CAR do not rely on ground truth labels. Also, the original CAR paper confirms that RNP and CAR are directly comparable (as referenced in section 4). 
For  fair comparsion,  we train and validate the models using the same beer review dataset but with different data split and processing, and the performances of rationales are evaluated on the same annotated test set.
% Since previous work reported results with different sparsity levels \cite{chang2020invariant}, we reported our results under several sparsity levels for direct comparison with previous work. 
As shown in Table \ref{tab:table_invariant}, DMR obtains the best performance in almost all metrics and sparsity combinations. 
In addition, our DMR method does not need ground-truth labels to generate rationales, as the predicted labels provided by the teacher classifier are used instead.
% we vary the rationale lengths and set the sparsity level at 7.9, 15.8, 23.7 to match the experiment settings in~\cite{chang2020invariant}. 


% To evaluate our DMR on the model classification, We use rationales generated by DMR and original full texts to train classifiers with the same structure respectively. 
The classification results in the Table~\ref{tab:rationales classification} show that better rationalization does not substantially improve classification, but with our method, training a classifier on the rationales is able to achieve performance comparable to using full text. 
% and rationales even outperforms full texts on the aspects of appearance.

The results in Table~\ref{tab:table_game} and ~\ref{tab:table_invariant} reveal the effectiveness of distribution matching.  Compared with existing approaches, DMR is able to extract more accurate rationales and the advantages can be extended to all sparsity levels. And Table~\ref{tab:rationales classification} presents that extracted rationales by our DMR are comparable to full texts on the classification. 






% \usepackage{multirow}
\subsection{Ablation Study}
\subsubsection{Effectiveness of our Matching Losses}
We conducted ablation studies to understand the importance of feature space matching and output space matching in the training process. 


In Table~\ref{tab:ablation_study}, we show the performances of DMR with different matching losses removed (row begin with ``-'') under different levels of sparsity. The rows with ``-fm'' stand for models that have the feature space matching loss removed, and the rows with ``-fm\&om'' correspond to models trained without neither the feature space matching nor the output space matching. 

As shown in the table, both feature space matching and output space matching contribute to the performance of our method. The improvements brought by both methods are consistent and substantial across different settings, which validates our motivation in the previous sections.

\begin{table*}[!ht]
\resizebox{\textwidth}{!}{%
% \small
\small
\begin{tabular}{@{}c|cc@{}}
\hline%\hline

Aspect     & DMR Rationale       & CAR Rationale\\ \hline

Appearance 
& \begin{tabular}[c]{@{}p{9cm}@{}}
\\
\textbf{\uline{tangerine pour with a small white head that clings to the edge of the glass .}}
% the aroma is comprise mostly of soapy , resiny hops - far from a punch in the face of west coast bitterness , and not all that impressive compared to others within the style . malty flavour and not all that hop-oriented . 
the hopping is smooth and mild , but the bitterness does gradually build , although it reminded me more of an english bitter instead of an american ipa . the malts come out as fruity with some honey . medium-light body with decent carbonation . i ca n't give it a glowing review because its not a great beer . pyramid seems to be very hit and miss , and this is a miss . 
%inspite of this , it still makes a damn drinkable beer and beats the living crap out of the major brands . thanks mark
\end{tabular} & 

\begin{tabular}[c]{@{}p{9cm}@{}}
\\
\uline{\textbf{tangerine pour with a} small white head that clings to the edge of the glass .}
% the aroma is comprise mostly of soapy , resiny hops - far from a punch in the face of west coast bitterness , and not all that impressive compared to others within the style . malty flavour and not all that hop-oriented .
the hopping is smooth and mild , but the bitterness does gradually build , although it reminded me more of an english bitter instead of an american \textbf{ipa . the} malts come out as fruity with some honey . medium-light body with decent carbonation . i ca n't give it a glowing review because its not \textbf{a great beer . pyramid seems} to be very hit and miss , and this is a miss . 
%inspite of this , it still makes a damn drinkable beer and beats the living crap out of the major brands . thanks mark
 \end{tabular} \\  \hline


Aroma      
& \begin{tabular}[c]{@{}p{9cm}@{}}
\\
appearence: pours a crystal clear amber with a thin , bubbly white head that dies to a collar. \textbf{\uline{smell : solid belgian pale ale malt and hop characteristics throughout, with that perfect yeast tinge.}} \textbf{taste} and mouthfeel : rich , full , thirst-quenching , and  smooth . very balanced and tasty , with the perfect mouthfeel . 

% barnyard malt  characteristics with almost pilsener type hops drinkability and overall : a classic. the perfect , easy drinking yet full flavored and full bodied belgian ale . definitly one that 's perfect for a session .
\\ 
\end{tabular}                                                                                                          

& \begin{tabular}[c]{@{}p{9cm}@{}}
\\
appearence : pours a crystal clear amber with a thin , bubbly white head that dies to a collar . \uline{smell : solid belgian pale ale malt and hop characteristics throughout , with that perfect yeasttinge}. taste \textbf{and mouthfeel : rich , full , thirst-quenching , and  smooth . very balanced and tasty , with the} perfect mouthfeel . 
% barnyard malt  characteristics with almost pilsener type hops drinkability and overall : a classic. the perfect , easy drinking yet full flavored and full bodied belgian ale . definitly one that 's perfect for a session . 
\\  
\end{tabular} \\  \hline

Palate     
& \begin{tabular}[c]{@{}p{9cm}@{}}
pours an amber with an orange hue . two inch white head fades quickly . very little 
lacing . smells like bread , not much else . taste some sweet malt , and grass . not 
much better than a macro . \textbf{\uline{lighter body with lots of carbonation.}} \textbf{not} a lot of flavor but this is a refreshing beer . i have no problem drinking these , i just would n't pursue it .
\end{tabular}                                                                            
& \begin{tabular}[c]{@{}p{9cm}@{}}
\\
\textbf{pours an} amber with an orange hue . two inch white head fades quickly . very little 
lacing . smells like bread , not much else . taste some sweet malt , and grass . not 
much better than a macro . \textbf{\uline{lighter body} \uline{with lots of carbonation.}} not a lot of flavor but \textbf{this is a } beer. i have no problem drinking these , i just would n't pursue it .
\end{tabular}                    \\ \hline%\hline
\end{tabular}%
}
\caption{\normalsize Examples of rationales generated by our DMR method and the baseline CAR method on the three aspects of the beer dataset. Underlined words are the human annotated labels, and bold word are predicted positive rationales.}
\label{tab:Rationale_Case}
\end{table*}



\begin{table*}[!ht]
\resizebox{\textwidth}{!}{%
% \small
\small
\begin{tabular}{@{}c|cc@{}}
\hline%\hline

Aspect     & DMR Rationale       \\ \hline

Appearance 
& \begin{tabular}[c]{@{}p{18cm}@{}}
\\
 \textbf{\uline{the beige head is comprised of }}\uline{medium-sized bubbles and}\textbf{\uline{ slowly , but inevitably ,}}\uline{ recedes to a thin strip ; there is some lacing adhering to the glass .} black malt ( i think ) lends the beer a not pleasantly bitter and toasted flavour . 
 %i could n't detect chocolate . beck 's dark is a bit watery on the palate and has a bitter finish i ca n't complain too much about beck 's dark but i ca n't rave too much about it , either .
 \\
\end{tabular} & 

\\  \hline


Aroma      
& \begin{tabular}[c]{@{}p{18cm}@{}}

% appearence: pours a crystal clear amber with a thin , bubbly white head that dies to a collar. \textbf{\textcolor{red}{\uline{smell : solid belgian pale ale malt and hop characteristics throughout, with that perfect yeast tinge.}}} \textbf{\textcolor{red}{taste}} and mouthfeel : rich , full , thirst-quenching , and  smooth . very balanced and tasty , with the perfect mouthfeel . barnyard malt  characteristics with almost pilsener type hops drinkability and overall : a classic. the perfect , easy drinking yet full flavored and full bodied belgian ale . definitly one that 's perfect for a session .\\ 
\\
pours with a nice foamy frothy off white head that lasts and a little lace . color is an ever so slightly \textbf{hazy amber . \uline{aroma is malty , grassy , hoppy , and bready beer .} flavor 's very similar along with} pretzels and with bitterness coming out at the end.
\end{tabular}                                                                                            \\  \hline

Palate     
& \begin{tabular}[c]{@{}p{18cm}@{}}
% pours an amber with an orange hue . two inch white head fades quickly . very little 
% lacing . smells like bread , not much else . taste some sweet malt , and grass . not 
% much better than a macro . \textbf{\textcolor{red}{\uline{lighter body with lots of carbonation.}}} \textbf{\textcolor{red}{not}} a lot of flavor but this is a refreshing beer . i have no problem drinking these , i just would n't pursue it .
%hazed and very opaque . aroma is fruity ( cloves and bananas ) . 
\\
typical of a hefeweizen taste shows notes of orange and the typical hefeweizen taste ( cloves and bananas ) . \textbf{\uline{smooth and very effervescent . almost no}} \uline{bitterness too . }\textbf{very drinkable and refreshing .} a nice \textbf{hefeweizen} . 
\end{tabular}                                                           
\\ \hline%\hline
\end{tabular}%
}
\caption{\normalsize Failure examples of rationales generated by our DMR method on the beer dataset. The underlined words are the human annotated labels, and the bold words are predicted positive rationales.}
\label{tab:failure_example}
\end{table*}

\subsubsection{Comparison of different Feature Space Matching Losses}
Many studies have shown that CMD outperforms MMD~\cite{Li2015GenerativeMM} and CORAL~\cite{sun2016deep} for its efficiency and invariance to different styles of input. 
In our experiments, we also find that using CMD matching can provide more stable and generally better results. 
Results in Table~\ref{tab:table_loss_sensitivity} show that using CMD can always lead to the best results with respect to the F1 scores on all aspects of beer review dataset.
% CORAL is competitive in the Aroma aspect, but fails to achieve high performance in the Palate and Appearance aspects. 
% Both CORAL and MMD obtains lower F1 scores in all three aspects.  
% As a result, CMD is the optimum choice for our loss function. 
% Using the CMD as matching framework, the F1 score is slightly higher than XXX in almost all aspects for both beer and hotel dataset. 
% However, the CMD can only provide XX\% compensation for using both teacher and student classifier. 
% Also, the CMD can outperforms
% \begin{figure}
%     \centering
%     \begin{subfigure}{0.8\linewidth}
%     \includegraphics[width=0.8\linewidth]{LaTeX/lambda_3.pdf}
%     \subcaption{}
%     \end{subfigure}
%     \begin{subfigure}{0.8\linewidth}
%     \includegraphics[width=0.8\linewidth]{LaTeX/lambda_4.pdf}
%     \subcaption{}
%     \end{subfigure}
%     \caption{Parameter Sensitivity of $\lambda_3$ and $\lambda_4$}
%     \label{fig:lambdas_sensitivity}
% \end{figure}
\subsubsection{Sensitivities of Hyper-parameters}
We also studies the influences of different values of hyper-parameters $\lambda_3$ and $\lambda_4$ in section~\ref{ssub:overall}, respectively. 
As presented in Figure~\ref{fig:lambdas_sensitivity}, the overall performance of our method is not sensitive to either the values of $\lambda_3$ or $\lambda_4$. 
% According to the figure, the rationale F1 score reaches the peak when $\lambda_3$ is set to 0.01. 
% The results indicate that a larger $\lambda_3$ will guide model to match input texts but cannot find the rationales related to true positive and negative labels. 
% Meanwhile, figure~\ref{fig:lambdas_sensitivity}(b) illustrates that the final F1 score is not sensitive to $\lambda_4$, although a larger $\lambda_4$ will slightly affect the performance due to learning from a weaker teacher model. 
\subsection{Case Studies}
In this section, we visualize the rationales generated by our DMR framework and the CAR framework.
As presented in Table~\ref{tab:Rationale_Case}, rationales generated by DMR are more accurate. For example, the DMR framework selects exactly the same rationales as the human annotations, while the CAR framework only finds a few related words combined with many unrelated words, specially in appearance and aroma aspects, which shows that DMR can extract meaningful and accurate rationales.In addition, we also show some failure examples in Table~\ref{tab:failure_example}.
% Our DMR still has a gap to generate consistent and pinpoint rationales. As shown in Table~\ref{tab:failure_example}, DMR sometimes generates segmented  or excessive rationales.
\section{Conclusions}
% In this paper, we proposed a distribution matching framework for rationalization (DMR), where the framework can extract rationales effectively. 
% The framework matches the distributions of the rationales and original full input texts by measuring the central moment discrepancy. 
% The framework is highly flexible and can be applied to many existing backbone rationale extraction methods, such as RNP~\cite{lei2016rationalizing} or CAR~\cite{chang2019game}. 
% Extensive experiments are performed in multi-aspect sentiment classification dataset, and the DMR framework outperforms all other state-of-the-art methods among all experimental settings. 
% Furthermore, ablation studies show the impact of different matching loss, and we evaluate DMR by studying some real cases from the multi-aspect dataset. 

In this paper, we propose a novel rationalization framework based on distribution matching called DMR. DMR aims to match rationales and the input text in both the feature space and the output space. 
For feature space matching, we formulate it as minimization of the central moment discrepancy (CMD) between input text features and the rationale features. For the output space matching, we transfer the knowledge from the output distribution of the original full text to that of the rationales in a teacher-student distillation framework.
The framework is highly flexible and can be applied to many existing rationale extraction methods. Extensive experiments show that the DMR framework outperforms state-of-the-art methods in most experimental settings.
Ablation studies show that both feature space matching and output space matching contribute to the final performance.
Moreover, case analysis show that DMR provides more meaningful and accurate rationales. In the future, it will be intriguing to apply our method to more interpretability settings such as non-classification tasks.


\section{Acknowledgments}
This work is funded by National Key R\&D Program of China (2020AAA0105200) and supported by Beijing Academy of Artificial Intelligence (BAAI).

\bibliography{aaai2021}
% \bibliographystyle{aaai}


\end{document}

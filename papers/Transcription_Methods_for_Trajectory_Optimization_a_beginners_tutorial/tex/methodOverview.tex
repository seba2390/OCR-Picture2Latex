\section{Optimal Control Overview}

There are three types of algorithms for solving optimal control problems\cite{Diehl2009}:
\begin{itemize}
\setlength{\itemsep}{0pt}
	\item{\bf Dynamic Programming: } Solve Hamilton-Jacobi-Bellman Equations over the entire state space.
	\item{\bf Indirect Methods: } Transcribe problem then find where the slope of the objective is zero.
	\item{\bf Direct Methods: } Transcribe problem then find the minimum of the objective function.
\end{itemize}

Dynamic programming is an excellent solution to the optimal control problem for unconstrained low-dimensional systems, but it does not scale well to high-dimensional systems, since it requires a discretization of the full state space. Indirect methods tend to be numerically unstable and are difficult to implement and initialize \cite{Betts2010}. For the remainder of this paper we will restrict focus to direct methods for transcribing and solving the optimal control problem. The solution to an optimal control problem via transcription scales well to high-dimensional systems, but yields a single trajectory through state and control space, rather than a global policy like dynamic programming.

\subsection{Trajectory Optimization Problem}
\label{sec:TrajectoryOptimizationProblem}

A trajectory optimization problem seeks to find the a trajectory for some dynamical system that satisfies some set of constraints while minimizing some cost functional. Below, I've laid out a general framework for a trajectory optimization problem.\\ \\

\begin{align}

\text{\bf Optimal Trajectory: }& \quad
\{ \mathbf{x}^*(t), \mathbf{u}^*(t) \}
\label{eqn:optimalTrajectory}\\

\text{\bf System Dynamics: }& \quad
\dot{\mathbf{x}} = \mathbf{f}(t,\mathbf{x},\mathbf{u})
\label{eqn:systemDynamics}\\

\text{\bf Constraints: }& \quad
\mathbf{c}_{\text{min}} < \mathbf{c}(t,\mathbf{x},\mathbf{u}) < \mathbf{c}_{\text{max}}
\label{eqn:constraints}\\

\text{\bf Boundary Conditions: }& \quad
\mathbf{b}_{\text{min}} < \mathbf{b}(t_0,\mathbf{x}_0,t_f,\mathbf{x}_f) < \mathbf{b}_{\text{max}}
\label{eqn:boundaryConditions}\\

\text{\bf Cost Functional: }& \quad
J = \phi(t_0,\mathbf{x}_0,t_f,\mathbf{x}_f) + \int_{t_0}^{t_f} g(t,\mathbf{x},\mathbf{u}) \; dt
\label{eqn:costFunctional}

\end{align}

One interesting thing to point out is the difference between a {\em state} $\mathbf{x}$ and a {\em control} $\mathbf{u}$. A state variable is a variable that is differentiated in the dynamics equation, where as a control variable only appears algebraically in the dynamics equation \cite{Betts2010}. In some cases there might also be unknown {\em parameters} (not shown) that are time-invariant variables that appear algebraically in the dynamics equation.


\subsection{Non-linear Programming}

Transcription methods for solving an optimal control problem work by converting a continuous problem (Section \ref{sec:TrajectoryOptimizationProblem}) into a non-linear programming problem (\ref{eqn:NonLinearProgramming}). Once in this form, the problem can be passed to a commercial solver, such as SNOPT\cite{Gill2005}, IPOPT\cite{Wachter2006}, or FMINCON \cite{MatlabOptimizationToolbox2014}.

\begin{align}
	\underset{\mathbf{z} \in \mathbb{R}^n}{\text{minimize}}  \quad  & \bar{J}(\mathbf{z}) \\
	\text{subject to: }  & \mathbf{l} \leq \left( 
			\begin{array}{c}
			\mathbf{z} \\
			\mathbf{\bar{c}}(\mathbf{z}) \\
			A \mathbf{z}
			\end{array}
			\right) \leq \mathbf{u}
			\label{eqn:NonLinearProgramming}	
\end{align}

There are many transcription algorithms that make this conversion, but they can all be divided up into two broad classes: {\bf shooting methods} and {\bf simultaneous methods}. The difference is based on how each method enforces the constraint on the system's dynamics. Shooting methods use a simulation to explicitly enforce the system dynamics. Simultaneous methods enforce the dynamics at a series of points along the trajectory.





%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%

\section{Shooting Methods}

Single-shooting is probably the simplest method for transcribing an optimal control problem. Consider the problem of trying to hit a target with a cannon. You have two decision variables (firing angle and mass of powder) and one constraint (trajectory passes through target). The dynamics are simple (projectile motion) and the cost function is the mass of powder. The single shooting method is similar to what a person might accomplish with experiments. You make a guess at the angle and amount of powder, and then fire the canon. If you shoot over the target, then perhaps you would reduce the mass of powder on the next test. By repeating this method, you would eventually be able to hit the target, while using as little powder as possible. Single shooting works the same way, just replacing the experiments with simulations.

\par In a more general case of single shooting, with a continuous control input, you would choose some arbitrary function to approximate the input. A few common choices are zero-order-hold, piecewise linear, piecewise cubic, or orthogonal polynomials. If the control is modeled with a piecewise function, then you must take care to align the discontinuities of the control with the integration steps in the simulation.

\par Single shooting works well enough for simple problems, but it will almost certainly fail on problems that are more complicated. This is because the relationship between the decision variables and the objective and constraint functions is not well approximated by the linear (or quadratic) model that the non-linear programming solver uses. 

\par Multiple shooting works by breaking up a trajectory into some number of segments, and using single shooting to solve for each segment. As the segments get shorter, the relationship between the decision variables and the objective function and constraints becomes more linear. In multiple shooting, the end of one segment will not necessarily match up with the start of the next. This difference is known as a defect, and it is added to the constraint vector. Adding all of the segments will increase the number of decision variables (the start of each segment) and the number of constraints (defects). Although it might seem that this would make the low-level optimization problem harder, it actually turns out to make it easier.

\par Figure \ref{fig:Shooting_Methods} shows a cartoon comparing single shooting and multiple shooting.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{img/Transcription__Shooting_Methods.pdf}
\caption{Single Shooting vs Multiple Shooting. In both methods the state trajectory is stored as the result of a simulation. Notice that multiple shooting is just like a series of single shooting methods, with a defect constraint added to make the trajectory continuous. Multiple shooting results in a higher dimensional non-linear program, but it is sparse and more linear than the program produced by single shooting.}
\label{fig:Shooting_Methods}
\end{figure}


%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%

\section{Simultaneous Methods}

There are a wide variety of simultaneous methods. The key difference between simultaneous methods and shooting methods is that simultaneous methods directly represent the state trajectory using decision variables, and then satisfy the dynamics constraint only at special points in the trajectory.

\subsection{Integral vs Differential Form}

For any trajectory optimization problem, there are two different ways to write the dynamics constraint: {\em derivative} and {\em integral}. The derivative method states that the derivative of the state with respect to time must be equal to the dynamics function ($\dot{\mathbf{x}} = \mathbf{f}(\mathbf{x}, \mathbf{u})$). The integral method states that the state trajectory must match the integral of the dynamics with respect to time ($\mathbf{x} = \int \mathbf{f}(\mathbf{x}, \mathbf{u}) \; dt$). Notice that shooting methods are a type of integral method. Figure \ref{fig:Integral_vs_Derivative} shows a cartoon of the difference, and more information can be found in the paper by Fran\c{c}olin {\em et al.} \cite{Franc}.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{img/Transcription__Integral_vs_Derivative.pdf}
\caption{Integral vs. derivative form of the optimal control problem.}
\label{fig:Integral_vs_Derivative}
\end{figure}

\subsection{Orthogonal Collocation}

Orthogonal collocation \footnotemark is a simultaneous (collocation) method that uses orthogonal polynomials to approximate the state and control functions. Orthogonal polynomials have several useful properties. The key concept is that a polynomial can be represented over some finite domain by its value at a special set of grid points over that domain. When represented in this form, it is easy to do fast and accurate numerical interpolation, differentiation, and integration of the polynomial \cite{Berrut2004}. 

\footnotetext{Orthogonal Collocation is often referred to as the {\em Pseudospectral Method} for transcription of an trajectory optimization problem. }


\subsection{H vs P scheme}

\par The simplest version of orthogonal collocation works by representing the entire trajectory as a single high-order orthogonal polynomial. The constraint on the dynamics (either integral or derivative form) is applied at the collocation points, which are chosen to be at the roots of the orthogonal polynomial. The cost function is then evaluated by numerical quadrature over the trajectory, which is just a weighted combination of the function's value at each collocation point. Convergence in this method is obtained by increasing the order of the polynomial (p-method). 

\par Representing the entire trajectory as a single orthogonal polynomial works well if the underlying solution is analytic. In many cases this is not true, such as when an actuator is saturated. In these cases the polynomial approximation will necessarily fail near the discontinuity. One solution is to represent the trajectory as a series of medium-order orthogonal polynomials. Each section of the trajectory is stitched together with defect constraints, like in multiple shooting, and the dynamics within a given segment are expressed using a constraint at the collocation points. The points where two segments are jointed are called {\em knot points}. Convergence in this type of method is obtained by increasing the number of trajectory segments (h-method). Figure \ref{fig:Transcription__Pseudospectral} shows a comparison of the single- and multi-segment orthogonal collocation methods.

\par The most sophisticated methods take this a step further, and adaptively refine the number and location of knot points along the trajectory and the order of the polynomial on each segment\cite{PattersonHagerRao}. This is the approach taken by the commercially available transcription algorithm GPOPS\cite{Patterson2013}.


\begin{figure}
\centering
\includegraphics[width=\textwidth]{img/Transcription__Pseudospectral.pdf}
\caption{Orthogonal Collocation Methods}
\label{fig:Transcription__Pseudospectral}
\end{figure}

\subsection{Special Cases}

Two commonly used simultaneous methods are {\em direct transcription} and {\em direct collocation}. Direct transcription is a simultaneous method that uses the integral form of the dynamics constraint. The control is represented as a piecewise-constant trajectory, and the state is piecewise linear. The decision variables in the optimization are the values for the control and state at each knot point.

\par Direct collocation is similar to direct transcription, but the input is represented as a piecewise-linear function of time, and the state is piecewise-cubic. The values of the state and control at each knot point are the decision variables. The slope of state is prescribed by the dynamics at each knot point. The collocation points are the mid-points of each cubic segment. The slope of the cubic at the collocation point is constrained to match the system dynamics at that point. Figure \ref{fig:Transcription_Collocation}.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{img/Transcription__Collocation.pdf}
\caption{Special Cases of simultaneous methods}
\label{fig:Transcription_Collocation}
\end{figure}



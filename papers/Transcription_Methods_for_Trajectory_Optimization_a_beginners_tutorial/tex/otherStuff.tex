\section{Miscellaneous}

This section covers a few odd topics that are useful to understand, but do not fit elsewhere.

\subsection{Regularization}
It is possible to create an optimal trajectory problem which does not have a unique solution. This will generally cause convergence problems, as the optimization program bounces between seemingly equivalent solutions. This problem is solved by adding a small regularization term to the objective function, which forces a unique solution. For dynamical systems, I have found that adding a small input-squared term to the cost function is generally sufficient. I've found regularization terms that are 6-8 orders of magnitude smaller than the primary objective term are often still effective.

\subsection{Constraint on Controls}
The correct way to apply a non-linear constraint to a control at the boundary of a trajectory is to create a dummy state to represent the control, and then let the optimization program determine the {\em derivative} of the control. The system dynamics can then be used to ensure feasibility of the control and its derivative. This technique is particularly useful for enforcing that the contact forces of a walking robot stay within their friction cone.

\subsection{Optimizing a Parameter}
Suppose that you would like to find an optimal trajectory, but there is at least one free parameter for your design. It is tempting to just add this parameter as an additional term when passed to the underlying optimization function. This is a bad idea, because it couples the Jacobian of the constraints, which is almost as bad as solving the problem using single shooting. The correct thing to do is to add a control to the system, and use the control instead of the parameter. A special constraint is then added to ensure that the control remains constant throughout the trajectory. This will quickly solve for the best possible parameter choice, while keeping the Jacobian of the constraints and objective function sparse.
\begin{table*}[t]
\centering
\begin{tabular}{l|ll|ll}
\hline
                            &  \multicolumn{2}{l|}{MiniImageNet}       & \multicolumn{2}{l}{TieredImageNet}      \\ \hline
Methods                      & 5-way, 1-shot      & 5-way, 5-shot      & 5-way, 1-shot      & 5-way, 5-shot      \\ \hline
Baseline++ \cite{chen2019closer}           & 53.97 $\pm$ 0.79\% & 75.90 $\pm$ 0.61\% & 61.49 $\pm$ 0.51\% & 82.37 $\pm$ 0.67\% \\
ProtoNet$^*$ \cite{snell2017prototypical}      & 63.56 $\pm$ 0.34\% & 81.08 $\pm$ 0.18\% & 69.53 $\pm$ 0.36\% & 84.02 $\pm$ 0.23\% \\
MetaOpt-SVM \cite{lee2019meta}                       & 62.64 $\pm$ 0.82\% & 78.63 $\pm$ 0.46\% & 65.99 $\pm$ 0.72\% & 81.56 $\pm$ 0.53\% \\
MatchNet \cite{vinyals2016matching}           & 63.08 $\pm$ 0.80\% & 75.99 $\pm$ 0.60\% & 68.50 $\pm$ 0.92\% & 80.60 $\pm$ 0.71\% \\
DSN-MR \cite{simon2020adaptive}                        & 64.60 $\pm$ 0.62\% & 79.51 $\pm$ 0.50\% & 67.39 $\pm$ 0.82\% & 82.85 $\pm$ 0.56\% \\
FEAT \cite{ye2020few}              & 66.78 $\pm$ 0.20\% & 82.05 $\pm$ 0.15\% & 70.80 $\pm$ 0.23\% & 84.79 $\pm$ 0.16\% \\
Seq-distill  \cite{seqdistill}                     & 64.80 $\pm$ 0.60\% & 82.14 $\pm$ 0.43\% & 71.52 $\pm$ 0.69\% & 86.03 $\pm$ 0.49\% \\
DN4$^{* \dagger}$  \cite{li2019revisiting}           & 63.72 $\pm$ 0.32\% & 81.54 $\pm$ 0.20\% & 70.23 $\pm$ 0.33\% & 84.01 $\pm$ 0.24\% \\
DeepEMD$^{\dagger}$ \cite{zhang2020deepemd}                           & 65.91 $\pm$ 0.82\% & 82.43 $\pm$ 0.56\% & 71.16 $\pm$ 0.87\% & 86.03 $\pm$ 0.58\% \\
SRL, DS (ours)$^\dagger$                    & \textbf{67.00 $\pm$ 0.27\%} & \textbf{82.68 $\pm$ 0.18\%} & \textbf{71.88 $\pm$ 0.32\%} & \textbf{86.24 $\pm$ 0.22\%} \\ \hline
\end{tabular}
\caption{Results on MiniImageNet and TieredImageNet. All the methods use ResNet-12 as the backbone network. For SRL, we set subspace basis size, $s=5$. *: Our re-implementation. $\dagger$: Using local CNN feature.}
\label{tab:sota}
\end{table*}


\subsection{Implementation}
For a fair comparison, we select the commonly used ResNet-12 as the backbone network of our SRL framework.
The softmax layer and the spatial average pooling are removed from the backbone.
All the images are resized to $84 \times 84$ pixels, and become $5 \times 5 \times 640$ tensors after analyzed by the backbone network.
To optimize the parameters of this backbone ResNet-12, we conduct a two-step training process.
In the first step, we pre-train the parameters by minimizing a cross entropy loss function of a standard classification task using training classes.
In the second step, we perform the episodic training mechanism described in Sec. \ref{sec:method}.
We adopt SGD optimizer for 10k iterations with an initial learning rate $0.002$, which decreases by a factor $0.1$ for every 2k iteration.
No data augmentation methods are applied during the episodic training.

The PS and DS are initialized by the subspaces extracted from the union of $K$ local CNN feature sets.
Then, we update these template subspaces using SGD with Cayley transform for 50 iterations.
The learning rate $\alpha$ for PS and DS are $0.1$ and $0.01$, respectively.

In our experiments, we follow the standard 5-way, 1-shot and 5-shot classification protocols, and sample 5,000 tasks with 15 query images for each target class.
The category of each query image is predicted independently (inductive scenario).
We report the average accuracy with the $95\%$ confidence interval of all the sampled tasks.


\subsection{Dataset}
To evaluate the efficacy of SRL, we conduct experiments on three benchmark datasets:
MiniImageNet \cite{Sachin2017}, TieredImageNet \cite{ren18fewshotssl} and Caltech-UCSD Birds-200-2011 \cite{cub}.

MiniImageNet is a subset of ImageNet \cite{russakovsky2015imagenet}. 
It consists of 100 classes of images, and 600 images per class.
The 100 classes are divided into 64, 16, 20 for training, validation and testing sets, respectively.

TieredImageNet contains 608 classes from 34 super-class of ImageNet, and 779,165 images in total.
The set of 608 classes is divided into subsets with 351, 97, and 160 classes for model training, validation, and testing, respectively, according to their super-class.
This arrangement increases the domain gap between training and evaluation phase.

Caltech-UCSD Birds-200-2011 (CUB) was designed for fine grained image recognition.
It contains 200 classes of bird images, 11,788 images in total.
Following the setup in previous works \cite{ye2020few,zhang2020deepemd}, we split the 200 classes into 100, 50, 50, classes for model training, validation and testing, respectively.
Comparing to other two aforementioned datasets, CUB is challenging because of the subtle difference among bird types. 

\begin{table}[t]
\centering
\begin{tabular}{l|ll}
\hline
Methods                      & 5-way, 1-shot               & 5-way, 5-shot               \\ \hline
ProtoNet$^*$      & 72.45$\pm$0.34\%          & 85.94$\pm$0.23\%          \\
MatchNet                      & 71.87$\pm$0.85\%          & 85.08$\pm$0.57\%          \\
Baseline++                      & 69.55$\pm$0.89\%          & 85.17$\pm$0.50\%          \\
DN4$^{* \dagger}$            & 72.30$\pm$0.32\%          & 85.23$\pm$0.23\%          \\
DeepEMD$^{\dagger}$                           & \textbf{75.65$\pm$0.83\%} & 88.69$\pm$0.50\%          \\
SRL, DS (ours)$^{\dagger}$                        & 75.32$\pm$0.27\%         & \textbf{88.81$\pm$0.21\%} \\ \hline
\end{tabular}
\caption{Results on CUB. All the methods use ResNet-12 as the backbone network. For SRL, we set subspace basis size, $s=5$. *: Our re-implementation. $^\dagger$: Using local CNN feature.}
\label{tab:sota_cub}
\end{table}


\begin{figure}[t]
\centering
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plot/fs_s_mini_2}
         \caption{Results on 5-way, 1-shot task of MiniImageNet}
         \label{fig:kshot_proto}
     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plot/fs_s_tiered_2}
         \caption{Results on 5-way, 1-shot task of TieredImageNet}
         \label{fig:kshot_dist}
     \end{subfigure}
     \caption{Sensitivity analysis with respect to the size of subspace basis. The results show that the accuracy saturates around $s=6$.}
     \label{fig:basis_size}
\end{figure}


\subsection{Analysis for SRL Design}
To better understand the property of SRL and validate our design choices, we conduct two quantitative studies: (1) sensitivity analysis for basis size of subspace representation (2) validating the choice of WSD.
%The first study is the sensitivity analysis for the basis size of subspace representation, and the second one aims to validate the choice of WSD.

In the first study, we adjust subspace basis size $s$, which is also the number of columns of $U$ in eq. (\ref{eq:sub_rep_problem}), and report the performance of 5-way, 1-shot classification task in MiniImageNet and TieredImageNet.
From the results shown in Fig \ref{fig:basis_size}, we find that the performance gets better when $s$ becomes larger, but saturates around $s=6$.
This observation is expected since the later included subspace basis components are with smaller singular values, and less important according to the definition of WSD.
The results also suggest that subspace representation with basis size $s=6$ is enough to preserve essential information for few-shot classification task.

In the second study, we compare the adopted WSD with another commonly used subspace distance measure, projection F-norm \cite{simon2020adaptive,edelman1998geometry}:
\begin{equation}
    D_p(U_1, U_2) = ||U_1U_1^T-U_2U_2^T||_F^2 = 2s-2||U_1^TU_2||_F^2
\label{eq:pfnorm}
\end{equation}
Specifically, we replace WSD with $D_p(U_1, U_2)$ in SRL, and follow the same training procedure to optimize the backbone CNN.
The performance of SRL with these two subspace distance functions are compared on the 5-way, 1-shot task of MiniImageNet.
From the results illustrated in Fig. \ref{fig:sd}, we observe that the performance of SRL with projection F-norm (eq. (\ref{eq:pfnorm})) drops while $s$ increasing, and performs worse than SRL with WSD in general.
The potential reason is that WSD re-weights the importance of each basis component, reflecting the distribution of local CNN features.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\linewidth]{plot/fs_sd.png}
    \caption{Comparison between SRL implementations with two types of subspace distance: WSD (eq. (\ref{eq:wsd})) and projection F-norm (eq. (\ref{eq:pfnorm}))}
    \label{fig:sd}
\end{figure}


\subsection{Analysis for Template Subspace}
\begin{table}[t]
\begin{tabular}{l|ll}
\hline
                 & MiniImageNet       & TieredImageNet     \\ \hline
SRL, PS               & 82.14 $\pm$ 0.18\% & 85.86 $\pm$ 0.23\% \\
SRL, DS               & \textbf{82.68 $\pm$ 0.18\%} & \textbf{86.24 $\pm$ 0.22\%} \\
Baseline (Union) & 80.93 $\pm$ 0.20\% & 83.98 $\pm$ 0.23\% \\
Baseline (NN)    & 80.56 $\pm$ 0.23\% & 83.11 $\pm$ 0.26\% \\ \hline
\end{tabular}
\caption{Comparison among K-shot aggregation methods on 5-way, 5-shot task of MiniImageNet and TieredImageNet.}
\label{tab:kshot}
\end{table}

In this experiment, we compare two types of template subspace, PS and DS, along with two other naive methods, baseline (union) and baseline (NN), in K-shot learning scenario.
Baseline (union) extracts the subspace from the union of all the local CNN features from K-shot images.
It is also adopted as the initialization step of PS and DS.
Baseline (NN) computes the subspace-subspace distance from query image to the nearest neighbor support image in terms of WSD.
All the methods are evaluated on the 5-way, 5-shot classification task of MiniImageNet and TieredImageNet.
%We also try to combine two types of template subspace, PS and DS by a weighted combination of their objective functions:

From the results illustrated in Table \ref{tab:kshot}, we can see that both PS and DS can outperform two naive baselines, and DS receives the best performance.
A possible explanation is that DS is optimized based on task-specific information, while PS is only conditioned on the intra-class information. 
Thus, when two confusing unseen concepts appear in the same sampled task, DS has a better chance to distinguish them.
%However, being task-independent can also be an advantage 

\iffalse. %%%%%%%%%%%%%%%%%%
We also conduct a follow-up study trying to combine PS and DS.
To do so, we derive the template subspace $U_{temp}$ by optimizing the weighted summation of eq. (\ref{eq:subspace_proto}) and eq. (\ref{eq:subspace_disc}):
\begin{equation}
    U_{temp} = \arg\min_{U} L_{disc}(U) + \alpha L_{proto}(U)
\end{equation}
where $\alpha$ is the hyper-parameter controlling the balance between PS and DS objectives.
However, the result shows that the best accuracy of 5-way, 5-shot task on MiniImageNet only increases $0.1\%$ from SRL with DS.
%%%% TODO how to fix?
Therefore, while compared with previous state-of-the-art, we choose DS as the template subspace for class-specific representation.
\fi %%%%%%%%%%%%%%%%%%

\subsection{Comparison with State-of-the-art}
We compare the performance of our SRL framework with two approaches using local feature set, DeepEMD \cite{zhang2020deepemd} and DN4 \cite{li2019revisiting}, as well as other previous state-of-the-art methods.
The experiment results are summarized in Table \ref{tab:sota} and \ref{tab:sota_cub}.
From this set of results, we have the following observations.
First, ProtoNet from our implementation receives competitive performance on three datasets, serving as a strong baseline.
Second, for 1-shot, 5-way task, our proposed SRL performs the best on MiniImageNet and TieredImageNet, and is only slightly worse than DeepEMD on CUB dataset.
Third, SRL outperforms all the other methods on the 5-way, 5-shot task of all three datasets.

\subsection{Visualization}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\linewidth]{plot/fs_vis.png}
    \caption{Visualization of subspace representation. Raw images are from MiniImageNet and CUB dataset. Brighter regions indicate higher cosine similarity between subspace basis component and the local CNN feature.}
    \label{fig:vis}
\end{figure}

%[analysis to weighted subspace distance]
%[analysis to k-shot aggregation strategy]
To understand the underline information captured by subspace representation, we visualize the subspace basis components extracted from images of MiniImageNet and CUB datasets.
Specifically, we calculate the cosine similarity between each basis component and the local CNN feature of each $5 \times 5$ regions.
Fig. \ref{fig:vis} shows the visualization results of the first two basis components. % of subspace representation.
The brightness of each spatial region is proportional to the cosine similarity between the components and the local CNN feature.
From the results, we can see that the first component contains shared information among all the features, while the second focuses on some specific local regions.
These local regions reflect the characteristics of the corresponding class, which would be useful for classification task.
However, observing the third and fourth example images from MiniImageNet, we find that their second basis components are highly correlated to the background regions
It indicates that the proposed SRL sometimes suffers from some dataset bias, and fails to represent the object.
%% is it called dataset bias?




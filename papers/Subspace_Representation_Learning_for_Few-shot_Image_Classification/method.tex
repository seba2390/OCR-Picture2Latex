%In few-shot image classification, we are given training and testing datasets, %$\mathcal{D}^{train}=\{(x,y) | y \in \mathcal{Y}_{train}]\}, \mathcal{D}^{test}=\{(x,y) | y \in  \mathcal{Y}_{test}\}$, whose label sets are mutually disjoint.
%$\mathcal{D}^{train}, \mathcal{D}^{test}$, whose label sets are mutually disjoint.
%Our goal is to use $\mathcal{D}^{train}$ to train a classification model that can be quickly adapted to unseen classes in $\mathcal{D}^{test}$ with limited amount of annotated examples.
%To achieve this goal, most previous works and ours follow the episodic training mechanism
%Since the standard testing scenario in most of the previous works is N-way, K-shot classification, we sample a support set $S \subset \mathcal{D}^{train}$ and an query set $Q \subset \mathcal{D}^{train}$ in each training episode, where $S=\{ \{\{(x_{i, j}, y_i) \}_{j=1}^{K} \}_{i=1}^N$ and $Q = \{(x_q, y_q)\}_{q=1}^{N_q}, y_q \in \{y_i\}_{i=1}^N$.
%% here I ignore the detail description of N-way K-shot, and leave it in later sections. Is it proper?

The goal of few-shot image classification task is to build a prediction model that can be quickly adapted to unseen classes with limited amount of annotated examples.
Most previous works validate their approaches to this task using $N$-way $K$-shot classification as testing scenario.
Specifically, we are given a support set $S= \{\{(x_{i, j}, y_i) \}_{j=1}^{K} \}_{i=1}^N$ and query set $Q = \{(x_q, y_q)\}_{q=1}^{N_q}, y_q \in \{y_i\}_{i=1}^N$, where $(x,y)$ is the pair of raw image and class label.
The prediction model is trained/adapted based on $S$, and evaluated on the classification results of $Q$.

In this work, we propose subspace representation learning (SRL) framework to tackle this task.
The overall architecture is illustrated in Fig. \ref{fig:arch}.
Concretely, our method represents an image as a subspace, which is estimated from the reconstruction of local CNN features of this image.
The dis-similarity between two images can be determined by a weighted subspace distance (WSD) between two subspaces.
In the rest of this section, we first introduce the concept of subspace representation.
Then, we elaborate the WSD adopted in SRL framework, and the end-to-end training process in the context of few-shot image classification.
Finally, we describe two types of template subspace, which can effectively summarize information about a specific class from K-shot examples.


\begin{figure*}
\centering
  \includegraphics[width=0.9\textwidth]{plot/fs_arch.png}
  \caption{The overall architecture of proposed subspace representation learning (SRL) framework. The backbone CNN extracts the local feature map ($h \times w \times d$) from each query and support image. After reshaping the feature map into a matrix $H \in \mathbb{R}^{d \times (h \cdot w)}$, whose columns are the CNN features at every spatial location, we extract the subspace representation by conducting SVD. The similarity between two images is determined by a weighted subspace distance (WSD). The end-to-end training is guided by the loss function of a distance based classifier.}
  \label{fig:arch}
\end{figure*}

\subsection{Subspace Representation}
Our method exploits a subspace to represent each training/testing image.
Given an image $x$, we extract the hidden feature map ($h \times w \times d$ tensor) using a backbone CNN with parameter $\Phi$, and collect the $d$-dimensional local feature vectors at all the spatial locations to form a matrix $H \in \mathbb{R}^{d \times (h \cdot w)}$.
Then, our method finds the best-fit $s$-dimensional subspace $U \in \mathbb{R}^{d \times s}$, which minimizes the reconstruction error with respect to $H$:
\begin{equation}
\begin{split}
    \min_{U}\; &||H - UU^TH||_F \\
    s.t. \;& U^TU = I
\end{split}
\label{eq:sub_rep_problem}
\end{equation}
where $||\cdot||_F$ is the Forbeneous norm of a matrix.
This optimization problem can be solved by singular value decomposition (SVD) of $H$, and the optimal $U$ is obtained by the top-$s$ right-singular vectors with the largest singular values.
%The optimization problem in eq. (\ref{eq:sub_rep_problem}) can be solved by singular value decomposition (SVD) of $H$, and the optimal $U$ is obtained by the top-$s$ right-singular vectors with the largest singular values.

Similar to other works \cite{li2019revisiting,zhang2020deepemd} leveraging local CNN features, our SRL framework is able to capture the spatial structure of an image.
However, there are two additional reasons why we choose to construct a  subspace representation.
First, a subspace encourages the preservation of diversity because of the orthonormal constraint in eq. (\ref{eq:sub_rep_problem}).
Second, using a subspace results in a compact representation for image, since we can set a small $s$ without sacrificing the performance.
More analysis of these two properties will be elaborated in the experiment section.


\subsection{Weighted Subspace Distance}
% To measure the dis-similarity between two images, we need to calculate the subspace-to-subspace distance and conduct metric learning in the space of subspace representation
To conduct metric learning in the space of subspace representation, we need to calculate subspace-to-subspace distance.
While several types of distance have been proposed, our SRL framework utilizes the weighted subspace distance (WSD) introduced in \cite{li2009weighted}:
Given two subspaces $U_1$ and $U_2$ representing two images $x_1$ and $x_2$, WSD is expressed as:
\begin{equation}
\begin{split}
    D(U_1, U_2) & = \sqrt{1 - \sum_{i=1}^s \sum_{j=1}^s \sqrt{ \lambda_{1,i}' \lambda_{2,j}' } (u_{1,i}^Tu_{2,j})^2 } \\
    \lambda_{1,i}' & = \frac{ \lambda_{1,i} }{ \sum_{l=1}^{s} \lambda_{1,l}}, \; \lambda_{2,j}'  = \frac{ \lambda_{2,j} }{ \sum_{l=1}^{s} \lambda_{2,l}}
\end{split}
\label{eq:wsd}
\end{equation}
%% TODO check if anyone use this before.
where $u_{1,i(2,j)}$ and $\lambda_{1,i(2,j)}$ are the $i(j)$-th column of $U_{1(2)}$, and the corresponding singular value obtained from SVD operation, respectively.
Comparing to other types of subspace distance, WSD considers the relative importance of each basis component in a subspace, so it can better capture the distribution of original local feature set.

\subsection{End-to-End Training}
The training process of our SRL framework follows the episodic learning mechanism \cite{vinyals2016matching}, which mimics the situation of a testing phase.
In each training iteration, we sample a pair of support and query sets $(S,Q)$ from training dataset.
Then, we extract the subspace representation for every image in $S$ and $Q$, and plug the WSD (eq. (\ref{eq:wsd})) between the two subspaces into a distance based classifier \cite{chen2019closer}.
Thus, the training objective of SRL can be formulated as: 
\begin{equation}
    \mathcal{L}_{e2e}(\Phi) = \sum_q log \left( \frac{exp(-D(U_{y_q}, U_q))}{\sum_{i=1}^N exp(-D(U_{y_i},U_q))} \right)
\label{eq:obj}
\end{equation}
where $U_q$ is the subspace representation of query. $U_{y_i}$ is the subspace representation of the supported image of class $y_i$ if $K=1$. 
In the case of $K>1$, $U_{y_i}$ stands for the template subspace that summarizes the $K$-shot information from class $y_i$.
The estimation of template subspace will be discussed in Sec. \ref{sec:kshot}.
By minimizing eq. (\ref{eq:obj}), the parameter set $\Phi$ of backbone CNN can be learned in an end-to-end manner.

\subsection{Template Subspace for K-shot Learning}
\label{sec:kshot}

\begin{figure*}[t]
\centering
  \begin{subfigure}[b]{0.35\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plot/fs_kshot_proto}
         \caption{Prototypical network \cite{snell2017prototypical}}
         \label{fig:kshot_proto}
     \end{subfigure}
     \hspace{5em}
     \begin{subfigure}[b]{0.35\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plot/fs_kshot_disc}
         \caption{Distance-based classifier. \cite{chen2019closer}}
         \label{fig:kshot_dist}
     \end{subfigure}
     \par\bigskip
     \begin{subfigure}[b]{0.35\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plot/fs_kshot_proto_subspace}
         \caption{Prototypical subspace (PS). (eq. (\ref{eq:subspace_proto}))}
         \label{fig:kshot_proto_subspace}
     \end{subfigure}
     \hspace{5em}
     \begin{subfigure}[b]{0.35\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plot/fs_kshot_disc_subspace}
         \caption{Discriminative subspace (DS). (eq. (\ref{eq:subspace_disc}))}
         \label{fig:kshot_disc_subspace}
     \end{subfigure}
     \caption{Comparison among different strategies for template vector/subspace ($v_{temp}$/$U_{temp}$) extraction from $K$-shot information. (a) A prototypical network takes mean vector of $K$-shot vector representations. (b) A distance based classifier obtains the class template vector whose Euclidean/Cosine distances to $K$-shot examples minimize a cross-entropy loss. (c) A prototypical subspace (PS) is the average subspace of $K$-shot subspaces. (d) A discriminative subspace (DS) optimizes a distance based classifier with WSD.}
     \label{fig:kshot}
\end{figure*}

To cope with the $K$-shot learning scenario, the SRL framework computes a template subspace $U_{temp}$ to aggregate the information from $K$ subspaces for each class.
In this work, we propose two types of template subspace to represent a class: A prototypical subspace and a discriminative subspace.
%Both of them effectively aggregate the information from K subspaces extracted from K images.

The prototypical subspace (PS) is the "average" of all $K$ subspaces, following the spirit of ProtoNet \cite{snell2017prototypical} in vector space.
Specifically, given K subspaces $U_1,U_2,...,U_K$ representing $K$ images of the same class, the prototypical subspace is obtained by the minimizing the summation of the distances between $U_{temp}$ and $U_i$:
\begin{equation}
    \mathcal{L}_{ps}(U_{temp}) = \sum_{j=1}^K D(U_{temp},U_j)
\label{eq:subspace_proto}
\end{equation}
On the other hand, the discriminative subspace (DS) can be calculated by training a distance-based classifier with respect to a support set $S$ of a $N$-way, $K$-shot classification task.
Given the set of $NK$ subspaces, $\{\{U_{i, j} \}_{j=1}^{K} \}_{i=1}^N$, extracted from $S$, the set of $N$ template subspaces $\boldsymbol{U_{temp}}= \{U_{temp}^{(i)}\}_{i=1}^N$ for N classes would be the minimizer of the following loss function:
\begin{equation}
    \mathcal{L}_{ds}(\boldsymbol{U_{temp}}) = \sum_{i=1}^N \sum_{j=1}^K log \left( \frac{exp(-D(U_{i,j}, U_{temp}^{(i)}))}{\sum_{l=1}^N exp(-D(U_{i,j}, U_{temp}^{(l)}))} \right)
\label{eq:subspace_disc}
\end{equation}
Please note that $\{U_{temp}^{(i)}\}_{i=1}^N$ are task-specific, since they are derived jointly from a $N$-way, $K$-shot task.
In contrast, PS is class-specific because the optimal $U_{temp}$ in eq. (\ref{eq:subspace_proto}) is independent to other $(N-1)K$ images in $S$.
Fig. \ref{fig:kshot} compares PS and DS, along with their correspondence in vector space.

While minimizing $\mathcal{L}_{ps}$ and $\mathcal{L}_{ds}$, $U_{temp}$ is subject to the orthonormal constraint ($U^TU=I$), which prevents a closed-form solution of both problems.
%TODO revise%
To solve this type of optimization problem with a SGD-like algorithm, we exploit the Cayley transform \cite{nishimori2005learning}, projecting the gradient to the tangent space of a Stiefel manifold.
We describe the update rule of estimating PS as an example.
Let $Z=\partial \mathcal{L}_{ps}/ \partial U_t$, where $U_t$ is the current estimated $U_{temp}$ in eq. (\ref{eq:subspace_proto}).
The calculation of the next $U_{temp}$ estimation $U_{t+1}$ can be expressed as:
\begin{equation}
\begin{split}
    &W = \hat{W} - \hat{W}^T, \; \hat{W} = ZU_t - \frac{1}{2}U_t(U_t^TZU_t^T)\\
    &U_{t+1} = (I-\frac{\alpha}{2}W)^{-1}(I+\frac{\alpha}{2}W)U_{t}
\end{split}
\label{eq:cayley}
\end{equation}
where $\alpha$ is a hyper-parameter analogous to the learning rate in SGD-like algorithms.


%%%%% put it in appendix
%In our implementation, we also utilize a fixed point iteration method proposed in \cite{li2020efficient} to avoid matrix inverse computation in eq. (\ref{eq:cayley}).
%This trick effectively accelerates the estimation of Cayley transform.


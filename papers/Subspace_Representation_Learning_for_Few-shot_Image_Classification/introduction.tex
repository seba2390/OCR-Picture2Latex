%%% cv version
%Despite all the great success of deep neural networks (DNNs) in many computer vision tasks, i.e. image classification and object detection, the scarcity of annotated data still deteriorates the practicality of DNNs.
Deep neural networks (DNN) has enabled huge advances in many computer vision tasks, such as image classification \cite{russakovsky2015imagenet} and object detection \cite{fasterrcnn}. %%ref?
However, the astounding success of DNN is conditioned on the availability of large scale datasets with thorough manual annotation, which is usually too expensive for real-world applications.
In contrast, the human visual system is capable of learning a new visual concept with only a few annotated examples.
This phenomenon inspired the development of few-shot learning \cite{snell2017prototypical,finn2017model,lee2019meta,zhang2020deepemd,li2019revisiting,Sachin2017,vinyals2016matching,relationnet,ye2020few}, which aims at obtaining a reliable prediction model that can easily be generalized to unseen concepts.

One of the mainstream approaches to few-shot image classification is based on metric learning \cite{snell2017prototypical,vinyals2016matching,relationnet,ye2020few}.
This type of method focuses on learning a good metric function from known concepts with sufficient labeled data, and transferring the learned metric to unseen concepts.
Specifically, they exploit a Convolutional Neural Network (CNN) to extract a feature vector for each image, and measure the similarity between two images in hidden feature space based on distance functions, such as Euclidean and cosine distance.
%The transferrability relies on the richness of the set of known concepts.
While receiving state-of-the-art performance, metric learning based methods are still not able to handle some unseen visual concepts with large intra-class variation and cluttered background \cite{zhang2020deepemd}.
One major reason is that an image-level feature vector ignores the spatial structure and diversity of an image.
In the context of few-shot image classification, this problem becomes more severe since there is not enough supervision signal to guide the network focusing on the correct local regions.
%, and deteriorates the performance of few shot learning.

In this paper, we propose a novel subspace representation learning (SRL) framework for few-shot image classification tasks.
The SRL framework represents an image as a subspace extracted from its local CNN features.
Then, the similarity between two images is measured by a subspace-to-subspace distance.
While many strategies \cite{zuccon2009semantic} have been proposed to compute the distance between two subspaces, we choose the weighted subspace distance (WSD) \cite{li2009weighted}, which considers the importance of each dimension and reflects the original distribution of local CNN features. 
The SRL framework supports end-to-end training using a loss function related to distance based classifier \cite{chen2019closer}.
%When $K$-shot examples are available for a class, we prepare two strategies to summarized the $K$-shot information.
%The first one is to obtain a class-specific subspace prototype by calculating the average of subspaces, while the second one is to learn a set of task-specific discriminative subspace.
When $K$-shot examples are available for a class, SRL utilizes a template subspace to summarize the information from $K$ images.
To do so, we adapt two popular strategies developed for vector space to SRL framework.
The first one is to obtain a class-specific subspace prototype by calculating the average of subspaces, while the second one is to learn a set of task-specific discriminative subspaces.
%Then, we combine the training objectives from two adapted strategies, and obtain the final template subspace by optimizing the new objective function.
Both strategies can be formulated as an optimization problem on a Stiefel manifold.
%, which is the set of matrices with column-wise orthornormal constraint.
In comparison with an image-level vector, a subspace is a compact representation capable of capturing the spatial structure and diversity of an image.

%the final template subspace for $K$-shot is obtained by solving an optimization problem 

%Compared to other previous works measuring the discrepancy between sets of local CNN features, subspace representation has several advantages.
%Comparing to other works \cite{} measuring the discrepancy between local feature sets, subspace representation has serveral advantages
%[interpretability]
%[diversity, because of the othornormal basis]

To evaluate the proposed SRL framework, we conduct experiments on three popular benchmarks for few shot image-classification: MiniImageNet, TieredImageNet and Caltech-UCSD Birds-200-2011 (CUB).
Experimental results show that our method achieves competitive/superior performance compared to state-of-the-art few-shot learning approaches.
In summary, our main contributions are three fold:
\begin{itemize}
    \item we tackle the few-shot image classification task by proposing the idea of subspace representation. \\
    \vspace{-0.1in}
    \item we propose and compare two types of template subspace to aggregate $K$-shot information. \\
    \vspace{-0.1in}
    \item our SRL framework achieves state-of-the-art performance on three public benchmarks. \\
    \vspace{-0.1in}
\end{itemize}
% contribution list arrangement

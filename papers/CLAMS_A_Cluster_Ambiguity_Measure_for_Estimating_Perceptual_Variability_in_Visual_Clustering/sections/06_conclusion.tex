\section{Discussion}
\label{sec:discuss}

Our approach presents a system to identify and assess the ambiguity of cluster structure in scatterplots. We provided preliminary steps toward a comprehensive automation system %as a measure of proxy 
to simulate human judgments 
%and evaluate scatterplot ambiguity. 
in scatterplots. In this section, we discuss the implications of our measure design and experiments 
%then explore the limitations and future works. 
including opportunities for future work. 


% effectiveness (\autoref{}) and reliability (\autoref{}) of our measure design, then discuss the findings about ambiguity
% 
% In this section, we discuss the development of an automated proxy for human perception, the validation of its credibility, the ambiguity of determining cluster ambiguity, and future work to improve the model and broaden its concept of ambiguity.
% 
% \begin{itemize}[noitemsep]
%     \item \textbf{Proxy for Human Perception:}  We replicate prior results that indicate cluster perception can be measured to inform design and analysis practice.
%     \item \textbf{Data-Driven Model to Deal with Wide Range of Scatterplot Patterns:} We develop \measure that deals with diverse dataset characteristics to measure and rank cluster ambiguity.
%     \item \textbf{Scalable Model to Rank Ambiguity:} With proposed applications and evaluations with available methods, we demonstrated the scalability and applicability of our \measure in a data analysis environment.
% \end{itemize}


\subsection{Proxy for Human Perception}
In this work, we provided preliminary steps toward developing the model to identify and rank intrinsic variability in visual perception. 
%, in our case conducting visual clustering. 
Evaluating variability based on human participation is not always feasible, scalable, or robust considering 
%wide diverse data characteristics. 
the diversity of data characteristics, visualization designs, and other factors that might influence people's perceptions. There are simply too many sources of variance to account for.
% 
\measure, which automatically generates a score simulating human judgments, offers a scalable and robust alternative to an approach that attempts to account for every possible source of variance. 
% such a human-based approach. 
% 
Our work demonstrates the promise of using statistical modeling to infer patterns over a corpus of human estimates.  
% 
%our applications (\autoref{sec:appl}) demonstrate the benefit of the automation. 
Extending our 
%Applying the findings as an actionable and 
approach to other perceptual tasks (e.g., outlier detection)
would 
%support us to inject 
bring the notion of perceptual variability to more complex and practical applications \cite{moritz2018formalizing}.

% as we have seen in available systems \cite{moritz2018formalizing}.

Toward this end, we provide a \href{http://www.clusterambiguity.dev.s3-website.ap-northeast-2.amazonaws.com/}{demo interface} that measures and explains cluster ambiguity. 
We believe that the interface will enhance the usability of \measure and moreover serve as a preliminary step toward future applications considering perceptual variability.

\subsection{Credibility of the User Study-Based Design Process}

\label{sec:credibility}

While designing \measure, we identified several factors that play a vital role in cluster perception through a user study (\autoref{sec:preexp}), and built a regression module estimating human cluster perception based on study findings (\autoref{tab:feature_eng}). These factors support building a robust module that accurately reflects how people identify clusters in data analysis (\autoref{sec:regmodel}).
Our ablation study (\autoref{sec:regmodeleval}) verifies the importance of these factors, validating the credibility of using human strategies to inform model parameters. 
Moreover, the main study (\autoref{sec:mainstudy}) showed that the measure built upon such a design process reliably estimates the ambiguity of scatterplots with a wide range of cluster patterns.

Our study asked participants about how the characteristics of datasets influence the ambiguity of a scatterplot (see \autoref{sec:mainstudy}). The findings from the interview validate the reliability of our design process. As shown in \autoref{fig:qual_study}, participants identified the factors that we have considered in our model (see \autoref{tab:feature_eng}), such as density, proximity, shape, and how clusters are located and related to each other (i.e., distribution). 
Note that such results also match well with prior findings~\cite{sedlmair2015data, sadahiro1997cluster,quadri21tvcg}. 

\subsection{\textit{Ambiguity} of Ambiguity}

While our interview revealed common factors that influence cluster perception (\autoref{sec:credibility}), it also showed that the perceived influence of different factors on ambiguity varies among participants. In other words, the definition of cluster ambiguity is \textit{ambiguous} to each participant. 
This observation depends on what factors are given more importance by different participants when determining a scatterplot's ambiguity.
For example, P01 said, \textit{"I find the shape of the group of points to be the main reason in identifying and separating clustering. If they have salient separable shapes, they are more clear"}, and P07 noted, \textit{"Proximity and concentration of the points help me separate the clusters quickly"}. 
\autoref{fig:qual_study} also supports this finding, showing that no single factor received complete agreement from the participants (see the white transparent bars).
Considering the variability across participants,
we conclude that ambiguity cannot be determined by a single person but must instead reflect a population of individuals. 
The fact that the performance of human annotators (i.e., participants) in predicting ground truth ambiguity varied in our main study (\autoref{sec:mainstudy}) supports this claim.
This observation indicates that, inevitably, multiple subjects are required for assessing ambiguity through human resources, thereby underscoring the importance of our automated solution.

\subsection{Limitations and Future Work}
\measure outperformed computational approaches and more than 50\% of participants (\autoref{sec:mainstudy}) in precisely estimating cluster ambiguity. However, there 
%is plenty of room 
are several opportunities to improve \measure.
For example, we found that \measure erroneously considers scatterplots with more numbers to have less ambiguity, as seen in \autoref{fig:topbottom}---the top eight clear scatterplots (top row) generally have more clusters than the top eight ambiguous ones (bottom row). We quantitatively demonstrate this bias in Appendix D.
\rev{We can also improve the method of aggregating pairwise ambiguity scores, which is currently a na{\"i}ve average. Considering cluster topology or their pairwise distances during the aggregation may better reflect human visual perception.}

\rev{
Another open direction is to generalize \measure. We can extend \measure to consider visual encoding (e.g., size, shape, and color of marks) of scatterplots by revising the features feed into our regression module. We may also improve our measure to deal with nested clusters by adopting hierarchical clustering algorithms \cite{mullner11arxiv} in place of GMM. We are also interested in
}
broadening the concept of ambiguity to encompass general visualization. 
For example, we can model the perceptual variability that may arise when examining cluster structures of high-dimensional data via scatterplot matrices or parallel coordinates. Moreover, we aim to develop a model estimating ambiguity in various perceptual tasks, including outlier detection and trend analysis.


\section{Conclusion}

We introduce \measure, a VQM for estimating the cluster ambiguity of a monochrome scatterplot, which originally required expensive human resources to compute. 
To serve as a proxy for human perception across a wide range of cluster patterns, our measure is designed based on a qualitative user study and is trained over perceptual data.
Through quantitative evaluations, we verified that \measure outperforms automatic competitors while showing competitive performance with human annotators. Our research findings not only demonstrate current applications but also invite discourse on potential future applications that capitalize on the concept of ambiguity.
In summary, our work represents a \rev{significant} advancement toward developing a comprehensive framework that elucidates the phenomenon of ambiguity in visualization. 

\newpage

% \vspace{5pt}
% \noindent \textbf{Interactive Demo of} \measure: \texttt{\href{http://clams-demo.s3-website.ap-northeast-2.amazonaws.com/}{clams-demo.com}.}

% Our approach is trained over perceptual data and works as a proxy for human perception for a wide range of scatterplots. 


% In conclusion, we have introduced CLAMS, a VQM for estimating the cluster ambiguity of a monochrome scatterplot. Our approach is trained over perceptual data and works as a proxy for human perception. By decomposing the input scatterplot using the Gaussian mixture model (GMM) and measuring ambiguity in a component-pairwise manner, our measure can deal with a wide range of cluster patterns while maintaining scalability. Our method can be used to improve the performance of clustering algorithms and aid in data analysis tasks. As future work, we plan to extend our approach to handle color scatterplots and explore its application in other domains.






% \subsection{Benchmarking Outlier Detection \fix{(Hyeon)}}
% \subsection{Computational Complexity and Scalability}



% searching for such defects and improving \measure will be an interesting future work; we discuss this issue in \autoref{sec:discuss}.
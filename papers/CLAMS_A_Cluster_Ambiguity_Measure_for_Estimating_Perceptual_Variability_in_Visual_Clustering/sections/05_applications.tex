\section{Applications}
\label{sec:appl}


% \measure allows us to automatically estimate the cluster ambiguity, which originally had to be figured out through user studies or direct observation.
% This supports perception-based optimization and benchmarking of data mining algorithms~\cite{aupetit19vis}, which we present here as applications of \measure. 
We introduce two applications of \measure that validate the effectiveness, generalizability, and applicability of \measure.
We present that 
\measure can further optimize nonlinear dimensionality reduction embeddings to reduce cluster ambiguity while maintaining accuracy (\autoref{sec:ambreduce}). 
We then demonstrate that the measure can be used to find reliable datasets for benchmarking clustering techniques (\autoref{sec:reliable}). 


\subsection{Reducing Cluster Ambiguity of Nonlinear Dimensionality Reduction Embeddings}

\label{sec:ambreduce}

\subsubsection{Problem Statement and System Design}

A common way to analyze the cluster structure of high-dimensional data is to use dimensionality reduction (DR)~\cite{nonato19tvcg} techniques, e.g., $t$-SNE~\cite{maaten08jmlr}, Isomap~\cite{tenenbaum00aaas}, or UMAP~\cite{mcinnes2020arxiv}, which synthesizes 2D representation (i.e., embedding) that preserves the original characteristics of the input high-dimensional data. 
The analysis is usually done by depicting the embedding as a scatterplot and conducting visual clustering. 
Recently, nonlinear DR techniques~\cite{lee07springer} that can reveal the complex data manifold have been widely developed~\cite{jeon22vis, fu19kdd,maaten08jmlr, mcinnes2020arxiv} and used for cluster analysis~\cite{becht19nature, fujiwara22arxiv}.  

Embedding varies by choice of DR technique or hyperparameter, where each can lead to significantly different analysis results. A typical way to address this problem is to optimize embeddings by assessing their accuracy in representing the original data. 
Diverse metrics to measure the accuracy of DR embeddings~\cite{jeon22tvcg, lee07springer, nonato19tvcg} have been developed for the purpose. 
However, an optimized embedding can still have an ambiguous cluster structure, which
can potentially harm the reliability of the analysis despite high accuracy (\autoref{sec:intro}). 
For the valid analysis of high-dimensional data, an embedding having both high accuracy and low cluster ambiguity is required.  

Here, we introduce an optimization system that can discover DR embeddings satisfying both high accuracy and low ambiguity, which we call \ambreducer. Given the input high-dimensional data $Z$, DR technique $t$, and DR accuracy metric $m$, \ambreducer first finds the \textit{intermediate} embedding that maximizes accuracy.
This is done by searching a hyperparameter setting $h_1 = \arg\max_{h\in H}{m(t(Z, h))}$, where $H$ denotes the set of every possible hyperparameter setting and $t(Z, h)$ represents the embedding made with $t$ using hyperparameter setting $h$. We use Bayesian optimization~\cite{snoek12nips} over $H$ while maximizing $m(t(Z, h))$. Then, the system searches for the \textit{final} embedding that maintains accuracy while reducing cluster ambiguity compared to the intermediate embedding. 
% hyperparameter that generates embedding maintaining accuracy while maximizing \measure score, which we denote as $CA$.
Formally, this is done by finding hyperparameter setting $h_2 = \arg\max_{h\in H}{loss(h, h_1)}$, where $loss$ is defined as
\resizebox{\linewidth}{!}{%
\begin{minipage}[t]{1.15\linewidth}
\vspace{-3pt}
\[
loss(h, h_1) = \left\{ \begin{array}{ccc}
   CA(t(X, h))    & \mbox{ if } &\mid m(t(Z, h_1)) - m(t(Z, h)) \mid < \tau \\
   \infty       & \mbox{ if } &\mid m(t(Z, h_1)) - m(t(Z, h)) \mid > \tau 
\end{array}  \right..
\]
\vspace{6pt}
\end{minipage}}
Here, $CA$ denotes \measure score, and $\tau$ denotes the threshold parameter, which can be set by users. $\tau$ adjusts the tradeoff between accuracy and cluster ambiguity. If we set small $\tau$, the final embedding made by $h_2$ tends to have high accuracy but has fewer chances to reduce ambiguity. 
\rev{The proper value of $\tau$ highly depends on the target application and domain. For example, the more analysts involved, the greater $\tau$ should be to give more room to reduce ambiguity. Automatically determining $\tau$ is important future work that extends the applicability of \ambreducer.}

\subsubsection{Evaluation}


\label{sec:ar_eval}


\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/ambreducer_scatter.pdf} \vspace{-5mm}
    \caption{Dimensionality reduction embeddings optimized solely based on the accuracy (top row; intermediate results of \ambreducer) and those optimized considering both accuracy and cluster ambiguity (bottom row; final results of \ambreducer). Our experiment shows that the accuracy of the final results has no significant difference compared to the intermediate results in terms of accuracy but has a substantially smaller amount of cluster ambiguity (\autoref{sec:ar_eval}, \autoref{fig:ar_exp}). \vspace{-4mm}}
    \label{fig:ar_scatter}
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/ambreducer_exp.pdf} \vspace{-7mm}
    \caption{The results of our evaluation on \ambreducer (\autoref{sec:ar_eval}). 
    We compared the accuracy and cluster ambiguity of the intermediate (optimized solely on accuracy; blue) and final (optimized based on both accuracy and cluster ambiguity; orange) embeddings made by \ambreducer.
    We found that there is no significant difference (ns) between the final and intermediate results in terms of accuracy (top), while the cluster ambiguity is significantly reduced ($p<.05$) in the final results (bottom). \vspace{-5mm}}
    \label{fig:ar_exp}
\end{figure}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/app_clustering.pdf}
    \vspace{-6.5mm}
    \caption{
    Results of the experiment demonstrating \measure's effectiveness in picking reliable clustering benchmark datasets (\autoref{sec:reliable}). 
    We first prepared a set of datasets (bottom-20 ($\mathbf{P}_l$; blue), middle-20 ($\mathbf{P}_m$; orange) or top-20 ($\mathbf{P}_h$; green) subset of 60 scatterplots we used in the main study based on \measure score) and clustering metrics (Silhouette Coefficient (a) or Calinski-Harabasz Index (b)).
    For each set, we compute the rankings of clustering techniques over individual datasets within the set based on clustering metrics.
    We then compute the within-set stability by assessing rank correlations of the rankings pairwisely.
    In general, the set consisting of datasets with less ambiguity showed better stability, confirming the hypothesis that datasets with less cluster ambiguity are more reliable for benchmarking clustering techniques.
    \vspace{-4.5mm}
    }
    \label{fig:app_clustering}
\end{figure*}


\noindent 
\textbf{Objectives and Design:}
We wanted to verify the effectiveness of \ambreducer.
We hypothesized that \ambreducer substantially reduces cluster ambiguity while maintaining accuracy.
To validate the hypothesis, we prepared 30 high-dimensional datasets, sampled from the datasets we used in our main study \autoref{sec:mainstudy}, and applied \ambreducer.
We collected the intermediate (based on $h_1$) and final (based on $h_2$) embeddings, and checked how the accuracy and cluster ambiguity varied between the two groups.
\autoref{fig:ar_scatter} depicts the subset of two groups.

\noindent
\textbf{Hyperparameter Setting:}
Our hyperparameter setting was as follows. 
For the DR technique, we used UMAP, as UMAP is widely used for cluster analysis in practice~\cite{becht19nature, sanchez2020dimensionality}.
We used Steadiness \& Cohesiveness~\cite{jeon22tvcg} (S\&C) as accuracy measures, as they are specially developed to measure the accuracy in preserving cluster structure.
We used the F1 score of S\&C to represent the accuracy of DR, which ranges from 0~to~1.
Finally, we arbitrarily set $\tau$ as 0.05. 

\noindent
\textbf{Results and Discussions:}
We used a $t$-test to check whether there is a significant accuracy (measured by S\&C) or cluster ambiguity (measured by \measure) difference between the final and intermediate embeddings.
Although there was no significant difference  in terms of accuracy ($t(58)=.455, p = .650$), we found that the cluster ambiguity of the final embeddings was significantly lower than the one of the intermediates ($t(58)=2.55, p < .05$). 
The result verifies our hypothesis, verifying the effectiveness of \ambreducer and the applicability of \measure.


\subsection{Finding Reliable Datasets for Clustering Benchmark}
\label{sec:reliable}
% 
We demonstrate an experiment validating \measure's effectiveness in selecting reliable datasets for benchmarking clustering techniques~\cite{liu10icdm}.
We hypothesized that if the cluster ambiguity of a dataset (a scatterplot in this case) is high, then the clustering benchmark using the dataset is unreliable. 
Our assumption is that if the dataset is ambiguous, which means that there is no explicit cluster structure to be found, the performance of clustering techniques to ``find the cluster'' will be insufficiently compared. 
Thus, clustering benchmarking with the ambiguous dataset will likely provide an arbitrary ranking of techniques, which harms the credibility of the evaluation. 
To verify the hypothesis, we prepared three sets of datasets having different cluster ambiguity levels and checked the stability of the rankings made by different datasets in each set. 
The detailed explanation of the experiment is as follows:

\noindent
\textbf{Objectives and Design:}
We wanted to check whether the cluster ambiguity of benchmark datasets affects the stability of the ranking of clustering techniques, which we use as a proxy for the reliability of the evaluation. 
We prepared three sets of datasets with the same cardinality: $\mathbf{P}_h$, $\mathbf{P}_m$, and $\mathbf{P}_l$, with each having high, middle, and low cluster ambiguity, respectively. 
For each set, we obtained rankings of clustering techniques, where each was made based on an individual dataset. We then checked how the rankings correlate with each other by averaging the pairwise rank correlation computed by Spearman's $\rho$.

\noindent
\textbf{Datasets:}
We used 60 scatterplots we gathered in the main evaluation for \measure (see \autoref{sec:mainstudy}). We sorted the scatterplots based on \measure score in descending order, and then assigned top-20, middle-20, and bottom-20 scatterplots to $\mathbf{P}_h$, $\mathbf{P}_m$, and $\mathbf{P}_l$, respectively.  

\noindent
\textbf{Clustering Techniques:}
We used eight techniques: HDBSCAN~\cite{campello13kdd}, DBSCAN, $K$-Means, $X$-Means~\cite{pelleg00icml}, Birch~\cite{zhang96sigmod}, and Agglomerative clustering~\cite{mullner11arxiv} with single, average, and complete linkage.

\noindent
\textbf{Measurements:}
We used the Silhouette coefficient~\cite{rousseeuw87jcam} and Calinski-Harabasz index~\cite{calinski74cis} to measure the performance of clustering techniques. To ensure that the evaluation reflected the maximum capability of clustering techniques, we ran Bayesian optimization and used the best score obtained while following the hyperparameter range setting of Jeon et al.~\cite{jeon22arxiv}.
Refer to Appendix C for detailed settings.


\noindent
\textbf{Results and Discussions:}
\autoref{fig:app_clustering} depicts the results.
We used a one-way ANOVA to analyze how the rank correlation scores vary due to the used set of datasets ($\mathbf{P}_l$, $\mathbf{P}_m$, $\mathbf{P}_h$). We used Tukey's HSD for post hoc analysis. 
For both the clustering metrics, the set of datasets had a significant effect (Silhouette: $F(3,567)=54.1, p < .001$; Calinski-Harabasz: $F(3, 567)=44.0, p < .001$). Post-hoc analysis revealed that the rank correlation scores over $\mathbf{P}_l$ and $\mathbf{P}_m$ were significantly higher than the ones over $\mathbf{P}_h$ for both metrics ($p < .001$ for every case). Meanwhile, scores over $\mathbf{P}_l$ were significantly higher than the ones over $\mathbf{P}_m$ for the Silhouette coefficient ($p < .001$), but not for the Calinski-Harabasz index ($p=0.301$). Such results indicate that using datasets with less cluster ambiguity makes the clustering evaluation more stable, confirming our hypothesis and validating the effectiveness of \measure in picking reliable datasets for the clustering benchmarks.







 
% Selecting the appropriate datasets is an important preliminary step for executing valid clustering benchmarks~\cite{jeon22arxiv}. 
% We can always cherry-pick datasets that praise a certain clustering technique or hyperparameter setting. 
% For example, by using the datasets with concave clusters, we can easily make density-based clustering techniques (e.g., DBSCAN~\cite{schubert17tbs}) outperform partitioning-based ones (e.g., $K$-Means~\cite{likas03pr}).





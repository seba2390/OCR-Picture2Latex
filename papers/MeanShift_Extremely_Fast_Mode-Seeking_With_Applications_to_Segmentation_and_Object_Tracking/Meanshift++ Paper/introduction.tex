\section{Introduction}

MeanShift \cite{cheng1995mean,comaniciu1999mean,fukunaga1975estimation} is a classical mode-seeking clustering algorithm that has a wide range of applications across machine learning and computer vision. Recent applications within computer vision include object tracking \cite{ning2012robust,vojir2014robust,leichter2010mean}, unsupervised image segmentation \cite{tao2007color,carreira2006acceleration,zhou2013mean}, video segmentation \cite{paris2007topological,dementhon2002spatio,paris2008edge}, image restoration \cite{arjomand2017deep,bigdeli2017image}, edge-preserving smoothing \cite{paris2008edge,barash2004common,buschenfeld2012edge}, point clouds \cite{lee2009shoreline,vosselman2013point,yue2018new}, and remote sensing \cite{ming2012semivariogram,ponti2012segmentation,chen2018airborne,michel2014stable}. More broadly in machine learning, MeanShift has been used for semi-supervised clustering \cite{anand2013semi,tuzel2009kernel}, manifold denoising \cite{xiang2016statistical,wang2010manifold}, matrix completion \cite{wang2011denoising,choudhary2016active}, anomaly detection \cite{aydin2013robust,yu2013scalable,tsai2010mean}, as well as numerous problems in medical imaging \cite{bai2013novel,tek2001vessel,zhou2011gradient,mayer2009adaptive,tek2010method,nguyen2012clustering,zhou2009anisotropic,zhou2014semi}, wireless sensor networks \cite{yu2020mean,zhou2009mean,xie2014k,sapre2018moth,wu2011video,qu2018incorporating}, and robotics \cite{kroemer2009active,lakaemper2009simultaneous,hu2013design,kato2005optimizing,yang2014robotic,cha2011mahru}.

Given a set of examples, MeanShift proceeds in iterations, where in each iteration, each point is moved to the average of the points within a neighborhood ball centered at that point. The radius of the ball is a hyperparameter, often referred to as the {\it bandwidth} or {\it window size}. All initial examples that converge to the same point are clustered together and the points of convergence are estimates of the modes or local maximas of the probability density function. It has been shown that MeanShift implicitly performs a gradient ascent on the kernel density estimate of the examples \cite{arias2016estimation}. MeanShift thus serves two purposes: mode-seeking and clustering.

MeanShift is often an attractive choice because it is non-parametric: unlike popular objective-based clustering algorithms such as $k$-means \cite{arthur2006k,kanungo2002efficient} and spectral clustering \cite{ng2002spectral,von2007tutorial}, it does not need to make many assumptions on the data, and the number of clusters is found automatically by the algorithm rather than a hyperparameter that needs to be set. In other words, MeanShift can adapt to general probability distributions. However, one of the main drawbacks of this procedure is its computational complexity: each iteration requires $O(n^2)$ computations. This is because for each example, calculating the window around the example is linear time in the worst case.

In this paper, we propose MeanShift++, a simple but effective procedure which first partitions the input space into a grid. Then, at each iteration, each point is assigned to its appropriate grid cell. We then approximate any point's window with the average point in its and its neighboring grid cells. Each iteration in this procedure runs in linear time to the number of data points, with the cost of being exponential to the dimension of the feature space (since the size of the grid is exponential in dimension). Such a trade-off is ideal in settings with a large number of data points but low dimensionality, which is often the case in computer vision applications. With the growing size of modern datasets and increasing resolution of data collected by sensors and cameras, it is becoming ever more urgent to have fast versions of classical techniques.

Our contributions are as follows:
\begin{itemize}
    \item We propose MeanShift++, a new mode-seeking procedure based on MeanShift that runs in $O(n\cdot 3^d)$ per iteration vs $O(n^2\cdot d)$ for MeanShift. MeanShift++ has no additional hyperparameters over MeanShift.
    \item We show that MeanShift++'s grid-based approximation attains near minimax optimal statistical consistency guarantees at approximating the true density.
    \item An extensive empirical analysis shows that MeanShift++ performs at least as well as MeanShift for clustering while being significantly faster.
    \item Image segmentation results show that MeanShift++ delivers almost identical segmentations as MeanShift while being as much as 10,000x faster. 
    \item Image segmentation experiments on the Berkeley Segmentation Dataset Benchmark (BSDS500) found that MeanShift++ performed on par or better than baselines despite being faster than most (and faster than MeanShift by 1,000x).
    \item We present a new object tracking algorithm based on MeanShift++ that can adapt to gradual color distributions and scene changes--something most MeanShift-based approaches cannot do due to the computational cost.
\end{itemize}


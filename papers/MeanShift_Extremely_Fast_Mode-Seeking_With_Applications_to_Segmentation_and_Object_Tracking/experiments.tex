\section{Experiments}
We compare Meanshift++ against MeanShift on various clustering tasks in Table~\ref{fig:datasetsummary_small}. These comparisons are made using the Scikit-Learn \cite{pedregosa2011scikit} implementation of MeanShift and our own implementation of MeanShift++ in Cython.

To measure the quality of a clustering result, we use the Adjusted Rand Index (ARI) \cite{hubert1985comparing} and the Adjusted Mutual Information (AMI) \cite{vinh2010information} scores, which compare the clustering with the partitioning induced by the labels of the data points, a popular way of comparing clustering performance \cite{jang2019dbscan++}. The benchmark datasets we use are labeled datasets, and we only cluster the features. 

As stated earlier, MeanShift++ is linear with respect to the number of data points and exponential in dimension. We thus show results on low-dimensional datasets. In Figure~\ref{fig:experiments}, we ran both algorithms on 19 benchmark datasets with $5$ or fewer dimensions, ranging from less than $100$ data points to millions of data points.

For the top five largest datasets, MeanShift failed to return a result for any setting of bandwidth despite running for more than 24 hours. MeanShift++ consistently outperformed MeanShift in both clustering quality and runtime for the rest of the datasets, as shown in Table~\ref{fig:datasetsummary_large}. We saw a significant speed reduction of over 100x on both small and large datasets, showing that MeanShift++ does not have significantly more overhead costs than MeanShift either. 

We also show in Figure~\ref{fig:experiments} the effect the bandwidth setting has on clustering performance and runtime for a few of the datasets to provide further insight into the stability of the procedures under the bandwidth hyperparameter.

We note that MeanShift++ outperforms MeanShift on many datasets, possibly due to a regularizing effect: by partitioning the space into grids and assigning every point in the same cell the same value instead of a unique value for each point, the gradient-ascent shifting step is more stable than in MeanShift. This regularization effect, combined with the option to tune the cell-length which essentially controls the amount of regularization, allows MeanShift++ to outperform Meanshift in some cases. 

However, these results are unlikely to generalize to higher dimensions. It is known that density-based procedures perform poorly in high dimensions due to the curse of dimensionality. Our theoretical results also show that rates become exponentially worse in higher dimension. 
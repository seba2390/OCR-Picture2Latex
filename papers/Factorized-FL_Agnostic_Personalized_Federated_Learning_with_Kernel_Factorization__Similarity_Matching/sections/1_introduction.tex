\section{Introduction}
\label{sec:intro}

\input{figures/fig_overview}
\input{figures/fig_concept}

% Federated Learning (FL) is a collaborative learning process whose goal is to learn a global model by aggregating the models from multiple clients, each of which trains on its private local data~\citep{McMahan2017CommunicationEfficientLO,li2020federated,Wang2020Federated,karimireddy2021scaffold,li2021modelcontrastive}. Although the decentralized features bring us various advantages, i.e. preservation of data privacy, reduction of computing cost at the server, etc., at the same time, the decentralized training process brings in significant vulnerability to heterogeneity. When the local data distributions are largely different across the participating clients, aggregating the knowledge learned at multiple clients may not be beneficial, and even an adversarial effect, which in turn will result in the performance degeneration of the global model. This vulnerability to heterogeneity is one of the most crucial challenges of federated learning. 

Personalized Federated Learning (PFL) aims to utilize the aggregated knowledge from other clients while learning a client-specific model that is specialized for its own task and data distribution, rather than learning a universal global model~\citep{arivazhagan2019federated,liang2020think,fallah2020personalized,zhang2021personalized}. While various personalized federated learning approaches have shown success in alleviating the data heterogeneity problem, yet, they are also limited as they follow the common assumptions of the standard federated learning setting, that (1) all participants use the same set of labels that are in the same order, and (2) all clients tackle the same task from the same domain.

In many real-world scenarios, the first assumption may not hold since the labels for the same task could be differently annotated depending on the user environment (Figure~\ref{fig:overview} Left). For example, when working with the same set of semantic classes, the labels across multiple clients could have a completely different ordering of the classes. In client 1, the label 1 may denote the ``Ship" class, while in client 2, the label 10 may denote the same class. Also, the same ``Car" class may be given the label ``Vehicle" or ``SUV". 

The second assumption severely limits the pool of devices that can participate in the collaborative learning process. However, clients working on different tasks and domains may have similar classes, or a common underlying knowledge, that may be helpful for the local models being trained at other clients (Figure~\ref{fig:overview} Right). Thus, it would be helpful if we can allow such domain-heterogeneous models to communicate the common knowledge across tasks and domains. 

However, federated learning under label and domain heterogeneity is a non-trivial problem, as most methods suffer from severe performance degeneration in such settings (Table~\ref{tbl:permuted}). We analyze this phenomenon in Figure~\ref{fig:concept}. Specifically, we train equally-initialized models on four different datasets and observe how different the gradient updates becomes as training goes on (we measure normalized $L_2$ distance of them). Learning on two MNIST partitions (split by an instance-wise manner) show the smallest difference (Figure~\ref{fig:concept} (a) and (b) Gray). Interestingly, simply permuting the labels of the partition 2 makes the gradient updates to largely diverge from the original gradients, which results in more severe heterogeneity compared to those of the the model trained with synchronized labels (Figure~\ref{fig:concept} (a) and (b) Red). Moreover, learning on completely different dataset (CIFAR-10) makes model gradients diverge more severely compared to learning on the dataset with permuted labels (Figure~\ref{fig:concept} (a) and (b) Blue). We conjecture that conventional loss function, i.e. cross entropy, and the corresponding back-propagation process do not actually care about task homogeneity, and thus it is not guaranteed that model parameters are identically updated when labels are permuted. These particularly lead to severe performance degeneration when performing federated learning (Figure~\ref{fig:concept} (c)). We measure performance on MNIST partition 1 while aggregating a model trained on the different dataset for every 3 epochs. We observe averaged models suffer from crucial performance degeneration in both  FL scenarios.


We name this challenging problem as the Agnostic Personalized Federated Learning (APFL) problem, where participants with personalized labels or from multiple domains can collaboratively learn while benefiting each other. An APFL problem has two critical challenges: (1) Label Heterogeneity for the discrepancy of the labels, due to the lack of a synchronized labeling scheme across the clients; and (2) Domain Heterogeneity for the discrepancy in the task and domains tackled by each participant. 

To tackle these challenges, we propose a novel method \texttt{Factorized-FL}, which factorizes model parameters into basis vectors and aggregate them in the factorized parameter space. This allows to factorize the the model aggregation to take place in a semantic parameter basis space which is more robust to the use of different labels. Also, the factorization results in the separation of the client-general and client-specific knowledge, and thus prevents the aggregation of incompatible knowledge across clients. Moreover, to further alleviate the model from collapsing into a degenerate solution, we measure the task similarity across the clients using the factorized parameters, to allow selective aggregation of the knowledge among the relevant models that work on similar tasks or domains. We extensively validate our method on both label- and domain-heterogeneous settings, and show that our method significantly outperforms the current state-of-the-art personalized federated learning methods. This work can be summarized as follows:

\vspace{-0.05in}
\begin{itemize}[leftmargin=0.2in]
    \vspace{-0.1in}    
	\item We introduce Agnostic Personalized Federated Learning (APFL) and study its two critical challenges, Label and Domain Heterogeneity.
	\vspace{-0.075in}
	\item We propose a novel FL method named Factorized-FL, which factorizes model parameters to reduce parameter dimensionality for alleviating knowledge collapse, and utilize task-level similarity for matching relevant clients.
	\vspace{-0.2in}
	\item We extensively validate our method in both label- and domain-heterogeneous scenarios and show our method outperforms the current state-of-the-art methods.
\end{itemize}

%In sum, label and domain heterogeneity make local models highly heterogeneous and these lead to severe performance degeneration in federated learning scenarios. 
Our work brings together ideas from recurring vulnerability detection, and program analysis and testing.
In the following paragraphs, we compare our work to advances in these areas.

\paragraph{Patch-based Discovery of Recurring Vulnerabilities}
Redebug~\cite{jang2012redebug} and Securesync~\cite{pham2010detection} find recurring vulnerabilities by using syntax matching of templates derived from vulnerability patches.
Thus, {\it patched} vulnerabilities form the basis of their template-based matching algorithms.
In contrast, we template a vulnerability based on automatically localized failures, and debug information obtained from fuzzer reported crashes.
What makes our setting more challenging is the lack of a reliable code pattern (usually obtained from a patch) to build a template from.
As we have shown, it is possible to construct vulnerability templates even in this constrained environment and find additional vulnerabilities even {\it in the absence} of patches.

\paragraph{Code Clone Detection}
We are not the first to present a pattern-based approach to vulnerability detection.
Yamaguchi et al.~\cite{yamaguchi2012generalized} project vulnerable code patterns derived from patched vulnerabilities on to a vector space.
This permits them to extrapolate known vulnerabilities in current code, thereby permitting the discovery of recurring vulnerabilities.

Other researchers have focused on finding code clones regardless of them manifesting as vulnerabilities~\cite{bellon2007comparison, baxter1998clone,kontogiannis1996pattern,marcus2001identification}.
Code clone detection tools such as CPMiner~\cite{li2006cp}, CCFinder~\cite{kamiya2002ccfinder}, Deckard~\cite{jiang2007deckard} solve the problem of finding code clones but rely on sample code input to be provided.
These tools solve the more general problem of finding identical copies of user-provided code.
Although these tools serve as a building block for recurring vulnerability discovery, they require that the user specifies the code segment to be matched.
In a setting where a security analyst is auditing third-party code, manual specification of code templates might not be feasible.
By automatically performing template matching on fuzzer-discovered program crashes, leverage the fuzzer for the specification for vulnerable code patterns.

\paragraph{Hybrid Vulnerability Discovery}
SAGE~\cite{godefroid2012} is a white-box fuzz testing tool that combines fuzz testing with dynamic test-case generation.
Constraints accumulated during fuzz testing are solved using an SMT solver to generate test cases that the fuzzer alone could not generate.
This is expensive because it requires a sophisticated solver.
In a similar vein, Driller~\cite{stephens2016driller} augments fuzzing through selectively resorting to symbolic execution when fuzzer encounters coverage bottlenecks.
The use of symbolic execution to augment fuzzing is complementary to our approach.
In practice, security audits would benefit from both our approach as well as that proposed by prior researchers.

Saner~\cite{balzarotti2008} combines static and dynamic analyses towards identifying XSS and SQL injection vulnerabilities in web applications.
The authors of Saner use static analysis to capture a set of taint source-sink pairs from web application code, and subsequently use dynamic analysis on the captured pairs to tease out vulnerabilities.
Their evaluation on popular PHP applications show that dynamic analysis is able to bring down the number of false positives produced by static analysis, and find multiple vulnerabilities.
Like our work, Saner demonstrates that static and dynamic analyses can effectively complement each other.
In contrast to Saner, we differ in the order of analyses performed (we perform static analysis driven vulnerability exploration after confirmed taint source-sink pairs have been found), and in the target programming language.

Yamaguchi et al.~\cite{yamaguchi2015automatic} automatically infer search patterns for taint-style vulnerabilities from source code by combining static analysis and unsupervised machine learning.
They show that their approach helps reduce the amount of code audit necessary to spot recurring vulnerabilities by up to 94.9\%, enabling them to find 8 zero-day vulnerabilities in production software.
Their work is close in spirit to ours.
However, we avoid the computational overhead involved in their workflow (building a code property graph, pattern clustering etc.), while retaining their template matching run time.
In our framework, fault localization and result ranking run times are almost negligible.

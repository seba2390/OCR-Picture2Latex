\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2021

% ready for submission
%\usepackage{neurips_2022}
\usepackage{graphicx}
% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\usepackage[preprint]{nips}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2021}

% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{neurips_2021}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{bbding}
\usepackage{bm}

\makeatletter
\newcommand{\biggg}{\bBigg@{1.1}}  
\def\bigggl{\mathopen\biggg}
\def\bigggm{\mathrel\biggg}
\def\bigggr{\mathclose\biggg}
\makeatother


\title{Advancements and Trends in Ultra-High-Resolution Image Processing: An Overview}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors' names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.
\author{Zhuoran Zheng$^{1}$~~~Boxue Xiao$^{2}$\\
	$^{1}$CSE, Nanjing University of Science and Technology~~~~$^{2}$Hong Kong Polytechnic University\\
	{\tt\small zhengzr@njust.edu.cn}
	%{\tt\small james371507@gmail.com, mhyang@ucmerced.edu}
	%{\small\url{https://sites.google.com/site/renwenqi888/research/dehazing/gfn}}
}

%\author{%
%	David S.~Hippocampus\thanks{Use footnote for providing further information
	%	about author (webpage, alternative address)---\emph{not} for acknowledging
%		funding agencies.} \\
%	Department of Computer Science\\
%	Cranberry-Lemon University\\
%	Pittsburgh, PA 15213 \\
%	\texttt{hippo@cs.cranberry-lemon.edu} \\
	% examples of more authors
	% \And
	% Coauthor \\
	% Affiliation \\
	% Address \\
	% \texttt{email} \\
	% \AND
	% Coauthor \\
	% Affiliation \\
	% Address \\
	% \texttt{email} \\
	% \And
	% Coauthor \\
	% Affiliation \\
	% Address \\
	% \texttt{email} \\
	% \And
	% Coauthor \\
	% Affiliation \\
	% Address \\
	% \texttt{email} \\
%}

\begin{document}
	\bibliographystyle{plain}
	\maketitle
	
	
\begin{abstract}
%
Currently, to further improve visual enjoyment, Ultra-High-Definition (UHD) images are catching wide attention.
%
Here, UHD images are usually referred to as having a resolution greater than or equal to $3840 \times 2160$.
%
However, since the imaging equipment is subject to environmental noise or equipment jitter, UHD images are prone to contrast degradation, blurring, low dynamic range, etc.
%
To address these issues, a large number of algorithms for UHD image enhancement have been proposed.
%
In this paper, we introduce the current state of UHD image enhancement from two perspectives, one is the application field and the other is the technology.
%
In addition, we briefly explore its trends.
\end{abstract}
	


\section{Application Field}
%
Here, we introduce several algorithms for implementing image enhancement on UHD image degradation scenarios. Notably, most of these methods are implemented to run on a single GPU shader (RTX3090 or V100) in real-time ($>$30fps).
%

\noindent \textbf{Image dehazing.}
%
UHD image dehazing started with~\cite{zheng2021ultra}, which employs a bilateral learning approach to enhance 4K images. After that, Xiao et al.~\cite{xiao2024single} propose a pyramid model to enhance the dehazing effect of 4K images. Recently, Zhuang et al.~\cite{10323236} proposed a novel Mixer model to conduct real-time dehazing of 4K images. In addition to the above methods, AODNet~\cite{li2017all} can also achieve the dehazing of 4K images in real-time. It is worth noting that the way of dividing the patches is not suitable for the image-dehazing task, it can suffer from the grid effect~\cite{zheng2021ultra}.



\noindent \textbf{HDR enhancement.}
%
HDRNet~\cite{gharbi2017deep} is a very well-known network that enhances a UHD degraded image in real-time.
%
HDRNet introduces bilateral filters to deep learning to reconstruct degraded images of arbitrary resolution.
%
Later, Zheng et al.~\cite{zheng2021ultra1} improved the algorithm to make it more efficient in reconstructing a low dynamic range UHD image.
%
Currently, a large number of algorithms~\cite{yao2023bidirectional,zhang2023multi} are focused on solving the problem of UHD HDR video.
%
In addition, exposure correction on UHD images is also a concern~\cite{zhou20234k,wang2021real,liu20234d,zeng2020learning,yang2022adaint,zhang2022dualbln,yang2022seplut,jiang2023meflut,wang2023lgabl}.


\noindent \textbf{Low light image enhancement.}
%
The enhancement of UHD low-light images begins with~\cite{lin2022uhd}, which employs a bilateral learning approach to enhance a dim image.
%
Subsequently, a large number of methods and benchmarks have been proposed for UHD low-light image enhancement.
%
For example, wang et al.~\cite{wang2023ultra} propose a Transformer-based approach to spatial domains.
%
Li et al.~\cite{li2023embedding} propose to solve the problem of contrast degradation of UHD images in the frequency domain.
%

\noindent \textbf{Underwater image enhancement.}
%
Wei et al.~\cite{wei2022uhd} propose a two-domain learning method to enhance the visibility of underwater images. Jiang et al.~\cite{jiang2023five} propose a lightweight network that can run a UHD water image on a single GPU.

\noindent \textbf{Image super-resolution.}
%
Zhang et al.~\cite{zhang2021benchmarking} first propose a benchmark for 4K image super-resolution.
%
Currently, this task has seen the emergence of a professional competition to evaluate the performance of 4K image super-resolution algorithms~\cite{zamfir2023towards,conde2023efficient,gankhuyag2023lightweight}.
	
	
\noindent \textbf{Denoising and demosaicing.}
%
Guan et al.~\cite{guan2022memory} propose a convolution with a memory architecture to achieve the denoising of UHD images.
%
Yu et al.~\cite{yu2022towards} have accomplished the demosaicing of 4K images.

\noindent \textbf{Image deblurring.}
%
Zheng et al.~\cite{zheng2022uhd} propose for the first time an algorithm for deblurring UHD images in real-time.
%
In addition, there is an algorithm~\cite{deng2021multi} for deblurring UHD videos.

\noindent \textbf{Others.}
%
4K image matting~\cite{sun2023ultrahigh}, inpainting~\cite{schrader2023efficient}, UDC~\cite{luo2022under,zhengimage} is also starting to come into its own.


\section{Method}
%
Up to now, the processing methods for UHD images are mainly categorized into 3 groups, bilateral learning~\cite{zheng2021ultra,gharbi2017deep,zheng2021ultra1,wang2023lgabl,lin2022uhd,xu2023direction,xia2020joint,xu2021bilateral,zhou20234k}, LUT~\cite{yang2022seplut,jiang2023meflut,zhang2022dualbln,yang2022adaint,liu20234d,wang2021real,li2022mulut,jo2021practical}, and pyramid~\cite{xiao2024single,jiang2023five,liang2021high}.
%
As shown in Figure~\ref{fig:fig1}, overall, all of the above methods require downsampling the UHD image and feeding it into a model of higher complexity to learn an attention-like tensor.
%
Finally, this tensor is upsampled (bilinear interpolation or subpixel convolution) to the same resolution as the original image acting on the original input signal.
%
It is worth noting that the model can run in real-time thanks to the low flops rather than the optimization of the operators.
%


	
%\section{Method}
%
%Specifically, we start by downsampling the input image $\mathbf{I}$ to a fixed resolution of $128 \times 128$ ($\mathbf{I_{l}}$).
%
%Specifically we conduct a U-SNN on input image $\mathbf{I}$ to yield a feature map $\mathbf{F}$.
%
%This feature map $\mathbf{F}$ is then fed into a U-shaped network that has a basic unit based on spikingjelly (\url{https://github.com/fangwei123456/spikingjelly}).
%
%Finally, the output of this network is upsampled to the resolution of the raw image after making a residual with $\mathbf{I}$ and conducting a $nn.PixelShuffle(2)$ or $nn.PixelShuffle(4)$ .
%
%Notably, the feature maps $\mathbf{F_sam}$ obtained from the SAM are fused with the original images $\mathbf{I}$ and fed into the network.
%It is worth noting that our input image is 5-dimensional information that performs a multi-step pattern.


%
%\vspace{-2mm}
%\section{Dataset}
%
%Our dataset uses a Redmi phone to record outdoor scenes and a total of 2000 4k resolution clips are generated.
%
%The low-resolution images are obtained by implementing 2000 clips downsampling and JPEG compression.
%

\vspace{-0mm}
\begin{figure*}[h]
	\centering%	
	\includegraphics[width=0.945\textwidth]{framess1.png}
	\caption{\textbf{A flow diagram of popular UHD image enhancement algorithms}. It is worth noting that some tensors may be splashed in using human a priori knowledge, such as the LUT model. Some tensors are progressively upsampled such as the pyramid model. In general, none of the existing methods can avoid the paradigm where the input image is downsampled.}
	\label{fig:fig1}
	\vspace{-0mm}
\end{figure*}


\section{Discussion and Future Work}
%
So far, tasks such as image de-rain, image de-reflection, and image de-dropping have not been addressed.
%
This may be due to the difficulty in constructing the dataset.
%
In this paper, we note that there are 3 hard to overcome problems with existing UHD image enhancement tasks.
%
1) The training process of pairs of UHD images inevitably requires downsampling of the images, which can result in the trained model receiving ``knowledge'' that may differ from the real 4K images.
%
2) For now, common convolutional and MLP operators are not tailor-made to address UHD image enhancement efficiently.
%
3) UHD synthetic datasets are expensive to build, for example, dehazing 10,000 pairs of 4K images takes 1 week of rendering on a single GPU.
%

In the future, one of the first issues we will address is to change the learning paradigm shown in Figure~\ref{fig:fig1}.
%
This is due to the inevitable loss of information that comes with downsampled images.
%
Second, facing this single hyperscale example, we may need to refer to some fine-tuning scheme of the larger model to alleviate this problem.
%
Predictably, UHD images are a worthwhile direction to think about in the field of image enhancement.
%


%\vspace{-2mm}
%\section{Discussion}
%To compute clearer edge information, we introduce CNN (tail end of the network) in the process of network inference.
%
%In addition, we will implement the algorithm in the RK3855J dev board to meet the needs of embedded development.

\bibliography{4KSR}

\end{document}




















%% bare_conf.tex
%% V1.4
%% 2012/12/27
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex,
%%                    bare_jrnl_transmag.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
%\documentclass[conference]{IEEEtran}
\documentclass[letterpaper, 10 pt, conference]{ieeeconf} 
% Add the compsoc option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}

%\overrideIEEEmargins



% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.


%
% \usepackage{amssymb}
% \usepackage[thmmarks]{ntheorem}
% \theoremheaderfont{\bfseries}
% \theorembodyfont{\normalfont}
% \theoremseparator{:}
% \theoremsymbol{$\blacksquare$}
%\newenvironment{IEEEproof}{\paragraph{IEEEproof:}}{\hfill$\square$}

% \newtheorem*{IEEEproof}{IEEEproof}

\let\proof\relax   
\let\endproof\relax


\usepackage{amsthm}



% *** CITATION PACKAGES ***
%
\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.


%\usepackage{enumitem}



% % *** GRAPHICS RELATED PACKAGES ***
% %
% \ifCLASSINFOpdf
%    \usepackage[pdftex]{graphicx}
%   % declare the path(s) where your graphic files are
%   % \graphicspath{{../pdf/}{../jpeg/}}
%   % and their extensions so you won't have to specify these with
%   % every instance of \includegraphics
%   % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
% \else
%   % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
%   % will default to the driver specified in the system graphics.cfg if no
%   % driver is specified.
%    \usepackage[dvips]{graphicx}
%   % declare the path(s) where your graphic files are
%   % \graphicspath{{../eps/}}
%   % and their extensions so you won't have to specify these with
%   % every instance of \includegraphics
%   % \DeclareGraphicsExtensions{.eps}
% \fi
% % graphicx was written by David Carlisle and Sebastian Rahtz. It is
% % required if you want graphics, photos, etc. graphicx.sty is already
% % installed on most LaTeX systems. The latest version and documentation
% % can be obtained at: 
% % http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% % Another good source of documentation is "Using Imported Graphics in
% % LaTeX2e" by Keith Reckdahl which can be found at:
% % http://www.ctan.org/tex-archive/info/epslatex/
% %
% % latex, and pdflatex in dvi mode, support graphics in encapsulated
% % postscript (.eps) format. pdflatex in pdf mode supports graphics
% % in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% % that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% % not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% % which can result in "jaggedy"/blurry rendering of lines and letters as
% % well as large increases in file sizes.
% %
% % You can find documentation about the pdfTeX application at:
% % http://www.tug.org/applications/pdftex
% 
% 

%usepackage{IEEEtrantools}

% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{breqn}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Do not use the stfloats baselinefloat ability as IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/dblfloatfix/




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/url/
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )

\usepackage[inline]{trackchanges}
%\usepackage[footnotes]{trackchanges}
%\usepackage[margins]{trackchanges}
%\usepackage[finalnew]{trackchanges}


%\usepackage{flushend}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}


\addeditor{swanand}
\addeditor{alex}
\addeditor{brenden}
\addeditor{salim}
\newcommand\alex[1]{\add[alex]{#1}}
\newcommand\alexn[1]{\notee[alex]{#1}}
\newcommand\alexr[1]{\remove[alex]{#1}}
\newcommand\salim[1]{\add[salim]{#1}}
\newcommand\salimn[1]{\notee[salim]{#1}}
\newcommand\swanand[1]{\notee[swanand]{#1}}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{amsfonts, amssymb, amscd, xspace}
%\usepackage{IEEEtrantools}

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{color}
\usepackage{graphicx}
\usepackage{epstopdf}

\usepackage{xfrac}


\setcounter{MaxMatrixCols}{28}


% Theorem/Definition/Lemma Declarations
\newtheorem{mds_privacy}{MDS Solution Satisfies Privacy Constraint}
\newtheorem{partition_privacy}{Paritioning Queries Satisfy Privacy Constraint}
\newtheorem{partition_mds_trans}{Partitioning Queries Transmissions at most as many as MDS Solution}
\newtheorem{dec_trans_by_one}{Lemma: After First Client At Least One Transmission is Redundant}
\newtheorem{mult_client_trans}{Upper Bound on the Number of Transmissions for Partitioning Query Solution for Multiple Clients}
\newtheorem{scen2_privacy}{Privacy Constraint for Scenario II}
\newtheorem{scen2_privacy_matrix}{Privacy Constraint for Scenario II Transmission Matrix}
\newtheorem{linear_optimality}{Partitioning Query is Optimal over Linear Codes in One-Client Case}

%%%%%%% Anoosheh

%%%%%%%%%% Swanand Macros
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{construction}{Construction}
\newtheorem{property}{Property}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{fact}{Fact}
%\newtheorem{IEEEproof}{Proof}

\newcommand{\Sset}{\mathcal{S}}

\newcommand{\etal}{{\it et al.}}
\newcommand{\ie}{{\it i.e.}}
\newcommand{\eg}{{\it e.g.}}

\newcommand{\wi}[1]{w_{#1}} % w_i
\newcommand{\si}[1]{s_{#1}} % s_i
\newcommand{\Wi}[1]{W_{#1}} % W_i
\newcommand{\Si}[1]{S_{#1}} % S_i
\newcommand{\Sw}[1]{S_{#1}} % S_w
\newcommand{\Xj}[1]{X_{#1}} % X_i

\newcommand{\Q}[2]{Q^{[#1, #2]}} % Q^[w,s]
\newcommand{\A}[2]{A^{[#1,#2]}} % A^[w,s]

\newcommand{\Hp}[1]{H\left(#1\right)} % H(.)
\newcommand{\Hc}[2]{H\left(#1 \mid #2\right)} % H(.|.)
\newcommand{\I}[2]{I\left(#1\: ; \: #2\right)} %I(. ; .)

\newcommand{\rank}{\textrm{rank}}
\newcommand{\twomatrix}[2]{\begin{bmatrix} #1 \\ #2\end{bmatrix}}

\newcommand{\Z}{\mathbb{Z}} %Set of integers
\newcommand{\Zp}{\mathbb{Z}^{+}} %Set of positive integers
\newcommand{\GF}[1]{\mathbb{F}_{#1}} % Galois field

\newcommand{\code}{\mathcal{C}} % Code C
\newcommand{\dual}{\mathcal{C}^{\perp}} % Dual code C
\newcommand{\codeproj}[1]{\mathcal{C}\mid_{#1}} % Projected Code C |_S

\newcommand{\codepts}{C} % Code points C
\newcommand{\codeptsj}[1]{C_{#1}} % Subset of code points C_j
\newcommand{\codeptsinfoj}{I_{j}} % Subset of info points I_j

\newcommand{\codep}{\mathcal{C}^{'}} % Code C'
\newcommand{\codeptsp}{C^{'}} % Code points C'

\newcommand{\vect}[1]{\mathbf{#1}} %vector 
\newcommand{\cw}{\mathbf{c}} %vector c
\newcommand{\cwt}{\tilde{\mathbf{c}}} %vector c_tilde

\newcommand{\supp}[1]{\textsf{Supp}\left(#1\right)} % support
\newcommand{\wt}[1]{\textsf{wt}\left(#1\right)} % wt
\newcommand{\wtc}[1]{\textsf{wt}_c\left(#1\right)} %crisscross weight
\newcommand{\dims}[1]{\textsf{dim}\left(#1\right)} % dimension
\newcommand{\loc}[1]{\textsf{Loc}\left(#1\right)} % locality
\newcommand{\rnk}[1]{\textsf{rank}\left(#1\right)} % rank
\newcommand{\modulo}[1]{\:\: \textsf{mod}\left(#1\right)} % rank

\newcommand{\rep}[2]{{R}_{#1}\left(#2\right)} % repair group
\newcommand{\gam}[1]{\Gamma\left(#1\right)} % repair group + c_i
\newcommand{\repcw}[2]{\tilde{\cw}_{#1,#2}} % repair c/w
\newcommand{\Hm}[1]{H^{#1}} % H^i
\newcommand{\subspace}[1]{\langle #1 \rangle} % < . >
\newcommand{\dualpo}{\dual_{1:7}} % C_{1:7}
\newcommand{\dualpt}{\dual_{8:14}} % C_{8:14}

\newcommand{\nkd}{(n,k,d)} % (n,k,d)
\newcommand{\nkdq}{[n,k,d]_q} % [n,k,d]_q
\newcommand{\dc}{\times} % don't care 'x'
\newcommand{\ri}{r_i} % r_i
\newcommand{\cwi}{\vect{c}_i} % c_i
\newcommand{\cwl}{\vect{c}_l} % c_l
\newcommand{\cwset}[1]{\vect{c}_{#1}} % c_{T}


\newcommand{\ceillr}[1]{\left\lceil#1\right\rceil} % left ceil, right ceil
\newcommand{\floorlr}[1]{\left\lfloor#1\right\rfloor} % left ceil, right ceil
\newcommand{\setS}{S} % subset S
\newcommand{\setT}{T} % subset T
\newcommand{\setSi}[1]{\setS_{#1}} % subset S_i
\newcommand{\setTi}[1]{\setT_{#1}} % subset T_i

\newcommand{\lj}[1]{l_{#1}} % l_j
\newcommand{\kj}[1]{k_{#1}} % k_j
\newcommand{\ktj}[1]{\tilde{k}_{#1}} % \tilde{k}_j
\newcommand{\bj}[1]{\beta_{#1}} % beta_j
\newcommand{\gj}[1]{\gamma_{#1}} % gamma_j
\newcommand{\xq}[2]{{#1}^{[#2]}} % {x}^[i]

\newcommand{\ra}{r_a} % r_a
\newcommand{\setSp}{S^{'}} % subset S'
\newcommand{\setP}{P} % set P
\newcommand{\setPpartition}{\mathcal{P}} % set P

\newcommand{\GFm}[1]{\mathbb{F}_{{#1}^m}} % Galois field extension q^m
\newcommand{\GFnm}[1]{\mathbb{F}_{#1}^{N\times m}} % Galois field extension q^{M x m}
\newcommand{\GFmn}[1]{\mathbb{F}_{#1}^{m\times n}} % Galois field extension q^{m x n}
\newcommand{\GFext}[2]{\mathbb{F}_{{#1}^{#2}}} % Galois field extension q^{}

\newcommand{\basis}[1]{\mathcal{#1}} % Basis {}

\newcommand{\al}[1]{\alpha_{#1}} %\alpha_{}
\newcommand{\be}[1]{\beta_{#1}} %\beta_{}

\newcommand{\dr}[1]{d_R\left(#1\right)} % rank distance
\newcommand{\dm}[1]{d_{min}\left(#1\right)} % min distance
\newcommand{\degq}[1]{\textsf{deg}_q\left(#1\right)} % q-degree

\newcommand{\m}{\vect{m}} % message m
\newcommand{\mij}[1]{\vect{m}_{#1}} % message m_{ij}
\newcommand{\eij}[1]{e_{#1}} % erasures e_{ij}
\newcommand{\wij}{\omega_{ij}} % message a_ij
\newcommand{\cwG}{\mathbf{c}_{\textrm{Gab}}} %vector c_{Gab}
\newcommand{\cwGj}[1]{\mathbf{c}_{\textrm{Gab}}^{#1}} %vector c_{Gab}^j

\newcommand{\codeLRC}{\code_{\textrm{LRC}}} % C_LRC



\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}


\renewcommand{\baselinestretch}{1.015}

\renewcommand{\qedsymbol}{$\blacksquare$}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
% Do not put math or special symbols in the title.
\title{\LARGE \bf
Private Information Retrieval with Side Information}

\IEEEoverridecommandlockouts

\begin{document}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
%\author{{}}



% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
\author{Swanand Kadhe, Brenden Garcia, Anoosheh Heidarzadeh, Salim El Rouayheb,  and
 Alex Sprintson}

% \author{\IEEEauthorblockN{Swanand Kadhe\IEEEauthorrefmark{1},
% Brenden Garcia\IEEEauthorrefmark{1},
% Anoosheh Heidarzadeh\IEEEauthorrefmark{1},
% Salim El Rouayheb\IEEEauthorrefmark{2}, and
% Alex Sprintson\IEEEauthorrefmark{1}}
% \IEEEauthorblockA{\IEEEauthorrefmark{1}%Department of Electrical and Computer Engineering\\
% Texas A\&M University,
% College Station, TX} %\\ Email: TBD}
% \IEEEauthorblockA{\IEEEauthorrefmark{2}Illinois Institute of Technology, Chicago, IL\\
% %Email:  salim@iit.edu
% \vspace{-1.5em}}}%\thanks{The work of S. El Rouayheb  was supported in part by NSF Grant CCF 1652867.}}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
%\boldmath
\begin{abstract}
We study  the problem of Private Information Retrieval (PIR) in the presence of prior side information. The problem setup includes a database of  $K$ independent messages possibly replicated on several servers, and a user that needs to retrieve one of these messages. In addition, the user has some prior side information in the form of a subset of  $M$ messages, not containing the desired message and unknown to the servers. This problem is motivated by practical settings in which the user can obtain side information  opportunistically from other users or has   previously downloaded some messages using classical PIR schemes. The objective of the user is to retrieve the required message without revealing its identity while minimizing the amount of data downloaded from the servers.  

We focus on achieving information-theoretic privacy in  two  scenarios: (i) the user wants to protect jointly its demand and side information; (ii) the user wants to protect only the information  about its demand, but not the side information. To highlight the role of side information, we focus first on the case of a single server (single database). In the first scenario, we prove that the minimum  download cost is $K-M$ messages, and in the second scenario it is  $\lceil \frac{K}{M+1}\rceil$ messages, which should be compared to $K$ messages, the minimum download cost in the case of no side information. Then, we extend  some of our  results to the case of the database replicated on  multiple servers.  
% In a nutshell, the  savings brought by the side information in the second scenario is equivalent to a reduction of the database size by a factor roughly equal to the size of side information (from $K$ to $\frac{K}{M+1}$). 
Our proof techniques relate  PIR  with side information to the    index coding problem. We leverage this connection  to prove converse results, as well as to design  achievability schemes. 
% To highlight the role of side information, we focus first on the case of a single server and  distinguish between two scenarios: (i) the user wants to protect jointly its demand and side information; (ii) the user wants to protect only the information  about its demand. In the first scenario, we prove that the minimum  download cost is $K-M$ messages, and in the second it is  $\lceil \frac{K}{M+1}\rceil$, which should be compared to $K$ messages, the minimum download cost in the case of no side information.   Our proof techniques relate  PIR  with side information to the    index coding problem. We leverage this connection  to prove converse results, as well as   achievability schemes. \notee[brenden]{Do we add that we mention multiple servers in the abstract now as well?}
% \salim{I will fix this once we finalize the multiple server section.} 
 
 
%  We focus on the problem of Private Information Retrieval (PIR) in the presence of prior side information. The problem setup includes a database that stores a set of $K$ independent messages $X$ and a client that needs to retrieve a message from $X$. In addition, the client has some prior side information about a different set of messages in $X$. The objective of the client is to retrieve the required message from the database without revealing its identity while minimizing the rate of data transmission from the database.  This problem can arise in practical settings in which the client was able to obtain the side information about some of the messages in $X$ through prior communication rounds, by communicating with other clients, passive eavesdropping, or other means. 
 
%  We focus on the setting with a single server, {and consider the following two scenarios: (i) the user wants to protect the information only about their demand; (ii) the user wants to protect their demand and side information  jointly. We establish the capacity of the PIR in both cases.} Our proof techniques are based on the key observation that the problem at hand can be reduced to the problem of constructing an instance of the Index Coding problem of minimum rate. This reduction can be used to prove the converse results as well as to construct the achievability scheme. 
 
 
%\remove[brenden]{ We also consider settings in which
 %the identity of the transmitted message as well as the side information set need to be protected.}
 %
 %
 % Our IEEEproof techniques include partition-based algorithms that enable to apply existing PIR algorithms (such as due to Jafar \etal) to the settings with side information.
 %
 % We also establish the connection of PIR problem with the Index Coding problem and use this connection to prove the converse.
 %
 %
	
% We consider the problem of Private Information Retrieval (PIR) in settings in which a client has prior side information about the data. In this problem a client needs to retrieve a packet or a set of packets from the server or multiple server without revealing the identity of the  packets and with minimum number of transmissions. We show that the client's side information can be leveraged to minimize the number of transmissions that need to be made by the server. We consider several variations of the problem that include the settings with a single client, multiple clients as well the case of multiple servers. For each variation, we establish matching upper and lower bounds on the number of transmissions. Our IEEEproof techniques include partition-based algorithms that leverage existing results for private information retrieval (due to Jafar \etal). We also establish the connection of PIR problem with the Index Coding problem and use this connection to establish lower bounds.
\end{abstract}




\blfootnote{Swanand Kadhe, Brenden Garcia, Anoosheh Heidarzadeh, and Alex Sprintson are with the Department of Electrical and Computer Engineering at Texas A\&M University, USA; emails:\{swanand.kadhe,brendengarcia,anoosheh,spalex\}@tamu.edu. 

Salim El Rouayheb is with ECE Department  at Rutgers University, email: sye8@soe.rutgers.edu. Part of this work was done while he was with the ECE department at the Illinois Institute of Technology.


 The work of S. El Rouayheb  was supported in part by NSF Grant CCF 1652867 and ARL Grant W911NF-17-1-0032.}


\section{Introduction}
\label{sec:intro}
% \salim{comments on first paragraph: I think we should agree on the nomenclature: is it user or client? Is he/she retrieving packets or files?  databases or servers or both? Also I think citing Christina's work here is not appropriate. I'm not sure it is even PIR. We should cite the original work by sundan et al. and refer to survery papers in the CS commmunity then say there is recent growing interst in PIR for coded information and cite. Also, we should talk about IT PIR vs computational PIR since we want to highlight PIR with single server later.
% I can do that but Need help including the bib file i sent by email.}



Consider the following Private Information Retrieval (PIR) setting first studied in \cite{Chor:PIR1995,chor1998private}:  a user  wishes to privately download  a message belonging to a database with copies stored on a single or   multiple remote servers, without revealing which message it is requesting. 
In a straightforward PIR scheme, the user would  download all the messages in  the database. This scheme may not be feasible due to the its high communication cost. In the case of a single server (i.e., there is only one copy of the database),  it can be shown that downloading  the whole database is necessary to achieve perfect privacy in an information-theoretic sense. If computational (cryptographic) privacy is desired, then PIR schemes with lower communication overhead do exist \cite{kushilevitz1997replication, cPIRPoly}, but they do not offer information-theoretic privacy guarantees and usually have high computational complexity. In contrast, in this paper, we design and analyze schemes that achieve information-theoretic privacy.



Interestingly, more efficient PIR schemes, achieving perfect  information-theoretic privacy,  can be constructed when the database is replicated on multiple servers with restriction on the servers' collusion.
%restriction is placed on the servers' collusion.
 This replication-based model  has been the one that is predominantly studied in the PIR literature, with  breakthrough results in the past few years 
 (e.g., \cite{sun2016capacitynoncol, sun2016capacity, yekhanin2010private, beimel2001information, beimel2002breaking,gasarch2004survey}). 
Recently, there has been a renewed  interest in  PIR for the case in which the data is  stored on the servers using erasure codes, which result in  better storage overhead compared to the traditional replication techniques \cite{shah2014one, chan2014private, tajeddine2016private, extended, banawan2016capacity, fazeli2015pir, blackburn2016pir, freij2016private}. 






% In recent years, the Private Information Retrieval (PIR) problem has attracted a significant interest from the information-theoretic community \cite{Karmoose2017,Sun2017} \alexn{Brenden - do we need to cite more papers?} In PIR problem, a client needs to retrieve a packet or a set of packets from one or more information servers such that each server will not be able to determine the identity of the packets requested requested by the client. The main objective of this problem is to minimize the total amount of information that needs to be downloaded from the servers. 
% %
% Sun et al. \cite{Sun2017} identified the maximum rate achievable for the classical PIR problem and present a scheme which can achieve the capacity. 
% %
% \alexn{Should other papers be discussed here?}

%



%A classical problem of study for client privacy is the Private Information Retrieval problem (PIR problem). In PIR there are a number of servers that a client can communicate to retrieve a certain packet that the client wants. In the PIR problem, the goal is for the client to request packets from the servers in a way such that the client retrieves the packet it wants while not revealing which particular packet the client actually wants. 
%
%\alexn{Brenden - we need to summarize the main works in this area. We can start with the works done by the CS communities and then recent works by Jafar et al.}

In this paper, we study the  PIR problem when  the user has  prior side information about the database. In particular, we assume that the user already has a random subset of the database messages that is unknown to the server(s)\footnote{We assume that this side information subset does not contain the desired message. Otherwise, the problem is degenerate.}. This  side information could have been obtained in several ways. For example, the user could have obtained  these messages opportunistically from other users in its network,  overheard them from a wireless broadcast channel, or downloaded them previously through classical PIR schemes. The next example illustrates how this side information could be leveraged to devise efficient  PIR schemes. In particular, 
the following example shows that perfect information-theoretic privacy can be achieved with  a single server case without having to download the entire database.


\begin{example}[single-server  PIR with side information]\label{ex:intro}
Consider a remote server that has a database formed of  an even number of binary messages  denoted by $X_1,\dots,X_K$ of equal length.  A user wants to download one of these messages from the server without revealing to the server which one. Moreover, the user has one  message as side information chosen uniformly at random among all the other messages and unknown to the server. We propose two PIR schemes that leverage the side information  and compare them to the straightforward scheme that downloads all the $K$ messages.
\begin{enumerate}
% \item{\em Straightforward PIR} scheme downloads all the $k$ files. Here, the user does not leverage its side information to retrieve its desired file.

\item{\em Maximum Distance Separable (MDS) PIR scheme.} This scheme downloads $K-1$ messages. The user sends to the server the number of messages in its side information  (one in this example). The server responds by coding all the messages using a $(2K-1,K)$ systematic MDS code and 
sending  the $K-1$ parity symbols of the code. Therefore, the user can always decode all the messages using its side information and the coded messages received from the server.

\item{\em Partition and Code PIR scheme.} This scheme downloads $K/2$ messages. Suppose the message the user wants is $X_W$ and the one in its side information is $X_S$ for some $W,S \in\{1,\dots,K\}$, $W\neq S$. The user chooses  a random partition of $\{1,\dots,K\}$ formed only of sets of size $2$ and containing $\{W,S\}$, and sends indices of all pairs in the partition to the server. The server sends back the XOR of the messages indexed by each subset. For example, suppose  $W=1$ and  $S=2$, i.e, the user wants $X_1$ and has $X_2$ as side information.  The user chooses a random partition $\{\{i_1,i_2\},\{i_3,i_4\},\dots,\{i_{K-1},i_K\}\}$ and sends it to the server. The partition is chosen such that $\{1,2\}$ is a part of the partition (i.e., $i_j=1$ and $i_{j+1}=2$ for some $j\in\{1,3,\dots,K-1\}$. 
% \alexn{this does not look like a random partition} \notee[brenden]{Although this doesn't look like a random partition, it is hard to describe a random partition of K elements (when K isn't an actual number) without losing some clarity. I think this is fine as is, if the later examples show more random partitions.} 
The server responds with $X_{i_1}+X_{i_2},\dots, X_{i_{K-1}}+X_{i_K}$. The user can always decode because it always receives $X_W+X_S$. Intuitively, perfect privacy is achieved here because the index of the desired message can be in any subset of the partition, and in each subset it could be either one of messages in the subset, since the server does not know the index of the side information. \hfill\rule{1.3ex}{1.3ex}
 \end{enumerate}
 \end{example}
We will show later that the two schemes above are optimal but achieve different privacy constraints. The MDS PIR scheme protects both the indices of the desired message and that of the side information, whereas the Partition and Code scheme protects only the former.



\subsection{Our Contributions}
\label{sec:contributions}
We consider the PIR with side information problem as illustrated in  Example~\ref{ex:intro}. A user wishes to download a message from a set of $K$ messages that belong to a database stored on a single remote server or replicated on several {\em non-colluding} servers. 
% %} \alexn{I think it is misleading to talk about multiple servers in the contribution section since we assume that the servers do not collude.} 
% \notee[brenden]{With the addition of the Multi-Server section we should mention it, but I think later on separated from this part in this contributions section}\swanand{Done.} 
The user has  a random subset of $M$ messages as side information. The identity of the messages in this subset is unknown to the server. We focus on PIR schemes that achieve information-theoretic privacy. The figure of merit that we consider for  the PIR schemes is the download rate, which dominates the total communication rate (download plus upload) for large message sizes. Under this setting, we distinguish between two types of privacy constraints: (i) hiding both the  identity of the requested message and that of  the side information from the server; and (ii) hiding only the identity of the desired message. The latter, and  less stringent, privacy constraint is justified when the side information is obtained opportunistically given that  it is random and assumed to be independent of the user's request. In the case in which  the side information messages were  obtained previously through PIR, this constraint implies that the identity of these messages may be leaked to the server(s). However, this type of privacy can still be relevant when privacy is only desired for a certain duration of time, i.e., when the user is  ambivalent about protecting the identity of messages downloaded as long as it has happened far enough in the past.  

First, we focus on the  single server scenario as the canonical case to understand the role of side information in PIR. We  characterize the   capacity of PIR with side information in the case of a single server for the two privacy constraints mentioned above. We show that when protecting both the side information and the request, the minimum download rate\footnote{The download rate is defined as the inverse of the normalized download cost.} for PIR is $(K-M)^{-1}$, and this can be achieved by a generalization of the MDS PIR scheme in Example~\ref{ex:intro}. Moreover, we show that when only protecting the request, the minimum download rate is $\lceil \frac{K}{M+1}\rceil^{-1}$, and this can be achieved by a generalization of the Partition and Code PIR scheme in Example~\ref{ex:intro}. We present achievability and converse proofs that use among others connections to index coding. Second, we tackle the case of $N>1$  servers storing replicas of the database. In this case, when $(M+1)\mid K$, we devise a PIR scheme with side information that achieves a download rate equal to  $$\left(1 + \frac{1}{N} + \cdots + \frac{1}{N^{\frac{K}{M+1}-1}}\right)^{-1}.$$ Our scheme for the multiple servers uses ideas from the single server scheme in conjunction with the scheme due to Sun and Jafar \cite{sun2016capacitynoncol} for settings with no side information.


% \notee[brenden]{Add description of what was addded as pertaining to multiple servers here}\salim{I will fix this once we finalize the multiple server section.}

%Multiple servers??? \notee[brenden]{Remember to remove this or keep it depending on whether or not we do the multiple servers example}


\subsection{Related Work} \label{sec:related-work}
The initial work on PIR in \cite{Chor:PIR1995,chor1998private} and in the literature that followed  focused on  designing PIR schemes for replicated data that have   efficient  communication cost accounting  for  both the size of the user queries and the servers' responses. PIR schemes with communication cost that is subpolynomial in the number of messages were devised in \cite{beimel2002breaking} and \cite{dvir20162}. Information-theoretic bounds on the download rate (servers' responses) and achievable schemes were  devised in \cite{sun2016capacitynoncol} and \cite{sun2016capacity}. 
Recently, there has been   a growing body of work studying   PIR for coded data motivated by lower overhead of codes
 \cite{shah2014one, chan2014private, tajeddine2016private, extended, banawan2016capacity, fazeli2015pir, blackburn2016pir, freij2016private,tajeddine2017private1,tajeddine2017private2}.

The role of side information in improving PIR schemes has so far received little attention in the literature. The closest work to ours is the concurrent work  of Tandon \cite{Tandon2017} in which the capacity of  {cache-aided PIR} is characterized. The main difference with the model in \cite{Tandon2017} is our assumption that the indices of the side information messages are unknown to  the servers, as is the case in the scenarios mentioned above. This lack of knowledge at the servers can be leveraged to reduce the communication cost of PIR even in the case of a single server. We also restrict our study to side information that is subset of the data, whereas the cache model in \cite{Tandon2017} allows any function of the data.  Another related line of work is that of {private broadcasting} by Karmoose et al.\cite{Karmoose2017}, which considers the index coding setting with multiple users with side information and a single server. Here too, the server does know the content of the side information at the users. Moreover, the privacy constraint  is to protect the request and side information of a user from the other users through a carefully designed encoding matrix. In contrast, the goal of our scheme is to protect the identity of the requested data from the server. We also note that the case in which the side information is unknown at the server was also considered in the index coding literature under the name of  {blind index coding} \cite{kao2017blind}. However, the goal there was to minimize the broadcast rate without privacy constraints. 
%\alexn{Did they derive lower bounds on the capacity?}

% Ravi's Work Differences:
% \begin{itemize}
% \item Side information of the client was known publicly to the server; our assumption is that the server just knows the size of the side information
% \begin{itemize}
% 	\item May want to say that in this case, just telling the server the clients side information will leak information about possible want set. I.e. a reason we don't just use his scheme.
% \end{itemize}
% \item Side information is allowed to be a function of the messages in the server, not exact replicas like in our scenario
% \end{itemize}

% Salim: Will continue this later.
% Christina's Work Differences:
% \begin{itemize}
% \item Their work focused on protecting privacy against another client taking part in the index coding scheme; the server wasn't the adversary.
% \item Focused more on how Encoding Matricies could leak information about to clients about clients.
% \end{itemize}


% In \cite{Karmoose2017} \notee[brenden]{Christina's work} the authors explore the PIR with side information problem but through the lens of protecting the privacy of a client from another client in the system. In their model, the server knows all the information of the clients and the goal is to design an encoding matrix such that no or minimal information about a particular client is leaked to the others. This is different from the situation considered in this paper, as in this paper the server knows nothing a priori about the clients, other than the a priori probability distributions of the clients' want and side information sets. 

% In \cite{Banawan2017} \notee[brenden]{Work by Sennur Ulukus and Karim Banawan that covers multi-message PIR. Might consider removing paragraph if we don't cover multi-message retrieval in paper} Multi-Message PIR is discussed. The authors derive the capacity of Multi-Message PIR in certain situations and derive bounds for the capacity in complementing situations. Namely, the authors prove that obtaining the packets jointly, rather than obtaining them individually in the way described in \cite{Sun2017}. The authors describe a scheme that modifies the scheme in \cite{Sun2017} to use MDS coding with downloaded side information to achieve capacity or be within the capacity bounds respectfully. Our work looks at retrieving numbers of packets with already present side information. As in \cite{Sun2017} the side information used in the work has to be downloaded from the servers first. 





%%%%



\section{Problem Formulation and Main Results}
\label{sec:basics}
%\notee[anoosheh]{Need to define $[m]$ for any integer $m$; and need to define $X_1^K$, not even sure we need this notation.}

For a positive integer $K$, denote $\{1,\dots,K\}$ by $[K]$. % \notee[Salim]{Don't you think it's more common to use lower case to denote constant integers.}. 
For a set $\{X_1,\dots,X_K\}$ and a subset $S\subset {[K]}$, let \mbox{$X_S = \{X_j : j\in S\}$}. For a subset $S \subset [K]$, let $\mathbf{1}_S$ denote the characteristic vector of the set $S$, which is a binary vector of length $K$ such that, for all $j\in[K]$, its $j$-th entry is $1$ if $j\in S$, otherwise it is $0$. Let $\GF{q}$ denote the finite field of order 
$q$. %that is indexed from 1 to K and has 1's in the indicies given by the set S, and 0's elsewhere.

We assume that the database consists of a set of $K$ messages $X = \{\Xj{1}, \dots,\Xj{K}\}$, with each message being independently and uniformly distributed over $\GF{2^t}$ (i.e., each message $X_j$ is $t$ bits long). %\alex{message is $t$ bits long and distributed uniformly} . %\notee[brenden]{Should we mention that t is the length? or number of bits of the messages} \alexn{addressed that.}%(Each message $X_i$ is a string of $t$ bits, and hence $H(X_i) = t$.) 
%Thus, we have 
% \begin{IEEEeqnarray}{rCl}
% \label{eq:equal-entropy}
% \Hp{\Xj{1}} & = & \Hp{\Xj{2}} = \cdots = \Hp{\Xj{K}}\\
% %\end{equation}
% %\begin{equation}
% \label{eq:indep-X}
% \Hp{\Xj{1}^K} & = & \sum_{i = 1}^{K}\Hp{\Xj{i}}.
% \end{IEEEeqnarray}
% \notee[anoosheh]{Given (1), one can simplify (2)}
We also assume that there are $N\geq 1$ non-colluding servers %\salimn{we should update this for multiple servers. Right?} databases, 
which store identical copies of the $K$ messages.

%\footnote{Our main focus in this paper is on the case $N \geq 1$.} %The messages are replicated across $N$ databases, with each database storing all the $K$ messages. 

A user is interested in downloading a message $X_W$ for some $W\in [K]$. We refer to $W$ as the \emph{demand index} and $X_W$ as the demand. %\notee[brenden]{demand 'set' or just demand?} 
The user has the knowledge of a subset $X_S$ of the messages %of size $M$ ($M<K$) 
for some $S\subset [K]$, $|S| = M$, $M<K$. %messages indexed by the set $S \subset [K]\setminus\{W\}$. %, \ie, the user has the messages $X_S = \{X_j: j\in S\}$. 
We refer to $S$ as the \emph{side information index set} and $X_S$ %interchangeably 
as the \emph{side information}. 
%The user wants to download a message indexed by $W \in [K]$ {\it privately} without leaking any information about $W$ to any of the databases. We refer to $W$ as \emph{demand}. 

%The demand set $W$ and the side information set $S$ are realizations of two random variables, denoted respectively as 
Let $\mathbf{W}$ and $\mathbf{S}$ denote the random variables corresponding to the demand index and the side information index set. %, distributed jointly as $(\mathbf{W},\mathbf{S}) \sim p_{\mathbf{W},\mathbf{S}}(W,S)$. 
We restrict our attention to the class of distributions $p_{\mathbf{W}}(\cdot)$ of $\mathbf{W}$ such that $p_{\mathbf{W}}(W) > 0$ for every $W\in[K]$.

An important distribution of $\mathbf{W}$ and $\mathbf{S}$ that we focus on in this work is as follows. Let the demand index $W$ be distributed uniformly over $[K]$, i.e., 
\begin{equation}
\label{eq:WantSetDist}
p_{\mathbf{W}}(W) = \frac{1}{K},
\end{equation} for all $W\in [K]$.
Further, let the side information index set $S$ have the following conditional distribution given $W$: %  of size $M$ is distributed conditionally on the demand $W$ and uniformly over $[K]\setminus \{W\}$, i.e., 
\begin{equation}\label{eq:SideInfoDist}
p_{\mathbf{S}|\mathbf{W}}(S|W) = \left\{
\begin{array}{ll}
\frac{1}{\binom{K-1}{M}}, & \textrm{if}\:\:W\not\in S \:\: \textrm{and}\:\: |S| = M,\\
0, & \textrm{otherwise}.\\
\end{array}
\right.
\end{equation}
% \begin{equation}
% \label{eq:SideInfoDist}
% p_{\mathbf{S}|\mathbf{W}}(S|W)=\frac{1}{\binom{K-1}{M}},
% \end{equation} 
% for all $W\in [K]$ and all $S\subset [K]\setminus \{W\}$, $|S| = M$. 
We note that this implies  the following joint distribution on $(\mathbf{W},\mathbf{S})$: %, referred to as the ``symmetric distribution'':
\begin{equation}\label{eq:dist}
p_{\mathbf{W},\mathbf{S}}(W,S) = \left\{
\begin{array}{ll}
\frac{1}{(K-M)\binom{K}{M}}, & W\not\in S,|S| = M,\\
0, & \textrm{otherwise}.\\
\end{array}
\right.
\end{equation}
We assume that the servers do not know the side information realization at the user and only know the  {\it a priori} distributions 
$p_{\mathbf{W}}(W)$
 and $p_{\mathbf{S}|\mathbf{W}}(S|W)$.

% \notee[brenden]{Should we add that the server also the a priori distributions of $W$ and $S|W$ as well?}

To download the message $\Xj{W}$ given the side information $\Xj{S}$, the user sends a query $\Q{W}{S}_j$ from an alphabet $\mathcal{Q}$ to the $j$-th server. 
%\alexn{We do not define the query formally. This is fine, but we might need to discuss this. Also, we might need to say what we are ignoring the number of bits in the query.}
%
The $j$-th server responds to the query it receives with an answer $\A{W}{S}_j$ over an alphabet $\mathcal{A}$. We refer to the set of queries and  answers as the {\it PIR with side information (PIR-SI) scheme}. Our focus in this paper is on non-interactive  (single round) schemes. Further, we assume that the servers do not collude with each other. A PIR-SI scheme should satisfy the following requirements.


\begin{itemize}
	\item[1.]  For every $j\in[N]$, 
    the query $\Q{W}{S}_j$ to the server $j$ 
    is a (potentially stochastic) function of $W$, $S$, and $\Xj{S}$. We assume that the answer from the server
is a deterministic function of the query and the messages, i.e.,
\begin{equation}
\label{eq:answer}
\Hc{\A{W}{S}_j}{\Q{W}{S}_j,\Xj{1}, \Xj{2}, \cdots, \Xj{K}} = 0,
\end{equation} for all $W\in [K]$, $S\subseteq[K]\setminus\{W\}$, and $j\in[N]$. 

\item[2.] From the answers $A^{[W,S]}_1,\dots,A^{[W,S]}_N$ 
and the side information $X_S$, the user should be able to decode the desired message $X_W$, i.e.,
\begin{equation}
\label{eq:decodability}
\Hc{\Xj{W}}{\A{W}{S}_1, \cdots , \A{W}{S}_N ,\Xj{S}} = 0,
\end{equation} for all $W\in [K]$, $S\subseteq[K]\setminus\{W\}$.
 
\item[3.]  The PIR-SI scheme should guarantee privacy for the user by ensuring one of the following two  conditions, referred to as  $W$-privacy and $(W,S)$-privacy as defined below. %We consider two different privacy requirements as follows:
% \begin{itemize}
% \item[(i)]   $W$-\textbf{privacy}: A database cannot infer any information about the demand from the query and the answer, %the queries preserve the privacy of the demand $W$, 
% i.e., for all $j\in[N]$, we have
% \begin{equation}
% \label{eq:privacy}
% \I{\mathbf{W}}{\Q{\mathbf{W}}{\mathbf{S}}_j,\A{\mathbf{W}}{\mathbf{S}}_j,\Xj{1}, \Xj{2},\cdots,\Xj{K}} = 0.
% \end{equation} 
% \item[(ii)] $(W,S)$-\textbf{privacy}: A database cannot infer any information about the demand as well as the side information set from the query and the answer,
% %the queries preserve the privacy of the demand $W$ and the side information $S$, 
% i.e., for all $j\in[N]$, we have
% \begin{equation}
% \label{eq:privacy2}
% \I{\mathbf{W},\mathbf{S}}{\Q{\mathbf{W}}{\mathbf{S}}_j,\A{\mathbf{W}}{\mathbf{S}}_j,\Xj{1},\Xj{2},\cdots,\Xj{K}} = 0.
% \end{equation}
% \end{itemize} %We refer to the privacy requirements (i) and (ii) as $W$-privacy and $(W,S)$-privacy, respectively. 

\begin{definition}
$W$-\textbf{privacy}: Any server cannot infer any information about the demand index from the query, answer, and messages %the queries preserve the privacy of the demand $W$, 
i.e., for all $j\in[N]$, we have
\begin{equation}
\label{eq:privacy}
\I{\mathbf{W}}{\Q{\mathbf{W}}{\mathbf{S}}_j,\A{\mathbf{W}}{\mathbf{S}}_j,\Xj{1}, \Xj{2},\cdots,\Xj{K}} = 0.
\end{equation} 
\end{definition}

\begin{definition}
$(W,S)$-\textbf{privacy}: Any server cannot infer any information about the demand index as well as the side information index set from the query, answer, and messages
%the queries preserve the privacy of the demand $W$ and the side information $S$, 
i.e., for all $j\in[N]$, we have
\begin{equation}
\label{eq:privacy2}
\I{\mathbf{W},\mathbf{S}}{\Q{\mathbf{W}}{\mathbf{S}}_j,\A{\mathbf{W}}{\mathbf{S}}_j,\Xj{1},\Xj{2},\cdots,\Xj{K}} = 0.
\end{equation}
\end{definition}



We refer to a PIR-SI scheme preserving $W$-privacy or $(W,S)$-privacy as $W$-PIR-SI or $(W,S)$-PIR-SI scheme, respectively. 
\end{itemize}

%For any given set of queries preserving $W$-privacy or $(W,S)$-privacy, 
The \emph{rate} of a a PIR-SI scheme is defined as the ratio of the message length ($t$ bits) to the total length of the answers (in bits) as follows:\footnote{Note that the download rate dominates the total communication rate for large enough messages.}
\begin{equation}
\label{eq:rate}
R = \frac{t}{\sum_{j=1}^{N}\Hp{\A{W}{S}_j}}.
\end{equation}
The \emph{capacity} of $W$-PIR-SI or $(W,S)$-PIR-SI problem, respectively denoted by $C_{W}$ or $C_{W,S}$, is defined as the supremum  of rates over all $W$-PIR-SI or $(W,S)$-PIR-SI schemes for a given $N$, $K$, and $M$, respectively. 

% \notee[brenden]{Should we mention why we only care about the entropy of the Answers here? i.e. why download cost is emphasized but not upload cost?}\swanand{Added a footnote.}



%%%%% Brenden's model: To be included for the achievable partitioning scheme

% In the scenario considered there is a server that has a set of $n$ packets $X=\{x_1,x_2,...,x_n\}$. There is one client in the problem.

% The client in the problem has an index of a packet that it wants from the server $W\in[n]$ and a set that indexes the packets in the client's side information $S=\{S_1,S_2,...,S_k\}\subseteq[n]\setminus W$. The want index and the side information in the problem are distributed with a certain distribution and are Random Variables. For this particular scenario it is assumed that the want index is distributed as shown in Equation \ref{eq:WantSetDist} where $w\in[n]$, and the Side Information is defined conditioned on the want index, as given in Equation \ref{eq:SideInfoDist}; for completeness the joint distribution is given in Equation \ref{eq:WantAndSideJointDist}.

% \begin{equation}
% \label{eq:WantSetDist}
% p_{W}(w)=\frac{1}{n};\;w\in[n]
% \end{equation}

% \begin{equation}
% \label{eq:SideInfoDist}
% p_{S|W}(\{s_1,s_2,...,s_k\}|w)=\frac{1}{\binom{n-1}{k}};\;s_i,w\in[n]\forall i\;and\\ \;s_1,s_2,...,s_k,w\;distinct
% \end{equation}

% \begin{equation}
% \label{eq:WantAndSideJointDist}
% p_{S,W}(\{s_1,s_2,...,s_k\},w)=\frac{1}{\binom{n}{k+1}};\;s_i,w\in[n]\forall i\;and\\ \; s_1,s_2,...,s_k,w\;distinct
% \end{equation}

% In the set-up the client sends a set of queries to the server for the server to satisfy. The queries that the client sends to the server are denoted as the set $Q=\{Q_1,Q_2,...,Q_t\};t\in \mathbb{N}$.

% The notation $x_{\{i_1,i_2,...,i_k\}}$ denotes a packet of the form $x=\sum_{j=1}^{k}\alpha_{j}x_{i_j};\alpha_j \neq 0\; \forall j$. The notation $x_{A}$ is similar and denotes a packet of the form $x=\sum_{j\in A}\alpha_{j}x_{j};\alpha_j \neq 0\; \forall j$.

% The privacy constraint for the Index Coding-PIR problem is that the mutual information between the want set of the client and the queries that the client sends is 0; knowing the query of the client does not reveal any more information about the want index of the client to the server that the server doesn't know a priori. This constraint is denoted $I(W;Q)=0$. It should be noted that in the scenarios considered the server knows the size of each clients side information. 

% \section{Main Theorems}

\section{Main Results}
First, we summarize our main results for single server case in Theorems \ref{thm:single-server-PIR} and~\ref{thm:single-server-PIR2}, which characterize the capacity  $W$-PIR-SI and   $(W,S)$-PIR-SI, respectively. 
\begin{theorem}
\label{thm:single-server-PIR}
For the $W$-PIR-SI problem with $N=1$ server, $K$ messages, and side information size $M$, when the demand index $\mathbf{W}$ and the side information index set $\mathbf{S}$ are jointly distributed according to~\eqref{eq:dist}, %(conditionally on $\mathbf{W}$) are respectively distributed according to~\eqref{eq:WantSetDist} and~\eqref{eq:SideInfoDist}, 
the capacity is
\begin{equation}
\label{eq:capacity-partition}
C_{W} = \left\lceil \frac{K}{M+1}\right\rceil^{-1}.
\end{equation}
\end{theorem}


Our proof for Theorem~\ref{thm:single-server-PIR} is based on two parts. We prove the converse in Section~\ref{sec:converse-partitioning} for any joint  distribution of $(\mathbf{W,S})$. Then, we construct an achievability scheme in Section~\ref{sec:achievability-partitioning} for the distribution given in~\eqref{eq:dist}. %uniform distribution.

% More generally, for the $W$-PIR-SI problem with $N=1$ database, $K$ messages, and size information size $M$, regardless of the joint distribution of the side information set and the demand, we  show that the capacity $C_W$ is upper bounded by $\left\lceil K / (M+1) \right\rceil^{-1}$ (see the proof of the converse part in Section~\ref{sec:converse-partitioning}). For the special case of the uniform distribution, we  show that this upper bound is also achievable (see the proof of the achievability part in Section~\ref{sec:achievability-partitioning}).  

\begin{theorem}
\label{thm:single-server-PIR2}
For the $(W,S)$-PIR-SI problem with $N=1$ server storing $K$ messages %, and side information size $M$, 
and for any arbitrary joint distribution of the demand index $\mathbf{W}$ and the side information index set $\mathbf{S}$ such that the size of $\mathbf{S}$ is equal to $M$, the capacity is 
\begin{equation}
\label{eq:capacity-mds}
C_{W,S} = (K-M)^{-1}.
\end{equation}
\end{theorem}
%\alexn{We might need to add a discussion here of Theorem 2}


First, we  show that the capacity $C_{W,S}$ of the $(W,S)$-PIR-SI problem with $N = 1$ server, $K$ messages, and size information size $M$ is upper bounded by $(K-M)^{-1}$ for any  joint distribution of the side information index set and the demand index (see %the proof of the converse part in 
Section~\ref{sec:converse-mds}). Further, we  construct a  scheme based on maximum distance separable (MDS) codes, which achieves this bound for any arbitrary joint distribution of $(\mathbf{W},\mathbf{S})$ such that the size of $\mathbf{S}$ is equal to $M$ (see Section~\ref{sec:achievability-mds}).  

Next, we state our main result for multiple servers storing replicas of the database, which gives a lower bound on the capacity of $W$-PIR-SI problem based on an achievability scheme.
\begin{theorem}
\label{thm:multi-server-PIR}
For the $W$-PIR-SI problem with $N$ servers, each storing $K$ messages, and side information size $M$ such that $(M+1)\mid K$, when the demand index $\mathbf{W}$ and the side information index set $\mathbf{S}$ are jointly distributed according to~\eqref{eq:dist}, %(conditionally on $\mathbf{W}$) are respectively distributed according to~\eqref{eq:WantSetDist} and~\eqref{eq:SideInfoDist}, 
the capacity is lower bounded as
\begin{equation}
\label{eq:capacity-partition}
C_{W} \geq \left(1 + \frac{1}{N} + \cdots + \frac{1}{N^{\frac{K}{M+1}-1}}\right)^{-1}.
\end{equation}
\end{theorem}
%Our proof is constructive. 
Our PIR scheme %is a modification of 
builds up on the scheme in~\cite{sun2016capacitynoncol}, which is for the case of no side-information.

\section{$W$-Privacy Problem}
\label{sec:IEEEproofs}

%For the single-database case $(N = 1)$, we drop the subscript from the query and the answer, and denote them as $\Q{W}{S}$ and $\A{W}{S}$ for any given demand $W$ and side information set $S$, respectively.

Our converse proofs for Theorems~\ref{thm:single-server-PIR} and~\ref{thm:single-server-PIR2} in the single-server case use the following simple yet powerful observation. %\notee[brenden]{If this was a sentence you were going to add, it looks good to me to add}

\begin{proposition}
\label{prop:necessity}
Let $\A{W}{S}$ be an answer from the server that  satisfies the decodability requirement ~\eqref{eq:decodability} and the $W$-privacy requirement~\eqref{eq:privacy}. Then, the following two conditions hold:
\begin{enumerate}
\item For each message $X_i, i=1,\dots, K,$ there exists a subset  $\Xj{S_i}\subseteq\{\Xj{1},\cdots,\Xj{K}\} \setminus \Xj{i}$, with $|\Xj{S_i}| = M $, and a decoding function $D_{i}$ satisfying $D_i\left(\A{W}{S},\Xj{S_i}\right) = X_i$.
\item There exists a function $D_W$ such that $D_W\left(\A{W}{S},\Xj{S}\right) = X_W$. 
\end{enumerate}
\end{proposition}
\begin{proof}
The first condition is implied by the $W$-privacy requirement. Indeed, if this was not the case, then the server would know that message $X_i$ is not one of the messages requested by the user which, in turn, would violate the $W$-privacy condition (\ref{eq:privacy}). Note that the first condition holds under the assumption that $\mathbf{W}$ has a distribution such that $p_{\mathbf{W}}(W) > 0$ $\forall W\in[K]$.  

The second condition is implied by the decodability requirement.
\end{proof}

%Our converse proofs for Theorems~\ref{thm:single-server-PIR} and~\ref{thm:single-server-PIR2} in the single-server case build up on 
The above proposition enables us to show a relation of the PIR-SI problem with an instance of index coding with side information problem~\cite{BarYossef:IT:11,effros2015equivalence,el2010index}. We begin with briefly reviewing the index coding problem.   

\subsection{Index Coding problem}

% Our converse IEEEproofs for Theorems~\ref{thm:single-server-PIR} and~\ref{thm:single-server-PIR2}

%\textbf{Index coding problem:}
Consider a server with $K$ messages $\Xj{1},\cdots, \Xj{K}$ of length $t$ with $\Xj{j}\in\{0,1\}^t$. Consider $L$ clients $R_1, \cdots, R_L$, $L\geq K$, where for each $i$, $R_i$ is interested in one message, denoted by $\Xj{f(i)}\in \{\Xj{i}\}$, and knows some subset $\Xj{S_i} \subset \{\Xj{i}\}$ of the other messages, referred to as its side information. %Every client $R_i$ knows a subset of messages indexed by $S_i\subseteq[K]\setminus\{i\}$, referred to as its side information. 
%An index code of length $\ell$ is a binary code of block-length $\ell$ which enables client $i$ to decode $\Xj{f(i)}$ for any $i$ and $[\Xj{1},\cdots, \Xj{K}] \in \{0,1\}^{tK}$.

An index code of length $\ell$ for this setting is a set of codewords in $\{0,1\}^{\ell}$ together with an encoding function $E:\{0,1\}^{tK} \rightarrow \{0,1\}^{\ell}$, and a set of $L$ decoding functions $D_1, \cdots, D_L$ such that $D_i\left(E\left(X_1,\cdots,X_K\right),X_{S_i}\right) = \Xj{f(i)}$ for all $i\in[L]$ and $[X_1, \cdots, X_K] \in \{0,1\}^{tK}$. We refer to $E\left(X_1,\cdots,X_K\right)$ as a {\it solution} to the instance of the index coding problem. 


When $L = K$ and every client requires a distinct message, the side information of all the clients can be represented 
by a simple directed graph $G = \left(V,E\right)$, where $V = \{1,2,\cdots,K\}$ with the  vertex $i$ corresponding to the message $\Xj{i}$, and there is an arc $(i,j)\in E$ if $j \in S_i$. %client $R_i$ contains message $\Xj{j}$ in its side information. 
 We denote the out-neighbors of a vertex $i$ as $\mathcal{N}(i)$.

For a given instance of the index coding problem, the minimum encoding length $\ell$ as a function of message-length $t$ is denoted as $\beta_t$, and the {\it broadcast rate} is defined as in ~\cite{Alon:FOCS:08, Blasiak:IT:13}
\begin{equation}
\label{eq:broadcast-rate}
\beta = \inf_t \frac{\beta_t}{t} 
\end{equation}

% \salimn{I think betat/t is the broadcast rate. inf betat/t is the capacity.}\swanand{Capacity is defined as the inverse of broadcast rate according to Younh-Han Kim's papers.}

\subsection{Converse for Theorem~\ref{thm:single-server-PIR}}
%\subsection{IEEEproof of Theorem~\ref{thm:single-server-PIR}}
%\label{sec:IEEEproofs}
%
%\subsubsection{Converse}
\label{sec:converse-partitioning}
%The converse IEEEproof is built up on the following observation. In order to ensure $W$-privacy, %the answer $\A{\mathbf{W}}{\mathbf{S}}$ should satisfy the following necessary condition that. Intuitively, 
%one should be able to decode every message $\Xj{j}$ using the answer $\A{\mathbf{W}}{\mathbf{S}}$ and some side information $S$ of size $M$ such that $j\notin S$. If certain message cannot be decoded in this way, then that message is ruled out as a possibility for the demand, which leaks information about the demand.
%Our main idea for the 


The key step of the converse is to show that for any  scheme that satisfies the $W$-privacy constraint (\ref{eq:privacy}), the answer from the server must be a solution to an instance of the index coding problem that satisfies certain requirements as specified in the following lemma.


%The IEEEproof of the converse for one client follows a couple of steps. First a necessary condition on an index coding solution that maintains the privacy condition is stated and shown; a generalization of the condition is made; these classes of index coding solutions are then translated into the language of graphs by the side information graphs of particular index coding instances; a lower bound on the Maximum Acyclic Induced Subgraph (MAIS) of the possible side information graphs is given, giving a lower bound for the length of an index coding solution; then an achievable scheme is that meets the bound is shown for a particular distribution, demonstrating tightness.

%Because there is one client in the scenario considered, the client can send the server the exact transmissions that it wants the server to send. This simplifies the analysis as the client can send the requested index coding solution to the server, and the privacy is then based on the index coding solution.

%A necessary condition on a solution to the one server-one client scenario considers whether or not each packet contained in the server can be decoded with some appropriatly sized set of side information, given the solution. If there was some packet in the solution that could not be decoded with any appropriately sized side information set, then that packet could be ruled out as a possibility for a wanted packet, which leaks information on the want set of the client. This intuition is formalized below.

%Now, we specify a necessary condition that a response from the database  must satisfy for any $W$-private scheme.

% \begin{lemma}
% A necessary condition for an index coding solution that satisfies the privacy constraint $I(W;Q^{[W,S]},A^{[W,S]},X_1,X_2,...,X_K)=0$ is the following:

% In a solution I, it must hold that $\forall i \in [K]$, each $X_i$ must have some set of side information $S_i \subseteq \{X_1,X_2,...,X_K\} \setminus \{X_i\}$ with $|S_i| \leq M$ such that $X_i$ can be decoded with I and $S_i$. 
% \end{lemma}
% \begin{IEEEproof}
% Suppose that a solution I has some $i\in [K]$ such that $X_i$ cannot be decoded by some $S_i$ with $|S_i| \leq M$, then clearly the client could not have wanted that packet, as the client is assumed to have side information of size M, so the server knows that $W \neq i$ making $p_{W|Q}(i|A)=0$ making the the query and want set dependent.

% \end{IEEEproof}
% \swanand{The lemma below is an attempt to formalize the lemma above. Is the lemma below too formal?}



\begin{lemma}
\label{lem:necessary-condition}
% For a $W$-private scheme, for any demand $W$ and side information set $S$, the answer $\A{W}{S}$ from the database must be a codeword of an  index code 
% for a side information graph $G$ such that $\mathcal{N}(W) = S$ and the out-degree of every vertex in $G$ is $M$.
For a $W$-PIR-SI scheme, for any demand index $W$ and side information index set $S$, the answer $\A{W}{S}$ from the server must be a solution to an instance of the index coding problem that satisfies the following requirements:
\begin{enumerate}
	\item The instance has the messages  $X_1, \cdots, X_K$;
	\item  There are $K$ clients such that each client wants to decode a distinct message from $X_1, \cdots, X_K$, and possesses a side information that includes $M$ messages;
	\item  The client that wants $X_W$ has the side information set $X_S$; for each other client the side information set has $M$ arbitrary messages from $X_1, \cdots, X_K$.
\end{enumerate}
%
%
% a codeword of an index code for the following problem. There are $K$ clients such that each client wants to decode a distinct message from $X_1, \cdots, X_K$, and each client possesses a side information of some other $M$ messages. In addition, the client interested in $X_W$ has the side information $X_S$.
\end{lemma}

\begin{proof}
% Let $\A{W}{S}$ be an answer from the server that  satisfies the decodability requirement ~\eqref{eq:decodability} and the $W$-privacy requirement~\eqref{eq:privacy}. First, we note that the $W$-privacy requirement implies that for each message $X_i, i=1,\dots, K,$ there exists a subset  $\Xj{S_i}\subseteq\{\Xj{1},\cdots,\Xj{K}\} \setminus \Xj{i}$, with $|\Xj{S_i}| = M $, and a decoding function $D_{i}$ satisfying $D_i\left(\A{W}{S},\Xj{S_i}\right) = X_i$.
% % \salim{Just to eliminate confusion for the readder: What is the range of i? Also $S_W$ is actually $S$.I'd say for all i from 1 to K and i diff then W. and for i = W Si=S...} \notee[brenden]{Check to see if what I added did make it clearer or not}.
% Indeed, if this was not the case, then the server would know that message $X_i$ is not one of the messages requested by the user which, in turn, would violate the $W$-privacy condition (\ref{eq:privacy}). Second, we note that the decodability requirement implies that there exists a function $D_W$ such that $D_W\left(\A{W}{S},\Xj{S}\right) = X_W$. 

The sets $\Xj{S_i}$ mentioned in Proposition~\ref{prop:necessity} can be used to construct the following instance of the Index Coding problem.  The instance has the message set $X_1, \cdots, X_K$ and  $K$ %$=\{1,\dots,K\}$\salimn{You  mean just $K$ or $[K]$. seems that notation is wrong here.} 
clients $\{R_1,\cdots,R_k\}$ such that:
\begin{itemize}
	\item Client $R_W$ requires packet $X_W$ and has the side information set $\Xj{S}$;
	\item Each other client $R_i,\ i\neq W$ requires $X_i$ and has side information set $\Xj{S_i}$.
\end{itemize} 
It is easy to verify that the instance satisfies all the conditions stated in the lemma and that  $\A{W}{S}$ is the feasible index code for this instance.  
% We need to prove that there exists a function $D_W$ such that $D_W\left(\A{W}{S},\Xj{S}\right) = X_W$, and for every $i\ne W$, there exists a set $S_i \subseteq[K]\setminus\{i\}$ of size $M$ such that there exists a subset $\Xj{S_i}\subset\{\Xj{i}\}$ and a function $D_i$ satisfying $D_i\left(\A{W}{S},\Xj{S_i}\right) = X_i$. The first condition follows from the decodability requirement of the scheme given in~\eqref{eq:decodability}, and the second condition follows from the $W$-privacy~\eqref{eq:privacy}.
% We essentially need to prove that, for a $W$-private scheme, one can construct a side information graph $G$ with $\mathcal{N}(W) = S$ and out-degree of every vertex in $G$ equal to $M$ such that there exist a set of $K$ functions $D_1, \cdots, D_K$ such that $D_j\left(\A{W}{S},X_{\mathcal{N}_j}\right) = X_j$ for every $W$, $S$, and $[X_1, \cdots, X_K] \in \{0,1\}^{tK}$.
% Note that for any directed graph on the vertex set $[K]$ with $\mathcal{N}(W) = S$, there exists a function $D_W$ such that $D_W\left(\A{W}{S},\Xj{\mathcal{N}(W)}\right) = X_W$ due to the decodability of the scheme, see~\eqref{eq:decodability}. Now, suppose, for the contradiction, that there exists a message $X_i$, $i\ne W$ such that one cannot find a decoding function $D_i$ for any side information graph with our-degree $M$. This implies that no user with a side information of $M$ messages can decode a message $X_i$ from $\A{W}{S}$. This rules out $i$ as a candidate for $W$ from the perspective of the database, thus leaking some information about $W$. This contradicts that the answer $\A{W}{S}$ is generated by a $W$-private scheme. 
\end{proof}


% The necessary condition can be generalized to mention side information sets of a constant size.

% \begin{corollary}
% \label{cor:gen_nec_cond}
% A necessary condition for an index coding solution that satisfies the privacy constraint $I(W;Q^{[W,S]},A^{[W,S]},X_1,X_2,...,X_K)=0$ is the following:

% In a solution I, it must hold that $\forall i \in [K]$, each $X_i$ must have some set of side information $S_i \subseteq \{X_1,X_2,...,X_K\} \setminus \{X_i\}$ with $|S_i| = M$ such that $X_i$ can be decoded with I and $S_i$.
% \end{corollary}
% \begin{IEEEproof}
% The IEEEproof of the necessity for privacy is the same with the added logic. 

% If there exists an $i \in [K]$ such that the corresponding $S_i$ that allows $X_i$ to be decoded has size $|S_i| < M$, indices can be added arbitrarily to these sets to make their cardinality k. Add $\alpha := M - |S_i|$ indices to $|S_i|$; add indices $\{j_1,...,j_{\alpha}\} \subseteq [K] \setminus S_i \cup \{i\}$ to $S_i$. This will not affect decodability of packet $X_i$; already have $H(X_i|I,S_i)=0$, $H(X_i|A,S_i,X_{j_1},...X_{j_{\alpha}}) \leq H(X_i|A,S_i)=0$, implying entropy is still 0.
% \end{IEEEproof}

% Given an instance of the single server-single client PIR with side information, a partially determined index coding solution that satisfies the necessary condition for privacy can be identified.

% Assume without loss of generality, by relabeling packets, that the client in the original PIR problem wants packet 1, and has side information of size M identified as $S_1 = \{2,3,...,M+1\}$. The partially determined Index Coding problem can be described in the following way. 
% \begin{itemize}
% \item There are K clients $\{c_1,c_2,...,c_K\}$
% \item Client $c_1$ represents the original client in the PIR problem.
% 	\begin{itemize}
%     \item Wants packet 1; $w_1=1$
%     \item Has Side Information $S_1 = \{ 2, 3, ..., M+1\}$
%     \end{itemize}
% \item Clients $c_i;i\in \{2,3,...,K\}$ represent some virtual clients
% 	\begin{itemize}
%     \item Wants packet i; $w_i = i$
%     \item Has an undetermined set of side information. However it is known that $|S_i|=M$
%     \end{itemize}
% \end{itemize}

% From this partially determined Index Coding problem instance a number of Index Coding instances can be considered, by considering all possibilities for the $S_i$'s $i \in \{2,3,...,K\}$. An index coding solution to these possible instances satisfy the necessary condition for privacy. Let $\mathcal{I}$ be the set representing the possible Index Coding instances for the partially determined Index Coding problem.

% For each possible instance in $\mathcal{I}$, there exists a side information graph that can be constructed, in which each node represents a want set and a demand of a client and each node has an out-edge connecting it to each node indexed in its side information set. It is noted that each node in this graph has out-degree of M. Let $\mathcal{G}$ denote all possible side information graphs induced by the possible index coding instances in $\mathcal{I}$.

% \notee[brenden]{Add Citation for MAIS Lower Bound and possibly Side information graph}

Note that Lemma~\ref{lem:necessary-condition} shows that the answer $\A{W}{S}$ from the server must be a solution to an instance of the index coding problem in which the out-degree of every vertex in the corresponding side information graph $G$ is equal to $M$. %side information graph $G$ such that out-degree of every vertex in $G$ is $M$.
Next, we lower bound the broadcast rate for an index coding problem with side information graph $G$ such that out-degree of every vertex in $G$ is $M$ as follows.

%It is a known bound that given an instance of an index coding problem and the problems side information graph, a lower bound to the size of the index coding solution, L, is given by the size of the maximum acyclic induced subgraph of the problems side information graph.

%In other words if G is the side information graph for a given index coding problem, then L is bounded by:
% \begin{equation}
% |MAIS(G)|\leq L
% \end{equation}

% Then if we consider an instance of the single server-single client PIR problem, we can lower bound the length of a solution by looking at the side information graphs pertaining to the possible index coding scenarios produced by the instance:

% \begin{equation}
% \label{eq:GenLowBound}
% \min_{G\in \mathcal{G}}(|MAIS(G)|) \leq L
% \end{equation}

\begin{lemma}
\label{lem:mais-lower-bound}
Let  $G$ be a directed graph on $K$ vertices such that each vertex has out-degree $M$. Then, the broadcast rate of the corresponding instance of the index coding problem is lower bounded by $\lceil \frac{K}{M+1} \rceil$.
\end{lemma}
\begin{proof}
For any side information graph $G$, the broadcast rate $\beta$ is lower bounded by the size of the maximum acyclic induced subgraph (MAIS) of $G$, denoted as $MAIS(G)$~\cite{Alon:FOCS:08,Arbabjolfae:17}.

We show that for any graph $G$ that satisfies the conditions of the lemma (i.e., the out-degree of each of the $K$ vertices of $G$ is $M$) it holds that 
$$MAIS(G)\geq \left\lceil \frac{K}{M+1} \right\rceil.$$

%the size of $MAIS(G)$ is at least $\lceil \frac{K}{M+1} \rceil$ when out-degree of each of the $K$ vertices of $G$ is $M$.
%Let G be a directed graph with K verticies (V = \{1,...,K\}) and with each vertex having out-degree M. 

Specifically, we build an acyclic subgraph of $G$ induced by set $Z$ through the following procedure:

%Then an acyclic subgraph, induced by a set Z, of G can be formed using the following greedy procedure:

\begin{itemize}
	\item[] \hspace{-0.5cm} \textbf{Step 1.} Set $Z = \emptyset$ and  a  candidate set of vertices $V'=V$;
	\item[] \hspace{-0.5cm} \textbf{Step 2.} Add an arbitrary vertex $i\in V'$ into $Z$, i.e.,\\
$Z = Z \cup \{i\}$;
	\item[] \hspace{-0.5cm} \textbf{Step 3.} Set $V' = V' \setminus (\mathcal{N}(i) \cup \{i\})$;
	\item[] \hspace{-0.5cm} \textbf{Step 4.} There are two cases:
	\begin{itemize}
		\item[] \hspace{-0.5cm}\textbf{Case 1:} If $V' \neq \emptyset$, then repeat Steps 2-4.
		\item[] \hspace{-0.5cm}\textbf{Case 2:} If $V' = \emptyset$, then terminate the procedure and return $Z$.
	\end{itemize}
\end{itemize}

%\textbf{Step 1.} Set a variable $i = 1$, and $Z = \emptyset$. Set a tracking set of vertices $V'=V$.



%\textbf{Step 3a.} Let the set $\bar{V}_i$ represent the verticies adjacent to vertex i on outward paths from i.

%
%
% \textbf{Step 4.} There are two cases:
% \textit{Case 1:} If $V' \neq \emptyset$ then set $i = j$, where $j$ is an arbitrary element in $V'$, and repeat steps 2 - 4.
% \textit{Case 2:} If $V' = \emptyset$ then terminate the procedure, $Z$ is a set that induces an acyclic subgraph of $G$.

It is easy to see that the vertices in set $Z$ returned by the procedure induce an acyclic subgraph of $G$. If the vertices are ordered in the order they are added to $Z$, then there can only be an edge $(i,j)$ if $j$ was added to $Z$ before $i$. This implies that the subgraph induced by $Z$ cannot contain a cycle. 

%vertex, so this graph is acyclic.

Further, note that the set $Z$ contains at least $\lceil \frac{K}{M+1} \rceil$ vertices. At each removal step, there are at most $M+1$ vertices removed from $V$. %; at most M from removing out-degree neighbors, and one from moving the vertex into Z. If $(M+1) | K$, then the procedure iterates at least $\frac{K}{M+1}$ times, as there are at most $M+1$ verticies being removed from V' on every iteration. If $(M+1) \nmid K$ then 
Thus, the procedure iterates at least $\lceil \frac{K}{M+1} \rceil$ times, and in each iteration we add one vertex to $Z$. This implies that the size of $Z$ is at least  $\lceil \frac{K}{M+1} \rceil$.
\end{proof}
%; at most $M+1$ verticies are removed at every stage, leaving at least one vertex left at the $\frac{K}{M+1}$'st iteration. If during an iteration, a vertex being put into the set Z has less than $M$ out-neighbors, then the procedure would iterate more than $\lceil \frac{K}{M+1} \rceil$ times. 

%Because a Maximum Induced Acyclic subgraph can be bigger than this graph, but not smaller, this gives a lower bound on $|MAIS(G)|$.


\begin{corollary}[Converse of Theorem~\ref{thm:single-server-PIR}]
%In the one server-one client PIR with side information problem, where a client wants one packet from the server and has $M$ packets for side information, the number of transmissions required by the server to maintain privacy is lower bounded by $\lceil \frac{K}{M+1} \rceil$
For the $W$-PIR-SI problem with single server, $K$ messages, and side information size $M$, the capacity is at most ${\left\lceil \frac{K}{M+1} \right\rceil}^{-1}$.
\end{corollary}
\begin{proof}
Lemmas~\ref{lem:necessary-condition} and \ref{lem:mais-lower-bound} imply that the length of the answer $A^{[W,S]}$ is at least $t\cdot{\left\lceil \frac{K}{M+1} \right\rceil}$ bits %\salim{bits} 
for any given $W$ and $S$. Then, by \eqref{eq:rate}, it follows that $R\leq  \left\lceil \frac{K}{M+1} \right\rceil^{-1}$. 	
%From Lemma~\ref{lem:necessary-condition},~\eqref{eq:rate}, and~\eqref{eq:broadcast-rate}, we have $R \leq 1/\beta$. Thus, the result follows from Lemma~\ref{lem:mais-lower-bound}.
% Given an instance of the single server-single client described in the hypothesis of the Theorem, we can identify the partially determined Index Coding problems and side information graphs, $\mathcal{I}$ and $\mathcal{G}$ derived above from Corollary \ref{cor:gen_nec_cond}.
% Notice then that a lower bound on the length of an index coding solution is given in \ref{eq:GenLowBound}. Every graph in $\mathcal{G}$ satifies the hypothesis of Lemma \ref{lem:reg_mais_low_bound}, and so the MAIS of any G in $\mathcal{G}$ can be bounded below by $\lceil \frac{K}{M+1} \rceil$.
% Putting this together the IEEEproof is finished by formally stating the chain of inequalities as given below:
% \begin{equation}
% \left \lceil \frac{K}{M+1} \right \rceil \leq \min_{G \in \mathcal{G}}(|MAIS(G)|) \leq L
% \end{equation}
\end{proof}

\subsection{Achievability for Theorem~\ref{thm:single-server-PIR}}
\label{sec:achievability-partitioning}
In this section, we propose a $W$-PIR-SI scheme for $N=1$ server, $K$ messages, and side information size $M$, which achieves the rate $\left\lceil \frac{K}{M+1}\right\rceil^{-1}$.  Recall that we assume that the distribution of the demand index $W$ and the conditional distribution of the side information index set $S$ given $W$ are given respectively in~\eqref{eq:WantSetDist} and~\eqref{eq:SideInfoDist}. %Also, recall that, for a subset $S \subset [K]$, $\mathbf{1}_S$ denotes the characteristic vector of $S$. 
%a the characteristic  vector of $S$ and  of length $K$ such that, for all $j\in[K]$, its $j$-th entry is $1$ if $j\in S$, otherwise it is $0$.\salim{We say recall. Did we mention it before. It's called the characteristic vector of the S if you wanna mention it.}
%the demand $W$ and the side information set $S$ are distributed uniformly, i.e., $p_{\mathbf{W},\mathbf{S}}(W,S)$ is given by \eqref{eq:WantSetDist} and \eqref{eq:SideInfoDist}. % To be more specific %\notee[brenden]{Is this the only way to get the distribution given in (1)},
% we assume that the demand $W$ is distributed uniformly over $[K]$, i.e.,
% \begin{equation}
% \label{eq:WantSetDist}
% p_{\mathbf{W}}(W) = \frac{1}{K},
% \end{equation} for all $W\in [K]$, and the side information set $S$ of size $M$ is distributed conditionally on the demand $W$ and uniformly over $[K]\setminus \{W\}$, i.e.,
% \begin{equation}
% \label{eq:SideInfoDist}
% p_{\mathbf{S}|\mathbf{W}}(S|W)=\frac{1}{\binom{K-1}{M}},
% \end{equation} for all $W\in [K]$ and all $S\subset [K]\setminus \{W\}$, $|S| = M$.
%In the following we consider two different cases as follows: (i) $(M+1) | K$, and (ii) $(M+1) \nmid K$. 
%In order to show an achievable scheme for the W-PIR problem distributions on the want set and side information set, compatible with Equation \ref{eq:dist}  for the client are  assumed. The want set is assumed to be distributed uniformly at random from the available indicies, shown in Equation \ref{eq:WantSetDist}. The side information set is distributed conditionally on the want set, and its distribution is given in Equation \ref{eq:SideInfoDist}. The distributions describe picking a clients want index from the K possible packets in the server uniformly at random, then picking the M side information packets uniformly at random from the remaining M-tuples contained in the server after removing the want index. For simplicity it is assumed also that $(M+1) | K$; a description of the scheme for when $(M+1) \nmid K$ is given later \notee[brenden]{When should it be described}.
We describe the proposed scheme, referred to as the {\it Partition and Code} PIR scheme, in the following. %For simplicity, we first present the scheme when $(M+1) \mid K$, and then consider the case $(M+1)\nmid K$.   


%\notee[brenden]{should we say the user "chooses a partition uniformly at random" or say the user "arbirtrarily partitions" the set} 

{\bf Partition and Code PIR Scheme:} Given $K$, $M$, $W$, and $S$, denote $g\triangleq\left\lceil \frac{K}{M+1} \right\rceil$. The scheme consists of the following three steps.

{\it Step 1.} The user creates a partition of the $K$ messages into $g$ sets. For the ease of understanding, we describe the special case of $(M+1)\mid K$ first. 

(a) Special case of $(M+1)\mid K$: Denote $P_{1}\triangleq W \cup S$. The user randomly partitions the set of messages $[K] \setminus P_{1}$ into $g-1$ sets, each of size $M+1$, denoted as $P_2,\dots,P_{g}$.

(b) General case: %When $(M+1)\nmid K$, the user creates the partition as follows.
Let $P_1,\dots,P_{g}$ be a collection of $g$ empty sets. Note that, although empty at the beginning, once constructed, the sets $P_1,\dots,P_{g-1}$ will be of size $M+1$, and the set $P_g$ will be of size $K - (g-1)(M+1)$.
The user begins by assigning probabilities to the sets according to their sizes: the sets $P_1,\dots,P_{g-1}$ are each assigned a probability $\frac{M+1}{K}$, and the set $P_g$ is assigned a probability $\frac{K - (g-1)(M+1)}{K}$. Then, the user chooses a set randomly according to the assigned probabilities of the sets. 

If the chosen set is a set $P\in \{P_1,\dots,P_{g-1}\}$, then the user fills the set $P$ with the demand index $W$ and the side information index set $S$ of the user. Next, it fills the remaining sets choosing one index at a time from the set of indices of the remaining messages uniformly at random until all the message indices are filled. 

If the chosen set is the set $P_g$, then it fill $P_g$ with the demand index $W$, and fill the remaining \mbox{$K - (g-1)(M+1)-1$} places in the set $P_g$ with randomly chosen elements from the side information index set $S$. (Note that once $P_g$ is filled, it is possible that not all of the indices in the side information index set $S$ are placed in the set.) Next, fill the remaining sets by choosing one index at a time from the set of indices of the unplaced packets uniformly at random until all packet indices are placed. 


{\it Step 2.} The user sends to the server a uniform random permutation of the partition $\{P_1,\cdots,P_g\}$, ie., it sends $\{P_1, \cdots, P_g\}$ in a random order. %Once the sets $P_1,\dots,P_g$ are constructed, the user sends the vectors in the set $\{\mathbf{1}_{P_1},\dots,\mathbf{1}_{P_g}\}$ to the server in a random order as the query $Q^{[W,S]}$.

%\salim{Are we going through all this to construct the partition because the divisibility problem or because fo general prob distributions? if it is divisibility,  to be kind to the reader, I'd start by say inf M+1 divide K we do this ... Otherwise, we do the following construction... if divisibility is not the problem one "Warning" sentence should come first to explain why we are doing what we are doing. Why not a totally random partition would not work.} \notee[brenden]{Could the added paragraphs be checked to see if this may address this comment, and if not, what else might we do to make it easier on the reader?} \remove[brenden]{query $Q^{[W,S]}$ as a random permutation of $\{\mathbf{1}_{P_1},\dots,\mathbf{1}_{P_g}\}$ to the database} \salim{Maybe say that we send the partitions P1 to Pg  and not the vectors bc that is a very inefficient way. We don't care about upload but still.} \notee[brenden]{There was discussion at some point about making our query alphabet binary strings for both cases, which is why we describe them as these vectors. I'm not sure which is the better way to describe the queries though.}\swanand{Agree with Brenden. Also, not clear to me why sending binary vectors is inefficient?}.\salim{bc the way it is done now you can send any g subsets of any size. But we know that these susets have specific size and arwe not independent. It is more efficient to send the actual partition. Meaning suppose you are partitionning the set a b c d into two subsets ad and bc. Just send adbc to the serer and he can parse it out every two symbols together instead what is sent is 1001 and 0110. It's not a big deal but a bit distracting. We do not need to specify the actual coding to send these partitions. I would just say send partitions such and such to the server without saying how we code them.} 

{\it Step 3.} The server computes the answer $\A{W}{S}$ as a set of $g$ inner products given by $\A{W}{S} = \{A_{P_1},\dots,A_{P_{g}}\}$, where $A_P = [X_1,\dots,X_K]\cdot \mathbf{1}_{P}$ for all $P\in \{P_1,\dots,P_{g}\}$.

Upon receiving the answer from the server, the user decodes $X_W$ by subtracting off the contributions of its side information $X_S$ from $A_{P}$ for some $P\in \{P_1,\dots,P_g\}$ such that $W\in P$.

%\textit{Example:} 
\begin{example}
Assume that $K=8$ and $M=2$. Assume that the user demands the message $X_2$ and has two messages $X_4$ and $X_6$ as side information, i.e., $W=2$ and $S=\{4,6\}$. Following the Partition and Code PIR scheme, the user labels three sets as $P_1,P_2,$ and $P_3$, and assigns probability $\frac{3}{8}$ to each of the two sets $P_1$ and $P_2$, and assigns probability $\frac{2}{8}$ to the set $P_3$. Next, the user chooses one of these sets at random according to the assigned probabilities. Assume the user has chosen the set $P_3$. The user then places $2$ into the set $P_3$, and chooses another element from $\{4,6\}$ uniformly at random to place in $P_3$ as well. Say the user chooses $6$ from the set $\{4,6\}$, then the set $P_3$ becomes $P_3 = \{2,6\}$. Then the user fills the other sets $P_1$ and $P_2$ randomly to exhaust the elements from $\{1,2,3,5,7,8\}$. Say the user chooses $P_1 = \{1,7,8\}$ and $P_2 = \{3,4,5\}$. Then the user sends to the server a random permutation of $\{\mathbf{1}_{P_1},\mathbf{1}_{P_2},\mathbf{1}_{P_3}\}$ as the query $Q^{[2,\{4,6\}]}$. The server sends three coded packets back to the user: $Y_1 = X_1 + X_7 + X_8$, $Y_2 = X_3 + X_4 + X_5$, and $Y_3 = X_2 + X_6$. The user can decode for $X_2$ by computing $X_2 = Y_3 - X_6$. From the server's perspective the user's demand is in either $\{1,7,8\}$ or $\{3,4,5\}$ with probability $\frac{3}{8}$ each, or in $\{2,6\}$ with probability $\frac{2}{8}$. The probability $P_1$ (or $P_2$) contains $W$ is $\frac{1}{3}$, and the probability that $P_3$ contains $W$ is $\frac{1}{2}$. In either case, it follows that $\mathbb{P}(\mathbf{W}=W|Q^{[1,\{2,3\}]})=\frac{1}{8}=p_{\mathbf{W}}(W)$. 
\end{example}
%\hfill\rule{1.3ex}{1.3ex}

%Given the demand $W$ and the side information set $S$, let $P^{*}\triangleq W \cup S$, and let $g\triangleq\frac{K}{M+1}$. To generate the query, the user first chooses a partition of $\{X_1,X_2,...,X_K\} \setminus P^{*}$ uniformly at random over all the partitions consisting of $g - 1$ sets of size $M+1$ each. 
%randomly partitions the set of packets  into $g-1$ sets, each of size $M+1$. Denote the sets of this partition by $P_1,\dots,P_{g-1}$. Then, the query $\Q{W}{S}$ is defined as a random permutation of $\{\mathbf{1}_{P^{*}}, \mathbf{1}_{P_{1}},...,\mathbf{1}_{P_{g-1}}\}$. %, where $\{i_1, i_2, \cdots, i_g\}$ is a random permutation of $\{0,1, \cdots, g-1\}$. %the user sends the query $Q^{[W,S]}$ \alex{which is a random permutation of vectors in }$\{\mathbf{1}_{P^{*}},\mathbf{1}_{P_1},\mathbf{1}_{P_2},...,\mathbf{1}_{P_{g-1}}\}$. % \notee[brenden]{Does it need to be stated that the packets need to permuted, or does the set notation of the query imply that they are sent unordered?} \notee[brenden]{Should these queries be appended if they are bit strings? How should these queries be formatted}.
%The database computes the answer $\A{W}{S}$ as a set of $g$ inner products given by $\A{W}{S} = \{A_{P^{*}}, A_{P_1},\dots,A_{P_{g-1}}\}$, where $A_P = [X_1,\dots,X_K]\cdot \mathbf{1}_{P}$ for all $P\in \{P^{*},P_1,\dots,P_{g-1}\}$. %between each binary vector $\mathbf{1}_P$ given by the query and the vector of packets $[X_1,...,X_K]$, and sends $A_P = [X_1,\dots,X_K]\cdot \mathbf{1}_P$ to the user. 
%Note that the user can decode for the packet $X_W$ it demands by subtracting off the contributions of its side information $X_S$ from $A_{P^{*}} = [X_1,\dots,X_K]\cdot\mathbf{1}_{P^{*}}$.  %We refer to this scheme as the \emph{Partition and Code PIR scheme}. 

%{\bf Partition and Code PIR Scheme:} First, the scheme starts by having the user \notee[brenden]{should we say the user "chooses a partition uniformly at random" or say the user "arbirtrarily partitions" the set} randomly partition the set of packets $\{X_1,X_2,...,X_K\} \setminus C$ into $g-1$ sets, each of size $M+1$. Denote these partitions by $P_1,\dots,P_{g-1}$. Then the user sends the query $Q^{[W,S]}=\{\mathbf{1}_C,\mathbf{1}_{P_1},\mathbf{1}_{P_2},...,\mathbf{1}_{P_{g-1}}\}$ \notee[brenden]{Does it need to be stated that the packets need to permuted, or does the set notation of the query imply that they are sent unordered?} \notee[brenden]{Should these queries be appended if they are bit strings? How should these queries be formatted}. Next, the server takes the inner product between each binary vector $\mathbf{1}_P$ given by the query and the vector of packets $[X_1,...,X_K]$, and sends $A_P = [X_1,\dots,X_K]\cdot \mathbf{1}_P$ to the user. Note that the user can decode for the packet $X_W$ it demands by subtracting off the contributions of its side information $X_S$ from $A_{C} = [X_1,\dots,X_K]\cdot\mathbf{1}_{C}$. We refer to this scheme as the \emph{partition and code scheme}. 


%In addition to the MDS coding solution to the Index Coding-PIR problem, there is another scheme that can achieve the privacy of the want index of the clients as well. To simplify analysis it is assumed that the total number of indicies in the client's want and side information sets divides the total number of packets; $(k+1)|n$. Denote $g:=\frac{n}{k+1}$.

%In this scheme the client first arbitrarily partitions $X\setminus W\cup S$ into $g-1$ sets of size $k+1$; denote these sets as $\{P_i\}_{i=1}^{g-1}$. The client then sends the query of $Q=\{x_{W\cup S},x_{P_1},x_{P_2},...,x_{P_{g-1}}\}$. The server then sends the requested packet to the client. It should be noted that the client can decode the packet it wants with the $x_{W \cup S}$ packet from the server by subtracting off the contributions of the packets in its side information.

% \textit{Example:}
% Assume that $K=6$ and $M=2$. Assume that the user demands the packet $X_1$, i.e., $W=1$, and has the two packets $X_2$ and $X_3$ as its side information, i.e., $M = 2$ and $S=\{2,3\}$. Following the Partition and Code PIR scheme for this example, the user sends a random permutation of two query vectors $Q^{[1,\{2,3\}]}=\{(1,1,1,0,0,0),(0,0,0,1,1,1)\}$ to the server. The server then sends two coded packets $t_1$ and $t_2$ to the user: $Y_1=X_1+X_2+X_3$ and $Y_2=X_4+X_5+X_6$, where $+$ denotes addition over $GF(2)$. The user then decodes for the packet $X_1$ by using $Y_1$ and subtracting off $X_2 + X_3$. %\notee[brenden]{Double check this reasoning and make sure it is correct}
% From the perspective of the server, the packet that the user demands is either one of the packets in the set $\{X_1,X_2,X_3\}$ or one of the packets in the set $\{X_4,X_5,X_6\}$, each with probability $\frac{1}{2}$. Now, given that the packet that the user demands is in one of the two sets, the probability of $W$ being any given index in the set is $\frac{1}{3}$. Thus, it follows that $\mathbb{P}(\mathbf{W} = W|Q^{[\{1\},\{2,3\}]})=\frac{1}{6}=p_{\mathbf{W}}(W)$, and hence satisfying the $W$-privacy requirement.  \hfill\rule{1.3ex}{1.3ex}

% \add[brenden]{When $(M+1)|K$ holds the scheme simplifies. With this divisibility assumption, one can pick a number $i$ from $[g]$ ($g = \frac{K}{M+1}$) uniformly at random and fill the set $P_i$ with $W \cup S$, and have the rest of the sets $\{P_j\}_{j \neq i;j\in [g]}$ be a random partition of the elements in $[K]\setminus W \cup S$ into sets of size $g$. This is illustrated in the following example.

% \textit{Example:} Assume that $K=9$ and $M=2$. Assume that the user demands the message $X_8$ and has two messages $X_3$ and $X_9$ as side information, i.e., $W=3$ and $S=\{3,9\}$. The user then sets $P_1 = \{3,8,9\}$ and randomly partitions the remaining elements, making sets $P_2 = \{X_5, X_6, X_7\}$ and $P_3 = \{X_1, X_2, X_4\}$. The user then sends the server a random permutation of the vectors $\{\mathbf{1}_{P_1}, \mathbf{1}_{P_2}, \mathbf{1}_{P_3}\}$ as the query $Q^{[8,\{3,9\}]}$. The server sends the user $Y_1=X_3 + X_8 + X_9$, $Y_2 = X_5 + X_6 + X_7$, and $Y_3 = X_1 + X_2 + X_4$. From the server's perspective the demand is in a particular set in the partition with probability $\frac{1}{3}$ and the probability that a particular index in that set is the user's demand is $\frac{1}{3}$. It follows that $\mathbb{P}(\mathbf{W}=W|Q^{[8,\{3,9\}]})=\frac{1}{9}=p_{\mathbf{W}}(W)$ } %\hfill\rule{1.3ex}{1.3ex}

In the following, we show that the Partition and Code PIR scheme satisfies the $W$-privacy requirement for the setting in which the user's demand index $W$ and side information index set $S$ (given $W$) are distributed according to~\eqref{eq:WantSetDist} and~\eqref{eq:SideInfoDist}, respectively.

\begin{lemma}[Achievability of Theorem~\ref{thm:single-server-PIR}]
\label{lem:WPIRAch-NonDivis}
Consider the scenario of a $W$-PIR-SI problem in which:
\begin{itemize}
\item The server has packets $\{X_1,X_2,...,X_K\}$;
\item There is one user with $|W|=1,|S|=M$ such that $0\leq M\leq K-1$;
\item The demand index $W$ and the side information index set $S$ (given the demand index $W$) follow the distributions given in \eqref{eq:WantSetDist} and \eqref{eq:SideInfoDist}, respectively.
\end{itemize}
In this scenario, the Partition and Code PIR scheme satisfies the $W$-privacy, and has rate $R = \left\lceil \frac{K}{M+1} \right\rceil^{-1}$.
%\footnote{It is noted that Lemma \ref{lem:WPIRAch-NonDivis} is a generalization of Lemma \ref{lem:WPIRAch}}.
\end{lemma}

\begin{proof}%(sketch)
To show that the Partition and Code PIR scheme satisfies the $W$-privacy, it suffices to show that $$\mathbb{P}(\mathbf{W}=W|Q^{[W,S]})=p_{\mathbf{W}}(W).$$ 

%Let $P_{*}\in \{P_1,\dots,P_{g}\}$ be such that $W\in P_{*}$. %(Note that $P_{*}$ may or may not be the same as $P^{*}= W\cup S$.) Using similar ideas as in the proof of Lemma~\ref{lem:WPIRAch}, it follows that $$\mathbb{P}(\mathbf{W}=W|Q^{[W,S]}) = \mathbb{P}(P = P_{*})\times \mathbb{P}(j=W|P = P_{*}).$$ 
%In order to compute the conditional probability it is noted that $p_{\mathbf{W}|Q}(W|Q^{[W,S]})=\mathbb{P}(j \in Q_{i})\mathbb{P}(j = W|j \in Q_{i})$, where $Q_{i}$ is the set of indicies of the one locations for one of the vectors sent to the server. 
We consider two cases as follows:
\begin{itemize}
\item[(i)] $W$ %$P_{*}$ 
is in one of the sets in $\{P_1,\dots,P_{g-1}\}$. In this case, for every $i\in[g-1]$, we have
\begin{IEEEeqnarray}{rCl}
\mathbb{P}(\mathbf{W}\in P_{i}|Q^{[W,S]}) &=& \sum_{j\in P_i}\mathbb{P}(\mathbf{W} = j|Q^{[W,S]})\nonumber\\
&=& \frac{M+1}{K},\nonumber %\quad \forall i\in[g-1],
\end{IEEEeqnarray}
and $$\mathbb{P}(\mathbf{W}=W|\mathbf{W}\in P_i,Q^{[W,S]}) = \frac{1}{M+1}.$$ %\quad \forall i\in[g-1],
% Thus, 
% \begin{eqnarray*}
% \mathbb{P}(\mathbf{W} = W|Q^{[W,S]}) & = & \sum_{i = 1 }^{g} \mathbb{P}(\mathbf{W} = W | \mathbf{W} \in P_i)\mathbb{P}(\mathbf{W} \in P_i)\\ %\frac{M+1}{K}\times \frac{1}{M+1} \\ 
% & = & \frac{1}{K}.
% \end{eqnarray*}
\item[(ii)] $W$ is the set $P_g$. In this case, $$\mathbb{P}(\mathbf{W} \in P_{g}|Q^{[W,S]})= \frac{K - (g-1)(M+1)}{K},$$ and $$\mathbb{P}(\mathbf{W}=W|\mathbf{W} \in P_{g},Q^{[W,S]}) = \frac{1}{K - (g-1)(M+1)}.$$ 
% Thus,
% \begin{eqnarray*}
% \mathbb{P}(\mathbf{W}=W|Q^{[W,S]}) &=& \frac{K - (g-1)(M+1)}{K} \\ & & \hspace{0.25cm}\times \hspace{0.25cm} \frac{1}{K - (g-1)(M+1)} \\ &=& \frac{1}{K}.
% \end{eqnarray*}
\end{itemize}
Thus, we have 
\begin{eqnarray*}
\mathbb{P}(\mathbf{W} = W|Q^{[W,S]})\hspace{65mm} \\  = \sum_{i = 1 }^{g} \mathbb{P}(\mathbf{W} = W | \mathbf{W} \in P_i,Q^{[W,S]})\mathbb{P}(\mathbf{W} \in P_i | Q^{[W,S]})\hspace{7mm}\\ %\frac{M+1}{K}\times \frac{1}{M+1} \\ 
= \frac{1}{K}. \hspace{77mm}
\end{eqnarray*}
% \begin{eqnarray*}
% \mathbb{P}(\mathbf{W}=W|Q^{[W,S]}) &=& \frac{K - (g-1)(M+1)}{K} \\ & & \hspace{0.25cm}\times \hspace{0.25cm} \frac{1}{K - (g-1)(M+1)} \\ &=& \frac{1}{K}. 
% \end{eqnarray*}
%In both cases  (i) and (ii), it holds that 
 %\[\mathbb{P}(\mathbf{W}=W|Q^{[W,S]}) = \frac{1}{K} = p_{\mathbf{W}}(W).\] %The rest of the proof regarding the rate of the Partition and Code PIR scheme follows the exact same lines as in the proof of Lemma~\ref{lem:WPIRAch} (and hence omitted). 

To compute the rate of the scheme, note that 
\begin{eqnarray*} 
H(A^{[W,S]}) &=& H([A_{P_1},A_{P_2},\dots,A_{P_{g}}]) \\ &=&\sum_{P\in \{P_1,P_2,\dots,P_{g}\}} H(A_{P}) \\ &=&  t\times g,
\end{eqnarray*} 
where the equalities follow since the messages $X_j$'s (and hence the answers $A_P$'s) are independently and uniformly distributed. %, which gives $H(A_P) = t$ for all $P\in \{P_{1},\dots,P_{g}\}$. 
Thus, the Partition and Code PIR scheme has rate $$R = \frac{t}{t\times g} = \frac{1}{g}=\frac{M+1}{K}.$$ 
\end{proof}




% \begin{lemma}\label{lem:WPIRAch}
% Consider the scenario of a $W$-PIR-SI problem in which:
% \begin{itemize}
% \item The server has packets $\{X_1,X_2,...,X_K\}$;
% \item There is one user with $|W|=1,|S|=M$ such that $\,0\leq M\leq K-1$ and $(M+1)|K$;
% \item The demand $W$ and the side information $S$ (given the demand $W$) follow the distributions given in~\eqref{eq:WantSetDist} and~\eqref{eq:SideInfoDist}, respectively.
% \end{itemize}
% In this scenario, the Partition and Code PIR scheme satisfies the $W$-privacy, and has rate $R = \frac{M+1}{K}$.
% \end{lemma}

% %  where the user asks for $Q^{[W,S]}=\{\mathbf{1}_{C},\mathbf{1}_{P_1},\mathbf{1}_{P_2},...,\mathbf{1}_{P_{g-1}}\}$

% \begin{proof}
% To show that the Partition and Code PIR scheme satisfies the $W$-privacy constraint, it suffices to show that \[\mathbb{P}(\mathbf{W}=W|Q^{[W,S]})=p_{\mathbf{W}}(W).\]


% From the perspective of the server, all sets are equally likely to include $W$, and each index in each set is equally likely to be $W$. Thus, the probability that a given set, say $P$, where $P\in \{P^{*}, P_1,\dots,P_{g-1}\}$, includes the demand $W$ (i.e., $W\in P$) is equal to \[\mathbb{P}(P = P^{*}) = \frac{1}{g}.\] %since each set in the query is equally likely and $W\in P^{*}$.
% Also, provided that $P = P^{*}$ the probability that a given index, say $j$, in the set $P$  is equal to the demand $W$ (i.e., $j=W$) is  \[\mathbb{P}(j = W|P = P^{*})=\frac{1}{M+1}.\] %since there are $M+1$ indices in each set. 
% Putting these together, we get
% \[\mathbb{P}(\mathbf{W}=W|Q^{[W,S]})=\frac{1}{g} \times \frac{1}{M+1}=\frac{1}{K}=p_{\mathbf{W}}(W).\] Furthermore, 
% \begin{eqnarray*} 
% H(A^{[W,S]}) &=& H([A_{P^{*}},A_{P_1},\dots,A_{P_{g-1}}]) \\ &=&\sum_{P\in \{P^{*},P_1,\dots,P_{g-1}\}} H(A_{P}) \\ &=&  t\times g
% \end{eqnarray*} since the messages $X_j$'s (and hence the answers $A_P$'s) are independently and uniformly distributed, and $H(A_P) = t$ for all $P\in \{P^{*},P_1,\dots,P_{g-1}\}$. 
% Thus, the Partition and Code PIR scheme has rate $$R = \frac{t}{t\times g} = \frac{1}{g}=\frac{M+1}{K}.$$ 
% \end{proof}
%Thus, the query sent by the user is independent from the perspective of the server, and $I(\mathbf{W};Q^{[W,S]},A^{[W,S]},X_1,...,X_K)=0$.\notee[brenden]{Should probably note somewhere that Answer is determined completely by Query, so this is same as just query in mutual information}


% one best strategy for the server to guess the demand is as follows: (i) the server chooses one of the partitions at random, say $Q_{i}$, where $Q_{i}\in \{C, P_1,\dots,P_{g-1}\}$ is the set of indices of one of the query vectors $\mathbf{1}_{C},\mathbf{1}_{P_1},\mathbf{1}_{P_2},...,\mathbf{1}_{P_{g-1}}$ that the user sends to the server; and (ii) the server picks one of the indices in the partition $Q_i$ at random, say $j\in Q_i$, as the demand. From (i) and (ii), it follows that the probability $\mathbb{P}(\mathbf{W}=W|Q^{[W,S]})$ that the server guesses the demand $W$ correctly is equal to $\mathbb{P}(Q_{i} = C)\times \mathbb{P}(j = W|Q_i = C)$. Since each partition in the query is equally likely, then $\mathbb{P}(Q_{i} = C) = \frac{1}{g}$, and since there are $M+1$ indices in each partition, then $\mathbb{P}(j = W|Q_{i} = C)=\frac{1}{M+1}$.    

% \subsection{Removing the divisibility requirement}

% Below, we slightly modify the Partition and Code PIR scheme proposed for the case that $(M+1) \mid K$ to handle the case that $(M+1) \nmid K$. 

% Note that this algorithm is a generalization of the algorithm presented in Section~\ref{sec:achievability-partitioning}. Similarly, Lemma~\ref{lem:WPIRAch-NonDivis} generalizes Lemma~\ref{lem:WPIRAch} for the case when $(M+1)|K$ is not required. 


% \notee[brenden]{This one was too long when I moved it to display environment}.

% \subsubsection{Number of Transmissions Comparison with MDS Scheme}
%
% \notee[brenden]{When/Should we put this in the paper?}
% \begin{lemma}
% The Partitioning Query scheme, in the case of one client, is at least as good as the MDS Coding Solution in terms of the number of transmissions for all sizes of side information possible.
% \end{lemma}
%
% \begin{IEEEproof}
% First note that the parameter $M$ can take integer values within $0\leq M \leq K-1$. Then comparing the number of transmissions required by the partitioning query scheme and the MDS coding scheme we have that the partitioning query scheme yields less than or equal to the number of transmission than the MDS Coding scheme for all possible parameters $M$.
% \begin{multline}
% \\
% \frac{K}{M+1}\leq K-M \\
% K \leq (K-M)(M+1) \\
% %n \leq nk + n - k^2 - k \\
% 0 \geq M^2 -KM +M \\
% %0 \geq k(k-(n-1)) \\
% 0 \leq M \leq K-1 \\
% \end{multline}
% \end{IEEEproof}

% \notee[brenden]{Currently its own subsubsection, wanted to write out the ideas before I figured out how to incorporate it}


%In either case $p_{\mathbf{W}|Q}(W|Q^{[W,S]})=p_{\mathbf{W}}{W}$ So the query sent by the client is independent from the perspective of the server, and $I(\mathbf{W};Q^{[W,S]},A^{[W,S]},X_1,...,X_K)=0$.

% \section{Protecting the Demand as well as Side Information}
% \label{sec:protect-side-info}


\section{$(W,S)$-Privacy Problem}
%\subsection{IEEEproof of Theorem~\ref{thm:single-server-PIR2}}
\label{sec:IEEEproof-theorem-2}

In this section we consider $(W,S)$-privacy in the PIR-SI problem. We show the proof of the converse and the achievability for Theorem \ref{thm:single-server-PIR2} through a reduction to an index coding instance and an MDS coding scheme, respectively.


\subsection{Converse for Theorem~\ref{thm:single-server-PIR2}}
\label{sec:converse-mds}
When protecting the demand index and the side information index set of the user, the privacy constraint becomes $$I(\mathbf{W},\mathbf{S};Q^{[\mathbf{W},\mathbf{S}]},A^{[\mathbf{W},\mathbf{S}]},X_1,X_2,...,X_K) = 0.$$ For this case, a lower bound of $K-M$ on the number of transmissions can be shown. The proof of the converse in this case shows a necessary condition for privacy and a class of index coding problems that satisfy the necessary condition; and obtains a lower bound on the number of transmissions needed to solve the index coding problem that {belong to this class}. 

\begin{lemma}
\label{lem:WSNecessaryCondition}
% A necessary condition for a solution that satisfies the privacy constraint for protecting the demand and side information set of a client is the following:
% In a solution I, it must hold that $\forall i \in [K]$, $X_i$ must be able to be decoded with I and all side information $X_S \in X_{\mathcal{S}_i}$ where $X_{\mathcal{S}_i} \triangleq \{X_S \subset \{X_1,X_2,...,X_K\} \setminus \{X_i\}: |X_S| = M\}$.
For a $(W,S)$-PIR-SI scheme, for any demand index $W$ and side information index set $S$, the answer $\A{W}{S}$ from the server must be a solution to an instance of the index coding problem that satisfies the following requirements:
\begin{enumerate}
	\item The instance has the message set $X_1, \cdots, X_K$;
	\item  There are $L = (K - M)\binom{K}{M}$ clients such that each client wants to decode one message, and possesses a side information set that includes $M$ other messages;
	\item  The client that wants $X_W$ has the side information set $X_S$; for each $i\in[K], i\ne W$, for each $S_i\subset[K]\setminus\{i\}$ such that $|S_i| = M$, there exists a client that demands $X_i$ and possesses $\Xj{S_i}$ as its side information.
\end{enumerate}
\end{lemma}

\begin{proof}
Given a demand index $W$ and a side information index set $S$, let $\A{W}{S}$ be an answer from the server that satisfies the decodability requirement~\eqref{eq:decodability} and the $(W,S)$-privacy requirement~\eqref{eq:privacy2}. First, we note that the decodability requirement implies that there exists a function $D_{W,S}$ such that $D_{W,S}\left(\A{W}{S},\Xj{S}\right) = X_W$. Second, we note that the $(W,S)$-privacy requirement implies that for each message $X_i$ and every set $S_i\subseteq[K]\setminus\{i\}$ of size $M$, there exists a function $D_{i,S_i}$ satisfying $D_{i,S_i}\left(\A{W}{S},\Xj{S_i}\right) = X_i$. Otherwise, for a particular $\{i,S_i\}$, the server would know that the user cannot possess $\Xj{S_i}$ and demand $\Xj{i}$, which, in turn, would violate the $(W,S)$-privacy requirement~\eqref{eq:privacy2}.  

Now, consider an instance of the index coding problem satisfying the conditions stated in the lemma. Since  decoding functions exists for each client as argued above, $\A{W}{S}$ is a feasible index code for this instance.  
% Suppose that for a solution I there exists some $i$ such that $\exists X_S \in X_{\mathcal{S}_i}$ such that $X_i$ can't be decoded from I and $X_S$. Then the server knows that the clients demand couldn't have been $i$ with the side information set being S. Then the server knows that $p_{\mathbf{W},\mathbf{S}}(i,S)=0$. Because the a priori probability of this combination is assumed \notee[brenden]{Make sure this is assumed} to be non-zero, this leaks information about the possible (W,S) combinations and the privacy constraint for (W,S) privacy is not satisfied.
\end{proof}

% An index coding scenario with a solution that satisfies the necessary condition can be defined. In this index coding scenario, there are numerous users. For each possible combination of demand and side information set of size $M$ there is a user. Any index coding solution to this scenario guarantees that the necessary condition is satisfied. \notee[brenden]{Does this need to be a formal lemma}

Next, we give a lower bound on the broadcast rate for an instance satisfying the conditions in Lemma~\ref{lem:WSNecessaryCondition}.

\begin{lemma}
\label{lem:WSTransmissionBound}
For any instance of the index coding problem satisfying the conditions specified in Lemma~\ref{lem:WSNecessaryCondition}, the broadcast rate is at least $K - M$.
% Any solution to the index coding scenario that satisfies the necessary condition for given parameters $K$ and $M$ requires at least $K-M$ transmissions.
\end{lemma}

\begin{proof}
Let $J$ denote an instance of the index coding problem satisfying the conditions in Lemma~\ref{lem:WSNecessaryCondition}. Let $J'$ be an instance of the index coding problem with the $K$ messages $X_1,\cdots,X_K$ and $K-M$ clients. Each client has the side information $X_S$ and wants to decode one distinct message from $\{X_1,\cdots,X_K\}\setminus X_S$. Clearly, a solution to instance $J$ is also a solution to instance $J'$. Since the messages are independent, the broadcast rate for $J'$ is at least $K-M$, which completes the proof. 
\end{proof}

% Let a S here denote the set $S=\{1,2,...,M\}$. Look at the subset of all users that have the side information set S. Call the index coding instance induced by the subset of users as the sub-instance. In this sub instance there are $K-M$ users, all with side information set S, and one with demand $M+1$ one with $M+2$, and so on until the one with $K$. Denote the side information graph of the original instance as G, and the side information graph of the sub instance as $G_S$. 

% Because there are more users in the original instance of index coding, it is clear that $\beta(G_S) \leq \beta(G)$. Then we can find a lower bound on $\beta(G_S)$ and that lower bound will be a lower bound on $\beta(G)$. The $MAIS(G_S)$ is a lower bound on $\beta(G_S)$. Notice that in $G_S$ the set of vertices $Z=\{M+1,M+2,...,K\}$ induces an acyclic subgraph. Because $Z \cap S = \emptyset$ there are no edges in this induced subgraph, and it is acyclic. The size of this induced graph is $K-M$ and we have the following inequalities:
% \begin{equation*}
% K-M \leq MAIS(G_S) \leq \beta(G_S) \leq \beta(G)
% \end{equation*}

\begin{corollary}[Converse of Theorem~\ref{thm:single-server-PIR2}]
For the $(W,S)$-PIR-SI problem with $N=1$ server, $K$ messages, and side information size $M$, the capacity is at most $(K-M)^{-1}$.
\end{corollary}

\begin{proof}
Lemmas~\ref{lem:WSNecessaryCondition} and~\ref{lem:WSTransmissionBound} imply that the length of the answer $\A{W}{S}$ is at least $(K-M)t$ for any given $W$ and $S$. Thus, by using~\eqref{eq:rate}, it follows that $R\leq (K-M)^{-1}$. %a neccessary condition is used to create an index coding scenario whose solution satisfies the necessary condition. Lemma  gives a lower bound on the broadcast rate of the index coding scenario, and $R\leq 1/\beta(G) = (K-M)^{-1}$
\end{proof}

\subsection{Achievability for Theorem~\ref{thm:single-server-PIR2}}
\label{sec:achievability-mds}

In this section, we give a $(W,S)$-PIR-SI scheme based on a maximum distance separable (MDS) code that achieves the rate of $1/(K - M)$. We assume that $t\geq \log_2(2K-M)$. %An achievability scheme when protecting the demand and the side information set of the user is to have the user ask for certain linearly independent packets from the server so that the user can decode for every packet with its side information.

\textbf{MDS PIR Scheme:} Given a demand index $W$ and a side information index set $S$ of size $M$, the user queries the server to send the $K - M$ parity symbols of a systematic $(2K - M, K)$ MDS code over the finite field $\GF{2^t}$. We assume that  $t\geq\log_2(2K-M)$, or equivalently, $2^t \geq 2K - M$. Thus, it is possible construct a $(2K - M,K)$ MDS code over $\GF{2^t}$. The answer $\A{W}{S}$ from the server consists of the $K - M$ parity symbols. %First, the user constructs a generator matrix for a $[K,K-M]$ generalized Reed-Solomon code over a binary-extension field $\mathbb{F}_{2^q}$ for sufficiently large $q$ such that $2^q > K$. (Note that an extension field of $\mathbb{F}_2$ is used so that every element in the field can be represented as a binary vector.) To this end, the user constructs a $(K-M) \times K$ matrix $V$ of the following form:
% \begin{equation*}
% V=
% \begin{pmatrix}
% 1&1&\hdots&1 \\
% \alpha_1^1 & \alpha_2^1 & \hdots & \alpha_K^1 \\
% \alpha_1^2 & \alpha_2^2 & \hdots & \alpha_K^2 \\
% \vdots & \vdots &  & \vdots \\
% \alpha_1^{K-M-1} & \alpha_2^{K-M-1} & \hdots & \alpha_K^{K-M-1} \\
% \end{pmatrix}
% \end{equation*}
% where $\alpha_i \in \mathbb{F}_{2^q}\setminus \{0\}$ for all $i\in [K]$, and $\alpha_i$'s are distinct.

% Next, the user sends $K-M$ binary vectors of length $qK$ to the server corresponding to the rows of the generator matrix. The database then sends back to the user the inner product of the coefficient vectors that the binary query vectors represent and the vector of messages. These inner products can be represented as the rows of a matrix $T$ of the following form:
% \begin{equation*}
% T=V
% \begin{pmatrix}
% X_1\\
% X_2\\
% \vdots \\
% X_K
% \end{pmatrix}.
% \end{equation*}
%We refer to this scheme as the \textit{MDS PIR scheme}. 
\begin{lemma}[Achievability of Theorem~\ref{thm:single-server-PIR2}]
The MDS PIR scheme satisfies the decodability condition in~\eqref{eq:decodability} and the $(W,S)$-privacy condition in~\eqref{eq:privacy2}, and it has the rate of $R = (K-M)^{-1}$.%as described above is feasible. In other words, given the transmissions $T$ from the database the user is able to decode for the message it demands.
\end{lemma}

%IEEEproof Sketch before I formalize it\notee[brenden]{Don't include this in final version}:
%\begin{itemize}
%\item Consider transmissions (rows of T)
%\item Then for each transmission, subtract of contributions from packets in $X_S$
%\item This can be viewed as a $(K-M) \times (K-M)$ submatrix of V, whose columns correspond to $[K]\setminus S$
%\item Because V is a generator of MDS code, this matrix is full rank, and all packets can be decoded. 
%\end{itemize}
\begin{proof}
(Sketch) For a $(2K - M, K)$ systematic MDS code, given the $K - M$ parity symbols and any $M$ out of the $K$ messages, the user can decode all of the remaining $K - M$ messages as the code is MDS. Thus, the user can recover its demanded message. 

To ensure the $(W,S)$-privacy, note that the query and the answer are independent of the particular realization of demand index $W$ and side information index set $S$, but only depend on the size $M$ of the side information index set. As the server already knows the size of the side information index set, it does not get any other information about $W$ and $S$ from the query and the answer. Thus, the MDS PIR scheme satisfies the $(W,S)$-privacy requirement.
%\end{proof}

% From the transmissions sent to the user, the user can subtract off the contributions from the packets that they have. This can be viewed as removing the columns of $V$ indexed by the set $S$ \notee[brenden]{Is there an easier/cleaner way to formalize this idea}, as these are the columns corresponding to the contributions to the transmissions that are given by the packets that the user doesn't have. This $(K-M) \times (K-M)$ submatrix is full rank by the MDS property of $V$. Because of this the packet that user demands can be solved for and the code is feasible. \notee[brenden]{Add to this sentence that this submatrix is invertible and the user can solve for the packet they need?}

% \begin{lemma}
% The MDS PIR scheme as described above satisfies the $(W,S)$-PIR privacy constraint.
% \end{lemma}

%IEEEproof Sketch: \notee[brenden]{Delete the IEEEproof sketch before final}
%\begin{itemize}
%\item Can put V into systematic form at the database
%\item Because MDS code with $d_{min} = M+1$ every row of systematic matrix has M+1 non-zero entries
%\item This will hold no matter how columns are permuted either
%\item Because of this, vectors with any combination of $M+1$ non-zero locations can be generated by rows of V
%\item Because of this, any vectors with any contribution for any possible $W \cup S$ are possible and so the a priori probabilities are unchanged
%\end{itemize}

% \begin{IEEEproof}
% Knowing the queries sent by the client form rows of a generator matrix of an MDS code, the server can try putting the matrix in systematic form. By the minimum distance property of the code, no matter how the server permutes the columns of the matrix $V$, every row of the matrix will have $M+1$ non-zero locations. 

% Also by the minimum distance property, permuting columns and putting $V$ into a systematic form and permuting back to the original column order of $V$, gives a procedure to generate vectors with all possible combinations of $M+1$ non-zero locations.

% Because all vectors with all possible combinations of $M+1$ non-zero locations can be generated by $V$, the database gains no knowledge about the set $\{W\} \cup S$ that the user has. Because of this, no possible combinations of $W$ and $S$ are ruled out and no information is leaked to the server, and all a priori probabilities are unchanged. 
% \end{IEEEproof}

% \begin{lemma}
% The rate of the MDS PIR scheme is \mbox{$R = (K-M)^{-1}$.} 
% \end{lemma}

%IEEEproof Sketch:
%\begin{itemize}
%\item Because they are i.i.d messages, then entropy of the answers, which are linear combinations of the messages, is the same as the entropy of a single message.
%\item Because messages are independent, the entropy of two linearly independent answers are independent
%\item Then the rate should fall out. 
%\end{itemize}

%\begin{proof}
To compute the rate, note that for any $W$ and $S$, the answer $\A{W}{S}$ of the MDS PIR scheme consists of $K-M$ parity symbols of a $(2K-M,K)$ systematic MDS code over $\GF{2^t}$. For an MDS code, any parity symbol is a linear combination of all the messages. Thus, as each message is distributed uniformly over $\GF{2^t}$ and the code operates over $\GF{2^t}$, every parity symbol is also uniformly distributed over $\GF{2^t}$. Further, since the messages are independent, the parity symbols are independent. Hence, we have $H(\A{W}{S}) = (K - M)t$. %and the pari In the scheme, the database answers with $K-M$ linearly independent combinations of the messages $X_1,X_2,...,X_K$. Label these linearly independent combinations as $A_1,A_2,...,A_{K-M}$. Then $H(A^{[W,S]})=H(A_1,A_2,...,A_{K-M})$ for the scheme. Because each $A_i, i \in [K-M]$ is a linear combination of the i.i.d Random Variables $X_1,X_2,...,X_K$, $H(A_i) = H(X_1)=t$. Then because the $X_K$'s are independent, and $A_1,A_2,...,A_{K-M}$ are linearly independent, we have that $H(A_1,A_2,...,A_{K-M}) = \sum_{i=1}^{K-M} H(A_i) = (K-M)H(A_1) = (K-M)t$.
Therefore, the rate of the MDS PIR scheme is $R=(K-M)^{-1}$. 
\end{proof}
%\subsubsection{Example} 
%\label{sec:MDSexample}

%\notee[brenden]{Mention that in this case, the distribution of packets only assumes that nothing has a zero probability}
%Consider a particular realization of this scenario where the packets the server has are $\{X_1,X_2,...,X_6\}$, $K=6$, and the client has 2 packets as side information, $M=2$. Say in this particular realization $W=1$ and $S=\{2,3\}$; the instance is shown in \notee[brenden]{Do we really need this illustration of the situation?} Figure \ref{pic:six-packet-setup}. In this case the query the client sends would be $Q^{[W,S]}=\{X_1,X_2,...,X_6\}$, the server, knowing the client has 2 packets as side information, could then use a Generalized Reed-Solomon \notee[brenden]{Generalized? or just regular Reed-Solomon Code?} code over GF(7). It is noted that GF(6) would suffice, but GF(7) is used to simplify the example. 

% \begin{figure}
% \label{pic:six-packet-setup}
% \centering
% \includegraphics[scale=0.35]{six_packet_example.png}
% \caption{Particular Instance of Index-Coding-PIR Problem with Six Packets}
% \end{figure}
% \notee[brenden]{Do we need to include this figure}

%The server then gets the query and encodes the packets it has and sends them to the client. The transmissions can be encoded as the rows of the resulting matrix T, given by the matrix multiplication in Equation \ref{eq:MDStransmissions}
%\begin{equation}
%\label{eq:MDStransmissions}
%T=
%\begin{pmatrix}
%1 & 1 & 1 & 1 & 1 & 1 \\
%0&1&2&3&4&5\\
%0&1&4&2&2&4\\
%0&1&1&6&1&6
%\end{pmatrix}
%\begin{pmatrix}
%X_1\\
%X_2\\
%X_3\\
%X_4\\
%X_5\\
%X_6
%\end{pmatrix}
%\;over\;GF(7)
%\end{equation}

%The client with these transmissions, coupled with their side information can decode all of the packets that the server has, and in particular it can decode for $X_{1}$.

%\subsubsection{General Analysis - Privacy and Number of Transmissions}

%\notee[brenden]{Do we need to state the privacy of this scheme formally? OR say because the client asks for everything then it is obviously private}



% \section{Single Server Multi-Message PIR with Side Information ?}
% \label{sec:multi-message-pir}

% Now consider the situation in which a client has one packet as side information and wants a pair of a packets from a server. Say the want set is distributed uniformly over all possible pairs of packets that are contained in the server and that the side information packet is then picked uniformly at random from the remaining packets in the server. Then we show through an Index-Coding/Graph theoretical argument that the optimal number of transmissions required to preserve the privacy of the want set of the client is $n-1$ for wanting a $l \geq 2$ packets. 




% \subsection{Set-Up}

% \textbf{To Include}
% \begin{itemize}
% \item How to construct Graph
% \item The necessary condition for multiple packets
% \item How the graph is equivalent to solution of multiple message index coding solution
% \end{itemize}

% \subsubsection{Constructing the Graph}

% To construct the multi-message side information graph, consider virtual clients that represent all pairs of possible want sets. For each packet in the want set of each client, make two nodes in the following way. For client with want set pair $\{i,j\}$, there will be two nodes labeled, $x_i^j$ and $x_j^i$. It should be noted that there is no edge between these two nodes. 

% Denote by $x_i^*$ to be all nodes that are labelled with the integer i in their subscript. For all of the nodes $x_i^j$ and $x_i^k$ $\in x_i^*$, make edges $(x_i^j,x_i^k)$ and $(x_i^k,x_i^j)$; fully connect all nodes in $x_i^*$. 

% For each pair of nodes represented, both $x_i^j$ and $x_j^i$ have edges that go from $(x_i^j,x_k^*)$ and $(x_j^i,x_k^*)$, where k is some undetermined side information set of a pair of clients (clearly $k \neq i$, $k \neq j$). 

% \subsection{Lower Bound/Induced Acyclic Graph Procedure}

% Below is the description of the procedure and some justifications for the steps.

% \textbf{Step 1.} Start by relabeling the packets so that the original client has $W=\{1,2\}$ and has $S=\{3\}$. After relabeling construct the graph as described earlier.   

% The step is done to make the description of the algorithm and IEEEproof easier, it can be started with an arbitrary pair of packets. 

% \textbf{Step 2.} Denote the set $Z$ \textbf{(no intuition or reason for the label Z for the set, but needed a letter)} as the nodes that induce the "running" subgraph. Put the nodes $x_1^2$ and $x_2^1$ into the set Z. Let $I_Z$ denote the lower indicies of the set Z; $I_Z:=\{i \in \mathbb{N} | x_i^j \in Z\}$. Set the label $k = 3$. Set a variable $r=0$.

% Notice that the edges $(x_1^2,x_2^1)$ and $(x_2^1,x_1^2)$ are not present in the graph by construction. All the edges $(x_1^2, x_3^{*})$ and $(x_2^1,x_3^{*})$ are in the graph; $x_1^2$ and $x_2^1$ are connected to all $x_3$ nodes. 

% \textbf{Step 3.} Look into all of the nodes $x_k^*$ and look for one of two Cases.

% Case I: This case is the case where there is some node $x_k^i$ such that it has out-edges $(x_k^i,x_j^*)$ where $j \notin I_Z$. In this case the procedure goes to Step 3a.

% Case II: Is the case that all of the nodes $x_k^*$ have out edges of the form $(x_k^i,x_j^*)$, where $j \in I_Z$. In this case, the procedure goes to Step 3b.

% \textbf{Step 3a.} Add the node $x_k^i$ to the set Z; set k equal to the subscript of the nodes that the newly added node points to.Then set $r = r+1$, and repeat Step 3 with the updated Z.

% \textbf{Step 3b.} Add the nodes $x_j^k$ where $j \notin I_Z \cup \{k\}$ into Z. Then terminate the procedure.

% Notice that before adding the new nodes to Z, we have that $|Z| = 2+r$, and $|I_Z \setminus I_{Z\cup x_k^*}|=n-(2+r+1)=n-r-3$. Then this gives that the new $|Z|$ would be $2+r+n-r-3=n-1$. Notice also that this induced subgraph is acyclic due to two observations. \textit{Observation 1}: There are no edges $(x_k^i,x_j^k)$ for any i. This is due to the assumption of Case I, all outgoing edges from the $x_k^i$ nodes are going to nodes $x_l^*$, $l \in I_Z$. \textit{Observation 2}: All edges from the newly added nodes are of the form $(x_j^k,x_i^*)$, where $i \in I_Z$. This is because all of the nodes $x_k^l$ go to some $x_i^*$ for some $i\in I_Z$; and by construction pairs of nodes point to the same places. Because of the observations, there are no cycles.

% Whenever the process terminates, an induced acyclic subgraph is given by the nodes in set Z. The size of the acyclic subgraph is $n-1$. Any MAIS would have to be at least of this size; the procedure works on any graph that is described. This would give a lower bound in the multiple 

\section{$W$-Privacy for Multiple Servers}
\label{sec:multi-message-pir}

%\subsection{Achievability}
\label{sec:achievability-modified-Sun-Jafar}
% \salim{I think it is important here to empahsize that the two servers have replicated and not coded. For coded we don't know what to do for now.} \notee[brenden]{Do we need more than what is stated in the next paragraph?}\swanand{Modified the paragraph.}

In this section, we present a $W$-PIR-SI scheme, when data is replicated on multiple servers. The rate achieved by the proposed scheme gives a lower bound on the capacity of multiple-server $W$-PIR-SI problem.
% \salimn{should we say somewhere that the capacity is still open? Maybe also have a collection of open problems in the conclusion?} 
%We consider the case when the $K$ messages are replicated across $N$ databases. We present a $W$-PIR-SI 
Our scheme builds up on the scheme proposed by Sun and Jafar in~\cite{sun2016capacitynoncol}, which deals with the case of no side information ($M=0$). We refer to it as Sun-Jafar protocol. Next, we use an example to  describe this Sun-Jafar protocol.  The details can be found in~\cite{sun2016capacitynoncol}.

\begin{example} (Sun-Jafar Protocol \cite{sun2016capacitynoncol}) $N = 2$ servers, $K = 2$ messages, and $M = 0$, i.e., no side information. The protocol assumes that each of the messages is $t = N^K = 4$ bits long. 
For a message $X_{i}$, let $[{X}_{i,1},\cdots,{X}_{i,t}]$ be a uniform random permutation of its $t$ bits. The user chooses a random permutation of the bits of $X_1$, and an independent random permutation of the bits of $X_2$. Suppose that the user is interested in downloading $X_1$. Then, it requests the bits from the first server (S1) and the second server (S2) as given in Table~\ref{tbl:example}.

\begin{table}[!h]
\begin{center}
\begin{tabular}{|c|c|}
\hline
S1 & S2\\
\hline
${X}_{1,1}$% = \Xj{1,1}+\Xj{2,1}$ 
& ${X}_{1,2}$\\ %= \Xj{1,2}+\Xj{2,2}$\\
${X}_{2,1}$ % = \Xj{3,1}+\Xj{4,1}$ 
& ${X}_{2,2}$\\ % = \Xj{3,2}+\Xj{4,2}$\\
${X}_{1,3} + {X}_{2,2}$ % = \Xj{1,3}+\Xj{2,3}+\Xj{3,2}+\Xj{4,2}$ 
& ${X}_{1,4} + {X}_{2,1}$\\ % = \Xj{1,4}+\Xj{2,4}+\Xj{3,1}+\Xj{4,1}$\\
\hline
\end{tabular}
\end{center}
\caption{Queries for the Sun-Jafar protocol when $N = 2$ servers, $K = 2$ messages, and no side-information, when the user demands $X_1$. Each message is formed of  $4$ bits. 
}
\label{tbl:example}
\end{table}
Note that the user can decode the four bits of $X_1$ from the answers it gets. To ensure  privacy, note that each server is asked for a randomly chosen bit of each message and a sum of different pair of randomly chosen bits from each message. Therefore, a server cannot distinguish about which message is requested by the user. 
\end{example}
%\hfill\rule{1.3ex}{1.3ex}

Next, we give an example to outline our proposed scheme for multi-server PIR with side information before describing it formally.

\begin{example} 
(Multi-Server $W$-PIR-SI Scheme) $N = 2$ servers, $K = 4$ messages, and $M = 1$ message as side information. %Consider the case of $N = 2$ databases and $K = 4$ messages, 
Our scheme assumes that each message is $t = N^{\frac{K}{M+1}} = 4$ bits long. The  demand is privately chosen by the user, uniformly at random. The side information set has size $M = 1$. It is chosen uniformly at random from the other messages, and is unknown to the servers. 

Consider an instance when the user demands $X_1$, and the side information index  set $S = \{2\}$. First step is that the user forms a partition of $[K]$ into $g = K/(M+1) = 2$ sets $\{P_1,P_2\}$, where $P_1 = \{1,2\}$, and $P_2 = \{3,4\}$.\footnote{The general procedure for forming the partition is elaborated in the formal description of the scheme.} Next, the user sends a random permutation of $\{P_1,P_2\}$ to both the servers. The user and the servers form two {\it super-messages} by taking the sum of the messages indexed by $P_1$ and $P_2$ as follows: $\hat{X}_1 = \Xj{1} + \Xj{2}$ and $\hat{X}_2 = \Xj{3} + \Xj{4}$. %, where $+$ denote the sum over $\GF{2}$. 
The last step is that the user and the servers apply the Sun-Jafar protocol using the two super-messages $\hat{X}_1$ and $\hat{X}_2$, such that the user can download $\hat{X}_1$. The form of the queries is given in Table~\ref{tbl:example}.

% \salim{I suggest we move this to a separate example that comes before this one. Better than two nested examples I think. Also it gives a reader an idea of what sunjafar is. Also, we start the example by saying k=4 and now k=2... } We describe the Sun-Jafar protocol for $K = 2$ and $N = 2$ in the following. 
% For a message $\hat{X}_{i}$, let $[\hat{X}_{i,1},\cdots,\hat{X}_{i,t}]$ be a random permutation of its $t$ bits. The user chooses a random permutation of the bits of $\hat{X}_1 = X_1+X_2$, and an independent random permutation of the bits of $\hat{X}_2 = X_3+X_4$. Then, it requests the following bits from the first database (DB1) and the second database (DB2).

% \begin{table}[!h]
% \begin{center}
% \begin{tabular}{|c|c|}
% \hline
% DB1 & DB2\\
% \hline
% $\hat{X}_{1,1}$% = \Xj{1,1}+\Xj{2,1}$ 
% & $\hat{X}_{1,2}$\\ %= \Xj{1,2}+\Xj{2,2}$\\
% $\hat{X}_{2,1}$ % = \Xj{3,1}+\Xj{4,1}$ 
% & $\hat{X}_{2,2}$\\ % = \Xj{3,2}+\Xj{4,2}$\\
% $\hat{X}_{1,3} + \hat{X}_{2,2}$ % = \Xj{1,3}+\Xj{2,3}+\Xj{3,2}+\Xj{4,2}$ 
% & $\hat{X}_{1,4} + \hat{X}_{2,1}$\\ % = \Xj{1,4}+\Xj{2,4}+\Xj{3,1}+\Xj{4,1}$\\
% \hline
% \end{tabular}
% \end{center}
% \caption{Queries for $N = 2$, $K = 1$, $M = 1$, when $W = 1$ and $S = 2$. Note that $\hat{X}_1 = X_1+X_2$ and $\hat{X}_2 = X_3+X_4$.\salim{is the legend correct? Seems also that we are making the assumption that $t=2$?}}
% \end{table}

From the answers, the user obtains $\hat{X}_1$, from which it can decode the desired message $X_1$ using the side-information $X_2$. Note that the privacy property of the Sun-Jafar protocol guarantees that any DB cannot distinguish  which super-message is requested by the user. Since the desired message can be in either super-message, and in a super-message, any of the messages can be the demand, the privacy of the demand index is ensured. 
\end{example}
%\hfill\rule{1.3ex}{1.3ex}
% It is easy to verify that the user can decode for $[\Xj{1,1},\cdots,\Xj{1,4}]$ using the answers and the side information $[\Xj{2,1},\cdots,\Xj{2,4}]$. To ensure the privacy, first, note that each DB is asked for a randomly chosen bit of each super-message and a sum of different pair of randomly chosen bits from each super-message. Therefore, a DB cannot distinguish about which super-message is requested by the user. Now, the desired message can be in either super-message and in a super-message any of the messages can be the demand. 

Note that in the above example the proposed scheme requires to download $6$ bits, achieving the rate of $2/3$. It is shown in~\cite[Theorem 1]{sun2016capacitynoncol} that  the capacity of PIR with $N$ servers and $K$ messages and no side information is $(1 + 1/N + \cdots + 1/N^{K-1})^{-1}$. Therefore, if the user attempts to download the demand without using its side information, then the capacity is $(1 + 1/N + 1/N^2 + 1/N^3)^{-1} = 8/15$, which is smaller than $2/3$. 
% \salim{comment about the writing of this example: it seems that we apply  SJ scheme to the supermessages. Is it true? Why not explain it this way. Our scheme si two stages:1) apply a linear trans to create supermessages 2) Apply SJ scheme. I think the general proof would be easier since properties would follow from SJ scheme. } \notee[brenden]{I believe this has been done}\swanand{Done.}

% \salim{General comments:

% 1) It may be worthwhile investigating the multisever case with very large number of messages (i.e. k goes to infinity). The reason is that in this case the capacity is (n-1)/n and the scheme that achieves it is a generalization of the canonical example of Sudan et. Just use a secret sharing to send the queries. This way you avoid the complexity of SJ scheme and you may gain more insight about how to use the side info. Besides, if you compare (n-1)/n to the actual capacity it very close with roughly say something in the order of 100 messages (so infinity is 100 here). 


% 2) In the same regime K very large, I have lots of insight on how to design optimal PIR when the data is coded. See the examples in my paper with Razan ISIT 2016. I can explain these schemes to you. It will be nice to see how you can generalize this to the case with side info. Our schemes were later proved to be optimal by Sennur. But maybe we should side info with coded PIR on multi server to another paper since we want to put this on Arxiv ASAP.  
% }

Next, we describe our $W$-PIR-SI scheme for $N$ servers storing identical copies of the $K$ messages, when the user has a side information set of size $M$. We assume that $(M+1)\mid K$, and the messages are $t = N^{K/(M+1)}$ bits long. Recall that, for a subset $S \subset [K]$, $\mathbf{1}_S$ denotes the characteristic vector of the set $S$. %a binary vector of length $K$ such that, for all $j\in[K]$, its $j$-th entry is $1$ if $j\in S$, otherwise it is $0$. 
Let $g\triangleq\frac{K}{M+1}$.

{\bf  Multi-Server $W$-PIR-SI Scheme:}
Assume that each message is $t = N^{\frac{K}{M+1}}$ bits long.  The scheme consists of the following three steps.

{\it Step~1.} Given the demand index $W$ and the side information index set $S$, let $P_1 = W\cup S$. The user randomly partitions the set of messages $[K] \setminus P_{1}$ into $g - 1$ sets of size $M+1$ each, denoted as $\{P_2,\cdots,P_{g}\}$. 

{\it Step~2.} The user sends to all the servers a uniform random permutation of the partition $\{P_1, \cdots, P_g\}$, ie., it sends $\{P_1, \cdots, P_g\}$ in a random order. Then, the user and the servers form $g$ {\it super-messages} $\{\hat{X}_1,\dots,\hat{X}_g\}$, where $\hat{X}_i = [X_1,\dots,X_K]\cdot\mathbf{1}_{P_i}$ for $i\in[g]$.

{\it Step~3.} The user and the $N$ servers utilize the Sun-Jafar protocol with $g$ super-messages in such a way that the user can download the message $\hat{X}_1$. % assuming that the set of messages $\{\hat{X}_1,\cdots,\hat{X}_g\}$ is replicated across $N$ databases. In particular, when Sun-Jafar protocol asks the $j$-th database for the $l$-th bit of a super-message $\hat{X}_i$, then query the $j$-th database for the sum of the $l$-th bits of all the messages in belonging to set $P_i$.

\begin{lemma}
\label{lem:WPIRAch-NonDivis}
Consider the scenario of a $W$-PIR-SI problem in which:
\begin{itemize}
\item The $N$ servers store identical copies of $K$ messages $\{X_1,X_2,...,X_K\}$;
\item There is one user with $|W|=1,|S|=M$ such that $0\leq M\leq K-1$;
\item The demand index $W$ and the side information index set $S$ (given the demand index $W$) follow the distributions given in \eqref{eq:WantSetDist} and \eqref{eq:SideInfoDist}, respectively.
\end{itemize}
In this scenario, the multi-server $W$-PIR-SI scheme satisfies the $W$-privacy, and has rate $$R = \left(1 + 1/N + \cdots + 1/N^{K/(M+1)-1}\right)^{-1}$$
%\footnote{It is noted that Lemma \ref{lem:WPIRAch-NonDivis} is a generalization of Lemma \ref{lem:WPIRAch}}.
\end{lemma}
\begin{proof}%(sketch)
First, note that since the messages $\{X_1,\dots,X_K\}$ are uniform and independent, the super-messages $\{\hat{X}_1,\dots,\hat{X}_K\}$ are uniform and independent as well. Therefore, the rate of the scheme is that of the Sun-Jafar protocol for $N$ servers and $\frac{K}{M+1}$ messages,  which is $\left(1 + 1/N + \cdots + 1/N^{K/(M+1)-1}\right)^{-1}$, see~\cite[Theorem 1]{sun2016capacitynoncol}. 

To prove the privacy, we note that, since the Sun-Jafar protocol protects the  privacy of the demanded super-message, \ie, any server cannot have any information about which super-message the user is trying to download. Therefore, from the perspective of each server, every super-message is  equally likely to include the demanded message in the linear combination. Further, the demanded message can be any one of the $M+1$ messages in a super-message. In other words, we have
$$\mathbb{P}(\mathbf{W}\in P_i \mid \Q{W}{S}) = \frac{M+1}{K}, \quad \forall i\in[g],$$
and\\ 
$$ \mathbb{P}(\mathbf{W} = W \mid \mathbf{W}\in P_i,\Q{W}{S}) = \frac{1}{M+1},\quad\forall i\in[g].$$
Hence, we have
$$\mathbb{P}(\mathbf{W} = W|Q^{[W,S]})  = \frac{1}{K}.$$
% \begin{eqnarray*}
% \hspace{-2mm} & = & \hspace{-2mm} \sum_{i = 1 }^{g} \mathbb{P}(\mathbf{W} = W | \mathbf{W} \in P_i)\mathbb{P}(\mathbf{W} \in P_i)\\ %\frac{M+1}{K}\times \frac{1}{M+1} \\ 
% & = & \frac{1}{K}.
% \end{eqnarray*}
\end{proof}


\section{Conclusion}
\label{sec:conclusion}

In this paper we considered the problem  of 
Private Information Retrieval (PIR) with side information, in which the user has {\it a priori}  a subset of the messages at the server obtained from other sources. The goal of the user is to download a message, which  is not in its side information, from the server while satisfying a certain privacy constraints. We consider two privacy requirements: $W$-privacy in which the user wants to protect the identity its demand  (i.e., which message it wants to download), and $(W,S)$-privacy in which the user wants to protect the identity of the demand and  the side information  jointly. First, we focus on the case of single server (i.e., single database). We establish the PIR capacity for $(W,S)$-privacy for arbitrary distribution of the demand index $W$ and the side information index set $S$. %, and discuss an achievable scheme. 
In the case of $W$-privacy, we establish the  PIR capacity  for the uniform distribution. Second, we extend our PIR scheme for $W$-privacy to the case of multiple servers (multiple copies of the database). Our scheme for the multiple servers uses ideas from the single server scheme in conjunction with the no-side-information scheme of Sun and Jafar in~\cite{sun2016capacitynoncol}. The multi-server capacities of PIR with side information under the  $W$-privacy and $(W,S)$-privacy constraints remain open.

% class of distributions of $W$ and $S$, called the uniform distribution. %and discuss an achievable scheme. 

% As part of the future work, it would be interesting to consider the case of multiple users, where multiple users each with their own individual side information sets want to retrieve messages privately from the server. %is an interesting direction to explore . 
% How the queries of the users are structured and how the server minimizes the transmissions it needs to send to satisfy the clients are areas of interest. The case when a user wants to retrieve multiple messages from the server while leveraging their side information is another open direction; how to structure queries to protect all items in their demand set becomes an interesting problem. %Another question that is worth exploring is how a user already having side information affects schemes that already exists, and how this may affect the capacity of such situations.
\bibliographystyle{IEEEtran}
\bibliography{PIR_salim,coding1,coding2,pir_bib}


% that's all folks
\end{document}



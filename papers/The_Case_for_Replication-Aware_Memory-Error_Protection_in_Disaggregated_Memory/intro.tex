\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}

\IEEEPARstart{R}{ecent} technology advances in high-density, byte-addressable non-volatile memory (NVM)\ignore{~\cite{wang:model-nvm:micro:2020}}
and low-latency interconnects\ignore{~\cite{knebel:genz:hotchips:2019,pinto:thymesis:micro:2020}}
have enabled building rack-scale systems with a large disaggregated memory pool shared across decentralized compute nodes~\cite{pinto:thymesis:micro:2020, tsai:dpm:atc:2020}.
\ignore{
Although memory disaggregation can be applied to both DRAM~\cite{pinto:thymesis:micro:2020} and NVM~\cite{tsai:dpm:atc:2020}, 
we focus on NVM disaggregation due to its potential for building memory pools of higher capacity. 
}
Unlike conventional rack-scale systems that are built with monolithic servers, each of which contains memory that is directly attached to the processor (Figure \ref{fig:rack-scale-nvm}(a)), disaggregated architectures decouple the processor from memory into separate compute and memory nodes  (Figure \ref{fig:rack-scale-nvm}(b)). 
This improves 
\ignore{
(i) separate evolution and scaling of processing and memory, which lets tailoring the compute-to-memory ratio to the specific needs of the workload, 
}
(i) memory utilization as memory is shared across multiple compute nodes, and (ii) failure isolation as compute and memory nodes can fail independently. 
%without affecting each other's availability.

A key challenge with building a large disaggregated memory pool based on NVM is efficiently tolerating memory errors at scale.
Nanoscale NVM technologies can be denser but also less reliable than DRAM due to their higher random raw bit error rate (RBER)~\cite{zhang:pm-chipkill:micro:2018}.
Thus, while adopting NVM technologies is desirable as it enables disaggregated memory to scale to petabyte-order capacities, it also makes memory errors more frequent~\cite{faraboschi:mem-centric-os:hotos:2015}.
Hence, efficient techniques for mitigating memory errors will be key to building cost efficient disaggregated memory systems.
Unfortunately, traditional mitigation techniques, such as parity and chipkill-correct, which can detect or correct memory errors, incur expensive storage costs.
Recent work has explored optimizations for chipkill-correct for NVM~\cite{zhang:pm-chipkill:micro:2018}, but storage cost remains  expensive ($\sim27\%$).

In this paper, we make the case for \emph{Replication-Aware Memory Protection} (\ramp).
\ramp seeks to further improve storage cost of memory error protection by leveraging the insight that many data-centric applications targeted by disaggregated memory~\cite{pinto:thymesis:micro:2020}, such as key-value stores and data analytics, replicate data to improve performance and availability.
Such applications will likely continue to replicate their data across multiple memory nodes in disaggregated memory to avoid a memory node from becoming a performance bottleneck or a single point of failure.
For example, a recent disaggregated key-value store~\cite{tsai:dpm:atc:2020} and a disaggregated operating system (OS)~\cite{shan:legoos:osdi:2018} replicate memory contents to improve availability.

\begin{figure}[!t]
\centering
\includegraphics[width=3in]{fig/direct-vs-disaggregated}
\caption{Rack-scale non-volatile memory (NVM) architectures}
\label{fig:rack-scale-nvm}
\vspace{-0.5cm}
\end{figure}

\ramp lets applications employing replication to control the hardware-level memory error protection of individual replicas at each memory node to reduce storage overhead.
Instead of trying hard to prevent uncorrectable memory errors within a single memory node, an application can accept the possibility of uncorrectable errors, and employ weaker but lower-overhead resilience within individual memory nodes while relying on the collective protection conferred by the presence of available replicas in other memory nodes to tolerate a memory error.

To help applications determine the right protection strength of individual replicas, a key contribution of this paper is an analytical model that models the impact of individual protection strength on the collective protection strength.
We demonstrate the utility of our model by applying it to a recent chipkill-correct design~\cite{zhang:pm-chipkill:micro:2018}.
By weakening the chipkill protection of each individual replica, we reduce storage cost from $27\%$ down to $17.7\%$ while we attain the same protection level as the original design through the collective protection of multiple replicas. 
\subsection{Choosing replica protection strength}

A key challenge in applying \ramp is choosing the right hardware protection strength of individual replicas. 
Weakening hardware-level protection of individual replicas lowers storage cost but makes DUEs and NDEs more frequent, increasing UBER and SDC rates respectively.
We can recoup the lost UBER by correcting a DUE using available replicas, at the expense of a performance overhead to access and process additional replicas.
However, we cannot always rely on replicas to recoup the lost SDC rate. 
This is because a NDE that silently corrupts data may not trigger replication-based correction, unless the application can detect the error through other means, such as checksumming~\cite{zhang:pangolin:atc:2019}.
Hence, SDC rate may limit how much we can weaken individual replica strength.

\ignore{
Lowering protection strength, increases UBER and SDC of individual replicas.
Using available replicas to correct a memory error recoups the lost UBER.
It doesn't recoup the lost SDC because a silent error that goes undetected does not trigger a correction using replication.
SDC rates are typically lower than UBER rates, so this gives some space for improvement.
So, we can lower protection strength, as long as combined UBER of replicas and SDC of individual replicas remain above a target threshold.

This in turn makes accessing additional replicas because of a memory error more frequent, which introduces extra processing and communication and increases performance overhead.
}

To help application and system designers choose protection strength, we develop an analytical model that estimates the expected reliability and expected performance overhead when using available replicas to correct a DUE. 
For the reliability, we estimate the combined DUE resulting from using replicas to correct a memory error. 
Because NDE does not benefit from replication, we do not compute a combined NDE. 
However, we do estimate the NDE of each individual replica as a lower reliability bound. 
For the performance overhead, we compute the average number of additional replicas that are read to correct a memory error.
We assume that reading and processing each replica contributes fixed network bandwidth and CPU overhead per replica.

Our analytical model targets block-level replication, which is a common replication approach. 
The model differentiates between logical and physical blocks.
The logical block is the unit of recovery, that is the smallest unit of data that can be recovered by the replication protocol.
To enable recovery, a replication protocol maps a logical block to multiple physical block replicas stored across multiple memory nodes.
Reading a logical block may involve reading one or more physical blocks. 

\ignore{
Since we focus on protection techniques against random bit cell errors, our model focuses on read failures caused by uncorrectable memory errors due to random bit cell errors. 
Our model ignores other correlated failures that affect multiple bits and blocks, such as chip or channel failures due to logic circuit errors.
}

\ignore{
The model uses the following parameters: CPU cache-line size: $c$:, Physical-block size: $b$, Cache-line failure probability due to DUE: $p_c$, Physical-block failure probability due to DUE: $p_b$.
}

\begin{table}
\caption{Analytical model symbol notation}
\label{tab:model}
\vspace{-0.2cm}
\centering
\begin{tabular}{lp{6.5cm}}
\textbf{Symbol(s)} & \textbf{Description} \\
$c$, $b$        & \scriptsize{Cache-line size and physical-block size}\\
$\pcdue$, $\pcnde$  & \scriptsize{Cache-line failure probability due to DUE and NDE}\\
$\pbdue$, $\pbnde$  & \scriptsize{Physical-block failure probability due to DUE and NDE}\\
%$\pldue$, $\plnde$  & \scriptsize{Logical-block failure probability due to DUE and NDE}\\
$\pldue$  & \scriptsize{Logical-block failure probability due to DUE}\\
\end{tabular}
\vspace{-0.25cm}
\end{table}

The model uses the symbol notation shown in Table \ref{tab:model}.
%
Cache-line failure probability is the probability to fail when reading a cache-line worth of data from the memory system.
This probability depends on the memory protection scheme and the RBER of the NVM technology.
Although the RBER in NVM increases with the amount of time since last write or refresh, 
to simplify our model, we use a single worst-case value that is based on the RBER at the end of the refresh period\ignore{, which can range from a week to a year}. 
%
Physical-block failure probability is the probability to fail when reading a physical-block worth of data from the memory system.
Successfully reading a physical block entails successfully reading all the cache lines that comprise the block. 
We can derive the physical-block failure probability as follows:
\ignore{from the cache-line failure probability:}

% \begin{equation}
% p_b&= 1 - (1-p_c)^{b/c} \quad \mathrm{and} \quad  p_b&= 1 - (1-p_c)^{b/c} 
% \end{equation}
\vspace{-0.2cm}
\begin{equation*}
\pbdue= 1 - (1-\pcdue)^{b/c} \quad \mathrm{and} \quad \pbnde= 1 - (1-\pcnde)^{b/c}
\end{equation*}

%
We next study two common application-level redundancy schemes: primary-backup replication and erasure coding.

\mypar{Primary-backup replication}
For each logical block, the replication protocol maintains a primary physical block and a sequence of N-1 backup physical replica blocks.
When a compute node needs to read a logical block, it first reads the primary physical block. If the read fails because of a DUE, then it tries the next backup physical block in the sequence, continuing this process until it successfully reads a block. 
When the compute node exhausts trying all available physical blocks without successfully reading one, the logical-block read fails with an uncorrectable memory error.

The probability to have a DUE when reading a logical block is the joint probability of all physical-block reads to fail:
\[
\pldue = \pbdue^{N}
\]

\ignore{
\fixme{The probability to have a NDE when reading a logical block is the union probability of all physical-block reads to fail}:

\[
\plnde = \sum_{i=0}^{N-1} (1-\pbdue)^i \pbnde
\]
}

The average number of additional physical blocks that are read after failing to read the first physical block is:

\[
\begin{split}
a_r&= -1 + \sum_{i=0}^{N-1} \pbdue^i(1-\pbdue)(i+1)
\end{split}
\]

% \[
% \begin{split}
% a_r&= -1 + Np^{N-1}+\sum_{i=0}^{N-2} p_b^i(1-p_b)(i+1)
% \end{split}
% \]

\mypar{Erasure coding}
Erasure coding provides redundancy without the overhead of complete replication.
Erasure coding divides a logical block into K physical blocks and recodes them into N physical replica blocks, where N $>$ K.
%Reed-Solomon code (RS-code) is a commonly used coding scheme. RS(K, N)
When a compute node needs to read a logical block, it can perform the read using any K physical blocks of the N physical blocks. If the compute node fails to read any of the physical blocks (due to an uncorrectable memory error), then it tries another physical block. 
When the compute node exhausts trying all available physical blocks without successfully reading K blocks, the logical-block read fails with an uncorrectable memory error.

The probability to have a DUE when reading a logical block is the probability to have at least N-K+1 physical blocks fail due to a DUE:


\begin{equation*}
\pldue = \sum_{i=N-K+1}^{N}\binom{N}{i}\pbdue^{i}(1-\pbdue)^{N-i}
\end{equation*}

\ignore{
    \begin{equation*}
    \pldue = \sum_{i=N-K+1}^{N}f(i,N,\pbdue)
    \end{equation*}
    
    \begin{equation*}
    \mathrm{where}\quad
    f(k,n,p) = \binom{n}{k}p^{k}(1-p)^{n-k}
    \end{equation*}
    
    The probability to have a NDE is the number of ways in which we can read K physical blocks plus extra physical blocks due to DUE multiplied by the probability to have physical blocks fail due to DUE multiplied by the probability to have at least one physical block fail due to a NDE: 
    
    \begin{equation*}
    \plnde = \sum_{i=0}^{N-K}\binom{N}{K+i}f(i,K+i-1,\pbdue)\sum_{j=1}^{K-1}f(j,K-1,\pbnde)
    \end{equation*}
}

The average number of additional physical blocks that are read after failing to read any of the first K physical blocks is:

\begin{equation*}
a_r= -K + \sum_{i=0}^{N-K} \binom{N}{K+i} \binom{K+i-1}{i}\pbdue^{i}(1-\pbdue)^{K-1}(K+i)
\end{equation*}

\noindent where each sum term is the number of ways in which we can read physical blocks multiplied by the probability to have physical blocks fail due to DUE multiplied by the number of physical blocks read.
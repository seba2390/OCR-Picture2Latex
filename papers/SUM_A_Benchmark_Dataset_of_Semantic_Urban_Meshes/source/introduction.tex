\section{Introduction}%
\label{sec:intro}

Understanding the urban environment from 3D data (e.g.\ point clouds and 3D meshes) is a long-standing goal in photogrammetry and computer vision~\citep{matrone2020heritage, hackel2017semantic3d}. 
The fast recent developments in data acquisition technologies and processing pipelines have allowed us to collect a great number of datasets on our 3D urban environments. 
Prominent examples are Google Earth~\citep{Google3d}, texture meshes covering entire cities (e.g.\ Helsinki~\citep{Helsinki3d}), or point clouds covering entire countries (e.g., the Netherlands AHN~\citep{ahn2019}). 
These datasets have attracted interest because of their potential in several applications, for instance, urban planning~\citep{Chen2011,czynska2014application}, positioning and navigation~\citep{cappelle2012virtual,Peyraud2013,Hsu2015}, spatial analysis~\citep{Yaagoubi2015}, environmental analysis~\citep{Deng2016}, and urban fluid simulation~\citep{GarciaSanchez14}. 

To effectively understand the urban phenomena behind the data, a large amount of ground truth is typically required, especially when applying supervised learning-based techniques, such as a deep Convolutional Neural Network (CNN). 
The recent development of machine learning (especially deep learning) techniques has demonstrated promising performance in semantic segmentation of 3D point clouds~\citep{qi2017pointnet,landrieu2018large, thomas2019kpconv}. 
Compared to point clouds, a surface representation (in the form of a 3D mesh, often with textures, see Figure~\ref{fig:texside} and \ref{fig:semside} for an example) of the urban scene has multiple advantages: easy to acquire, compact storage, accurate, and with well-defined topological structures.

\begin{figure}[H]
	\includegraphics[width=\linewidth]{figures/overview_grids/zoom_tex_mesh.png} 
	\caption{Part of the semantic urban mesh benchmark dataset shown as a texture mesh.}
	\label{fig:texside}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{figures/overview_grids/zoom_sem_mesh2.png} 
	\centering
	\includegraphics[width=0.9\textwidth]{figures/semantic_results/semantic_legend.png}
	\caption{Part of the semantic urban mesh benchmark dataset, showing the semantic classes (unclassified regions are in black). }
	\label{fig:semside}
\end{figure}

This means that 3D meshes have the potential to serve as input for scene understanding. 
As a consequence, there is an urgent demand for large-scale urban mesh datasets that can be used as ground truth for both training and evaluating the 3D semantic segmentation workflows.

In this paper, we aim to establish a benchmark dataset of large-scale urban meshes reconstructed from aerial oblique images. 
To achieve this goal, we propose a semi-automatic mesh annotation framework that includes two components: (1) an automatic process to generate intermediate labels from the raw 3D mesh; (2) manual semantic refinement of those labels.
For the intermediate label generation step, we have developed a semantic mesh segmentation method that classifies each triangle into a pre-defined object class. 
This semantic initialization allows us to achieve an overall accuracy of 93.0\% in the classification of the triangle faces in our dataset, saving significant efforts for manually labelling.
Then, in the semantic refinement step, a mesh annotation tool (which we have developed) is used to refine the semantic labels of the pre-labelled data (at the triangle and segment levels).

We have used our proposed framework to generate a semantic-rich urban mesh dataset consisting of 19 million triangles and covering about 4 $km^2$ with six object classes commonly found in an urban environment: terrain, high-vegetation, building, water, vehicle, and boat (Figure~\ref{fig:semside} shows an example from our dataset).
With our semi-automatic annotation framework, generating the ground truth took only about 400 hours; we estimate that manually labelling the triangles would have taken more than 1000 hours. 
The contributions of our work are: 
\begin{itemize}
	\item a semantic-rich urban mesh dataset of six classes of common urban objects with texture information;
	\item a semi-automatic mesh annotation framework consisting of two parts: a pipeline for semantic mesh segmentation and 
	an annotation tool for semantic refinement;
	\item a comprehensive evaluation and comparison of the state-of-the-art semantic segmentation methods on the new dataset.
\end{itemize}
The benchmark dataset is freely available, and the semantic mesh segmentation methods and the annotation software for 3D meshes are released as open-source\footnote{\url{https://3d.bk.tudelft.nl/projects/meshannotation/}}.




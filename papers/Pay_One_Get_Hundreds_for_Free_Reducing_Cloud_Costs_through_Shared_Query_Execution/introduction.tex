\section{Introduction}

%%In \athena, it accounts only for every byte
%%read from \sss (S3) without taking into account how computationally expensive a
%%query is nor the bytes read from and written to intermediate results. In
%%\bigquery, it accounts for bytes read from storage plus bytes generated by
%%complex user-defined functions or from cross-join operations. Thus, as long as
%%the output size is proportional to the input size, the amount of bytes processed
%%is similar to the amount of bytes read from storage.  

%\Qaasl (\qaas) enables users to query data already hosted in the cloud without
%having to deploy any extra infrastructure and without requiring extra ETL
%processes for data in the cloud. The pricing model used in \qaas is
%straightforward as users are billed per the total number of bytes processed by
%each of their queries.

%The low initial investment cost and the pay-as-you-go pricing model makes \qaas

%\todo[inline]{The following paragraph was updated} 
\Qaasl (\qaas) enables users to query data already
hosted in the cloud without having to deploy extra infrastructure. Its pricing
model charges users only for the total number of bytes
processed by each query.  Applications accessing the same data set frequently
will become more expensive over time.  Examples of applications where sets
of queries will go repeatedly over the same data include search applications exploring a
solution space through parameter sweep queries to provide multiple alternative
answers (e.g., searching for airline tickets with multiple routes
\cite{Unterbrunner:2009:PPU:1687627.1687707}), reporting over different subsets
of the same data (e.g., maintaining BI dashboards
\cite{Wu:2014:CDV:2732951.2732964}), or what-if analysis.

Another appealing aspect of \qaas systems is the use of \sql for accessing and
managing data. Although, retrieving results is as easy as issuing \sql
statements, the possibilities for optimizing such systems are only at the \sql
level. Thus, users have almost no way to improve execution time further than
optimizing single query formulations and no obvious way to improve throughput
without directly increasing the monetary costs of executing queries.

The current pricing model from \qaasl systems, \athena and \bigquery, and the
limitations to optimize query execution motivate this work. In this context, we
extend the ongoing research on shared query execution to \qaasl systems by
exploiting sharing opportunities at the \sql level to reduce query
execution costs.  Existing work takes a rather invasive approach by modifying,
enhancing, or rewriting the query engine, which makes them not suitable for
\qaasl systems.

In this paper, we show how to group and rewrite
\sql queries to be executed as a batch without modifying the underlying
system.
Queries are grouped and re-written as
part of an external middleware and the process does not require user input.
Thus, we trade off individual query latency for a throughput increase
while maintaining low execution costs.  This results in a smaller amount of work
to be done (i.e., data access) by the shared execution of multiple queries
compared to performing each query one at a time. In practice, the cost of executing a group
of queries is often the same as for executing a single query due to the current
\qaasl pricing model.  For example, Figure~\ref{fig:in:tpch6_qcost} shows the
execution cost in \athena of running up to 128 parameterized instances of TPC-H
    Query 6, i.e., each one requiring different subsets of data although all of
    them accessing the same base table.
Executing one
query after the other (following a query-at-a-time approach)
results in a very expensive workload. 
However, if we use a shared execution
approach and execute the queries together as a batch, we get a flat execution cost
regardless of the number of queries in the batch.  Even just a few queries
grouped together already provide significant savings. By grouping
128 queries together, we can increase
the throughput of this query by over 66x without increasing execution
cost over running a single query.

%In this paper, we argue that leveraging sharing opportunities can be done at
%different levels of the data processing stack as , e.g., in the client, as an
%external library in the client or server side, or by modifying the server.

%\begin{figure}[H]
%    \def\svgwidth{0.5\linewidth}
%    \input{images/gradual_sharing.pdf_tex}
%    \centering
%    \caption{Levels for exploiting sharing opportunities.}
%    \label{fig:in:gradual_share}
%\end{figure} 


\begin{figure}[t]
    \includegraphics[width=0.4\textwidth]{plots/tpch1_qcost}
    \centering
    \caption{TPC-H Q6 execution cost in \athena.}
    \label{fig:in:tpch6_qcost}
\end{figure} 

The main contributions of this paper are: 1) we enable 
cloud based \qaasl systems to perform shared execution without having to
re-engineer the underlying engine; 2) we present how relational operators
can be rewritten at the \sql level to support sharing by using a nested
representation of which tuple is of interest to a query; 3) we analyze the impact
of sharing for different operators and for more complex queries in terms of cost
and execution time on cloud based \qaasl systems; 4) we demonstrate the
potential of our approach with a TPC-H workload that we show executes 
up to two orders of magnitude
cheaper.


\section{Introduction}\label{sec:intro}

% Necessity of RS
Nowadays, users are faced with such a large volume of  products and information to the extent that filtering has become a necessity. 
Furthermore, not every user has the same preferences, and therefore a standard selection cannot be performed.
Both problems can be tackled with Recommender Systems (RS), that provide users with a personalized list of items.
% long tail
Moreover, for organizations with vast inventories, it is of great interest to recommend infrequent products, \emph{i.e.} items queuing in the long tail of the catalogue of items~\cite{Anderson:2006:long_tail}.  
Nevertheless, most RS algorithms tend to over-recommend popular items, precisely because their metric performance generally decreases when recommending less frequent items~\cite{Steck:2011:IPR}.   

% Collaborative filtering with implicit feedback
An increasingly adopted approach to RS is collaborative filtering (CF) for implicit feedback datasets~\cite{HuKoren:2008:CF_implicit, Pan:2008:OCCF}.
This technique makes predictions about the interests of a user
by gathering  preferences in the form of purchases, clicks, logs, etc. from many other users.
These preferences are influenced by non-obvious factors that depend on the domain.
The goal of model based CF approaches such as matrix factorization is to infer
the latent factor model underlying the data.

% Introduction to Missing Information
Making predictions about user preferences in RS based on implicit feedback data is not an easy task, not only because of  the lack of information about unobserved user-item interactions, but also due to the subsequent high sparsity of the rating matrix.
In order to deal with this issue of missing information, several approaches can be considered. 
% Literature overview of Missing Information
A naive strategy for one--class collaborative filtering consists of considering all unobserved items either as negative examples (All Missing As Negative) or simply to ignore them (All Missing As Unknown)~\cite{Pan:2008:OCCF}. However, these two extreme methodologies may involve either biased recommendations (as some of the missing data might be relevant to the user) or trivial solutions caused by predicting all missing values as positive examples.
More advanced approaches entail the use of different weighting schemes in the error terms to balance observed and unobserved items~\cite{HuKoren:2008:CF_implicit, Pan:2008:OCCF, Steck:2010:MissingNotAtRandom}. In order to alleviate the computational burden of considering every single item during the training process  (which does not scale linearly as the item catalogue grows), several negative sampling techniques have been proposed, see \emph{e.g.}~\cite{Pan:2008:OCCF}. 

% missing information 
It should be noted that all these approaches cast missing entries as zeros, \emph{i.e.} treat unobserved user-item interactions as negative feedback. Since the loss functions considered in those works are designed to push items with negative feedback towards a zero recommendation, in practice  a zero preference will be inferred for most of the missing entries. 

% Work on multi-class 
In addition to the one-class collaborative filtering setting, the RS problem can be viewed as a multi-class classification problem, where the recommendation problem is cast as the calculation of the probability of a user belonging to each item class. Indeed, the multinomial distribution has been recently applied to different Autoencoder (AE) architectures~\cite{liang:2018:VAE}. In contrast to the above-mentioned objective functions, the log-likelihood of the multinomial distribution does not explicitly penalize missing entries so as to force them to have a zero probability of being recommended. However, the normalization condition of the probability distribution, together with the large item catalogues used in RS (typically  $>10$k items), make it unlikely that non-seen items have a probability of being recommended other than zero.

% Our proposal
In this paper we propose to tackle the problem of missing information by using a novel objective function that specifically forbids missing user--item interactions to have a preference prediction of $1$ (since they are not positive feedback) or $0$ (to distinguish them from negative feedback).  We name this cost function the \emph{Missing Information Loss} (MIL).
% Performance
We apply MIL to both Matrix Factorization (ML) and Denoising AE (DAE)~\cite{Vincent:2008:ECRF-AE}, as the later has been shown to be a generalization of traditional MF models~\cite{Wu:2016:CDAE-topN}. We compare the results with DAEs optimized with cross-entropy loss (in both point and pair--wise learning schemes)~\cite{Wu:2016:CDAE-topN} and the multinomial loss~\cite{liang:2018:VAE}; as well as MF models~\cite{HuKoren:2008:CF_implicit} trained with square and cross-entropy loss. 
%Our experiments demonstrate the competitive performance of MIL function.

% Contributions
Our contributions can be summarized as follows:
\begin{itemize}
\item We propose a new objective function (MIL) for modeling missing information in implicit feedback datasets. It explicitly forbids either a $1$ or $0$ prediction for the preference of unobserved user--item interactions, thus leaving the ranking process almost entirely to the low-rank process underlying all forms of matrix factorization. 
\item We show that the \textsc{MIL} function achieves state-of-the-art metric performance when applied to MF and DAE architectures, 
%in terms of rank--aware relevance and novelty metrics, 
similar to the best performing, well established, objective functions. 
\item Furthermore, we demonstrate that the observed competitive performance (in terms of relevance) occur while recommending popular items less frequently, which favours the appearance of medium and long--tail items in the ranked list of recommendations.
\end{itemize}
	
% Outline: 
The rest of the paper is organized as follows.
In section \ref{sec:model} we review some of the objective functions that are commonly used in RS literature, and introduce the MIL function. Next, we briefly revisit the DAE and MF architectures. 
After that, in section \ref{sec:protocols}, we describe the experimental methodology: datasets, metrics for evaluation, the implementation details of the proposed solution, and the baseline models used for comparison.
Next, section \ref{sec:results} shows the experimental results in terms of ranking metrics, as well as the observed distribution of recommendations.
Finally, we draw some conclusions in section \ref{sec:conclusions} and 
indicate future lines of research.

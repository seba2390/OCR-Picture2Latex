\documentclass[sigconf]{acmart}

\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers

\usepackage{booktabs} % For formal tables
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{color}
\usepackage{arydshln }


%Conference
\acmConference[WSDM]{The Twelfth International Conference on Web Search and Data Mining}{February 11--15}{Melbourne, Australia} 
\acmYear{2019}

\begin{document}
\title[Missing Information Loss]{A Missing Information Loss for implicit feedback datasets}

\author{Juan Ar\'evalo}
\affiliation{%
  \institution{BBVA Data \& Analytics}
}
\email{juanmaria.arevalo@bbvadata.com}

\author{Juan Ram\'on Duque}
\affiliation{%
  \institution{BBVA Data \& Analytics}
}
\email{juanramon.duque@bbvadata.com}

\author{Marco Creatura}
\affiliation{%
  \institution{BBVA Data \& Analytics}
}
\email{marco.creatura@bbvadata.com}

% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{Ar\'evalo, Duque and Creatura}

% Some useful commands
\newcommand{\MFsquare}{\textsc{MF-square}}
\newcommand{\MFmil}{\textsc{MF-mil}}
\newcommand{\MFce}{\textsc{MF-CE}}
\newcommand{\CEpointlinsig}{\textsc{CE$_{\rm Point}$ lin-sig}}
\newcommand{\CEpointsigsig}{\textsc{CE$_{\rm Point}$ sig-sig}}
\newcommand{\CEpairlinsig}{\textsc{CE$_{\rm Pair}$ lin-sig}}
\newcommand{\CEpairsigsig}{\textsc{CE$_{\rm Pair}$ sig-sig}}
\newcommand{\MULTItanhlin}{\textsc{MULTI tanh-lin}}
\newcommand{\MILlinsig}{\textsc{MIL lin-sig}}
\newcommand{\MILsigsig}{\textsc{MIL sig-sig}}


\begin{abstract}
% missing values and negative feedback
Latent factor models for Recommender Systems with implicit feedback typically treat unobserved user-item interactions (\emph{i.e.} missing information) as negative feedback. This is frequently done 
either through negative sampling (point--wise loss) or with a ranking loss function (pair-- or list--wise estimation). 
% Common objective functions allow zero prediction
Since a zero preference recommendation is a valid solution for most common objective functions, 
regarding unknown values as actual zeros results in users 
having a zero preference recommendation  for most of the available items. 

% MIL
In this paper we propose a novel objective function, the \emph{Missing Information Loss} (MIL), 
that explicitly forbids treating unobserved user-item interactions as positive or negative feedback. 
% application to AE and metrics
We apply this loss to both traditional Matrix Factorization and user--based Denoising Autoencoder, and compare it with other established objective functions such as cross--entropy (both point-- and pair--wise) or the recently proposed multinomial log-likelihood. MIL achieves competitive performance in ranking--aware metrics when applied to three datasets.
% towards long-tail recommendations
Furthermore, we show that such a relevance in the recommendation is obtained while displaying popular items less frequently (up to a $20 \%$ decrease with respect to the best competing method). This debiasing from the recommendation of popular items favours the appearance of infrequent items (up to a $50 \%$ increase of long--tail recommendations), a valuable feature for Recommender Systems with a large catalogue of products. 
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002951.10003317.10003347.10003350</concept_id>
<concept_desc>Information systems~Recommender systems</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Recommender systems}

\keywords{Collaborative Filtering, Autoencoders, Implicit Feedback, Missing Information}

\setcopyright{None}

\maketitle

\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{-10pt}

% Put all the sections with inputs

\input{intro}

\input{model}

\input{protocols}

\input{results}

\section{Conclusions and next steps}\label{sec:conclusions}

% definition of MIL
In this paper we present a novel objective function, the \emph{Missing Information Loss} (MIL), specifically designed for handling unobserved user-item interactions in implicit feedback datasets. In particular, MIL explicitly forbids treating missing user-item interactions as positive or negative feedback.
% What it does
We demonstrate that, thanks to the functional form of the MIL function, the ranking of unseen items is almost entirely left to the low--rank process, rather than forcing unobserved items to be at the tail of the recommendation (\emph{i.e.}, MIL does not force a zero predicted preference for unobserved user-item interactions). 

% Metric results
Extensive experiments with Matrix Factorization and Denoising Autoencoders conducted on three datasets, show that \textsc{MIL} models demonstrate competitive performance when compared with other traditional losses such as cross-entropy or the multinomial log-likelihood. 
% Best performing models 
% Analysis of recommendations
In addition, we study the distribution of the recommendations and observe that the reported metric performance takes place while recommending popular items less frequently (up to a $20 \%$ decrease with respect to the best competing method). Indeed, \textsc{MIL} models sharply increase the recommendation of medium--tail items, while almost linearly expanding the appearance of long--tail items with the ranking position in the list of recommendations. Such expansion results in up to a $50 \%$ increase of long--tail recommendations, a feature of utmost importance for industries with a large catalogue of items. 

% Future work
Future lines of research may involve the incorporation of negative feedback, or the usage of \textsc{MIL} in temporal--aware Recommender Systems (such as those using Recurrent Neural Networks).  
In addition, we hope that the results here reported  will bring forward first-principle mathematical derivations of the \textsc{MIL} function, so that the vast family of possible polynomials modelling the missing information term can be reduced, or even extended with more suitable functions. 

\begin{acks}
We would like to thank the continuous support and careful reading of the manuscript by the \emph{Edge} guild within BBVA Data \& Analytics, specially J. Garc\'ia Santamar\'ia and J. A. Rodr\'iguez Serrano. 
\end{acks}

%\bibliographystyle{ACM-Reference-Format}
\bibliographystyle{unsrt}
%\bibliography{sigproc} 

\input{MIL.bbl}
\end{document}

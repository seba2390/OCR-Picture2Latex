\section{Experimental protocols}\label{sec:protocols}
\subsection{Datasets}

We use the 
MovieLens--20M\footnote{http://grouplens.org/datasets/movielens}
and Netflix\footnote{http://www.netflixprize.com} explicit feedback  datasets.
As both  of these contain explicit ratings, we create binary preferences
by keeping ratings $\ge\!4$, which we interpret as positive feedback ($p_{ui}=1$).
Furthermore, we only keep users with at least 5 views.
Validation and test sets are obtained randomly, selecting a $10~\%$ of the original dataset for each set. We denote such datasets \textsc{ML20M} and \textsc{Netflix}.

In addition, we explore models performance on the Last.fm\footnote{https://www.upf.edu/web/mtg/lastfm360k} dataset~\cite{Celma:Springer2010}, an implicit feedback dataset consisting of tuples (user, artist, plays), that contains top artists by user. In order to make the comparison with the above datasets more straightforward, we binarize play counts and interpret them as implicit preference data. Next, we filter out artist with less than 50 distinct listening users, and user with less than 20 artists in their listening history. In the following, we name this dataset \textsc{Lastfm}.

\setlength{\belowcaptionskip}{5pt}
\begin{table}[htb]
\begin{tabular}{c c c c c}
 Dataset & \#users & \#items & \#pairs & \#pairs$_{\rm test}$ \\
\hline
\textsc{ML20M} & 136,7k & 20,3k & 7,99M & 1,0M \\
\textsc{Netflix}  & 463,4k & 17,7k & 45,5M & 5,7M \\
\textsc{Lastfm}  & 350,2k & 24,6k & 12,8M & 1,6M \\
\hline
\end{tabular}
\caption{Statistics of the datasets after preprocessing.}
\label{table:datasets}
\end{table}

The statistics of the training set after such  processing, as well as the number of user-item interactions in test, are presented in Table~\ref{table:datasets}. 
%We also represent the item popularity distribution in training, validation and test sets in Figure~\ref{fig:ditribution_dataset} for the \textsc{ML20M},  \textsc{Netflix}, \textsc{Lastfm} datasets, from top to bottom, respectively. As expected, validation and test distributions  follow the distribution of the training set. 

% \begin{figure}
%     \centering
%     \includegraphics[width=.7\linewidth]{figures/distributions_dataset.png}
%     \caption{Normalized distributions of user-item interactions in train (green), validation (red) and test (blue) sets for the  \textsc{ML20M},  \textsc{Netflix} and \textsc{Last-fm} datasets (from top to bottom, respectively).}
%     \label{fig:ditribution_dataset}
% \end{figure}

\subsection{Evaluation metrics}\label{subsec:metrics}
\setlength{\belowcaptionskip}{-10pt}
Given the set of adopted items in test, $\mathcal{I}_u^{\rm t}$, and the ranked list of predicted preferences, 
the relevance of a recommendation at position $k$ is given by ${\rm rel}_{ui}(k)$--${\rm rel}(k)$ from here on--, which equals $1$ if user $u$ adopted item $i$ in the test set, $0$ otherwise. In the calculation of metrics, we remove items observed in  training and validation from the list of recommendations. 
Next, we detail the metrics used for model evaluation.

\paragraph{Recall} It does not account for the relative ordering of the recommendation, and we defined it as~\cite{liang:2018:VAE}
\begin{equation}
{\rm Recall}@k = \frac{\sum_{s=1}^k {\rm rel}(s)}
{\mathcal{N}_u(k)}.
\end{equation}
Here, $\mathcal{N}_u(k) = \min\left(k,|\mathcal{I}_u^{\rm t}|\right)$, with $|\mathcal{I}_u^{\rm t}|$ the number of items adopted by user $u$ in testing. The final recall is averaged across all users in testing. 

\paragraph{Normalized Discount Cumulative Gain} In contrast to recall metric, the Discount Cumulative Gain (DCG) performs a logarithmic discount according to the position of a recommendation, that is
\begin{equation}
{\rm DCG}@k = \sum_{s=1}^k \frac{{\rm rel}(s)}
{\log_2(s+1)}.
\end{equation}
This quantity can be normalized by the Ideal DCG, 
\begin{equation}
{\rm IDCG}@k = \sum_{s=1}^{\mathcal{N}_u(k)} \frac{1}{\log_2(s+1)}.
\end{equation}
Finally, NDCG$@k= {\rm DCG}@k/{\rm IDCG}@k$, which we average across all users in the test set.

\paragraph{Novelty} Following reference~\cite{Vargas:2011:Novelty_diversity}, we define a novelty-weighted DCG score as
\begin{equation}\label{eq:nov-ndcg}
{\rm Nov\!-\!DCG}@k = 
-\sum_{s=1}^k \frac{{\rm rel}(s)\times \ln{\nu(i)}}
{\log_2(s+1)}.
\end{equation}
Here, $\nu(i)$ is the frequency of occurrences of item $i$  normalized to the total interactions in training. The corresponding novelty-weighted IDCG would be
\begin{equation}
{\rm Nov\!-\!IDCG}@k = 
\sum_{s=1}^{\mathcal{N}_u(k)} 
\frac{\max_{i\in\mathcal{I}_u}\left(-\ln \nu(i)\right)}
{\log_2(s+1)}.
\end{equation}
In other words, the highest DCG is obtained by ranking the most novel items (among those relevant to the user) in descending order. 
\subsection{Implementation details}\label{subsec:implementation}
The implementation of our model is performed in TensorFlow~\cite{tensorflow2015-whitepaper}.
%\footnote{The code will be available online at
%\url{https://github.com/bbvadata/RecApp}.
%}. 
The model can be trained in both CPU or GPU. 
When GPU is enabled, the use of queues to feed the tensors greatly speeds up the training.
% batch size and epoch
We set the batch size to $100$, and train every DAE model for $120$k iterations, so as to ensure proper convergence. For MF models we use $180$k iterations.
% number of neurons
The number of neurons is $200$ in all DAE experiments; for MF models, since the large number of users makes them prone to overfit, we train the models with $100$ and $200$ neurons and take the best performing model.
% weights and biases initialization
Weight matrices are initialized with random uniform values whose amplitude is computed as described by Glorot~\emph{et al.}~\cite{Xavier_initialization}. 
%Generally speaking, we discourage the use of random normal initialization without truncation.
For the biases we use a truncated random normal initialization with a standard deviation of $10^{-3}$. 
% Optimizer
Models are trained with Adam optimizer~\cite{Kingma2014AdamAM} and a learning rate of $10^{-3}$.
% gradient clip
%Additionally, we clip gradients whenever they exceed a norm of $1$, and apply batch normalization~\cite{icml2015_ioffe15_batch-norm} at every training step.

% Size of T and P sets
Concerning negative sampling in point and pair--wise schemes, 
%since we train with a batch size different form one, 
we fix the size of the target sets for every user (sets $\mathcal{T}_u$ and $\mathcal{P}_u$ for point and pair--wise learning, respectively, see subsection~\ref{subsec:losses}).
In particular, we make such sets proportional to the median number of items adopted by users, except for the multinomial loss, where all items are utilized~\cite{Liang:2016:CoFactor}.
The proportionality factors are hyper-parameters fine--tuned with the validation set, swapping the values $\{1,\,5,\,10,\,50,\,100,\,150\}$. We find a factor of $50$ or $100$ to provide the best results.
%(see additional comments in subsection~\ref{subsec:baseline_models}).

% Max norm regularization
%Regarding max--norm regularization, we notice that an asymmetric max--norm regularization might be required for the encoder/decoder weight matrices, depending on the activations and objective functions utilized for modeling. We swap $\alpha_{\rm enc}$ and $\alpha_{\rm dec}$ values in $\{0.0, 0.05, 0.1, 0.2, 0.3, 0.5, 1.0\}$, where $\alpha=0.0$ means no regularization.

% Regularization: noise and weight-decay
We add noise to the input vector of the AE~\cite{Vincent:2008:ECRF-AE, Wu:2016:CDAE-topN} using drop-out~\cite{liang:2018:VAE}. We fix the level of noise at $0.5$. Competitive performance is achieved after normalizing the AE input vector.
% Regularization of MIL is smaller
For DAE models, we swap the $L_2$ regularization strength $\lambda\in[10^{-7}-10^{-4}]$, while for MF models we take the form in equation~(\ref{eq:l2_reg_scaled}) with $\lambda\in[10^{0}-10^{3}]$, which provides a more stable training for MF models\footnote{Recall the different scales of the $\lambda$ factor in equations (\ref{eq:L2_reg}) and (\ref{eq:l2_reg_scaled}).}. In general we find that MIL models require smaller $\lambda$ factors than cross-entropy or multinomial--based models. This is expected, as the level of weight--decay regularization in equations~(\ref{eq:L2_reg}) and (\ref{eq:l2_reg_scaled}) depends on the value of the loss, which is smaller for MIL models.

\subsection{Baseline models}\label{subsec:baseline_models}
We implement the objective functions described in subsection \ref{subsec:losses} on a user-based DAE~\cite{Sedhain:2015:Autorec, Wu:2016:CDAE-topN} and compare the results with the MIL function. We also compare them with traditional Matrix Factorization with Weight Regularization~\cite{HuKoren:2008:CF_implicit}. In the following, we provide details on the training of the different models.

\textbf{Weight-Regularized Matrix Factorization} WRMF~\cite{HuKoren:2008:CF_implicit} is a linear factorization model  trained with square loss and weight decay. We use negative sampling with a sampling ratio of $100$ and $\lambda\sim 5-10$ (as obtained in the validation set). We call this model \MFsquare. In addition, we train WRMF models with MIL and point--wise cross--entropy losses, applying a sigmoid function at the output, so as to ensure $\hat{p}_{ui}\in(0,1)$. In these cases, we find that a sampling ratio of $100$ and $\lambda=50-500$ provide best results. We name these models \MFmil\, and \MFce, respectively.

\textbf{\emph{Denoising Autoencoder models}}

\textbf{Cross-entropy loss} For the cross-entropy loss defined in equations~(\ref{eq:cross-entropy}), (\ref{eq:point-wise}) and (\ref{eq:pair-wise}), we use linear--sigmoid and sigmoid--sigmoid activations at the encoder and decoder, respectively. We name the DAEs models with cross-entropy loss and point--wise estimation \CEpointlinsig\,and \CEpointsigsig; and those with pair--wise,  \CEpairlinsig \,and \CEpairsigsig. In order to prevent numerical instabilities, we ensure that the output preferences are in $[\varepsilon, 1-\varepsilon]$, with $\varepsilon=10^{-5}$. Regarding negative sampling, we find that the best sampling ratio is $50\times {\rm median}(\mathcal{I}_u)$ and $100\times {\rm median}(\mathcal{I}_u)$  for point and pair--wise estimation, respectively. Best weight-decay regularization is found to be $\lambda=2\cdot 10^{-5}$.

% Comparison to CDAE
The closest model to these baselines is the Collaborative Denoising AE (CDAE)~\cite{Wu:2016:CDAE-topN}, although for the sake of simplicity, in the present paper we do not include the user embedding of CDAE. 
% bad performance of BPR
Similar to CDAE, we find that  pair--wise learning does not achieve competitive results at the top of the ranked list~\cite{Wu:2016:CDAE-topN, liang:2018:VAE}. 

\textbf{Multinomial loss} AEs trained with a multinomial log-likelihood have recently been  introduced by Lian et al~\cite{liang:2018:VAE}, either applied to DAEs or Variational AEs (VAE) with partial regularization. Here, we focus on the multi-DAE modeling with $\tanh$-linear activations\footnote{
We use the actual implementation provided at \url{https://github.com/dawenl/vae_cf} to verify that the activation used at the decoder of multi-DAE is linear, although the original writing~\cite{liang:2018:VAE} suggests a $\tanh$ non-linearity for the decoder.
}, and name this baseline \MULTItanhlin. Our implementation exactly reproduces that of~\cite{liang:2018:VAE} when using $\lambda=2\cdot 10^{-5}$, input noise of $0.5$ and without applying negative sampling. 

\textbf{Missing Information loss} We apply the \textsc{MIL} function defined in equation~(\ref{eq:mil_def}) to linear-sigmoid and sigmoid-sigmoid DAEs. We name these models \MILlinsig\, and \MILsigsig, respectively. Best hyper-parameters of the loss turn out to be $A_{\rm MI}=10^6,\, \gamma_{\rm MI}=10$ and $\gamma_{+}=1$, after grid search the pairs $\left(A_{\rm MI}, \gamma_{\rm MI}\right)\in\{
(5\cdot10^1, 2)$, $(10^3, 4)$, $(2\cdot10^4, 6)$, $(5\cdot10^5, 10)$, $(1\cdot10^6, 10)$, $(5\cdot10^6, 10)$, $(5\cdot10^9, 15)\}$, and $\gamma_{+}=1$ or $2$. In addition, we use a sampling ratio of $50$ and $\lambda\in(10^{-6}, 10^{-5})$.
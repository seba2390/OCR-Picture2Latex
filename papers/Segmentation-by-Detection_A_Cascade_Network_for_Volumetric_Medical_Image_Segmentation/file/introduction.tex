Segmentation is essential in medical image analysis to identify the structures of interest, such as organs or tumors.
% Segmentation is an essential task in medical image analysis. 
Despite numerous approaches have been proposed over the past decade, it continues to be a challenging problem as medical images are complex in nature and rarely have any simple linear feature. 
Most traditional technique \cite{Boykov06GC,Caselles97geodesics,ChanVese01regions} utilize handcrafted features incorporated into an energy-based segmentation method or a machine learning classifier. Those methods can easily incorporate different types of regularizers and priors, making the segmentation problem easier and more flexible \cite{Cremers-et-al-ijcv07}. However, their performances rely on a good contour initialization, good parameter selection that is often done in a heuristic way, and the quality of the handcrafted features. Moreover, those traditional models are not flexible enough to account for the large appearance variation and abnormalities present in medical imaging. 

Deep convolutional neural networks (CNNs) have rapidly developed as a powerful tool in computer vision and pattern recognition and are recently widely used in anatomy delineation \cite{litjens2017survey}. The success of CNNs owe to the hierarchical representations automatically learned from the raw input rather than the traditional handcrafted features. 
Early CNNs formulate the segmentation problem as a pixel-wise classification by presenting local region around that pixel. This sliding window approach only considers local context and suffer from efficiency issues.
Fully Convolutional Network (FCN) \cite{long2015fully} addressed these issues by an end-to-end, pixels-to-pixels architecture which can be applied on an entire input image and prevent the decrease in resolution. Many deep architectures were proposed based on this model. One of the most successful network in medical image segmentation is the U-Net \cite{ronneberger2015u}. This architecture consists of a contracting path and a symmetric expanding path. The skip connections between these two paths enable global context as well as precise localization. 

Most image segmentation systems fine-tuned a pre-trained network to try to work around the requirement of large data sets for deep network training. 
% dana say something more here : why - training is costly, trander learning - OK to have few low level layers ... 
However, medical data is often 3D (e.g. MRI or CT volume) while the majority of pre-trained CNNs are 2D. Therefore, a slice-by-slice analysis is often adopted to exploit the pre-trained nets \cite{prasoon2013deep}. In this way the computation is less expensive but an important drawback is that the inter-slice anatomical context is not explored.
The 3D architectures \cite{cciccek20163d,milletari2016v} take on a whole volume to take the contextual information between slices into account. Still, the high cost in computation and low speed of convergence in training process are issues that remain unsolved.

The success of region proposal methods, especially the Region Proposal Networks (RPN) \cite{ren2015faster} have demonstrated the effectiveness of the attention mechanism in object detection. 
Localization is an easier problem than segmentation. Thus, 
% dana shortly mention advantages of RPNs - localization is an easier problem than segmentation etc. 
we can take the advantage of the attention mechanism in segmentation task and propose a cascade network for 3D volumetric data, named segmentation-by-detection.
Rather than focusing on an entire volume, the 2D detection module allows for region of interest (RoI) to come to attention as needed. This is especially important for medical data with low signal-to-noise ratio (SNR). Using representations that distill information in the potential region rather than a volume is also an efficient solution for volumetric data.
% dana: this last part could be better explained 

% balance in the resolution and localization
Intuitively, our framework consists of a 2D detection module based on RPN \cite{ren2015faster} and a 3D segmentation module that follows the U-Net architecture. Compared to other recent works on 3D FCNs \cite{milletari2016v,cciccek20163d,dolz20173d,he2017mask}, our contribution are two-fold. First, we propose a novel cascade architecture to combine the attention mechanism with the segmentation system, 
which allows for learning from potential object regions.
% dana : state advantages 
Second, the architecture can benefit from the pre-trained models by exploiting the learned weights in the detection module. Besides, the method used in each module is flexible to change depending on the data and segmentation task.
Experiments on 3D ultrasound data of femoral head shown that the proposed architecture is more accurate and efficient when compared to 3D U-Net and other related volumetric segmentation methods.
% dana put the models you compare with


\section{Related Work}
\textbf{Region Proposal Methods:} 
Region proposal algorithms are widely used for object detection in natural images \cite{girshick2014rich}. Usually, a set of rectangular region proposals are generated as candidate object regions for further processing. The region proposal method allows for local RoI to come to attention and reduce the interference of the global context which is especially meaningful for medical data with low SNR. 

RPN is currently the leading method. It was introduced in Faster R-CNN \cite{ren2015faster} and extended by Mask R-CNN \cite{he2017mask} for object instance segmentation. 
In the context of segmentation, a precise object localization with a bounding box helps correct labeling. Mask R-CNN implements this idea by adding a branch for predicting the segmentation mask, in parallel with the branch for classification and bounding box regression. Different from the above, 
our network is a cascade of a detector followed by a segmentation module and targeted for 3D volume data.
% our proposed segmentation-by-detection framework is targeted for 3D volume where the region proposals generated by the detector are further exploited by the segmentation module. 
\vspace{1em}
% dana this last sentance is not clear

\noindent\textbf{Volumetric Segmentation:} 
Early CNN-based methods in medical image segmentation often use a slice-by-slice analysis. In order to exploit the anatomic context between slices, many 3D architectures have been proposed recently. 3D U-Net \cite{cciccek20163d} is an extension of the 2D architecture \cite{ronneberger2015u} which combines context information from lower layers with semantically richer features from the higher layers. The segmentation module of the proposed method is based on 3D U-Net and learned from densely annotated data instead of sparsely annotated ones. 

Likewise, V-Net \cite{milletari2016v} utilizes the encoder and decoder scheme and proposes a Dice coefficient based loss layer for segmentation task. In \cite{dolz20173d}, a 3D fully CNN was proposed for subcortical structure segmentation which uses small kernels and deeper architecture to avoid computation and memory burden.
The common idea of all these architectures \cite{cciccek20163d,milletari2016v,dolz20173d} is to parse an entire volume, which makes the system somewhat inefficient. The proposed segmentation-by-detection architecture address that by integrating the attention mechanism that guides the network to learn from the potential RoI rather than the whole target volume.
% dana maybe we can say in better way 
% avoid disrupt from the surrounding noise
% exploit the pre-trained 2D models
% more accurate



 






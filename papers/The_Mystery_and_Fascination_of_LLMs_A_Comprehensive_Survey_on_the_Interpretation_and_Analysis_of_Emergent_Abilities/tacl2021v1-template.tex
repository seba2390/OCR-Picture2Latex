% File tacl2021v1.tex
% Dec. 15, 2021

% The English content of this file was modified from various *ACL instructions
% by Lillian Lee and Kristina Toutanova
%
% LaTeXery is mostly all adapted from acl2018.sty.

\documentclass[11pt,a4paper]{article}
\usepackage{times,latexsym}
\usepackage{url}
\usepackage[T1]{fontenc}
%%%%%%%%%%%%%% citation 
%\usepackage[sorting=none, maxbibnames=1, maxcitenames=1, backend=biber]{biblatex} % load the package
%\usepackage[sorting=none, backend=biber, stylename=ieee, giveninits=true]{biblatex} % load the package
% \usepackage[sorting=none, backend=bibtex, stylename=ieee, giveninits=true]{biblatex} % load the package
% \addbibresource{references.bib} % add a bib-reference file

%% Package options:
%% Short version: "hyperref" and "submission" are the defaults.
%% More verbose version:
%% Most compact command to produce a submission version with hyperref enabled
%%    \usepackage[]{tacl2021v1}
%% Most compact command to produce a "camera-ready" version
   \usepackage[acceptedWithA]{tacl2021v1}
%% Most compact command to produce a double-spaced copy-editor's version
%%    \usepackage[acceptedWithA,copyedit]{tacl2021v1}
%
%% If you need to disable hyperref in any of the above settings (see Section
%% "LaTeX files") in the TACL instructions), add ",nohyperref" in the square
%% brackets. (The comma is a delimiter in case there are multiple options specified.)

\usepackage{tacl2021v1}
% \setlength\titlebox{10cm} % <- for Option 2 below

%%%% Material in this block is specific to generating TACL instructions
\usepackage{xspace,mfirstuc,tabulary}
\newcommand{\dateOfLastUpdate}{Dec. 15, 2021}
\newcommand{\styleFileVersion}{tacl2021v1}

\newcommand{\ex}[1]{{\sf #1}}

\newif\iftaclinstructions
\taclinstructionsfalse % AUTHORS: do NOT set this to true
\iftaclinstructions
\renewcommand{\confidential}{}
\renewcommand{\anonsubtext}{(No author info supplied here, for consistency with
TACL-submission anonymization requirements)}
\newcommand{\instr}
\fi

%
\iftaclpubformat % this "if" is set by the choice of options
\newcommand{\taclpaper}{final version\xspace}
\newcommand{\taclpapers}{final versions\xspace}
\newcommand{\Taclpaper}{Final version\xspace}
\newcommand{\Taclpapers}{Final versions\xspace}
\newcommand{\TaclPapers}{Final Versions\xspace}
\else
\newcommand{\taclpaper}{submission\xspace}
\newcommand{\taclpapers}{{\taclpaper}s\xspace}
\newcommand{\Taclpaper}{Submission\xspace}
\newcommand{\Taclpapers}{{\Taclpaper}s\xspace}
\newcommand{\TaclPapers}{Submissions\xspace}
\fi

\usepackage{graphicx}
\usepackage{amsmath,bm}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{microtype}
\usepackage{adjustbox}
\usepackage{tikz}
\usepackage{pgf}

%%%% End TACL-instructions-specific macro block
%%%%

% \title{A Survey on the Interpretation of Large Language Models}
% \title{On the Interpretation of Emergent Abilities of Large Language Models: A Survey}
% \title{On the Interpretation of In-context Learning: A Survey}

%The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities
%Survey on the Interpretation and Analysis of Mysterious and Fascinating Emergent Abilities in LLMs
%Beyond Mystery: A Comprehensive Survey of Interpreting and Analyzing Emerge
%On the Interpretation of Emergent Abilities in Large Language Models: A Survey
%Interpreting Emergent Abilities of Large Language Models: A Survey
\title{The Mystery and Fascination of LLMs: A Comprehensive Survey \\
on the Interpretation and Analysis of Emergent Abilities}


% Author information does not appear in the pdf unless the "acceptedWithA" option is given

% The author block may be formatted in one of two ways:

% Option 1. Author’s address is underneath each name, centered.

% \author{
%   Template Author1\Thanks{The {\em actual} contributors to this instruction
%     document and corresponding template file are given in Section
%     \ref{sec:contributors}.} 
%   \\
%   Template Affiliation1/Address Line 1
%   \\
%   Template Affiliation1/Address Line 2
%   \\
%   Template Affiliation1/Address Line 2
%   \\
%   \texttt{template.email1example.com}
%   \And
%   Template Author2 
%   \\
%   Template Affiliation2/Address Line 1
%   \\
%   Template Affiliation2/Address Line 2
%   \\
%   Template Affiliation2/Address Line 2
%   \\
%   \texttt{template.email2@example.com}
% }

% % Option 2.  Author’s address is linked with superscript
% % characters to its name, author names are grouped, centered.

% \author{
%   Template Author1\Thanks{The {\em actual} contributors to this instruction
%     document and corresponding template file are given in Section
%     \ref{sec:contributors}.}$^\diamond$ 
%   \and
%   Template Author2$^\dagger$
%   \\
%   \ \\
%   $^\diamond$Template Affiliation1/Address Line 1
%   \\
%   Template Affiliation1/Address Line 2
%   \\
%   Template Affiliation1/Address Line 2
%   \\
%   \texttt{template.email1example.com}
%   \\
%   \ \\
%   \\
%   $^\dagger$Template Affiliation2/Address Line 1
%   \\
%   Template Affiliation2/Address Line 2
%   \\
%   Template Affiliation2/Address Line 2
%   \\
%   \texttt{template.email2@example.com}
% }
\author{Yuxiang Zhou$^1$, Jiazheng Li$^1$, Yanzheng Xiang$^{1}$, Hanqi Yan$^{1,2}$, Lin Gui$^{1}$, Yulan He$^{1,2,3}$ \\
$^{1}$King's College London, $^{2}$University of Warwick, $^{3}$The Alan Turing Institute\\
        \texttt{\{yuxiang.zhou,jiazheng.li,yanzheng.xiang\}@kcl.ac.uk}\\
       	\texttt{hanqi.yan@warwick.ac.uk}\\
        \texttt{\{lin.1.gui,yulan.he\}@kcl.ac.uk}}
\date{}

\begin{document}
\maketitle
% Briefly outline the purpose of the paper, its scope, key findings and implications.
% \begin{itemize}
% 	\item Background: Why interpretation of the emergent abilities (e.g., ICL) of LLMs is important.
% 	\item Existing works: How and what have they done to ICL interpretation.
% 	\item What we have done in this paper (high-level), and what we have done in detail.
% \end{itemize}
\begin{abstract}
Understanding emergent abilities, %~\cite{Wei2022EmergentAO}, 
such as in-context learning (ICL) and chain-of-thought (CoT) prompting 
in large language models (LLMs), is of utmost importance.
This importance stems not only from the better utilization of these capabilities across various tasks, but also from the proactive identification and mitigation of potential risks, including concerns of truthfulness, bias, and toxicity, that may arise alongside these capabilities.
In this paper, we present a thorough survey on the interpretation and analysis of emergent abilities of LLMs.
First, we provide a concise introduction to the background and definition of emergent abilities.
Then, we give an overview of advancements from two perspectives: 1) a macro perspective, emphasizing studies on the mechanistic interpretability and delving into the mathematical foundations behind emergent abilities; and 2) a micro-perspective, concerning studies that focus on empirical interpretability by examining factors associated with these abilities.
We conclude by highlighting the challenges encountered and suggesting potential avenues for future research.
We believe that our work establishes the basis for further exploration into the interpretation of emergent abilities. 
Additionally, we have created a repository\footnote{\url{www.github.xxx}} containing the resources referenced in our survey.
\end{abstract}

% While existing ICL surveys focus on comprehensive reviews, we narrow the scope to survey the analytical studies on ICL.
% More specifically, we target those works that attempt to interpret ICL from two different perspectives.
% \begin{itemize}
% \item  Background: Define ICL and highlight their growing importance in various fields. 
%  \item Motivation: Discuss the necessity for interpreting ICL, and emphasizing background in a more detail way.
%  \item Objective: State the aim of your paper, i.e., to review recent research on interpreting ICL.
%  \item Structure: Provide an overview of the rest of the paper.
% \end{itemize}
\section{Introduction}
Emergent abilities such as in-context learning (ICL) and chain-of-thought (CoT) prompting have become evident in large language models (LLMs) when they are scaled to certain levels~\cite{Wei2022EmergentAO}.
These capabilities are receiving heightened attention due to their remarkable adaptability and their parameter-free nature.
As shown in Figure~\ref{fig:intro}, LLMs such as LLaMA2~\cite{Touvron2023Llama2O} and GPT-4~\cite{OpenAI2023GPT4TR} have exhibited proficiency across various tasks, such as text classification, summarization, and question answering, with a minimal set of task-oriented examples or CoT demonstrations, all without the need for extensive re-training.
\begin{figure}
	\centering
	{\includegraphics[width=0.5\textwidth]{intro.fig.pdf}\label{vis(architure)}}
	\caption{Illustration of Emergent Abilities.}
 \label{fig:intro}
\end{figure}

The concept of emergent abilities within LLMs was originally introduced by~\citet{Wei2022EmergentAO}, defining them as \textit{capabilities that manifest in large-scale models but are absent in their smaller-scale counterparts}.
They further classified these abilities into two categories: 1)~\textit{few-shot prompting abilities}, referring to the capacity of LLMs to achieve significantly better results than random chance on certain tasks such as BIG-Bench~\cite{Srivastava2022BeyondTI} and TruthfulQA~\cite{Lin2021TruthfulQAMH}, when presented with only a small number of demonstration examples; % by few-shot prompting; 
2)~\textit{augmented prompting strategies}, where certain strategies produce less impressive outcomes compared to established baselines until applied to models of sufficient scale.
For example, this includes the chain-of-thought prompting strategy~\cite{Wei2022ChainOT,Suzgun2022ChallengingBT} and instruction tuning~\cite{Brown2020LanguageMA, Wei2021FinetunedLM,Chung2022ScalingIL}.

Many studies have investigated emergent abilities of LLMs. %falling under the first category.
\citet{Srivastava2022BeyondTI} introduced BIG-bench, encompassing 204 tasks designed to push the boundaries of what current LLMs can do. % capabilities of LLMs, 
They aim to systematically assess and extrapolate the emergent abilities of LLMs.
\citet{Bubeck2023SparksOA} presented an overview of the emergent abilities specifically related to GPT-4~\cite{OpenAI2023GPT4TR}.
%Another line of research has focused on abilities associated with the second category.
\citet{Dong2022ASO} and \citet{Chu2023ASO} summarized advancements in techniques related to ICL and CoT, respectively, within LLMs.
Beyond the scope of emergent abilities, several surveys have been conducted to consolidate research on other aspects of LLMs.
\citet{Liang2022HolisticEO}, \citet{Chang2023ASO}, and \citet{Srivastava2022BeyondTI} emphasized studies on the evaluation methodologies of LLMs.
Meanwhile, \citet{Huang2022TowardsRI} and \citet{Qiao2022ReasoningWL} conducted surveys on research addressing the reasoning abilities inherent in LLMs.
Furthermore, \citet{Cao2023ACS}, \citet{Zhou2023ACS}, and \citet{Yang2023HarnessingTP} provided summaries of various viewpoints regarding the interplay between the development of LLMs and ChatGPT~\cite{Ouyang2022TrainingLM}. 
\citet{Zhao2023ExplainabilityFL} conducted a survey on methods used to elucidate pre-trained LMs.

While these surveys serve the purpose of providing an overview of the progress in various facets of LLMs, they tend to be fragmented and place significant emphasis on studies that assess the effectiveness and performance of LLMs in specific tasks.
Furthermore, even though emergent abilities have demonstrated increasing success across various domains, our understanding of these abilities remains limited.
Recently, an increasing number of studies have attempted to interpret and analyze emergent abilities.
\citet{Garg2022WhatCT}, \citet{Dai2023WhyCG}, and \citet{Akyrek2023WHL} explained ICL through the lens of linear regression formulation.
\citet{Xie2021AnEO}, \citet{Wang2023LargeLM}, and \citet{Hahn2023ATO} provided an interpretation of ICL rooted in latent variable models.
Meanwhile, a distinct line of research has aimed to understand the influential factors affecting emergent abilities through empirical analyses.
\citet{Min2022RethinkingTR}, \citet{Wei2023LargerLM}, \citet{Wang2023LabelWA}, and \citet{Kim2022GroundTruthLM} demonstrated that the ICL performance is influenced by task-specific characteristics and multiple facets of ICL instances, including quantities, order, and flipped labels. %revise
Consequently, it is essential to systematically categorize and summarize these studies, not only for a deeper understanding and more effective utilization of emergent abilities across various tasks, but also to assist in anticipating and mitigating potential risks. These risks encompass concerns related to truthfulness, bias, and toxicity, that may arise alongside these capabilities.

In this paper, we present a thorough and organized survey of the research on the interpretation and analysis of emergent abilities.
First, we provide a brief introduction of the background and offer the definition of emergent abilities.
Then, we present a comprehensive overview of advancements, from two distinct viewpoints: 1) a macro perspective, encapsulating studies focused on mechanistic interpretability and theoretical investigations into the mathematical foundations of emergent abilities; 
and 2) a micro perspective, pertaining to studies that prioritize empirical interpretability by probing factors associated with these abilities. 
In conclusion, we highlight the existing challenges and suggest potential avenues for further research. % in this field.

\begin{table*}[t!]
  \centering
  \resizebox{\linewidth}{!}{
    \begin{tabular}{lllll}\toprule
    \textbf{Work} & \textbf{EA} & \textbf{Key Words} & \textbf{Models} & \textbf{Tasks} \\%\midrule
   		\midrule
   		\multicolumn{5}{c}{\textbf{Macro Perspective}}\\
    	\midrule 
        \citep{elhage2021mathematical} & ICL   & Mechanistic Interpretability & Transformer$^\dag$ & - \\
        \citep{Olsson2022IncontextLA} & ICL   & Mechanistic Interpretability & Transformer$^\dag$ & - \\
        \citep{Garg2022WhatCT} & ICL   & Regression Function Learning & Transformer$^\dag$ & Regression \\
        \citep{Li2023TransformersAA} & ICL  & Regression Function Learning & Transformer$^\dag$ & Regression \\
        \citep{Li2023TheCO} & ICL   & Regression Function Learning & Transformer$^\dag$ & Regression \\
        \citep{Akyrek2023WHL} & ICL   & Regression Function Learning & Transformer$^\dag$ & Regression \\
        \citep{Dai2023WhyCG} & ICL   & Gradient Descent, Meta-Optimization & GPT Family & Classification \\
        \citep{Oswald2022TransformersLI} & ICL   & Gradient Descent, Meta-Optimization & Transformer$^\dag$ & Regression \\
        \citep{Xie2021AnEO} & ICL   & Bayesian inference & Transformer$^\dag$, LSTM & Sythetic Generation  \\
        \citep{Wang2023LargeLM} & ICL   & Bayesian inference & GPT Family & Classification \\
        \citep{Jiang2023ALS} & ICL, CoT   & Bayesian inference & GPT$^\dag$&Sythetic Generation \\
        \citep{Zhang2023WhatAH} & ICL   & Bayesian inference & Transformer$^\dag$ & - \\
        
        % \citep{swaminathan2023schema} & ICL   & Bayesian inference & Clone-Structured Causal Graphs & Classification \\
    %\midrule
    	\midrule
    	\multicolumn{5}{c}{\textbf{Micro Perspective}}\\
    	\midrule 
            \citep{Shin2022OnTE} & ICL   &  \textsc{Data} Domain & GPT-3 & Classification, Translation \\
          \citep{Han2023UnderstandingIL} & ICL   &  \textsc{Data} Domain, \textsc{Data} Distribution & OPT Family & Classification \\
             \cite{Raventos2023PretrainingTD} & ICL & Task Diversity & GPT-2 & Regression \\
           \citep{Razeghi2022ImpactOP} & ICL   &  \textsc{Data} Term frequency & GPT Family & Reasoning \\
             \citep{Kandpal2022LargeLM} & ICL   &  \textsc{Data} Term frequency & BLOOM & QA \\
          \citep{Chan2022DataDP} & ICL   & \textsc{Data} Distribution & Transformer & Classification \\
          \citep{Wies2023TheLO} & ICL   & \textsc{Data} Distribution & GPT-2 & - \\
        \cite{Tay2022UnifyingLL} & ICL & \textsc{Data} Diversity & UL2, T5 ,GPT & Classification, QA, Reasoning \\
          \citep{Wei2022EmergentAO} & ICL, CoT   & Model Scale & GPT-3, Flan Family, LaMDA Family & Classification \\
          % \citep{Kirsch2022GeneralPurposeIL} & ICL   & Hidden state size & Transformer & Classification \\
          % \citep{Xie2021AnEO} & ICL   &  \textsc{Data} Distribution, Model Architecture & Transformer, LSTM & Classification \\
          % \citep{Berglund2023TheRC} & ICL   &  \textsc{Data} Term frequency & GPT Family, Llama-1 & QA \\
          \citep{Lu2021FantasticallyOP} & ICL   & Demonstration Order & GPT Family & Classification \\
          % \citep{an2023context} & ICL   & Order & GPT Family & Semantic Parsing \\
          % , Label Distribution
          % & \citep{Liu2023LostIT} & ICL   & Text Demonstration Order & QA \\
          \citep{Zhao2021CalibrateBU} & ICL   & Demonstration & GPT Family & Classification, Information Retrieval \\
          \citep{Liu2021WhatMG} & ICL   & Demonstration Order & GPT-3 & QA, Classification, Text Generation \\
          \citep{Min2022RethinkingTR} & ICL   & Input-Label Mapping & GPT-3, fairseq Family, etc. & Classification, Multi-choice Tasks \\
          \citep{Kossen2023InContextLI} & ICL   & Input-Label Mapping &  LLaMa Family, Falcon Family & Classification, QA \\
          \citep{Wei2023LargerLM} & ICL   & Input-Label Mapping & GPT-3 Family, PaLM Family, etc. & Classification \\
          \citep{Kim2022GroundTruthLM} & ICL   & Input-Label Mapping & GPT Family & Classification \\
          \citep{Tang2023LargeLM} & ICL   & Input-Label Mapping, Shortcuts & GPT Family, OPT Family & Classification \\
          \citep{Si2023MeasuringIB} & ICL   & Input-Label Mapping, Feature Bias & text-davinci-002, GPT-3 & Classification \\
          \citep{Wang2023LabelWA} & ICL   & Input-Label Mapping, Information Flow & GPT-J & Classification \\
          \citep{Wang2022TowardsUC} & CoT   & Demonstration & PaLM, text-davinci-003, etc. & Reasoning, QA \\
          \citep{Turpin2023LanguageMD} & CoT   & Demonstration & GPT-3.5, Claude 1.0 & Multi-choice Tasks  \\
    \bottomrule
    \end{tabular}}%`
\caption{Summary of research studies on the interpretation of emergent abilities in LLMs. EA is short for ``Emergent Abilities'' and QA stands for ``Question Answering''. \textsc{Data} refers to pre-training data. The symbol $^\dag$ denotes specifically designed models.}
  \label{tab:summ}%
\end{table*}%

% \begin{table*}[t!]
%   \centering
%   \resizebox{\linewidth}{!}{
%     \begin{tabular}{cp{0.3\linewidth}lll}\toprule
%     \textbf{Perspective} & \textbf{Work} & \textbf{Emergent Ability} & \textbf{\textcolor{white}{~~~~~~~~~~~~~~~~~~}Key Words} & \textbf{Tasks} \\\midrule
%     \multirow{9}[1]{*}{Macro} & \citep{elhage2021mathematical} & ICL   & Mechanistic Interpretability & - \\
%           & \citep{Olsson2022IncontextLA} & ICL   & Mechanistic Interpretability & - \\
%         & \citep{Garg2022WhatCT} & ICL   & Regression Function Learning & Regression \\
%         & \citep{Li2023TransformersAA} & ICL   & Regression Function Learning & Regression \\
%         & \citep{Li2023TheCO} & ICL   & Regression Function Learning & Regression \\
%         & \citep{Akyrek2023WHL} & ICL   & Regression Function Learning & Regression \\
%         & \citep{Dai2023WhyCG} & ICL   & Gradient Descent, Meta-Optimization & Classification \\
%           & \citep{Oswald2022TransformersLI} & ICL   & Gradient Descent, Meta-Optimization & Regression \\
%           & \citep{Xie2021AnEO} & ICL   & Bayesian inference & Classification \\
%           & \citep{swaminathan2023schema} & ICL   & Bayesian inference & Classification \\
%           & \citep{DBLP:journals/corr/abs-2304-09960} & ICL   & Bayesian inference & Classification \\
%     \midrule
%     \multirow{19}[2]{*}{Micro} & \citep{Chan2022DataDP} & ICL   & Pre-training Data Distribution, Model Architecture & Classification \\
%           & \citep{Razeghi2022ImpactOP} & ICL   & Training Data Term frequency  & Arithmetic Reasoning \\
%           & \citep{DBLP:conf/icml/KandpalDRWR23} & ICL   & Training Data Term frequency  & QA \\
%           & \citep{DBLP:conf/naacl/ShinLAKKKCLPHS22} & ICL   & Training Data Domain, Lexical Diversity & Classification, Translation \\
%           & \citep{Power2022GrokkingGB} & ICL   & Lexical Diversity, Training Data Quality & Arithmetic Reasoning \\
%           & \citep{Wei2022EmergentAO} & ICL   & Model Scale and Training Data Quality & Classification \\
%           & \citep{DBLP:journals/corr/abs-2212-04458} & ICL   & Hidden state size & Classification \\
%           & \citep{DBLP:conf/acl/HanSMTCW23} & ICL   & Training Data Domain, Pre-training Data Distribution & Classification \\
%           & \citep{Xie2021AnEO} & ICL   & Pre-training Data Distribution, Model Architecture & Classification \\
%           & \citep{Berglund2023TheRC} & ICL   & Training Data Term frequency  & QA \\
%           & \citep{Lu2021FantasticallyOP} & ICL   & Order, Label Distribution & Classification \\
%           % & \citep{Liu2023LostIT} & ICL   & Text Demonstration Order & QA \\
%           & \citep{Zhao2021CalibrateBU} & ICL   & Order & Classification \\
%           & \citep{Liu2021WhatMG} & ICL   & Order, Semantic Similarity & QA \\
%           & \citep{min-etal-2022-rethinking} & ICL   & Input-Label Mapping & Classification \\
%           & \citep{Kossen2023InContextLI} & ICL   & Input-Label Mapping & Classification \\
%           & \citep{Wei2023LargerLM} & ICL   & Input-Label Mapping & Classification \\
%           & \citep{Kim2022GroundTruthLM} & ICL   & Input-Label Mapping & Classification \\
%           & \citep{Tang2023LargeLM} & ICL   & Input-Label Mapping, Shortcuts within Demonstrations & Classification \\
%           & \citep{Si2023MeasuringIB} & ICL   & Input-Label Mapping, Feature Bias & Classification \\
%           & \citep{Wang2023LabelWA} & ICL   & Input-Label Mapping, Information Flow & Classification \\
%           & \citep{Wang2022TowardsUC} & CoT   & Demonstration & Arithmetic Reasoning, QA \\
%           & \citep{Turpin2023LanguageMD} & CoT   & Demonstration & Multiple-choice Tasks \\
%     \bottomrule
%     \end{tabular}}%`
% \caption{Summary of research studies on the interpretation of emergent abilities in LLMs.}
%   \label{tab:addlabel}%
% \end{table*}%
\input{2_Background-Notation}

% \begin{itemize}
% \item  Definition: Clearly define what ICL are and describe their architecture.
%  \item Emergent Abilities: Describe the unexpected abilities that emerge from these models, providing examples where relevant.
%  \item Importance and Uses: Discuss how and where ICL are currently being used, and why interpretation is crucial in these contexts.
% \end{itemize}
% \section{Background and Notation}
% Following~\citet{Wei2022EmergentAO}, we define the emergent abilities of LLMs as \textit{the abilities that emerge when LLMs scale up to certain extents and cannot be anticipated only by extrapolating the performance improvements of smaller-scale models.}
% %Need to revise: cannot be... to similar to the cited paper
% Specifically, with a few examples or chain-of-thought demonstrations, LLMs can produce \textit{satisfactory results}\footnote{Comparable or even better results than those achieved by LLMs fine-tuned on specifica tasks or datasets.} across various tasks without requiring continuous training or fine-tuning.

% %D=\{(x_i,y_i)\};Q=(q_1,...,q_j);Y=(y_1,...,y_j)
% Formally, define $D \in \mathcal T_{train}$ is a subset demonstration selected from the training set.
% $Q\in \mathcal T_{test}$ is the query in the test set, $Y$ is the label for each query, $\mathcal M$ is the LLM with frozen parameter $\Theta$, and $\mathcal F$ is the evaluation metric function. 
% For example, $\mathcal F$ usually represents accuracy or F1 score in classification tasks, such as sentiment analysis, and represents Rouge or BLEU~\cite{} in text generation tasks, such as summarization.
% The concept of emergent ability can be formalized with the equation:
% \begin{equation}
% 	\mathcal F (Y,\mathcal M_\Theta(D,Q))
% \end{equation}
% where $\mathcal M$ is usually considered to exhibit emergent abilities if the computed value from $\mathbb F$ exceeds a threshold. 
% Under this definition, we can group similar concepts within the few-shot prompting paradigm. 
% CoT can be viewed as a variant of ICL, with the primary distinction being the format of the demonstration. 
% Specifically, ICL demonstrations typically utilize a standard prompt, while CoT demonstrations incorporate an additional textual reasoning process.

% Based on our definition, we categorize existing literature on interpreting emergent capabilities into macro and micro perspectives. 
% Researchers in the macro category focus on general loss or the model architecture, aiming to find the correlation between the result of $\mathcal F$ and $\mathcal M$.
% Conversely, those in the micro category primarily centre their attention on the correlation between the result of $\mathcal F$ and $D$.

% \section{Interpreting Emergent Ability from Macro Perspective}
% Studies from the macro perspective centre on mechanistic interpretability, investigating factors related to $\mathcal M$, including model interal architectures, training mechanisms, general loss, active functions, and optimizations algorithms. 
% They aim to understand why, how, and when these factors affect the emergence of the abilities.
%%%%%% draft examples
% \subsection*{\textcolor{red}{Example}} To unravel the internal structures responsible for ICL, \citet{Olsson2022IncontextLA} designed 2-layer attention-only models.
% They tried to decompose the operations of transformers~\cite{}, studying a phase change that occurs early in traning in LLMs of every size.
% One striking discovery from their study was the potential role of induction heads~\cite{elhage2021mathematical} as a mechanistic source of ICL in a majority of LLMs.
% However, their conclusions  is only the beginnings and far from satisfactory reverse-engineering LLMs to address the safety isses, considering frontier LLMs that typically consist of hundreds of layers and boast billions or even trillions of parameters.
% On the other hand, as with any empirical or interventional study, there's the possibility of encountering numerous subtle confounders or alternative hypotheses.
% A plausible research direction might involve generalizing these findings to more complex models. 
% By empirically observing, perturbing, and delving deep into the learning process and structural formation, researchers can potentially piece together an indirect understanding of the mechanistic happenings within LLMs.

% \subsection{Model factors}
% \begin{itemize}
% 	\item architectures
%  \textcolor{blue}{3pages in total. HANQI:ICL: copy->linear->nonlinear}
% 	\item loss
% 	\item active function
% 	\item gradient \textcolor{blue}{HANQI: why ICL can approximate gradient}
% \end{itemize}

% \subsection{Traning factors}
% \begin{itemize}
% 	\item training data
%  \textcolor{blue}{HANQI:data distribution, training samples} 
% 	\item optimization algorithms
% 	\item grokking (Grokking works which aims to interpret LLMs by measuring)
% \end{itemize}

\input{3_Macro-Perspective}


% Studies from the micro perspective centre on empirical interpretability, probing the factors associated with $D$, such as type of tasks, and the quality, quantity, and sequence of demonstrations.
% They aim to explore how and why these factors are correlated with the result of $\mathbb F$.
\input{4_Micro-Perspective}
%%%%%% draft examples
% \subsection*{\textcolor{red}{Example}}
% \citet{Lu2023AreEA} provided analysis of emergent abilities while accounting for various confounding factors that might lead to biased LLM.
% They controlled for various emergent abilities in an attempt to differentiate between those that are inherently emergent and those that appear as a result of specific prompting techniques.
% Surprisingly, \citet{Lu2023AreEA} found that emergent abilities were only evident in two of the 14 experimental tasks they administered, with the rest primarily demonstrating memorization. 
% However, their study did not control for CoT, which also identified by~\citet{Wei2022EmergentAO} as a crucial emergent ability of LLMs.
% A potential future direction might be to account for additional emergent abilities, such as CoT, while also considering confounding factors like data leakage and memorizability.


% \subsection{Demonstration factors}
% \begin{itemize}
% 	\item quality
% 	\item quantity
% 	\item order
% \end{itemize}

% \subsection{Task factors}
% \begin{itemize}
% 	\item type of task
% 	\item evaluation metrics
% 	\item 
% \end{itemize}



% % \section{Recent Research on ICL interpretation}
% % Summarize existing works used for interpreting ICL, highlighting the unique aspects of each. 
% % It can initially be categorized into the following two general categories, with some preliminary works listed under each.

% % \textbf{For each perspective and method, please first provide brief summaries and main findings of each work. Then, illustrate the insights drawn from these works and discuss the current challenges and limitations of interpreting ICL from these perspectives.}

% % \subsection{Macro Perspective on ICL Interpretation}
% % Analyzing and interpreting ICL from a macro perspective, focusing on general loss or the model architectures.
% % \begin{itemize}
% % 	\item\textbf{Hanqi:} 
% %  \\
% %  \textbf{notes: use semantic scholar for citations, 1month deadline, application track. models > 10 billion parameters? Papers after 2022. ICML papers }
% %  Other perspectives: (1)Causal explanation~\cite{Meng2022LocatingAE}, counterfactual interpretation~\cite{Li2023CounterfactualRT,HoelscherObermaier2023DetectingEF}
 
% %  (2)self-critic~\cite{Yin2023DoLL}, 
 
% %  (3)uncertainty estimation of LLMs' outputs, bias~\cite{Simmons2022MoralML}, 
 
% %  (4)LLMs access to tools~\cite{Sarti2023InseqAI}, etc~\cite{Wang2023ConstructingWS,Brinner2023ModelIA,Lam2023LargeLM,Riemenschneider2023ExploringLL}.
% %  	\item \textbf{Lin:} From the perspective of LLMs themselves. For example, interpretation of neurons~\cite{bills2023language,Gurnee2023FindingNI,Foote2023N2GAS}, structure, active functions~\cite{Yang2023LocalIO}, and optimization algorithms~\cite{Barak2022HiddenPI,Du2023GeneralizingBF} in LLMs. 
% % \end{itemize}
% % \subsection{Micro Perspective on ICL Interpretation}
% % Analyzing and interpreting ICL from a micro perspective, focusing more on specific tasks. 
% % \begin{itemize}
% % 	\item \textbf{Jiazheng:} From the perspective of ``the way how to use LLMs'' or ``the emergent abilities~\cite{Wei2022EmergentAO} of LLMs". Such as, In-Context-Learning (ICL)~\cite{Xie2021AnEO,Olsson2022IncontextLA,Dai2023WhyCG,Wang2023LargeLM,Sun2023HowDI,Bansal2022RethinkingTR,Tang2023LargeLM}, Chain-of-Thought (CoT), and prompt tuning~\cite{Wei2021WhyDP,Singh2022ExplainingPI,Ju2023IsCP}.
% % 	\item \textbf{Yanzheng:} From the perspective of different domains (NLP~\cite{Liu2023LostIT,Wicke2023LMsST}, CV, Physical, Theory of Mind~\cite{Mahowald2023DissociatingLA,Shapira2023HowWD}, etc ) and tasks (Coding~\cite{Bubeck2023SparksOA}, Mathematical~\cite{Saunshi2020AME,Bubeck2023SparksOA}, Reasoning~\cite{Prystawski2023WhyTS,Jung2022MaieuticPL,Lewkowycz2022SolvingQR}, Planning~\cite{Collins2022StructuredFA, Valmeekam2023OnTP}). 

% % \end{itemize}

% \input{4_Micro-Perspective}
% % \input{sections/hanqi}
% % \section{Challenges and Insights}
% % \paragraph{Challenges} Discuss the current challenges and limitations of interpreting LLMs, such as the "black box" problem, difficulties in attributing specific outputs to specific inputs, etc.
% % Discuss the implications of these challenges, for example in terms of fairness, accountability, and transparency.


% % \paragraph{Insights} Categorize the key insights obtained from the interpretation of LLMs so far (e.g., how they handle long-term dependencies, how they generalize from limited data, how they invent narratives, etc.).
% % Discuss representative papers for each category, summarizing their methodologies, findings, and contributions.

% % \begin{itemize}
% %     \item Summarize the benefit of interpreting LLMs from the above perspectives. 
% % 	\item Given the findings and challenges discussed so far, speculate on possible future directions for research on interpreting LLMs.
% % 	\item Discuss how overcoming the current challenges might open up new applications for LLMs, or make current applications more effective, fair, or accountable.
% % \end{itemize}


% \begin{table*}[ht!]
% \centering
% \resizebox{\linewidth}{!}{
% \begin{tabular}{p{0.2\linewidth}p{0.4\linewidth}p{0.4\linewidth}}
% \toprule
% Perspective & Categories & Factors\\\midrule
% \multirow{2}{*}{Macro Perspective} & Linear regression formulation/meta learning & \citep{dai2023can, olsson2022context, von2023transformers, Akyrek2022TowardsTF}\\
%  & Latent space theory/ Bayesian inference & \citep{Xie2021AnEO, Wang2023LargeLM}\\\midrule
% \multirow{12}{*}{Micro-perspective} & \multirow{6}{*}{Pre-training Stage} & Pre-training data distribution\\
%  & & \citep{Chan2022DataDP, Razeghi2022ImpactOP}\\ 
%  & & Domain of pre-training data \\
%  & & \citep{DBLP:conf/naacl/ShinLAKKKCLPHS22, Razeghi2022ImpactOP, Power2022GrokkingGB} \\
%  & & Pre-training model architecture\\  
%  & & \citep{Chan2022DataDP, Xie2021AnEO} \\\cmidrule{2-3}
%  & \multirow{6}{*}{Inference Stage} & Order of demonstration \\
%  & & \citep{Zhao2021CalibrateBU, Liu2019RoBERTaAR, Zhao2021CalibrateBU, Liu2023LostIT}\\
%  & & Input-Label Mapping\\
%  & & \citep{min-etal-2022-rethinking,Kossen2023InContextLI,Kim2022GroundTruthLM, Tang2023LargeLM,Si2023MeasuringIB}\\
%  & & Chain-of-Thought Prompting\\
%  & & \citep{Wang2022TowardsUC,Turpin2023LanguageMD}\\\bottomrule
% \end{tabular}}
% \caption{Summary of factors that have a relatively strong influence on the emergent abilities.} 
% \end{table*}





\section{Challenges \& Future Directions} % for interpreting emergent abilities}
% \subsection{Challenge}
\subsection{Unified Framework}
There is currently no standardized framework available for understanding or interpreting emergent abilities. 
While researchers often investigate factors contributing to emergent abilities based on empirical insights, the resulting conclusion may not always be robust or broadly applicable to real-world applications.
The challenge lie in the multitude of factors that influence emergent abilities, many of which may not be directly modifiable with respect to the abilities themselves, as noted by~\citet{Wei2022EmergentAO}.
For instance, apart from the attention mechanism, ~\citet{Li2023TheCO} found that softmax unit plays a pivotal role in understanding ICL through function regression problems~\cite{Garg2022WhatCT,Akyrek2023WHL,Oswald2022TransformersLI}. 
From the micro-perspective, when examining how the extent of pre-training impacts emergent abilities, data quality serves a crucial role alongside factors like data scale and training time.
 
\subsection{Evaluation Metrics}
Current research efforts typically measure emergent abilities by assessing task performance or optimizing criteria such as gradient~\cite{Oswald2022TransformersLI} and token loss~\cite{Olsson2022IncontextLA} during the pre-training stage.
Another line of research~\citep{Shin2022OnTE, Razeghi2022ImpactOP} has discovered that the relationship between the evaluation measures of language models during training does not strongly correlate with the conventional evaluation metrics, such as F1-score, that have been used to measure performance of emergent abilities under most experimental setups.
However, a dedicated criterion explicitly designed for the assessment of emergent abilities is currently lacking.
In addition, assessing emergent abilities often becomes complicated due to the interwined emergence of other competencies~\cite{Lu2023AreEA}.
In this work, we postulate that the assessment of emergent ability can be based on its capability to produce \textit{satisfactory results} in comparison to a fine-tuned model. 
This approach provides a preliminary framework for devising evaluation criteria. 
However, it is important to note that this methodology is preliminary and not yet comprehensive or definitive. 
Further refinement and development of formal criteria are necessary to establish a robust and universally applicable evaluation metric for emergent ability itself.

\subsection{Cost and Computational Resources}
LLMs faced constraints related to their token capacity, which can lead to deficiency in coherence when dealing with longer demonstration examples or text generation. This limitation can result in challenges for emergent abilities, making it difficult to maintain a consistent and extended logical flow.
What's more, there are some experimental limitations that have hindered the exploration of this type of research. The pre-training stage of these models demands a huge amount of computational resources, which could become a barrier for researchers who lack the necessary resources \citep{Shin2022OnTE, Brown2020LanguageMA, Wei2022EmergentAO, Berglund2023TheRC}. This limitation has restricted investigations into the sources of emergent abilities in commonly used LLMs. Furthermore, the limited knowledge of the detailed lexical resources utilized during the pre-training stage adds complexity to the examination of their abilities \citep{Berglund2023TheRC}.
\vspace{-1mm}
\subsection{Transparency of Training Data}
Some studies \cite{Chan2022DataDP, Razeghi2022ImpactOP, Shin2022OnTE, Power2022GrokkingGB} have emphasized the connection between emergent abilities and the training data. 
It is clear that diverse, clearly structured pre-training data can facilitate the emergence of abilities, such as reasoning. Consequently, understanding how to better evaluate the data quality and how to construct high-quality training data may enable future research to better study the emergent abilities at the pre-training stage.
Hence, our community should refrain from treating the pre-training data of LLMs as black boxes.
Neglecting the role of pre-training data can lead to misinterpretations when assessing the emergent abilities.

\subsection{Causality rather than Correlation}
As demonstrated by \citet{Razeghi2022ImpactOP} and \citet{Power2022GrokkingGB}, intervening on the pre-training dataset, particularly with an emphasis on the emergence of reasoning abilities, offers a promising path for gaining deeper into the question of %interpretation thread to understand better whether the reasoning in the 
whether LLMs indeed possess reasoning abilities. Moreover, as highlighted by \citet{Chan2022DataDP}, delving into the intricacies of in-context and in-weights learning deserves further investigation, especially concerning how prior knowledge is signaled. It is crucial to make comparison between transformers and recurrent architectures, particularly in understanding their in-context learning capacities. What's more, there is a need for a more comprehensive interpretation of the impact of the ``Reversal Curse'' in extensive pre-training datasets for LLMs, considering the varying frequencies of reversed information.
% \subsubsection{Challenges}

% Despite the various progress made in interpreting the efficacy of the pre-training stage on the emergence of ICL, researchers also found some challenges: 

% The first challenge is the evaluation metrics for the pre-training stage. The relationship between the evaluation measurement of language models during the training does not strongly correlate with the performance of emergent abilities under most experiment setups. Therefore, commonly used evaluation metrics, such as perplexity, may hinder language models from maximizing their emergent capability.

% The second challenge is the pre-training data quality issue. Most works from this section \cite{Chan2022DataDP, Razeghi2022ImpactOP, Shin2022OnTE, Power2022GrokkingGB} have emphasized the connection between emergent abilities and the training data. It is clear that diverse, clearly structured pre-training data may urge the emergence of abilities, such as reasoning. Therefore, understanding how to better evaluate the data quality and how to construct high-quality training data may help future research to better study the emergent ability at the pre-training stage.

% What's more, there are some experimental limitations that have hindered the exploration of this type of research. The pre-training stage of these models requires a huge amount of computational resources, which could become a barrier for researchers who lack the necessary resources \citep{Shin2022OnTE, Brown2020LanguageMA, Wei2022EmergentAO, Berglund2023TheRC}. This has limited investigations into popularly used LLMs' source of emergent ability. Furthermore, the limited knowledge of the detailed lexical resources utilized during the pre-training stage makes it difficult to investigate their abilities \citep{Berglund2023TheRC}.

% \subsubsection{Future Work}

% As demonstrated by \citet{Razeghi2022ImpactOP, Power2022GrokkingGB}, intervention on the pre-training dataset focuses mainly on the emergent reasoning ability is a viable interpretation thread to understand better whether the reasoning in the LLM is actual. Moreover, as mentioned by \citet{Chan2022DataDP}, the nuances of in-context and in-weights learning warrant further exploration, especially concerning how prior knowledge is cued. Comparing transformers to recurrent architectures is essential, particularly in understanding their in-context learning capacities. What's more, the impact of the ``Reversal Curse'' in extensive pre-training datasets for LLMs needs further interpretation, given the varied frequency of reversed information.







% \begin{itemize}
% 	\item Summarize the main points of the paper, reiterating why the interpretation of LLMs is important and what the current state of research is.
% 	\item Restate the future directions suggested, and encourage other researchers to continue this line of inquiry.
% \end{itemize}
\section{Conclusion}
This paper has thoroughly reviewed the current research efforts aimed at interpretating and analyzing the emergent abilities of LLMs.
We have categorized these advancements into two main perspectives: 1) from a macro perspective, encompassing studies that focused on inner mechanism of emergent abilities through various theoretical frameworks, such as regression function learning, meta-optimization, and Bayesian inference;
2) from a micro perspective, highlighting studies that prioritize empirical interpretability by investigating factors associated with these abilities
We have identified the existing challenges and suggested potential avenues for further research in this area.
We believe that our work serves as a valuable resource for encouraging further exploration into the interpretation of emergent abilities of LLMs.


\bibliography{tacl2021}
\bibliographystyle{acl_natbib}
\end{document}








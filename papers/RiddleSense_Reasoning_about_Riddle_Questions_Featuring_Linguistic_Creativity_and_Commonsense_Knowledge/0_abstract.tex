% https://poets.org/glossary/riddle

% For example, the riddle ``\textit{I climb higher as I get hotter.  I cannot escape from my crystal cage.  What am I?}'' asks about the concept ``\textit{mercury}'' (as in a {thermometer}).
Question: \textit{I have five fingers but I am not alive.  What am I?}  Answer: \textit{a glove}. 

Answering such a riddle-style question is a challenging cognitive process, in that it requires complex commonsense reasoning abilities, an understanding of figurative language, and counterfactual reasoning skills, which are all important abilities for advanced natural language understanding (NLU).
However, there is currently no dataset aiming to test these abilities.
In this paper, we present \textsc{RiddleSense}\footnote{\url{https://inklab.usc.edu/RiddleSense/}}, a new multiple-choice question answering task,
which comes with the first large dataset (5.7k examples) for answering riddle-style commonsense questions. 
We systematically evaluate a wide range of  models over the \textsc{RiddleSense} challenge, and point out that there is a large gap between the best-supervised model and human performance --- suggesting intriguing future research in the direction of higher-order commonsense reasoning and linguistic creativity towards building advanced NLU systems. 

% \yl{Plz skip the abstract now.}

%Solving riddles is a challenging cognitive process for humans. 
%It requires complex commonsense reasoning ability
%A riddle is a question that is designed 
%We present a novel commonsense reasoning task, aiming to test the machine ability of answering multi-hop, complex riddle questions with commonsense knowledge.

% We collect distractors (i.e., incorrect choices) via adversarial filtering and carefully verification by humans, yielding a competitive benchmark for commonsense reasoning and general NLU. 
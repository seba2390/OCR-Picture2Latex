\section{Methodology}

% \begin{figure}[!t]
% \centering
% \includegraphics[width=\linewidth]{fig/FLDv3.pdf}
% \caption{Procedure of FLD}
% \label{Overview}
% \end{figure}

\begin{figure*}[!t]
\centering
\includegraphics[width=.8\linewidth]{fig/FLDv1.pdf}
\caption{Procedure of FLD}
\label{Overview}
\end{figure*}



\subsection{Motivation}
According to the attack analysis in constrain-and-scale~\cite{howtobackdoor}, the federated backdoor attacks are divided into two attack scenarios: single-shot attacks (\textit{Attack A-S}) and multi-shot attacks (\textit{Attack A-M})~\cite{xie2020dba,am1}.
\setlist[itemize]{leftmargin=*}
%\begin{itemize}

\noindent\textbf{\textit{Attack A-S}}: the attacker successfully embeds its backdoor trigger in only one round. The attacker performs parameter scaling on the compromised clients' updates to substitute the global model $G^{t}$ with a backdoor model $X$ in Equation~\ref{eq:backdooreq1}: 
\begin{equation}
\label{eq:backdooreq1}
X = {\sum_{i=1}^{n}} \frac{1}{n} w_{i}^{t}.
\end{equation}
To achieve this goal, the attacker can scale the model parameters as follows:
\begin{equation}
\begin{split}\label{eq:backdooreq2}
\tilde{w} _{n}^{t} 
& = nX-\sum_{i=1}^{n-1} w_{i}^{t}\approx nX-\sum_{i=1}^{n-1} G ^{t-1}\\
& = n\left ( X-G ^{t-1} \right )+G ^{t-1}.
\end{split}
\end{equation}
As the global model converges, $w_{i}^{t}\approx  G ^{t-1}$. In other words, the attacker scales up the model weights $X$ by $n$ to prevent the malicious updates from being mitigated by the aggregation.


\noindent\textbf{\textit{Attack A-M}} lets compromised clients accumulate malicious updates over multiple rounds, instead of directly scaling the uploaded parameters, to avoid being detected by the defense algorithm. 
%the malicious client does not scale the update, thus avoiding detection by the defence.The malicious clients are selected in multiple rounds thus accumulating malicious updates. 
%\end{itemize}
%After reviewing the backdoor defenses methods in FL, we found that the past defenses basically defaulted to the attacker performing \textit{Attack A-S} and ignoring \textit{Attack A-M}. However, after experiments, we found that the attacker can successfully embed the back model in the global model by using Attack A-M, and in this case, many defenses will fail, such as clipping, Euclidean distance, etc. 
We have thoroughly reviewed the SOTA backdoor defense works in federated learning~\cite{foolgold,krum,Trimmed_Mean,Bulyan,RFA,canyou} and found that existing methods focus on defending against \textit{Attack A-S} while overlooking \textit{Attack A-M}. Unsurprisingly, we found through empirical experiments that SOTA defense algorithms fail at defending against {\textit{Attack A-M}.
%\subsection{Overview}

To address the challenges mentioned above, we propose Federated Layer Detection~(FLD), an innovative defense method for effectively detecting backdoor attacks in federated learning that overcomes the deficiencies of previous works. As depicted in Fig.~\ref{Overview}, FLD consists of two components, namely Layer Scoring and Anomaly Detection. Layer Scoring assigns scores to the local models uploaded by the clients according to the concept of isolation. Anomaly Detection checks the outlier scores given by Layer Scoring to determine if an uploaded model is compromised. The overall process is as follows: 1) The server receives the local models from the clients participating in the current round. 2) The server assigns each layer of each model an outlier score using Layer Scoring. 3) The server labels each layer as abnormal or not according to its outlier score, and excludes from the aggregation the anomalous models that contain more anomalous layers than the predefined threshold, as summarized in Algorithm~\ref{algorithm1}.
\begin{algorithm}
    \caption{Overview}\label{algorithm1}
    \begin{algorithmic} [1]
        \algrenewcommand\algorithmicrequire{\textbf{Input:}}
        \Require Set of clients $ C = \left \{ C_{1},C_{2},C_{3},\cdots,C_{N}  \right \} $, local datasets $ D = \left \{ D_{1},D_{2},D_{3},\cdots,D_{N} \right \}$, the number of training iterations $T$, the percentage of participating clients per round $K$.
        \algrenewcommand\algorithmicrequire{\textbf{Output:}} 
        \Require Global model $G^T $
        \State Initialize the global model $G^0 $
        \For { $ t\ in \left [ 1,T \right ] $ }
        \State $ n\gets \max \left ( K\cdot N,1  \right ) $ 
        \State $ C^{t} \gets $ (random set of $n$ clients )
        \For {each client $ i\in C^{t} $ in parallel} 
        \State The server sends $G^{t-1}$ to client $i$
        \State $w_{i}^{t} \gets $ ClientUpdate$\left ( D_i, G^{t-1}  \right) $ 
        \State Client $i$ sends $w_{i}^{t}$ back to the server
        \EndFor
        \State $\left(S_{1} ,\cdots,S_{n}\right)\gets Layer Scoring\left(w_{1}^{t},\cdots,w_{n}^{t}\right)$
        \State $C_{b}^{t}\gets Anomaly Detection \left(S_{1} ,\cdots,S_{n}\right)$
        \State  $m\gets len\left ( C_b^t \right ) $
        \State  $  G^{t}=  \sum_{i\in  C_b}^{} \frac{1 }{m} w_{i}^{t}$
        \EndFor
    \end{algorithmic}
\end{algorithm}

%\subsection{Federated Layer Detection Design}

%
\subsection{Layer Scoring}
In round $t$, the parameter server sends the global model $G^{t-1}$ to the selected clients $i\in C^t$, each of which trains $G^{t-1} $ using its local data $D_{i}$ and sends the model parameters $w_{i}^{t}$ back to the server after local training is completed.
%Our aim is to eliminate the threat of potentially malicious local models.

Existing backdoor defense methods assess uploaded models based on either similarity or distance metrics. They usually flatten the parameters of each model layer and then stitch them into a vector to perform the assessment. However, different layers of the neural network have heterogeneous parameter value distribution spaces due to their different functions. For example, in a CNN, the lower layers learn to detect simple features such as stripes, the middle layers learn to detect a part of an object, and the higher layers learn to detect a concept (e.g., a person)~\cite{distribution}. As a result, directly flattening and splicing the parameters of each layer easily leads to the loss of important information and hence the escape of malicious models. Therefore, finer-grained detection is demanded.

To address this issue, we have devised a hierarchical detection method, Layer Scoring, to measure fine-grained model differences, as shown in Algorithm~\ref{algorithm2}. Layer Scoring examines and assigns an outlier score to each layer of the uploaded models in turn. To provide accurate scores, the outlier scoring method is crucial and faces the following challenges:
%The method , and for layer $j$, we use an outlier detection \textcolor{blue}{method} to detect layer $j$ of all uploaded models, assigning an anomaly score to each $j$ layer of each model. \textcolor{blue}{This outlier detection method faces two challenges:}

\noindent\textbf{C1}: \textbf{The proportion of compromised clients is unknown.} Many existing works on outlier detection reply to the impractical assumption of knowing the proportion of compromised clients in advance, which severely limits their applicability in reality. To address this limitation, in this work, we propose an algorithm without requiring such prior knowledge. As such, conventional outlier detection methods such as K-Nearest Neighbors (KNN) and One-Class SVM, which rely on prior knowledge of the number of neighbors, are not feasible. 

%Knowing the proportion of compromised clients is a common assumption in existing works which has a huge impact on their applicability in reality. In this work, we do not assume such knowledge. As a result, popular outlier detection methods such as KNN and ABOD which require the prior knowledge of the number of neighbors are not feasible.
%for the outlier detection method. For example, it is difficult to use commonly used algorithms such as KNN, LOF, etc., which require the number of neighbors to be specified in advance, or the choice of metric matrix, such as Euclidean distance or cosine distance, as we do not know the proportion of malicious attackers in advance.

\noindent\textbf{C2}: \textbf{Identifying backdoored models in dynamic scenarios.} In each round, the number of injected backdoors is unknown and may vary. Hence, it is important to have a stable backdoored model identification method that can effectively handle dynamic attacks. Otherwise, many false positives may be generated, failing the backdoor defenses and impacting the main task's accuracy.

% \textbf{C2}: \textbf{\textcolor{blue}{The detection algorithm is computationally expensive.}} The neural networks of complex outlier detection algorithms are too large and thus computation-intensive. For example, \textcolor{blue}{For example, the ResNet network has a parameter size in the tens of millions.}

To address the above challenges, we chose Connectivity-based Outlier Factor~(COF)~\cite{cof} as our outlier detection algorithm. COF is a density-based outlier detection algorithm that measures the degree of connectivity of a data point to its neighboring points. COF calculates the outlier score of each data point by comparing its average reachability distance to that of its neighbors. COF is advantageous over other distance-based outlier detection algorithms as it is less sensitive to the number of dimensions of the data and can effectively detect outliers in high-dimensional data. It is also able to detect outliers in non-uniform density data sets and is less affected by the presence of noise in the data. Additionally, COF does not require any assumptions about the underlying data distribution, making it more robust to different types of data. Therefore, COF is a better choice for identifying backdoored models in a dynamic federated learning setting where the proportion of compromised clients is unknown and may vary over time.
%是否需要列出cof的计算公式 tbd


% iForest is an unsupervised, non-parametric (no assumptions about the sample distribution) outlier detection algorithm that does not require distance or density calculations. 
% It has low computational complexity and time complexity of $\mathcal{O}(n)$. As such, iForest can effectively overcome the aforementioned challenges.

% 挑战1：outlier detection method的参数选择。例如KNN、LOF等算法需要指定计算邻居的个数，但由于我们实现不知道恶意攻击者的比例大小，因此难以选择。亦或是度量矩阵的选择，很多算法需要实现指定度量矩阵，例如欧氏距离或余弦距离，该选择哪一个度量距离也会对outlier detection method的效果影响
% 挑战2：模型权重的维度很大。在RenNet网络中，权重的维度已经达到十几w，使得复杂的异常检测算法难以计算。
% 为了解决上述挑战，我们选择了iForest作为我们的异常点检测算法。iForest是一种无监督、非参数（不对样本的整体分布进行假设）的outlier detection method，不需要计算距离和密度，计算复杂度低，时间复杂度为O（n）。因此，iForest可以有效地克服这两个挑战。


        
%介绍异常值得分的过程
\begin{algorithm}
    \caption{Layer Scoring}\label{algorithm2}
    \begin{algorithmic} [1]
        \algrenewcommand\algorithmicrequire{\textbf{Input:}}
        \Require The local model $w_{i}$ uploaded by each client $ i\in C^{t} $
        \algrenewcommand\algorithmicrequire{\textbf{Output:}} 
        \Require  The set of Layer Scoring $S_{i}$ for each client $ i\in C^{t}$ 
        \State \textbf{initialize }  $n\gets len\left ( C^{t} \right ) $
        \For {$layer\ j\ in \left [ 1,total \right ]$ } \Comment{$total$ is the number of layers of the model }
        \State  $\left ( s_{1}^{j} ,\cdots,s_{n}^{j} \right ) \gets  COF\left ( w_{1}^{j} ,\cdots,w_{n}^{j} \right ) $
        \For {$  i \in \left [ n \right ]$ } 
        \State Add $s_{i}^{j}$ to the set of Layer Scoring $S_{i}$
        \EndFor
        \EndFor
        \State return $S_{1} ,\cdots,S_{n}$
    \end{algorithmic}
\end{algorithm}



\subsection{Anomaly Detection}
Layer Scoring assigns each layer of each local model an outlier score. Then, Anomaly Detection uses the scores to identify the anomalous clients to safeguard the model from backdoor attacks. Anomaly Detection checks the scores \textit{layer by layer} and increments a model's flag count by one upon finding an abnormal layer score. In the end, the clients with the higher flag counts are marked as anomalies. In this paper, we mark clients with more than 50\% of the layer count as anomalies. The algorithm for determining layer anomalies needs to be carefully designed to achieve the three \textit{defense goals} as mentioned in Section~\ref{sec:problem}.

We follow the common assumption that less than 50\% of clients are compromised. We argue that the commonly employed Three Sigma Rule~\cite{ThreeSigmaRule} and Z-score~\cite{Zscore}} can not identify anomalous clients well, because these algorithms assess clients using the mean value, which can be strongly influenced and shifted towards the location of the outliers in the presence of extreme outliers, resulting in failed outlier identifications.
%Because these algorithms assess clients using the mean value which is often shifted to extreme large outlier values and thus fail to identify anomalies. 
%\textcolor{blue}{For example, suppose we have the following set of data: [1, 2, 3, 30, 60]. In this set of data, most of the values are relatively normal, but there is one outlier (60), which will greatly affect the result of the mean calculation. The mean of outlier scores is 19.2, which is shifted to the outlier value 60.If we use Three Sigma Rule or Z-score algorithms to determine the outliers, it may lead to misclassified 30 as benign. This is because these algorithms focus only on the mean value and ignore other factors.}
% \textcolor{blue}{ For example, if the outlier scores are $[1,2,3,30,60]$, then the mean of outlier scores is 19.2, which is shifted to the outlier value 60 and leads to failure of detection}. 
To solve this problem, we use MAD for anomaly detection because: 
%which can effectively avoid the mean value shifting caused by extreme values. 
\begin{enumerate*}
  \item \textbf{it tolerates extreme values} since MAD uses the median which is not affected by extreme values, and 
  \item \textbf{it can be applied to any data distribution}, unlike Three Sigma Rule and Z-score which are only applicable to normally distributed data.% MAD, on the other hand, is applicable to any type of data distribution.
\end{enumerate*}
The Anomaly Detection processes include: 
\begin{enumerate*}
  \item Calculate the median of all the outlier scores.
  \item Calculate the absolute deviation value of the outlier scores from the median.
  \item Assign the median of all the absolute deviation values to MAD.
  \item A layer whose outlier score deviates from the median by larger than $\mu$ MAD is classified as anomalous and the model's flag ($Outlierflag$) is incremented by one. $\mu$ is the hyperparameter which we set to 3 by default in the experiments.
\end{enumerate*}
In each round, the server gets all the uploaded models and checks all their layers to get $ Outlierflag_{i},\forall i\in \left [ n \right ] $. FLD classifies the models of which at least half of the layers are marked as anomalies as anomalous models and aggregates only the other models that are classified as benign models. 
%介绍异常层判断的过程
\begin{algorithm}
    \caption{Anomaly Detection}\label{algorithm3}
    \begin{algorithmic} [1]
        \algrenewcommand\algorithmicrequire{\textbf{Input:}}
        \Require: The set of Layer Scoring from each client $ i\in C_{t}$ are regarded as $S_{i}$
        \algrenewcommand\algorithmicrequire{\textbf{Output:}} 
        \Require  The benign clients set $C_b^t$
        \State \textbf{initialize }  $n\gets len\left ( C^{t} \right ) $
        \State \textbf{initialize }  $Outlierflag_{i}  \gets 0, \forall i\in \left [ n \right ] $
        
        \For {$layer\ j\ in \left [ 1,total \right ]$ } \Comment{$total$ is the number of layers of the model }
        \State  $ Me \gets  MEDIAN\left ( S_{1}^{j} ,\cdots,S_{n}^{j} \right ) $
        \State  $MAD\gets MEDIAN(\left | S_{1}^{j}-Me \right |, \cdots, \left | S_{n}^{j}-Me \right |)$
        \For {$  i \in \left [ n \right ]$ } 
        \State $ flag1\gets \left ( S_{i}^{j} >= Me + \mu *MAD\right  ) ?1:0$
        \State $ flag2\gets \left ( S_{i}^{j} <= Me - \mu *MAD\right  ) ?1:0$
        \State $ Outlierflag_{i}\gets Outlierflag_{i}+flag1+flag2$
        \EndFor
        \EndFor
        \For {$  i \in \left [ n \right ]$ }
        \If{$Outlierflag_{i}<total/2$}
        \State Add $i$ to the benign clients set $C_b^t$
        \EndIf
        \EndFor
        \State return $C_b^t$
    \end{algorithmic}
\end{algorithm}


\subsection{Private FLD}
Many attacks on federated learning have been proposed besides backdoor attacks, such as membership inference attack and attribute inference attack. These attacks all demonstrate the necessity of enhancing the privacy protection of federated learning to prohibit access to local model plaintext updates. In general, there are two approaches to protect the privacy of customer data: differential privacy and encryption techniques such as homomorphic encryption~\cite{hom} or multi-party secure computation~\cite{mpc}. Differential privacy is a statistical and simple-to-implement method, but with impacts on the model performance, while encryption provides strong privacy guarantees and protection, but at the cost of reduced efficiency.
%%再介绍Paillier同态加密
Specifically, homomorphic encryption is a cryptographic primitive that allows computations to be performed on encrypted data without revealing the underlying plaintext. The basic idea is to encrypt the plaintext first to obtain the ciphertext and continue the calculation operation on the ciphertext, decrypt the final ciphertext result to obtain the plaintext, to keep the result consistent with the calculation on the plaintext. For example, Paillier cryptosystem is a representative additive homomorphic encryption that has been commonly used in federated learning. It has the following two homomorphic properties:
\setlist[itemize]{leftmargin=*}
\begin{itemize}
\item \textbf{Homomorphic addition of plaintexts}: $\llbracket{ x_{1}\rrbracket}\cdot \llbracket{ x_{2}\rrbracket}= \llbracket{x_{1}+x_{2}\rrbracket}$, where $ x_{1}$ and $ x_{2}$ represent  plaintexts, $\llbracket{~\rrbracket}$ 
is an encryption operation.
\item \textbf{Homomorphic multiplication of plaintexts}: $ \llbracket{ x\rrbracket}^{r}= \llbracket{ r\cdot x\rrbracket} $, where  $ x$  represents  plaintext, $\llbracket{~\rrbracket}$ 
is an encryption operation, $r$ is  a constant.
\end{itemize}
Next we illustrate the applicability of FLD in federated learning homomorphic encryption scenarios.
First, we follow the federated setup of~\cite{privacyfl}:
\setlist[itemize]{leftmargin=*}
\begin{itemize}
\item \textbf{Server} is responsible for receiving the gradients submitted by all participants and conducting aggregation to obtain a new global model.
\item \textbf{Cloud Platform (CP)} performs homomorphic encryption calculations together with the server. The CP holds a \textit{(private-key, public-key)} pair generated by a trusted authority for encryption and decryption.
\end{itemize}
Our algorithm is summarized in Algorithm~\ref{algorithm4}.\\
\begin{algorithm}[t!]
    \caption{Private FLD}\label{algorithm4}
    \begin{algorithmic} [1]
        \algrenewcommand\algorithmicrequire{\textbf{Input:}}
        \Require: The local model $\llbracket{w_{i}}\rrbracket$ uploaded by each client $ i\in C^{t} $
        \algrenewcommand\algorithmicrequire{\textbf{Output:}} 
        \Require  The set of Layer Scoring $S_{i}$ for each client $ i\in C^{t}$ 
        \algrenewcommand\algorithmicrequire{\textbf{Server:}}
        \Require
        \State  Randomly select m nonzero integer $r_i $ for j in [1,m]
        \Comment{m is the length of $w_{i}$ }
        \For {$  j \ in \left [ 1,m \right ]$ } \Comment{$n$ is  }
        \State $ c_{ij} \gets \llbracket{\omega_{ij} }\rrbracket\cdot \llbracket{r_{j} }\rrbracket  $
        \EndFor
        \State send $\left \{  c_{ij}  \right \} _{j=1}^{j=n} $ to CP
    \end{algorithmic}
    \begin{algorithmic}[1]
    \algrenewcommand\algorithmicrequire{\textbf{CP:}}
    \Require:
    \For {$  j \ in \left [ 1,m \right ]$ } \Comment{$n$ is  }
        \State  $ \omega _{ij}^{'} \gets Dec(sk_{c},c_{ij} ) $
    \EndFor
    \State $\left(S_{1} ,\cdots,S_{n}\right)\gets Layer Scoring\left(w_{1}^{'},\cdots,w_{n}^{'}\right)$
    \State Send $\left(S_{1} ,\cdots,S_{n}\right)$ to PS
    \end{algorithmic}
\end{algorithm}
%我们遵循Privacy-Enhanced Federated Learning Against Poisoning Adversaries的设置，算法描述如下，
%参考文献的描述
%我们需要可信的密钥生成中心（KGC）生成一对非对称密钥（pk c, sk c）云平台 (CP) 的 LHE，其中私钥sk c 仅由 CP 保存。同时，所有授权用户，持有LHE的同一对非对称密钥( pk x , sk x )由 KGC 生成。此外，在年初协议中，服务提供商（SP）随机初始化全局模型参数 ωini t 。
%介绍cof异常算法为什么可以
Correctness: To ensure that FLD can effectively identify malicious gradients, we need to prove that homomorphic encryption does not affect the calculation of COF anomaly detection.
According to the properties of homomorphic encryption, we have 
\begin{equation}
    \begin{split}\label{hm}
	  c_{ij}
	& =  \llbracket{\omega_{ij} }\rrbracket\cdot \llbracket{r_{j} }\rrbracket \\
	& =  \llbracket{\omega_{ij} } + {r_{j} }\rrbracket .
    \end{split}
\end{equation}
so $\omega _{ij}^{'} = \omega_{ij}  + r_{j} $, for $\omega _{x}^{'} $ and $\omega _{y}^{'} $ the Euclidean distance is
    \begin{equation}
    \begin{split}\label{hm}
	  \left \| \omega _{x}^{'}-\omega _{y}^{'} \right \| 
        & = \sqrt{\sum_{j=1}^{n}{\left( \omega _{xj}^{'}-\omega _{yj}^{'} \right)^{2} }}\\
	& =  \sqrt{\sum_{j=1}^{n}{\left( \omega_{xj}  + r_{j}- (\omega_{yj}  + r_{j}) \right)^{2} }} \\
        & = \sqrt{\sum_{j=1}^{n}{\left( \omega _{xj}-\omega _{yj} \right)^{2} }}\\
        & = \left \| \omega _{x}-\omega _{y} \right \|.
    \end{split}
\end{equation}

When the distance metric is Euclidean distance, the COF anomaly detection algorithm can still function in the homomorphic encryption scenario and the results are consistent with the plaintext.

\subsection{Convergence Analysis}
To analyze the convergence of FLD, we propose the theorem of convergence and prove it.

% \subsection{Notation and Assumptions}
% Let $F_i$ denotes the local model of the $i$-th client, $i=1,2,\cdots,N$. Let $F$ denotes the global model in the central parameter server. Suppose our models satisfy Lipschitz continuous gradient, we make Assumptions \ref{assumption1} and \ref{assumption2}. 


% \begin{assumption}\label{assumption1}
% ($L$-smooth). $F_1,\cdots,F_N$ are all $L$-smooth: $\forall x,y, F_i(x)\leq F_i(y)+(x-y)^{\mathsf{T}}\nabla F_i(y)+\frac{L}{2}||x-y||_2^2$.
% \end{assumption}
 
% \begin{assumption}\label{assumption2}
% ($\mu$-strongly convex). $F_1,\cdots,F_N$ are all $\mu$-strongly convex:  $\forall x,y, F_i(x)\geq F_i(y)+(x-y)^{\mathsf{T}}\nabla F_i(y)+\frac{\mu}{2}||x-y||_2^2$.
% \end{assumption}
% We also follow the assumption made by~\cite{stich2018sparsified,yu2019parallel,li2019convergence} as follows.
% \begin{assumption}\label{assumption3}
% The expected squared norm of stochastic gradients is uniformly bounded, i.e., $\exists U>0$, $\mathbb{E}||\nabla F_i(\cdot)||^2 \leq U^2$ for all $i=1,\cdots,N$.
% \end{assumption}
% We make Assumption \ref{assumption4} to bound the expectation of $||w_i^t||^2$, where $w_i^t$ denotes the parameters of $F_i$ in $t$-round.
% \begin{assumption}\label{assumption4}
% (Bounding the expectation of $|| w_i^t ||^2$). The expected squared norm of $i$-th client's local model parameters is bounded: $\exists M>0$, $\mathbb{E}||w_i^t||^2 \leq M^2$ for all $i=1,\cdots,N$ and $t=1,\cdots,T$.
% \end{assumption}

% \subsection{Theorem and Proof}

%提出收敛性理论, FLD收敛
\newtheorem{thm}{Theorem}
\begin{thm}\label{thm1}
Let Assumptions \ref{assumption1} to \ref{assumption4} hold and $L$, $\mu$, $U$, $M$ be defined therein. Choose the learning rate $\eta^t=\frac{\theta}{t+\epsilon}$, $ \epsilon>0$, $\theta > \frac{1}{\mu}$, we define $\lambda=\max\{\frac{\theta A}{\theta \mu -1}, (\epsilon+1)Z_1\}$. Then FLD satisfies 
\begin{equation}
    \begin{split}
        \mathbb{E}[F(G^t)]-F^*
	\leq \frac{L}{2} Z_t 
	\leq \frac{L}{2}\frac{\lambda}{(t+\epsilon )^{\frac{1}{2}}}
	\stackrel{t \to \infty}{\longrightarrow}0,
    \end{split}
\end{equation}
where 
\begin{equation}
    \begin{split}
        & A=4U^2+M^2+2\Gamma, \\
        & Z_t=\mathbb{E}||G^t-G^*||^2.
    \end{split}
\end{equation}
\end{thm} 


\begin{proof}
%以下是证明过程
%第一部分证明\mathbb{E}||G^{t+1}-G^*||^2\mathbb{E}||G^{t+1}-G^*||^2有上界，其中G^{t+1}是第t+1轮全局模型的权重，G^*是全局模型最优权重。
Let $G^{t+1}$ denote the global model's parameters in the central server in $(t+1)$-round and $G^*$ be the optimal parameters in the central server. Additionally, $g^t=\sum\limits_{i\in C_b^t}p_i\nabla F_i(w_i^t,\xi_i^t)$, where $g^t$ denotes the gradient updates uploaded by the clients in $t$-round and $p_i$ denotes the weight of the $i$-client's gradient during aggregation. $\bar{g^t}=\sum\limits_{i\in C_b^t}p_i\nabla F_i(w_i^t)$ and $G^{t+1}=G^t-\eta^t g^t$, where $C_b^t$ denotes the collection of benign clients chosen by FLD in $t$-round. Then, we have 
\begin{equation}
    \begin{split}\label{ineq1}
	||G^{t+1}-G^*||^2
	& = ||G^t-\eta^t g^t-G^*-\eta^t \bar{g^t} + \eta^t \bar{g^t}|| \\
	& = \underbrace{||G^t-G^*-\eta^t \bar{g^t}||^2}_{P_1} \\
        & +\underbrace{2\eta^t<G^t-G^*-\eta^t \bar{g^t},\bar{g^t}-g^t>}_{P_2} \\
	& +(\eta^t)^2||\bar{g^t}-g^t||^2.
    \end{split}
\end{equation}

Since $\mathbb{E}g^t=\bar{g^t}$, we see $\mathbb{E}P_2=0$. Now we split $P_1$ into three terms:   
\begin{equation}
    \begin{split}\label{ineq2}
	P_1
	& = ||G^t-G^*-\eta^t \bar{g^t}||^2 \\
	& = ||G^t-G^*||^2\underbrace{-2\eta^t<G^t-G^*,\bar{g^t}>}_{P_3}+\underbrace{(\eta^t)^2||\bar{g^t}||^2}_{P_4}.
    \end{split}
\end{equation}

Focusing on the last term in the above equation, according to Assumption \ref{assumption3}, we have 
\begin{equation*}
\begin{split}
    \mathbb{E}P_4
 & =\mathbb{E}[(\eta^t)^2||\bar{g^t}||^2] \\
 & \leq (\eta^t)^2\sum\limits_{i\in C_b^t}p_i^2\mathbb{E}||\nabla F_i(w_i^t)||^2 \\
 & \leq (\eta^t)^2 U^2 .  
\end{split}
\end{equation*}

Consider $P_3$, it follows:
\begin{equation}
    \begin{split}\label{ineq3}
	P_3
	& = -2\eta^t<G^t-G^*,\bar{g^t}> \\
	& = -2\eta^t\sum\limits_{i\in C_b^t}p_i<G^t-w_i^t,\nabla F_i(w_i^t)>\\
	& -2\eta^t\sum\limits_{i\in C_b^t}p_i<w_i^t-G^*,\nabla F_i(w_i^t)>.
    \end{split} 
\end{equation}

It is well known that $-2ab\leq a^2+b^2$, so
\begin{equation}
    \begin{split}\label{ineq4}
    & -2<G^t-w_i^t,\nabla F_i(w_i^t)>\\ 
    & \leq ||G^t-w_i^t||^2+||\nabla F_i(w_i^t)||^2 .
    \end{split}
\end{equation}

According to Assumption \ref{assumption2}, it follows:
\begin{equation}
    \begin{split}\label{ineq5}
    & -<w_i^t-G^*,\nabla F_i(w_i^t)> \\
    & \leq -(F_i(w_i^t)-F_i(G^*)) -\frac{\mu}{2}||w_i^t-G^*||^2 .
    \end{split}
\end{equation}

%由 (5)，(6)，(7)，(8)，可得
Use Equation~\ref{ineq2} and Inequalities~\ref{ineq3},~\ref{ineq4},~\ref{ineq5}, we obtain the following formula
\begin{equation*}
    \begin{split}
	   P_1  
        & = ||G^t-G^*-\eta^t \bar{g^t}||^2 \\
	& \leq ||G^t-G^*||^2+(\eta^t)^2||\nabla F_i(w_i^t)||^2 \\
        & +\eta^t\sum\limits_{i \in C_b^t}p_i(||G^t-w_i^t||^2
         +||\nabla F_i(w_i^t)||^2) \\
	& - 2\eta^t\sum\limits_{i \in C_b^t}p_i(F_i(w_i^t)-F_i(G^*)+\frac{\mu}{2}||w_i^t-G^*||^2)\\
	& \leq (1-\eta^t\mu)||G^t-G^*||^2+((\eta^t)^2+\eta^t)||\nabla F_i(w_i^t)||^2\\
	& + \eta^t\sum\limits_{i \in C_b^t}p_i||G^t-w_i^t||^2 \\
        & \underbrace{- 2\eta^t\sum\limits_{i \in C_b^t}p_i(F_i(w_i^t)-F_i(G^*))}_{P_5}.
    \end{split} 
\end{equation*}
Motivated by ~\cite{li2019convergence}, we define $\Gamma=F^*-\sum\limits_{i\in C_b^t}p_iF_i^*$. $\Gamma$ is used to measure the degree of heterogeneity between the local models and the global model, in i.i.d data distributions, $\mathbb{E}\Gamma=0$. We have 
%计算p5
\begin{equation*}
    \begin{split}
	P_5 
	& = - 2\eta^t\sum\limits_{i \in C_b^t}p_i(F_i(w_i^t)-F_i(G^*))\\
	& = - 2\eta^t\sum\limits_{i \in C_b^t}p_i(F_i(w_i^t)-F_i^*+F_i^*-F_i(G^*))\\
	& \leq  2\eta^t\sum\limits_{i \in C_b^t}p_i(F^*-F_i^*)=2\eta^t \Gamma, 
    \end{split} 
\end{equation*}
Hence,
\begin{equation*}
    \begin{split}
	P_1
	& \leq (1-\eta^t\mu)||G^t-G^*||^2+((\eta^t)^2+\eta^t)||\nabla F_i(w_i^t)||^2\\
	& + \eta^t\sum\limits_{i \in C_b^t}p_i||G^t-w_i^t||^2 +2\eta^t \Gamma.
    \end{split} 
\end{equation*}

Utilize the above results, we have
%从而可得
\begin{equation}
    \begin{split}\label{ineq6}
	\mathbb{E}|G^{t+1}-G^*||^2
	& \leq (1-\eta^t\mu)\mathbb{E}||G^t-G^*||^2 \\
        & + ((\eta^t)^2+\eta^t)\mathbb{E}||\nabla F_i(w_i^t)||^2\\
	& + \eta^t\sum\limits_{i \in C_b^t}p_i\mathbb{E}||G^t-w_i^t||^2 +2\eta^t \Gamma \\
        & + (\eta^t)^2\mathbb{E}||\bar{g^t}-g^t||^2.
    \end{split}
\end{equation}
%至此，Part1 证明完毕

%Part 2
%利用Assumption 3证明有界
According to Assumption \ref{assumption3}, it follows:
\begin{equation}
    \begin{split}\label{ineq7}
	\mathbb{E}||g^t-\bar{g^t}||^2
	& = \mathbb{E}||\sum\limits_{i \in C_b^t}p_i\nabla F_i(w_i^t,\xi_i^t)-\nabla F_i(w_i^t)||^2 \\
	& \leq \sum\limits_{i \in C_b^t}p_i^2 (\mathbb{E}||\nabla F_i(w_i^t,\xi_i^t)||^2 \\
        & +\mathbb{E}||\nabla F_i(w_i^t)||^2) \\
	&\leq 2\sum\limits_{i \in C_b^t}p_i^2 U^2.
    \end{split} 
\end{equation}
%至此，Part2 证明完毕


%Part 3
%利用Assumption 4证明有界
According to Assumption \ref{assumption4}, it follows:
\begin{equation}\label{ineq8}
    \begin{split}
	\sum\limits_{i \in C_b^t}p_i||G^t-w_i^t||^2
	& = \sum\limits_{i \in C_b^t}p_i||\sum\limits_{i \in C_b^t}p_i w_i^t-w_i^t||^2 \\
	& \leq \sum\limits_{i \in C_b^t}p_i || w_i^t||^2 \\
	& \leq M^2.
    \end{split}
\end{equation}
%至此part 3证明完毕

%Part 4
%现在由前三部分的结论来证明最终结论。
So far, we have all the preparations ready to prove the final conclusion. Let  $Z_t=\mathbb{E}||G^t-G^*||^2$, $\eta^t=\frac{\theta}{t+\epsilon}$, $\epsilon>0$, $\theta > \frac{1}{\mu}$, $\lambda=\max\{\frac{\theta A}{\theta \mu -1}, (\epsilon+1)Z_1\}$, our goal of proving $Z_t \leq \frac{\lambda}{(t+\epsilon)^{\frac{1}{2}}}$ can be achieved as follows.
\newline
For $t=1$, it holds. Suppose that the conclusion establishes for some t and use Inequalities~\ref{ineq6},~\ref{ineq7},~\ref{ineq8}, we have $Z_{t+1}$ as follows: %Note $A=4U^2+M^2+2\Gamma$, use (\ref{ineq6}), (\ref{ineq7}), (\ref{ineq8}), it follows
\begin{equation}
    \begin{split}
        Z_{t+1}
	& \leq (1-\eta^t\mu) Z_{t}+((\eta^t)^2+\eta^t)U^2 + \eta^t M^2 \\
        &  + 2 (\eta^t)^2 \sum\limits_{i \in C_b^t}p_i^2 U^2+2\eta^t \Gamma \\
	& \leq (1-\eta^t\mu)Z_{t} + \eta^t A \\
	& = \frac{(t+\epsilon)^{\frac{1}{2}}-1}{(t+\epsilon)}\lambda+(\frac{\theta A}{t+\epsilon}-\frac{\theta \mu -1}{t+\epsilon}\lambda) \\
	& \leq \frac{\lambda}{(t+\epsilon +1)^{\frac{1}{2}}},
    \end{split}
\end{equation}
where $A=4U^2+M^2+2\Gamma$.
%t+1t+1时刻成立，于是Z_t \leq \frac{\lambda}{(t+\epsilon)^{\frac{1}{2}}}Z_t \leq \frac{\lambda}{(t+\epsilon)^{\frac{1}{2}}}成立。
%利用Assumption **1**，从而有
Then, from Assumption \ref{assumption1}, we get
\begin{equation}
    \begin{split}
        \mathbb{E}[F(G^t)]-F^*
	\leq \frac{L}{2} Z_t 
	\leq \frac{L}{2}\frac{\lambda}{(t+\epsilon )^{\frac{1}{2}}}
	\stackrel{t \to \infty}{\longrightarrow}0.
    \end{split}
\end{equation}
\end{proof}











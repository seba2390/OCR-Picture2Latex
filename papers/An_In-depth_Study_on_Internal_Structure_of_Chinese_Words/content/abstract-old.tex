    \begin{abstract}

Unlike English letters, Chinese characters have rich and specific meanings. Usually, the meaning of a word can be derived from its constituent characters in some way. 
Several previous works on syntactic parsing propose to annotate shallow word-internal  structures for better utilizing character-level information. 
%Many previous studies try to model and utilize word-formation laws for better word understanding and representation. 
%Different from most Indo-European languages such as English, Chinese characters convey meanings, and the meaning of most words are derived from their constituent characters.
This work proposes to model the deep internal structures of Chinese words as dependency trees with 11 labels for distinguishing syntactic relationships. 
%We endeavour to answer three questions. 1) What are 
%the word-formation laws for Chinese words? 2) How well can a model be trained to predict deep word-internal structures? 
%3) Is modeling word-internal structures beneficial for word representations? 
%Specifically, this work can be decomposed into four parts. 
First, based on newly compiled annotation guidelines, we 
%based on linguistic textbooks and sentence-level syntactic annotation projects.
manually annotate a word-internal structure treebank (WIST) consisting of over 30K multi-char words from Chinese Penn Treebank. 
To guarantee quality, each word is independently annotated by two annotators and inconsistencies are handled by a third senior annotator.  
Second, we present detailed and interesting analysis on WIST to reveal insights on Chinese word formation. 
Third, we propose word-internal structure parsing as a new task, and conduct benchmark experiments using a competitive dependency parser. 
Finally, we present two simple ways to encode word-internal structures, leading to promising gains on %and show that such structure-aware word representations is beneficial for 
the sentence-level syntactic parsing task. 
% 有点长，还要凝练。questions考虑放到introductions中


% Typically, words are considered as the basic semantic units for Chinese language processing and therefore the representation of words becomes a core issue. Previous work usually represents words by considering their contextual information or encode the constituent characters of words with the assumption that each word has a flat structure.
% Such word representations give no consideration to char-level syntactic structures for words, an informative linguistic source that can reflect the dependency relations between characters and convey meanings to alleviate out-of-vocabulary issues.
% In this work, we conduct an in-depth study on char-level syntactic structures. First, we manually annotate over xxx words with char-level syntactic structures according to our newly compiled annotation guideline and give detailed analysis to gain more
% insights on the construction of Chinese words.
% Then, we propose to parse the structures with a simple yet effective graph-based parser. Finally, by applying intra-word structures to two downstream tasks, i.e., word-based and char-based dependency parsing, we verify the effectiveness of intra-word character dependency structures and its potential capability in better understanding deeper level information of Chinese words. 

% Motivation两方面：
% 1）汉语中字有明确的含义，古代的时候单字词占绝大多数。由字到词的规律（即构词法）非常有趣，对于新词发现和理解应该也会很有帮助。
% 2）目前深度学习下，三种主流词表示方法：word emb, charLSTM（序列，不考虑深层次的字间关系），上下文相关表示，均没有考虑词内部结构。

\end{abstract}



% 龚晨：先不着急写abstract。先把要写的东西，乱七八糟的写出来，放在intro，最后根据实验结果再去梳理，再决定怎么讲故事。
% Traditionally, natural language processing tasks for Chinese language usually consider words or characters as basic linguistic units. On the one hand, word-based method preserves more semantic information. However（不是连词，这时两句话）, due to the flexibility of Chinese word construction, it is not easy for the model to accurately learn word semantics, especially for those out-of-vocabulary words. On the other hand, although character-based method can alleviate data sparseness issue, it is prone to suffer from ambiguity problem.
% In this paper, we investigate character-level dependency structure（尝试采用依存树来刻画词语的构成、构词法、构词法的翻译？word-building word-formation？ ） to capture the internal syntactic relations for words, a linguist source which contains richer syntax and semantic information than characters and is less sparse than words.
% 我感觉我们要把意义讲大一些。光是针对汉语构词法的研究，就很有意义了。
% First, we manually annotate over xxx words with intra-word character dependency structures according to our newly compiled annotation guideline. Then, we propose to parse intra-word character dependency by employing a simple yet effective graph-based parser. Finally, by 
% applying intra-word character dependency trees to two downstream tasks, i.e., word-based dependency parsing and semantic role labeling, we verify the effectiveness of intra-word character dependency structures and its potential capability in better understanding deeper level information of Chinese words. 

% 构词法研究的意义：更好的词表示；更好的词义理解；新词发现；新词的含义理解
\section{Discussion}
\label{sec:discussion}
\rev{We summarize the implications of our investigation, reflect on our limitations, and discuss promising directions for future research.}

\subsection{Implication}
\rev{
\paragraph{Create animated effects with model-free motion transfer.}
We contribute a novel approach in the emerging area of AI-generated content to design motion graphics using prevalent cross-domain GIFs as references.
Participants in the workshop acknowledge the ease of guiding animation generation with reference GIFs.
Despite various properties to coordinate in animation design, the underlying workflow of \tool{} helps users to author in a top-down manner instead of tweaking every details.
Beyond template engines, model-free motion transfer helps create more diversified effects.

\paragraph{Support human-AI collaboration with interpretable features.}
According to the user feedback in the workshop, the extracted key point helps them understand the causes of misalignment.
While most of our participants are unaware of the internal mechanism, they are able to correct the flaws introduced by the black-box model and intervene in the generation process to produce more desirable results.
In designing AI-empowered authoring tools, interpretable features are practical entry points for humans to inject requirements into the content creation process.


\paragraph{Consider design requirements of users at different levels.}
\tool{} supports both one-off generation and fine-grain control.
On the one hand, there are default values underlying algorithms to cater to the fast-generation need of causal users.
On the other hand, configurable parameters and the vector representation of generated results are also exposed for further adjustment.
When developing authoring support for prevailing artifacts, such as kinetic typography or data visualization, it is important to consider the requirements of different user profiles to make the authoring tool more useful.
}

\subsection{Limitation}
% 文字没有复杂的内部结构，丧失很多语义信息。可以结合word-as-image，动态+外形一起表达语义
% 变形过大的时候轮廓还是会不光滑：扩充控制点；用三角面片的形式来优化
% 对动图物体有要求：rigid body
% We pose three primary limitations of the proposed approach, including the deformation stability between frames, semantic expressiveness of text, and the utilization of interaction data. Accordingly, we propose potential solutions to address the identified issues.
% Drawing upon our reflections, we propose possible directions for future exploration.



\paragraph{Deformation stability.} 
When the motion amplitude of the character in the driving GIF is too large, excessive deformation may occur in the glyph, especially for fonts with only a few control points.
Severe deformation can result in distorted glyphs with discontinued outlines and low legibility.
This may be addressed by expanding the number of control points along the predefined glyph outline~\cite{iluz2023word}, using the triangulated mesh representation of glyphs~\cite{desbrun1999implicit}, \rev{and introducing global penalty in the loss function}.
\rev{In addition, as discussed in \autoref{sec:generalizability}, the automatic pipeline may fail for over-complicated GIF styles or typefaces, which requires more generalized models in motion trajectory extraction.}  
% First, When the deformation is too large, the similarity between the motion structure of the source motion and the glyph is low, or the model is not accurate enough in detecting key points.
% It may lead to excessive deformation, confusing relative positions of control points, sharp corners of the glyph, distortion, and other unsmooth conditions. 

% To overcome this problem, we can try to apply algorithms that expand control points for glyphs with fewer control points to generate smoother lines during generation time, while at refinement time, reducing the set of control points accordingly for glyphs with more control points. 
% This provides the right number of control points for interactive user adjustment. Additionally, optimization can be done in the form of triangular face slices.

\paragraph{\rev{Motion semantic perseverance.}} 
\rev{
As with other cross-domain motion transfer problems, when generated result may not preserve the original semantics, as text generally lacks comparable internal structures with GIFs, where the length of a text strongly influences the success.
With our approach, a ``goodbye'' may crawl like a snake but hardly a giraffe swinging its neck.
In addition, our objective function prioritizes the overall deformation of the exterior and may neglect the local and independent deformation of the interior.
For instance, the generated result may learn the waving gesture but miss the delicate eye blinking.}


\paragraph{\rev{Animation expressiveness.}}
We leverage motion transfer on text control points to deform the shape of text elements and mimic the general animated effects in the driving GIF.
However, in addition to learning the shape-deformation patterns, kinetic typography also concerns other properties~\cite{xie2023emordle}.
Future works may explore incorporating visual properties like colors and designing an integrated environment for a more flexible authoring experience.
% Compared to images, text generally lacks complex internal structure, which may not be as expressive in animation.
% As such, when transferring motion from a character to text, the full semantic information may be lost.
% Another impact is that it may cause our generated content to prioritize the overall deformation of the exterior while not giving enough attention to the local and independent deformation of the interior. As a result, there may be a loss of semantic information for both appearance and motion.
% For semantic enhancement, one possible solution is to further incorporate information from the input text into the glyph, expressing semantics with both the action and appearance.
% Additionally, adding color-changing channels over time may also be helpful.

% \paragraph{Utilization of interaction data.}
% \rev{Wakey-Wakey provided users with interactive modules for fine-tuning, where they could directly drag the control points.
% However, we did not fully exploit the value of user interaction logs. 
% First, the corrected results can be further used for model training and algorithm improvement.}
% Second, a recommendation model for interactive operations can be trained with historical operation data to improve users' experience.


% The effectiveness of a motion transfer technique can be evaluated based on several criteria. Here are some possible factors to consider:
    % Reduction of Motion: The primary goal of motion transfer techniques is to reduce the amount of motion transfer between two objects or surfaces. The effectiveness of a motion transfer technique can be evaluated by measuring the amount of motion transferred before and after the technique is applied.
    % Consistency of Results: The effectiveness of a motion transfer technique can be evaluated by assessing whether it consistently reduces motion transfer across different conditions, such as varying temperatures or loads.
    % Durability: The effectiveness of a motion transfer technique can be evaluated by measuring its durability over time, particularly under conditions that would cause traditional techniques to fail, such as high loads or extreme temperatures.
    % Compatibility with Other Materials: The effectiveness of a motion transfer technique can be evaluated by assessing its compatibility with other materials or coatings that may need to be applied to the same surface.
    % Ease of Application: The effectiveness of a motion transfer technique can also be evaluated based on how easy it is to apply and integrate into existing systems, particularly in industrial or manufacturing applications.

\subsection{Future Work}
% Here we list several promising directions for future works.

% \textit{Broaden the controlled parameter space for kinetic typography.}
% In recent years we have witnessed the emergence of \textit{variable fonts}, whose parameterized properties like weight and italic extent can be accessed within a continuous range.
% Our approach leverages the pre-existed control points to perform motion transfer.
% Apart from directly transforming the text outline, future works may search in the design space of variable fonts in the matching stage and produce more legible results.

% \textit{Generalize motion transfer for vector graphics.}
\rev{This work demonstrates a novice-friendly approach to creating text animation through cross-domain motion transfer.
While we focus on texts, it is also interesting to explore arbitrary anthropomorphized shapes, such as the dancing mushrooms in Disney's \textit{Fantasia}~\cite{fantasia} or sketches of monsters~\cite{su2018live,smith2023tog}.
Unlike human postures constrained by bones and flesh, motion graphics enjoy higher flexibility for exaggerating effects, which share similarities with text.
We note that the outline optimization should shift the focus from maintaining text legibility to shape semantics. 
Recent advances in large language-vision models like Stable Diffusion~\cite{rombach2022high} may help to regularize undesired artifacts.
In addition, animated data storytelling (\eg,~\cite{wang2021infomotion,Shu21Gif}) remains an exciting avenue for integrating expressive motions on visual marks.
As illustrated in the case of an animated word cloud (see \autoref{fig: wccase}), the positions of individual visual marks in a visualization can be regarded as the control points of a text.
Using our approach, it is possible to transfer motion into visualizations, which may extend existing visual vocabularies and further facilitate the comprehension of abstract data and the expression of emotions~\cite{lan21kineticharts, xie2023emordle}. }


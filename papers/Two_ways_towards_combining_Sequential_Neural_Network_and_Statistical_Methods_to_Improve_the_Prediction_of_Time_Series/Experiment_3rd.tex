\section{Experiment Analysis}
\subsection{Data Prepossessing}
Fig 1 shows the daily open stock price for "Federal Home Loan Mortgage Corp(FMCC)" Company from 01-02-2018 to 11-02-2018. In the very beginning, the stationary of this series should be checked since it's the requirement to build up the time related statistical model. Augmented Dickey-Fuller Test(ADF) test and KPSS test are the most popular method to check the stationary of the time series. The null hypothesis for ADF test is the time series is not stationary while the null hypothesis for KPSS is the time series is stationary. Table 1 and table 2 show the ADF and KPSS test results. From the P-value in Table, we should accept the null hypothesis of ADF test and reject the null hypothesis of KPSS test and conclude the time series is not stationary at the 5 percent level of significance.
\begin{table}[]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
\multicolumn{5}{|l|}{Table 1: ADF Test Results for Open Price}                 \\ \hline
\multicolumn{3}{|l|}{Dickey-Fuller}          & \multicolumn{2}{l|}{-1.9106}    \\ \hline
\multicolumn{3}{|l|}{P-value}                & \multicolumn{2}{l|}{0.6135}     \\ \hline
\multicolumn{3}{|l|}{Null hypothesis} & \multicolumn{2}{l|}{Non-stationary} \\ \hline
\end{tabular}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
\multicolumn{5}{|l|}{Table 2: KPSS Test Results for Open Price}         \\ \hline
\multicolumn{3}{|l|}{KPSS Level}      & \multicolumn{2}{l|}{2.2152}     \\ \hline
\multicolumn{3}{|l|}{P-value}         & \multicolumn{2}{l|}{0.01}       \\ \hline
\multicolumn{3}{|l|}{Null hypothesis} & \multicolumn{2}{l|}{Stationary} \\ \hline
\end{tabular}
\end{table}
Next, the key becomes how to transfer the unstationry data into stationary one. There are many different methods can be used to make the data more stationary like logarithm, difference, Power transform, etc. Here we use the most popular one-difference to transform the data. Fig 2 shows the differences data of the original time series.Further, the stationary will be checked again to ensure that the data is stable after the difference. Table 3 and table 4 show the ADF and KPSS test results. From the p-values in table 2, one can conclude that the differenced data is stationary now. 

\begin{table}[]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
\multicolumn{5}{|l|}{Table 3: ADF Test Results for Open Price}              \\ \hline
\multicolumn{3}{|l|}{Dickey-Fuller}   & \multicolumn{2}{l|}{-6.6027}        \\ \hline
\multicolumn{3}{|l|}{P-value}         & \multicolumn{2}{l|}{0.01}           \\ \hline
\multicolumn{3}{|l|}{Null hypothesis} & \multicolumn{2}{l|}{Non-stationary} \\ \hline
\end{tabular}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
\multicolumn{5}{|l|}{Table 4: KPSS Test Results for Open Price}         \\ \hline
\multicolumn{3}{|l|}{KPSS Level}      & \multicolumn{2}{l|}{0.36596}    \\ \hline
\multicolumn{3}{|l|}{P-value}         & \multicolumn{2}{l|}{0.092}      \\ \hline
\multicolumn{3}{|l|}{Null hypothesis} & \multicolumn{2}{l|}{Stationary} \\ \hline
\end{tabular}
\end{table}

\subsection{ARIMA-GARCH Model}
\subsubsection{ARIMA Model Selection}

When the series are stationary, the next step is to build up a appropriate ARIMA model for it. ACF and PACF plots will be helpful to make selection for ARIMA model, which are shown in fig 3. From the ACF and PACF plots, we do see the auto-correlation and partial auto-correlation in the time series. However, to make a more accurate model, we use the auto.arima function in R studio to make the exact selection. The auto.arima function in R studio will select the model  based on either the AIC, BIC or AICc. Fig 4 shows the result of auto.arima. So far, ARIMA(5,0,2) will be used to model the differenced time series. The Table 3 below shows the result of ARIMA(5,0,2) model. 
\begin{table}[]
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\multicolumn{6}{|c|}{Table 5: Results of ARIMA Model} \\ \hline
 & ar1 & ar2 & ar3 & ar4 & ar5 \\ \hline
Coefficients of AR & -0.618 & -0.3506 & -0.0379 & 0.0299 & 0.1604 \\ \hline
standard errors & \multicolumn{1}{l|}{0.471} & \multicolumn{1}{l|}{0.4322} & \multicolumn{1}{l|}{0.1109} & \multicolumn{1}{l|}{0.1000} & \multicolumn{1}{l|}{0.0835} \\ \hline
 & \multicolumn{3}{c|}{ma1} & \multicolumn{2}{c|}{ma2} \\ \hline
Coefficients of MA & \multicolumn{3}{c|}{0.5223} & \multicolumn{2}{c|}{0.1836} \\ \hline
standard errors & \multicolumn{3}{c|}{0.4800} & \multicolumn{2}{c|}{0.4469} \\ \hline
AIC & \multicolumn{5}{c|}{-593.7} \\ \hline
\end{tabular}
\end{table}
\subsubsection{ARIMA Model Diagnostic Test}
The significance test of the model is mainly to test the validity of the model.The residuals for a good model should not contain any correlation information,that is, the residuals should be the white noise; Otherwise, the model is not valid and other models should be reconsidered. Ljung-Box test is a powerful tool to test the white noise. The null hypothesis of this test is the tested series is a white noise while the alternative hypothesis is the series is not a white noise. The table below shows the Ljung-Box test result, from which one can not reject the null hypothesis and conclude that the ARIMA(5,0,2) model is valid.

\begin{table}[]
\centering
\begin{tabular}{|c|l|l|c|l|}
\hline
\multicolumn{5}{|c|}{\begin{tabular}[c]{@{}c@{}} Table 6: Ljung-Box Diagnostic Test   \\    Results for ARIMA Model \end{tabular}} \\ \hline
\multicolumn{3}{|c|}{Lag} & \multicolumn{2}{c|}{P-value} \\ \hline
\multicolumn{3}{|c|}{2} & \multicolumn{2}{c|}{0.9497} \\ \hline
\multicolumn{3}{|c|}{4} & \multicolumn{2}{c|}{0.9762} \\ \hline
\multicolumn{3}{|c|}{6} & \multicolumn{2}{c|}{0.9906} \\ \hline
\multicolumn{3}{|c|}{8} & \multicolumn{2}{c|}{0.9945} \\ \hline
\multicolumn{3}{|c|}{10} & \multicolumn{2}{c|}{0.9989} \\ \hline
\multicolumn{3}{|c|}{12} & \multicolumn{2}{c|}{0.9998} \\ \hline
\multicolumn{3}{|c|}{14} & \multicolumn{2}{c|}{0.9954} \\ \hline
\multicolumn{3}{|c|}{16} & \multicolumn{2}{c|}{0.9984} \\ \hline
\multicolumn{3}{|c|}{18} & \multicolumn{2}{c|}{0.9987} \\ \hline
\multicolumn{3}{|c|}{20} & \multicolumn{2}{c|}{0.9987} \\ \hline
\end{tabular}
\end{table}

\subsubsection{ARCH Effect Test}
ARCH effect measures the fluctuation of time series. After the model passes the test, there is no correlation between the residuals themselves but the relationship between the changes in the residuals needs to be considered. In other words,  the homogeneity of variance in the residuals should be take into account. Fortunately, the homogeneity test of variance can be converted to the autocorrelation test of the residual square sequence. Therefore, the Lagrange Multiplier(LM) test method is used to test the autocorrelation of the residual square sequence, to simply find whether there is the ARCH effect in the residual sequence. The null hypothesis of the LM test is that the variance of the residual square sequence is homogeneous. Table x shows the result of LM test, from which one can reject the null hypothesis and conclude there is arch effect in the residual sequence. Then GARCH model should be used next. 
\begin{table}[]
\centering
\begin{tabular}{|c|l|l|c|l|}
\hline
\multicolumn{5}{|c|}{\begin{tabular}[c]{@{}c@{}}Table 7: Ljung-Box Arch Effect Test \\ Results for  Residuals\end{tabular}} \\ \hline
\multicolumn{3}{|c|}{Lag} & \multicolumn{2}{c|}{P-value} \\ \hline
\multicolumn{3}{|c|}{2} & \multicolumn{2}{c|}{9.992e-16} \\ \hline
\multicolumn{3}{|c|}{4} & \multicolumn{2}{c|}{2.753e-14} \\ \hline
\multicolumn{3}{|c|}{6} & \multicolumn{2}{c|}{4.745e-13} \\ \hline
\multicolumn{3}{|c|}{8} & \multicolumn{2}{c|}{3.561e-12} \\ \hline
\multicolumn{3}{|c|}{10} & \multicolumn{2}{c|}{2.579e-11} \\ \hline
\multicolumn{3}{|c|}{12} & \multicolumn{2}{c|}{1.178e-10} \\ \hline
\multicolumn{3}{|c|}{14} & \multicolumn{2}{c|}{6.767e-10} \\ \hline
\multicolumn{3}{|c|}{16} & \multicolumn{2}{c|}{2.105e-09} \\ \hline
\multicolumn{3}{|c|}{18} & \multicolumn{2}{c|}{8.386e-09} \\ \hline
\multicolumn{3}{|c|}{20} & \multicolumn{2}{c|}{3.15e-08} \\ \hline
\end{tabular}
\end{table}

\subsubsection{Building Up ARIMA-GARCH Model}
GARCH part model selection is based on AIC. The table below display all the AIC value for P&Q from 1 to 5. From table x, we finally select ARIMA(5,0,2)-GARCH(1,1) model since this model has the smallest AIC. The specific model information is shown in equation x. 

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\multicolumn{6}{|l|}{Table 8: Arima(5,0,2)-Garch(p,q) order selection} \\ \hline
    & 1           & 2           & 3          & 4          & 5          \\ \hline
1   & -3.144827   & -3.112094   & -3.114695  & -3.080765  & -3.047413  \\ \hline
2   & -3.132756   & -3.107489   & -3.089428  & -3.055498  & -3.022146  \\ \hline
3   & -3.102736   & -3.077602   & -3.064161  & -3.030231  & -2.996879  \\ \hline
4   & -3.070756   & -3.045544   & -3.030231  & -3.004964  & -2.971612  \\ \hline
5   & -3.048537   & -3.023396   & -3.004462  & -2.979283  & -2.954017  \\ \hline
\end{tabular}
\end{table}
\subsubsection{ARIMA-GARCH Model Diagnostic Test}
After build up the ARIMA(5,0,2)-GARCH(1,1) model, we still need to check the validity of the model. Ljung-Box test will be used to test whether the residuals here is white noise and Lagrange Multiplier test will be used to check the arch effect of the residuals. Table X shows the  results for both of the tests, from which one can conclude ARIMA(5,0,2)-GARCH(1,1) model is valid and all the arch effect is deleted.
\begin{table}[]
\centering
\begin{tabular}{|l|l|}
\hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{@{}l@{}}Table 9: Ljung-Box Diagnostic Test\\ Results for ARIMA-GARCH Model\end{tabular}} \\ \hline
Lag & P-value \\ \hline
2   & 0.9409  \\ \hline
4   & 0.8442  \\ \hline
6   & 0.2973  \\ \hline
8   & 0.2289  \\ \hline
10  & 0.3505  \\ \hline
12  & 0.5196  \\ \hline
14  & 0.4261  \\ \hline
16  & 0.5607  \\ \hline
18  & 0.6848  \\ \hline
20  & 0.7812  \\ \hline
\end{tabular}
\end{table}
\subsection{Results analysis of decomposition based method}
According to the ARIMA-GARCH model above, one can get the unstable part $N_t$ by $N_t = y_t - ARIMA(5,0,2)-GARCH(1,1)$. Next, ML models are used to deal with $N_t$. To predict the future, we will make both one-step and multi-steps predictions. The results below show the comparisons among ARIMA-GARCH-SVR, ARIMA-GARCH-LSTM, SVR, LSTM and ARIMA-GARCH, from which one can see ARIM-GARCH-SVR model has the best performance. Figure~\ref{PreM1}

\begin{wrapfigure}
  \vspace{5pt}
  \begin{center}
\includegraphics[width=2.5 in]{images/Predictions_M1.png}
  \end{center}
  \vspace{-20pt}
  \caption{\footnotesize Open Price Predictions of Different Methods}
\label{PreM1}
  \vspace{10pt}
\end{wrapfigure}

%[12]{r}{2.5in}
\begin{wrapfigure}
  \vspace{5pt}
  \begin{center}
\includegraphics[width=2.5 in]{images/MSEs_M1.png}
  \end{center}
  \vspace{-20pt}
  \caption{\footnotesize MSEs}
\label{MseM1}
  \vspace{20pt}
\end{wrapfigure}

%[12]{r}{2.5in}
\begin{wrapfigure}
  \vspace{5pt}
  \begin{center}
\includegraphics[width=2.5 in]{images/RollingM1.png}
  \end{center}
  \vspace{-20pt}
  \caption{\footnotesize Multiple Steps Predictions of Open Price}
\label{Rolling}
  \vspace{20pt}
\end{wrapfigure}

\begin{wrapfigure}
  \vspace{5pt}
  \begin{center}
\includegraphics[width=2.5 in]{images/RollingMse.png}
  \end{center}
  \vspace{-20pt}
  \caption{\footnotesize MSEs of Different Prediction Steps}
\label{RollingMse}
  \vspace{20pt}
\end{wrapfigure}


\subsection{Results analysis of statistics extraction based method}

First, the original data will be modeled as a comparison. A "Many input to many output" LSTM is trained with epochs 100 to make next 10 steps prediction. The parameter of look back size changing from 10 to 50 with step of 5. The results come from training stage show look back size of 40 will have the lowest training losses. Then, the extract the statistic $h_t$ will be added as a new variable with the past values of $y_t$ into LSTM. The training results show the look back size of 40 is the best choice. Figure X shows the  profiles of predicted values of LSTM with solo $y_t$ as input, of LSTM with $y_t$ and $h_t$ and the true values. And the table X1 gives the MSE of the two LSTM prediction results. 


%there are two different algorithms: rolling algorithm and non-rolling algorithm. The rolling method will keep adding the next test data into the training set and only make 1 step prediction each time;while the non-rolling method just based on the original training set and make multi-steps prediction.



































\section{Introduction}

In recent years, we are seeing a rapid growth of data from the increasing deployments of sensors and sources of various types. The availability of massive data calls for new and more advanced schemes to analyze the data, and apply the knowledge to  enable more intelligent and powerful applications.  Data-based (model-less) applications attempt to extract information directly from the data without preprocessing through complex models. Machine learning systems are becoming increasingly employed in complex high-stakes settings such as medicine (e.g. radiology, drug development), financial technology (e.g. stock price prediction, digital financial advisor), and even in law (e.g. case summarization, litigation prediction). Despite this increased utilization, there is still a lack of sufficient techniques available to be able to explain and interpret the decisions of these deep learning algorithms.

The convergence of data and model has been reflected from at least two aspects. First, massive data have transformed the way how system states can be estimated and predicted, which is essential for reliable system operations and decision making. Second, data also provide a venue to critically examine and refine traditional “model-based” methods for many applications. These have led to the “data-driven” methods that have greatly empowered the applications. However, a subtle issue is how to properly integrate data-driven methods with existing knowledge or models. After all, many application field have been extensively studied for the last almost a century, and has well-established theories and models. Data, big or small, can better reflect the knowledge or help discover new knowledge, but are not expected to fundamentally change the established knowledge. Therefore,maximizing the potential of data-driven methods while at the same time respecting basic theories and knowledge to enable new and powerful applications is currently a grand challenge.

The introduction of new information may be helpful to  improve the performance of both the model-based and data-based learning. However, a more valuable research is how to integrate models without introducing new information to improve the performance of the model. To achieve this goal, in this paper, we propose three methods, which give 3 directions to integrate both model based and data based learning to produce "1+1 $>$ 2" effect. The first one presents a  way of decomposing the data into different parts, such as linear stable part, nonlinear stable part  and unstable part. The mathematical models will model both the linear and nonlinear stable parts while the machine learning method will handle the unstable part. The mathematical models can account for most of data; as for the unstable part, machine learning method will take effect. The merit of this method is that it improves the predictive ability of the model without reducing model interpretation, and has better performance than the single used mathematical models and machine learning methods. The second method starts from a completely different perspective from the first method. Not based on the decomposition of the data, but relying on the extraction of statistics come from mathematical models. It still uses mathematical statistics models to model first, then extracts valuable statistics information, and finally feeds the extracted statistics as new features into the machine learning learner for training. The contribution here is not the method of adding new features into the machine learning learner but the thought of how to incarcerate model based and data based learning and the way to generate and extract new features. Different from the  ways of adding new features by introducing new information to help boost the learning ability, our method acquires new features without any new information. Take time series data as an example, after the ARIMA-GARCH model established, the GARCH term, that is conditional variance, is noticed by us due to the Time-varying characteristics. Then we propose to utilize the GARCH term as a new feature to be fed into the machine learner to improve model performance. In the third method, we consider to incorporate both the first two methods to better improve the performance of the learners. On the basis of  decomposition method, method 2 is applied to model and make prediction for the unstable part.
\section{Results and Analysis}
In our internal testing of the DPT regime, we set up a CNN from scratch. Note that the pre-training regime could also be carried out for large, state-of-the-art deep networks too.

For Phase 1, our network was able to quickly converge to satisfactorily low binary cross-entropy values between the predicted edge maps and the ground truth values. This can be verified in Figure \ref{fig:fig2}. In 10-15 epochs, the model was able to reach a stable loss value.
\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{figs/p1_model_loss.png}
  \caption{Phase 1 - The figure shows successful learning of edge detection by our participating network.} 
  \label{fig:fig2}
\end{figure}

In Phase 2, our network was modified as per the specifications provided in Section \ref{subsec-p2}. When trained with the Shapes2D dataset, the network was able to converge to a near-perfect accuracy in about 10 epochs as seen in \ref{fig:fig3}. However, this phase struggled with some over-fitting. This was circumvented to some degree with the addition of some dropout layers \cite{srivastava2014dropout} to force the network to learn more robust and generalisable representations. These layers were removed later to maintain the pre-training requirements.

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{figs/p2_model_accuracy.png}
  \caption{Phase 2 - The figure shows successful learning of shape recognition} 
  \label{fig:fig3}
\end{figure}

Upon successful completion of the two phases of DPT, we proceeded to benchmark our DPT model against a Vanilla model of the same architecture but with randomly initialised weights. The benchmark was used to verify if the pre-trained weights in the network fare better for a real-world recognition task compared to a vanilla model without any special weights. \ref{fig:fig4} shows that both DPT and the vanilla models converge to similar training accuracy levels. However, these results suggest the contrary to our hypothesis that the DPT regime would lead to faster convergence compared to a non-pretrained model. 

Figure \ref{fig:fig4} suggests that the representations learned during the pre-training process weren't directly extendable to the real-world setting simulated by the Imagenette dataset. The pre-trained weights from DPT seem to be holding the model back instead of boosting performance. This could be due to the sub-optimal configuration of the phases that led to overfitting on the phases in each dataset.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figs/DPT_benchmark.png}
  \caption{Benchmark - Training accuracy comparison between DPT and vanilla models} 
  \label{fig:fig4}
\end{figure}
\section{Related Work}
In this section, we discuss relevant related work that inspired our proposed approach of \textsc{Developmental PreTraining} as a solution to the data requirements of deep networks, especially in settings with limited availability of image data. 

\subsection{Curriculum Learning}
Curriculum Learning \cite{bengio2009curriculum} in deep neural networks draws inspiration from educational theory, guiding models through a structured progression of tasks during training. This approach aims to enhance critical metrics of a DL system like learning efficiency, and  generalization by training with handpicked, structured data-points in relation to randomly shuffled data-points in traditional training regimes. The meaningful structure of data-points is designed for the model to learn more meaningful and robust features and patterns in its data -- analogous to how a student might with a high school syllabus.

Vanilla curriculum learning \cite{bengio2009curriculum, spitkovsky2009baby} involves presenting training data in an increasing order of difficulty which is determined by a set of rules dependent on the nature of the data. Self-paced curriculum learning leverages an external set of rules to determine objective difficulty of the data-points and a metric on the model's performance on the data-points \cite{jiang2015self}.

In DPT, we hope to leverage the concept of curriculum learning to choose the nature of data in the pre-training regime in a sequentially meaningful manner with the hopes of the model learning enough primitive representations for visual processing that can be transferred to specialised tasks.

\subsection{Cognitive Neuroscience and Visual Development}\label{subsec_cogneuro_visual}
In order to develop a pre-training curriculum for \textsc{DPT}, we decided to borrow insights from early visual development. We are trying to equip our deep networks with very basic visual information processing abilities that can be transferred to a range of tasks -- similarly how an infant's inductive biases allow it to learn visual recognition tasks early on in their lives. 

Studying early visual development \cite{zaadnoordijk2022infantlessons, smith2017developmental} in humans holds much promise to the development of robust and generalisable machine learning applications in the field of vision. One common feature in early visual is a phased 'curriculum' prominent in visual learning. This curriculum starts from ingrained priors in the infant like a bias for edges \cite{linsley2020recurrentedge} to the varying set of scenes that the infant is capable of viewing determined by its physical mobility at that stage in development \cite{zaadnoordijk2022infantlessons, smith2017developmental}.

Additionally, Vogelsang et al. \cite{vogelsang2018potential} also emphasise the effects of the gradual improvement of initial low visual acuity in newborn infants on their visual development. The authors run CNN simulations to show faster convergence when trained with blurry images at the beginning and normal images towards the end. This implicit curriculum forces the visual systems to learn low-level features over larger spatial fields at the beginning and transition to more fine-grained features with reducing blur in the image. This process was found to introduce representations in the network that are more robust and generalisable to unseen images. 

This line of work introduces potential additions for a curriculum-based pre-training approach. In DPT, we prioritise a phased transition in our pre-training regime that is a common feature in the works cited in this section.

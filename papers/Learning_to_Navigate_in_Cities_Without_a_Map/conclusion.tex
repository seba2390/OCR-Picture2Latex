Navigation is an important cognitive task that enables humans and animals to traverse a complex world without maps.
We have presented a city-scale real-world environment for training RL navigation agents, introduced and analysed a new courier task, demonstrated that deep RL algorithms can be applied to problems involving large-scale real-world data, and presented a multi-city neural network agent architecture that demonstrates transfer to new environments. 
A multi-city version of the Street View based RL environment, with carefully processed images provided by Google Street View (i.e., blurred faces and license plates, with a mechanism for enforcing image take-down requests) has been released for Manhattan and Pittsburgh and is accessible from \url{http://streetlearn.cc} and \url{https://github.com/deepmind/streetlearn}. The project webpage at \url{http://streetlearn.cc} also contains resources on how to build and train an agent.
Future work will involve learning landmarks from images and scaling up the navigation and path-planning thanks to hierarchical RL approaches.

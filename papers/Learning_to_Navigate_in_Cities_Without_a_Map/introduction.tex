\begin{figure}[h]
\begin{subfigure}{.58\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{figures/streetlearn_diversity3.png}
  \caption{Diverse views and corresponding local maps in Street View.}
  \label{fig:streetview}
\end{subfigure}%
\begin{subfigure}{.42\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{figures/streetlearn_cities.pdf}
  \caption{Street View regions used in this study.}
  \label{fig:nyc}
\end{subfigure}
\caption{\textbf{(a)} Our environment is built of real-world places from Street View (we illustrate Times Square and Central Park in New York City and St.\ Paul's Cathedral in London). The green cone represents the agent's location and orientation. \textbf{(b)} We use large regions of London and Paris and in New York we focus on 5 different regions to show transfer.}
% \vskip -0.4in
\vskip -0.2in
\end{figure}

The subject of navigation is attractive to
various research disciplines and technology domains alike, being at once a subject of inquiry from the point of view of neuroscientists wishing to crack the code of grid and place cells~\cite{banino2018vector,cueva2018emergence}, as well as a fundamental aspect of robotics research. The majority of algorithms involve building an explicit map during an exploration phase and then planning and acting via that representation. 
In this work, we are interested in pushing the limits of end-to-end deep reinforcement learning for navigation by proposing new methods and demonstrating their performance in large-scale, real-world environments. Just as humans can learn to navigate a city without relying on maps, GPS localisation, or other aids, it is our aim to show that a neural network agent can learn to traverse entire cities using only visual observations. In order to realise this aim, we designed an interactive environment that uses the images and underlying connectivity information from Google Street View, and propose a dual pathway agent architecture that can navigate within the environment (see Fig.~\ref{fig:streetview}).

Learning to navigate directly from visual inputs has been shown to be possible in some domains, by using deep reinforcement learning (RL) approaches that can learn from task rewards -- for instance, navigating to a destination. Recent research has demonstrated that RL agents can learn to navigate house scenes \cite{zhu_icra2017, wu2018building}, mazes  (e.g. \cite{mirowski2016learning}), and 3D games (e.g. \cite{lample_aaai17}). These successes notwithstanding, deep RL approaches are notoriously data inefficient and sensitive to perturbations of the environment, and are more well-known for their successes in games and simulated environments than in real-world applications. It is therefore not obvious that they can be used for large-scale visual navigation based on real-world images, and hence this is the subject of our investigation.


The primary contributions of this paper are (a) to present a new RL challenge that features real world visual navigation through city-scale environments, and (b) to propose a modular, goal-conditional deep RL algorithm that can solve this task, thus providing a strong baseline for future research.
\emph{StreetLearn}\footnote{\url{http://streetlearn.cc} (dataset) and \url{https://github.com/deepmind/streetlearn} (code).}%, along with agent code.} 
%
is a new interactive environment for reinforcement learning that features real-world images as agent observations, with real-world grounded content that is built on top of the publicly available Google Street View. Within this environment we have developed a traversal task that requires that the agent navigates from goal to goal within London, Paris and New York City. 
To evaluate the feasibility of learning in such an environment, we propose an agent that learns a goal-dependent policy with a dual pathway, modular architecture with similarities to the interchangeable task-specific modules approach from~\cite{devin2017learning}, and the target-driven visual navigation approach of~\cite{zhu_icra2017}. The approach features a recurrent neural architecture that supports both locale-specific learning as well as general, transferable navigation behaviour. Balancing these two capabilities is achieved by separating a recurrent neural pathway from the general navigation policy of the agent. This pathway  addresses two needs. First, it receives and interprets the current goal given by the environment, and second, it encapsulates and memorises the features and structure of a single city region. Thus, rather than using a map, or an external memory, we propose an architecture with two recurrent pathways that can effectively address a challenging navigation task in a single city as well as transfer to new cities or regions by training only a new locale-specific pathway.

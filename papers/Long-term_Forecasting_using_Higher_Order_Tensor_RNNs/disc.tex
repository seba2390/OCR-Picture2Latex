In this paper, We studied long-term forecasting  under nonlinear dynamics. We proposed a novel class of RNNs -- \trnn{} that directly learns the nonlinear dynamics using higher-order structures. We  provided the first  approximation guarantees for its representation power. We demonstrated the benefits of \trnn{} to forecast accurately for significantly longer time horizon in both synthetic and real-world multivariate time series data.

In terms of future work, forecasting \emph{chaotic dynamics}, still presents a significant challenge to any sequential prediction model. Hence, it would be worthwhile to study how to learn robust models for chaotic dynamics. For other sequence modeling tasks, such as language, there does not (or is not known to) exist a succinct analytical description of the data-generating process. It would also be interesting to go beyond forecasting and further investigate the effectiveness of \trnn{}s in such domains as well.

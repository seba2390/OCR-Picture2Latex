\subsection{Theoretical Analysis}
% tensor-train
We provide theoretical guarantees for the proposed \trnn{} model by analyzing a class of functions that satisfy some regularity condition. For such functions, tensor-train decomposition preserve weak differentiability and yield a compact representation.
%
We combine this property with neural network theory to bound the approximation error for \trnn{} with one hidden layer, in terms of:
%
1) the regularity of the target function $f$, 2) the dimension of the input, and 3) the tensor train rank.

In the context of \trnn{}, the target function $f(\V{x})$ with $\V{x} = \V{s} \otimes \ldots \otimes \V{s}$, is the system dynamics that describes state transitions.
%
Let us assume that $f(\V{x})$ is a Sobolev function: $f\in\mathcal{H}^k_\mu$, defined on the input space $\T{I}= I_1 \times I_2\times \cdots I_d $, where each $I_i$ is a set of vectors. The space $\mathcal{H}^k_\mu$ is defined as the set of  functions that have bounded derivatives up to some order $k$ and are $L_\mu$-integrable:
%
\begin{eqnarray}
\mathcal{H}^k_\mu =  \left\{  f  \in L^2_\mu(I):\sum_{i\leq k}\|D^{(i)}f\|^2   < +\infty \right\},
\end{eqnarray}
%
where $D^{(i)}f$ is the $i$-th weak derivative of $f$ and $\mu \geq 0$.\footnote{A weak derivative generalizes the derivative concept for (non)-differentiable functions and is implicitly defined as: e.g. $v\in L^1([a,b])$ is a weak derivative of $u\in L^1([a,b])$ if for all smooth $\varphi$ with $\varphi(a) = \varphi(b) = 0$: $\int_a^bu(t)\varphi'(t) = -\int_a^bv(t)\varphi(t)$.}

Any Sobolev function admits a Schmidt decomposition: $f(\cdot) = \sum_{i =0}^\infty \sqrt{\lambda_i} \gamma (\cdot)_i \otimes \phi (\cdot)_i $, where $\{\lambda \}$ are the eigenvalues and $\{\gamma\}, \{ \phi\}$ are the associated eigenfunctions.
%
Applying the Schmidt decomposition along $x_1$, we have 
\begin{eqnarray}
f(\V{x}) = \sum_{\alpha_1} \sqrt{\lambda_{\alpha_1}}\gamma (x_1)_{\alpha_1}\phi(x_2,\cdots, x_d)_{\alpha_1}
\end{eqnarray}

We  can apply similar Schmidt decomposition along $x_2$
\begin{eqnarray}
\sqrt{\lambda_{\alpha_1}}\phi(x_2,\cdots, x_d)_{\alpha_1} = \sum_{\alpha_2} \sqrt{\lambda_{\alpha_2}}\gamma (x_2)_{\alpha_1,\alpha_2}\phi(x_3,\cdots, x_d)_{\alpha_2}
\end{eqnarray}


Recursively performing such operation, and let $\gamma(x_d)_{\alpha_{d-1},\alpha_d} = \sqrt{\lambda_{\alpha_{d-1}}}\phi(x_d)_{\alpha_{d-1}}$ and $\T{A}^j(x_j)_{\alpha_{j-1}, \alpha_j} =\gamma(x_j)_{\alpha_{j-1}, \alpha_j}$, the target function $f \in \mathcal{H}^k_\mu$ can be decomposed as:
%
\begin{eqnarray}
f(\V{x}) = \sum_{\alpha_0,\cdots,\alpha_d=1}^\infty
%
% \T{A}^1_{\alpha_0, x_1, \alpha_1}
\T{A}^1(x_1)_{\alpha_0\alpha_1}
%
\cdots
%
\T{A}^d(x_d)_{\alpha_{d-1}\alpha_d},
\label{app:eqn:ftt}
\end{eqnarray}
%
where $\{\T{A}^j(\cdot)_{\alpha_{j-1}\alpha_j} \}$ are basis functions,  
% $\{ \T{A}^d(x_d)_{\alpha_{d-1}\alpha_d} = \sqrt{\lambda_{d-1} (\alpha_{d-1})} \phi(x_d)_{\alpha_{d-1}} \}$
%
satisfying $\langle \T{A}^j(\cdot)_{im}, \T{A}^j (\cdot)_{in} \rangle =\delta_{mn}$.
%
We can truncate Eqn \ref{app:eqn:ftt} to a low dimensional subspace ($\V{r}<\infty$), and obtain the \ti{functional tensor-train (FTT)} approximation of the target function $f$:
%
\begin{eqnarray}
f_{TT}(\mathbf{x}) = \sum_{\alpha_0,\cdots,\alpha_d=1}^\mathbf{r}
%
\T{A}^1(x_1)_{\alpha_0\alpha_1}
%
\cdots
%
\T{A}^d(x_d)_{\alpha_{d-1}\alpha_d}.
\label{app:eqn:ftt}
\end{eqnarray}.

FTT approximation in Eqn \ref{app:eqn:ftt} projects the target function to a subspace with finite basis. And the approximation error can be bounded using the following Lemma:
\begin{lemma}[FTT Approximation \cite{bigoni2016spectral}]
	Let $f\in \mathcal{H}^k_\mu$ be a H\"older continuous function, defined on a bounded domain $\mathbf{I} = I_1 \times \cdots \times I_d \subset \R^d$ with exponent $\alpha > 1/2$, the FTT approximation error can be upper bounded as
	\begin{eqnarray}
	\|f- f_{TT} \|^2 \leq \|f \|^2 (d-1)\frac{(r+1)^{-(k-1)}}{(k-1)}
	\end{eqnarray}
	for $r\geq 1$ and
	\begin{eqnarray}
	\lim_{r\rightarrow \infty}\|f_{TT}-f\| ^2 =0
	\end{eqnarray}
	for $k>1$
	\label{app:lemma:ftt}
\end{lemma}
%
Lemma \ref{app:lemma:ftt} relates  the approximation error to the  dimension  $d$,  tensor-train rank $r$,and  the regularity of the target function $k$. In practice, \trnn{} implements a polynomial expansion of the input states $\V{s}$, using powers $[\V{s}, \V{s}^{\otimes 2}, \cdots, \V{s}^{\otimes p}]$ to approximate $f_{TT}$, where $p$ is the degree of the polynomial.  We can further use the classic spectral  approximation  theory to connect the \trnn{} structure  with the degree of the polynomial, i.e., the order of the tensor. Let $I_1 \times \cdots \times I_d = \V{I} \subset \R^d $. Given a  function $f$  and its polynomial  expansion  $P_{TT}$, the approximation error  is therefore bounded by:
%\begin{theorem}
%	Let the state transition function $f\in \mathcal{H}^k_\mu$ be a H\"older continuous function defined on a input  domain $\mathbf{I} \subset \R^d$, with  bounded derivatives up to order $k$ and finite Fourier magnitude distribution $C_f$. Then a single layer Tensor Train RNN can approximate $f$ with an estimation error of $\epsilon$ using with $n$ hidden units:
%	%
%	$$ n \geq \frac{C_f^2}{\epsilon}(d-1)\frac{(r+1)^{-(k-1)}}{(k-1)} +\frac{C_f^2}{\epsilon} C(k)p^{-k}$$
%	%
%	where $C_f = \int |\omega|_1 |\hat{f}(\omega) d \omega|$, $d$ is the size of the state space, $r$ is the tensor-train rank and $p$ is the degree of higher-order polynomials \aacomment{i.e., the order of tensor}.
%	\label{app:eqn:thm}
%\end{theorem}
%
\begin{lemma}[Polynomial Approximation]
	Let $f\in  \mathcal{H}^k_\mu$ for $k>0$. Let $P$ be  the approximating polynomial with degree $p$, Then
	\[ \|f - P_N f\| \leq C(k)p^{-k}|f|_{k,\mu}  \]
\end{lemma}

Here $|f|^2_{k,\mu} =\sum_{|i|=k}\|D^{(i)}f\|^2 $ is the semi-norm of the  space $\mathcal{H}^k_\mu$.  $C(k)$ is the  coefficient of the spectral  expansion.  By definition, $\mathcal{H}^k_\mu$ is equipped with a norm $\|f\|^2_{k,\mu} =\sum_{|i|\leq k}\|D^{(i)}f\|^2$ and a semi-norm $|f|^2_{k,\mu} =\sum_{|i|=k}\|D^{(i)}f\|^2 $. For notation simplicity, we muted the subscript $\mu$ and used $\|\cdot\| $ for $\|\cdot \|_{L_{\mu}}$.

So far, we have obtained the  tensor-train approximation error with the regularity of the target function $f$. Next we will  connect the tensor-train approximation and the approximation error  of neural networks with one layer hidden units. Given a neural network with one hidden layer and sigmoid activation function, following Lemma describes the classic result of  describes the error between a target function $f$ and the single hidden-layer neural network that approximates it best:
%
\begin{lemma}[NN Approximation \cite{barron1993universal}]
	Given a function $f$ with finite Fourier magnitude distribution $C_f$, there exists a  neural network with $n$ hidden units $f_n$, such that
	\begin{eqnarray}
	\| f - f_n\| \leq \frac{C_f}{\sqrt{n}}
	\end{eqnarray}
	where $C_f = \int |\omega|_1  | \hat{f}(\omega) | d \omega$ with Fourier representation $f(x)=\int e^{i\omega x}\hat{f}(\omega) d\omega$.
	\label{app:lemma:nn}
\end{lemma}

We can now generalize Barron's approximation lemma \ref{app:lemma:nn} to \trnn{}.  The target time series is  $f(\V{x}) = f(\V{s}\otimes \dots \otimes \V{s})$.  We can express the function using FTT, followed by the polynomial expansion of the  states concatenation $P_{TT}$. The approximation error of \trnn{}, viewed as one layer hidden 

\begin{eqnarray*}
	\|f- P_{TT}\| & \leq& \|f- f_{TT}\| +\| f_{TT} - P_{TT}\| \\
	&\leq& \|f\|\sqrt{ (d-1)\frac{(r+1)^{-(k-1)}}{(k-1)}} + C(k)p^{-k}|f_{TT}|_k\\
	&\leq& \|f-f_n\|\sqrt{ (d-1)\frac{(r+1)^{-(k-1)}}{(k-1)}} + C(k)p^{-k} \sum\limits_{i=k}  \|D^{(i)}(f_{TT}-f_n)\|  +o(\|f_n\|)\\
	&\leq & \frac{C^2_f}{n} (\sqrt{ (d-1)\frac{(r+1)^{-(k-1)}}{(k-1)}} + C(k)p^{-k} \sum\limits_{i=k}  \|D^{(i)}f_{TT}\| ) +o(\|f_n\|)
\end{eqnarray*}

Where $p$ is the order of tensor and $r$ is the tensor-train rank. As the rank of the tensor-train and the polynomial order increase, the required size of the hidden units become smaller, up to a constant that depends on the regularity of the underlying dynamics $f$.

\subsection{Additional Experiments}
\paragraph{Genz dynamics}
Genz functions  are often used as basis for evaluating high-dimensional function approximation.  Figure \ref{app:fig:genz} visualizes different Genz  functions, realizations of dynamics and predictions from \tlstm{} and baselines.  We can see for ``oscillatory'', ``product peak'' and ``Gaussian '', \tlstm{} can better capture the complex dynamics, leading to more accurate predictions.  



\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/f1.png}
        \caption{$g_1$ oscillatory}
        \label{app:fig:f1}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df1.png}
        \caption{$g_1$ dynamics}
        \label{app:fig:df1}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df1_17.png}
        \caption{$g_1$ predictions}
        \label{app:fig:f2}
    \end{subfigure}\\ % f1

        \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/f2.png}
        \caption{$g_2$ product peak}
        \label{app:fig:f2}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df2.png}
        \caption{$g_2$ dynamics}
        \label{app:fig:df2}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
    %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df2_3.png}
        \caption{$g_2$ predictions}
        \label{app:fig:df2}
    \end{subfigure}\\ % f2
            \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/f3.png}
        \caption{$g_3$ corner peak}
        \label{app:fig:f3}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df3.png}
        \caption{$g_3$ dynamics}
        \label{app:fig:df3}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
    %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df3_7.png}
        \caption{$g_3$ predictions}
        \label{app:fig:df3}
    \end{subfigure}\\ % f3 g


    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/f4.png}
        \caption{$g_4$ Gaussian}
        \label{app:fig:f4}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df4.png}
        \caption{$g_4$ dynamics}
        \label{app:fig:df4}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df4_8.png}
        \caption{$g_4$ predictions}
        \label{app:fig:f4}
    \end{subfigure}\\ % f4

        \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/f5.png}
        \caption{$g_5$ continuous}
        \label{app:fig:f5}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df5.png}
        \caption{$g_5$ dynamics}
        \label{app:fig:df5}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
    %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df5_1.png}
        \caption{$g_5$ predictions}
        \label{app:fig:df5}
    \end{subfigure}\\ % f5

            \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/f6.png}
        \caption{$g_6$ discontinuous}
        \label{app:fig:f6}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figure/df6.png}
        \caption{$g_6$ dynamics}
        \label{app:fig:df6}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
    %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.26\textwidth}
        \includegraphics[width=\textwidth]{Figure/df6_5.png}
        \caption{$g_6$ predictions}
        \label{app:fig:f6}
    \end{subfigure}
%
    \caption{Visualizations of  Genz  functions,  dynamics and predictions from \tlstm{} and baselines. Left column: transition functions, middle: realization of the dynamics and right: model predictions for LSTM (green) and \tlstm{} (red).}
    \label{fig:genz}
 \vskip -0.2in
 \end{figure}




\paragraph{Moving MNIST}
%
 Moving MNIST \cite{srivastava2015unsupervised} generates around $50,000$ video sequences of length $100$ on the fly. The video is generated by moving the digits in the MNIST image dataset along a given trajectory  within a canvas of size $48\times 48$. The trajectory reflects the dynamics of the movement. In this experiment, we used $cos$ and $sin$ velocity. 






%\subsection{Training speed}
%

%\begin{figure}[ht]
%\begin{center}
%    \begin{subfigure}[t]{0.48\linewidth}
%        \centering
%        \includegraphics[width=\linewidth]{Figure/traffic_st_train_speed.png}
%    \end{subfigure}
%    \begin{subfigure}[t]{0.48\linewidth}
%        \centering
%        \includegraphics[width=\linewidth]{Figure/climate_st_train_speed.png}
%    \end{subfigure}
%    %
%    \caption{
%    Training speed performance as the log-loss (log-RMSE) versus training step for the models with the best long-term forecasting accuracy. The hidden state is 256-dimensional (\trnn{}) and 32-dimensional (others). We observe that \trnn{}s converge faster than baselines, although to the same asymptotic loss.
%    }
%    \label{app:fig:error_horizon}
%\end{center}
%\end{figure}

% Traffic, climate vis
%\begin{figure}[htbp]
%\begin{center}
%    \begin{subfigure}[b]{0.32\textwidth}
%        \includegraphics[width=\textwidth]{Figure/traffic_pred_1.png}
%    \end{subfigure}
%    \begin{subfigure}[b]{0.32\textwidth}
%        \includegraphics[width=\textwidth]{Figure/traffic_pred_2.png}
%    \end{subfigure}
%    \begin{subfigure}[b]{0.32\textwidth}
%        \includegraphics[width=\textwidth]{Figure/traffic_pred_3.png}
%    \end{subfigure}\\
%    \begin{subfigure}[b]{0.32\textwidth}
%        \includegraphics[width=\textwidth]{Figure/climate_pred_1.png}
%    \end{subfigure}
%    \begin{subfigure}[b]{0.32\textwidth}
%        \includegraphics[width=\textwidth]{Figure/climate_pred_3.png}
%    \end{subfigure}
%    \begin{subfigure}[b]{0.32\textwidth}
%        \includegraphics[width=\textwidth]{Figure/climate_pred_6.png}
%    \end{subfigure}
%    \caption{Top: $18$ hour ahead predictions for hourly \textsl{traffic} time series  given $5$ hour as input for LSTM, MLSTM and \tlstm{}.
%%
%    Bottom: $300$ days ahead predictions for daily \textsl{climate} time series given $2$ month observations as input for LSTM, MLSTM and \tlstm{}.}
%    \label{app:fig:pred_vis}
%\end{center}
%        \vskip -0.2in
%\end{figure}




\begin{figure}[htbp]
\begin{center}
        \begin{subfigure}[b]{\textwidth}
            \includegraphics[width=\textwidth]{Figure/mnist_true.png}
            \label{app:fig:lorenz_80}
            \label{app:fig:f1}
        \end{subfigure}\\
                \begin{subfigure}[b]{\textwidth}
            \includegraphics[width=\textwidth]{Figure/mnist_lstm_pred.png}
            \label{app:fig:lorenz_80}
            \label{app:fig:f1}
        \end{subfigure}\\
                \begin{subfigure}[b]{\textwidth}
            \includegraphics[width=\textwidth]{Figure/mnist_tlstm_pred.png}
            \label{app:fig:lorenz_80}
            \label{app:fig:f1}
        \end{subfigure}
         \caption{Visualizations of  ground truth and predictions from \tlstm{} and baselines for moving MNIST. Top: ground truth; Middle: LSTM predictions; Bottom: \tlstm{} predictions.}
    \label{app:fig:genz}
     \vskip -0.2in
    \end{center}
\end{figure}



%\begin{figure}[htbp]
%    \centering
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/f1.png}
%        \caption{$g_1$ oscillatory}
%        \label{app:fig:f1}
%    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%      %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df1.png}
%        \caption{$g_1$ dynamics}
%        \label{app:fig:df1}
%    \end{subfigure}
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df1_17.png}
%        \caption{$g_1$ predictions}
%        \label{app:fig:f2}
%    \end{subfigure}\\ % f1
%
%        \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/f2.png}
%        \caption{$g_2$ product peak}
%        \label{app:fig:f2}
%    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%      %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df2.png}
%        \caption{$g_2$ dynamics}
%        \label{app:fig:df2}
%    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%    %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df2_3.png}
%        \caption{$g_2$ predictions}
%        \label{app:fig:df2}
%    \end{subfigure}\\ % f2
%            \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/f3.png}
%        \caption{$g_3$ corner peak}
%        \label{app:fig:f3}
%    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%      %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df3.png}
%        \caption{$g_3$ dynamics}
%        \label{app:fig:df3}
%    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%    %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df3_7.png}
%        \caption{$g_3$ predictions}
%        \label{app:fig:df3}
%    \end{subfigure}\\ % f3 g
%
%
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/f4.png}
%        \caption{$g_4$ Gaussian}
%        \label{app:fig:f4}
%    \end{subfigure}
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df4.png}
%        \caption{$g_4$ dynamics}
%        \label{app:fig:df4}
%    \end{subfigure}
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df4_8.png}
%        \caption{$g_4$ predictions}
%        \label{app:fig:f4}
%    \end{subfigure}\\ % f4
%
%        \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/f5.png}
%        \caption{$g_5$ continuous}
%        \label{app:fig:f5}
%    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%      %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df5.png}
%        \caption{$g_5$ dynamics}
%        \label{app:fig:df5}
%    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%    %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df5_1.png}
%        \caption{$g_5$ predictions}
%        \label{app:fig:df5}
%    \end{subfigure}\\ % f5
%
%            \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/f6.png}
%        \caption{$g_6$ discontinuous}
%        \label{app:fig:f6}
%    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%      %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.3\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df6.png}
%        \caption{$g_6$ dynamics}
%        \label{app:fig:df6}
%    \end{subfigure}
%    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%    %(or a blank line to force the subfigure onto a new line)
%    \begin{subfigure}[b]{0.26\textwidth}
%        \includegraphics[width=\textwidth]{Figure/df6_5.png}
%        \caption{$g_6$ predictions}
%        \label{app:fig:f6}
%    \end{subfigure}
%%
%    \caption{Visualizations of  Genz  functions,  dynamics and predictions from \tlstm{} and baselines. Left column: transition functions, middle: realization of the dynamics and right: model predictions for LSTM (green) and \tlstm{} (red).}
%    \label{app:fig:genz}
% \vskip -0.2in
% \end{figure}








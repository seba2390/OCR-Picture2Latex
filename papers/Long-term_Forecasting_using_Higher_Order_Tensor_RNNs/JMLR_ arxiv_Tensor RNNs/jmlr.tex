\documentclass[twoside,11pt]{article}
% about 20 main file, 30 total 
% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

\usepackage{jmlr2e}

\usepackage{algorithm}
\usepackage{algorithmic}
%\usepackage{breakurl}
%\usepackage[breaklinks]{hyperref}
\usepackage{wrapfig}
\usepackage{graphicx} % \texttt{\texttt{}}more modern

 % and their extensions so you won't have to specify these with
 % every instance of \includegraphics
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}

\usepackage{wrapfig}
\usepackage{subfiles}
\usepackage[subpreambles=false]{standalone}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables
\usepackage{url}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{wrapfig}
\usepackage{color}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}


\usepackage{enumitem}
%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.

\input{newcommands}
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
%\newcommand{\theHalgorithm}{\arabic{algorithm}}


% Definitions of handy macros can go here

\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}

% Heading arguments are {volume}{year}{pages}{date submitted}{date published}{paper id}{author-full-names}

\jmlrheading{1}{2019}{1-48}{4/00}{10/00}{yu18}{Rose Yu, Stephan Zheng, Anima Anandkumar, Yisong Yue}

% Short headings should be running head and authors last names

\ShortHeadings{Higher-Order Tensor RNNs}{Yu et al.}
\firstpageno{1}

\begin{document}

\title{Long-Term Forecasting using  Higher-Order Tensor RNNs}

\author{\name Rose Yu \email rose@caltech.edu 
       \AND
       \name Stephan Zheng \email stephan@caltech.edu 
       \AND
      \name Anima  Anandkumar \email anima@caltech.edu 
       \AND
       \name Yisong Yue \email yyue@caltech.edu \\
        \addr Department of Computing and Mathematical Sciences\\
       California Institute of Technology\\
       Pasadena, CA 91125, USA}

\editor{Francis Bach, David Blei and Bernhard Sch{\"o}lkopf}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
  We present Higher-Order Tensor RNN (\trnn{}), a novel family of neural sequence architectures for multivariate forecasting in environments with nonlinear dynamics.
  %
  Long-term forecasting in such systems is highly challenging, since there exist long-term temporal dependencies, higher-order correlations and sensitivity to error propagation.
  %
  Our proposed recurrent architecture addresses these issues by learning the nonlinear dynamics directly using higher-order moments and higher-order state transition functions.
  %
  Furthermore, we decompose the higher-order structure using the tensor-train decomposition to reduce the number of parameters while preserving the model performance.
  %
  We theoretically establish the approximation guarantees and the variance bound for \trnn{} for general sequence inputs. We also
  demonstrate $5 \sim 12\%$  improvements for long-term prediction over general RNN and LSTM architectures on a range of simulated environments with nonlinear dynamics, as well on real-world time series data.
  %
\end{abstract}

\begin{keywords}
   Time Series, Forecasting, Tensor, RNNs, Nonlinear Dynamics
\end{keywords}


\section{Introduction}
\label{intro}
\input{intro}
%
\section{Related Work}
\label{related}
\input{related}
%
\section{Higher-Order Tensor RNNs}
\label{trnn}
\input{trnn}
%
\section{Approximation Theorem for HOT-RNNs}
\label{thm}
\input{thm}

\section{Variance Bound for \trnn{}}
\label{gen}
\input{gen}
%
\section{Experiments}
\label{exp}
\input{exp}
%
\section{Discussion}
\label{disc}
\input{disc}

% Acknowledgements should go at the end, before appendices and references

\acks{We would like to acknowledge support for this project
from the National Science Foundation (NSF grant IIS-9988642)
and the Multidisciplinary Research Program of the Department
of Defense (MURI N00014-00-1-0637). }

% Manual newpage inserted to improve layout of sample file - not
% needed in general before appendices/bibliography.

\vskip 0.2in
\newpage
\bibliography{jmlr}

\newpage

\appendix
\section*{Appendix A.}
\label{app:theorem}
\input{app}

% Note: in this sample, the section number is hard-coded in. Following
% proper LaTeX conventions, it should properly be coded as a reference:

%In this appendix we prove the following theorem from
%Section~\ref{sec:textree-generalization}:



\end{document}

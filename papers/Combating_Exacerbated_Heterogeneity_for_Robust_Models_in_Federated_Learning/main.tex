
\documentclass{article} % For LaTeX2e
\usepackage{iclr2023_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{color, colortbl}
\definecolor{mydarkblue}{rgb}{0,0.08,0.45}
\definecolor{greyC}{RGB}{180,180,180}
\definecolor{greyL}{RGB}{235,235,235}
\usepackage[colorlinks,citecolor=mydarkblue]{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{multicol}
\usepackage{multirow}
\usepackage{makecell}
%\usepackage{ulem}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{algorithmic,algorithm}

\usepackage{soul}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}
%\usepackage{algpseudocode}
\usepackage{threeparttable}
%\usepackage{subcaption}
\usepackage{subfigure}
\usepackage{dsfont}
\usepackage{enumerate}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{natbib}


\usepackage{wrapfig}


\usepackage{framed}
\usepackage{color}
\definecolor{shadecolor}{rgb}{0.92,0.92,0.92}


\newcommand{\T}{{\hspace{-0.25ex}\top\hspace{-0.25ex}}}
\newcommand{\ST}{\mathrm{s.t.}}
\newcommand{\bE}{\mathbb{E}}
\newcommand{\bR}{\mathbb{R}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\bx}{{x}}
\newcommand{\bxprime}{{x}'}
\newcommand{\bxtidle}{\tilde{{x}}}
\newcommand{\epsball}{\mathcal{B}_\epsilon}
\newcommand{\xadv}{\tilde{{x}}}
\newcommand{\yadv}{\tilde{y}}


% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
%\usepackage[textsize=tiny]{todonotes}


\title{Combating Exacerbated Heterogeneity for \\ Robust Models in Federated Learning}

%\title{Combating Exacerbated Heterogeneity for\\ Robust Decentralized Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

    \makeatletter
\def\@fnsymbol#1{\ensuremath{\ifcase#1\or \dagger\or \ddagger\or
   \mathsection\or \mathparagraph\or \|\or **\or \dagger\dagger
   \or \ddagger\ddagger \else\@ctrerr\fi}}
    \makeatother

\author{Jianing Zhu$^{1}$ \quad
Jiangchao Yao$^{2,3}\thanks{Corresponding authors: Bo Han (bhanml@comp.hkbu.edu.hk) and Jiangchao Yao (Sunarker@sjtu.edu.cn).}$ \quad
Tongliang Liu$^4$ \quad
Quanming Yao$^5$ \quad\\ \bf
Jianliang Xu$^1$ \quad
Bo Han$^{1\dagger}$ \quad
\\[1ex]
${}^1$Hong Kong Baptist University
${}^2$Shanghai Jiao Tong University
${}^3$Shanghai AI Laboratory\\
${}^4$Sydney AI Centre, The University of Sydney
${}^5$Tsinghua University \\[1ex]
\text{\{csjnzhu,\;xujl,\;bhanml\}@comp.hkbu.edu.hk\;Sunarker@sjtu.edu.cn}\\
\text{
tongliang.liu@sydney.edu.au\; qyaoaa@tsinghua.edu.cn}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
%Privacy and security concerns in real-world applications have led to the development of adversarially robust federated models. However, simply combining adversarial training and federated learning in one framework can lead to undesired robustness deterioration. This is due to the fact that the generated adversarial data can exacerbate the heterogeneity among local clients, resulting in poor performance of the federated learning approach. To address this problem, we propose a novel framework called Slack Federated Adversarial Training (SFAT), which assigns client-wise slack during aggregation to combat the intensified heterogeneity. The convergence of the proposed method is analyzed theoretically, and we demonstrate the rationality and effectiveness of SFAT using various benchmarked and real-world datasets and different adversarial training and federated optimization methods.

Privacy and security concerns in real-world applications have led to the development of adversarially robust federated models. However, the straightforward combination between adversarial training and federated learning in one framework can lead to the undesired robustness deterioration. We discover that the attribution behind this phenomenon is that the generated adversarial data could exacerbate the data heterogeneity among local clients, making the wrapped federated learning perform poorly. To deal with this problem, we propose a novel framework called \textit{Slack Federated Adversarial Training} (SFAT), assigning the client-wise slack during aggregation to combat the intensified heterogeneity. Theoretically, we analyze the convergence of the proposed method to properly relax the objective when combining federated learning and adversarial training. Experimentally, we verify the rationality and effectiveness of SFAT on various benchmarked and real-world datasets with different adversarial training and federated optimization methods. The code is publicly available at: \url{https://github.com/ZFancy/SFAT}.
\end{abstract}
\section{Introduction}

Federated learning~\citep{mcmahan2017communication} has gained increasing attention due to the concerns of data privacy and governance issues~\citep{smith2017federated,li2018federated,kairouz2019advances,lit2020federated,karimireddy2020scaffold,khodak2021federated}. However, training in local clients aggravates the vulnerability to adversarial attacks~\citep{Goodfellow14_Adversarial_examples,kurakin2016adversarial,li2021neural,sanyal2020benign}, motivating the consideration of adversarial robustness for the federated system. For this purpose, some recent studies explore to integrate the adversarial training into federated learning~\citep{kairouz2019advances,zizzo2020fat,shah2021adversarial}. Federated adversarial training faces different challenges from perspectives of the distributed systems~\citep{lit2020federated} and the learning paradigm~\citep{kairouz2019advances}. Previous works mainly target overcoming the constraints in the communication budget~\citep{shah2021adversarial} and the hardware capacity~\citep{hong2021federated}.



%Previously, several works~\citep{shah2021adversarial, hong2021federated} focus on the practical challenges to consider the adversarial robustness in federated systems. For example, ~\citet{shah2021adversarial} pointed out that the restriction of communication between clients and server hinders the effectiveness of adversarial training, and thus proposed a dynamic schedule on the local training epochs to achieve the expected robustness in the limited communication budget. \citet{hong2021federated} considered the hardware constraint where some clients are not able to participate in the adversarial training, and they proposed a robustness propagation method to share the adversarial robustness among the clients.

However, one critical challenge in the algorithmic aspect is that the straightforward combination of two paradigms suffers from the unexpected robustness deterioration, impeding the progress towards adversarially robust federated systems. As shown in the Figure~\ref{fig1:a}, when considering the Federated Adversarial Training (FAT)~\citep{zizzo2020fat} that directly employs adversarial training~\citep{Madry_adversarial_training} in federated learning based on FedAvg~\citep{mcmahan2017communication}, one typical phenomenon is that its robust accuracy dramatically decreases at the later stage of training compared with the centralized cases~\citep{Madry_adversarial_training}. To the best of our knowledge, there is still a lack of in-depth understanding and algorithmic breakthroughs to overcome it, as almost all the previous explorations~\citep{shah2021adversarial,hong2021federated} still consistently adopt the conventional framework (\textit{i.e.}, FAT).

\begin{figure*}[!t]
    \centering
    %\hspace{-1mm}
    \subfigure[Centralized AT vs. FAT]{
    \includegraphics[scale=0.16]{central_vs_fedavg_large_rounds.pdf}
    \label{fig1:a}
    }
    \hspace{0.35in}
    \subfigure[FAT vs. SFAT (ours)]{
    \includegraphics[scale=0.16]{afat_fat.pdf}
    \label{fig1:b}
    }
    %\includegraphics[scale=0.33]{motivation_bias.pdf}
    %\includegraphics[scale=0.18]{diff_training_curve.pdf}
    %\includegraphics[scale=0.18]{diff_alpha.pdf}
    \vspace{-4mm}
    \caption{(a) comparison between centralized AT~\citep{Madry_adversarial_training} and FAT~\citep{zizzo2020fat} in terms of the robust accuracy and the natural accuracy. (b) comparison between FAT and SFAT (our proposed method). All the experiments of FAT and SFAT are conducted on \textit{CIFAR-10} dataset (Non-IID) with $5$ clients, and use natural test data and adversarial test data generated by PGD-20~\citep{Madry_adversarial_training} to evaluate the natural and robust accuracies. Compared with centralized AT, FAT shows performance decreasing (especially the robust accuracy) along with the learning process. In comparison, our proposed SFAT can achieve a higher robust accuracy than FAT (as indicated by the black dash line) by alleviating the deterioration. The underlying reason is elaborated out in Figure~\ref{fig:reason}.}
    \label{fig:motivation}
    \vspace{-4mm}
\end{figure*}

We dive into the issue of robustness deterioration and discover that it may attribute to the intensified heterogeneity induced by adversarial training in local clients (as Figure~\ref{fig:reason} in Section~\ref{sec:motivation}). Compared with the centralized adversarial training~\citep{Madry_adversarial_training}, the training data of FAT is distributed to each client, which leads to the adversarial training in each client independent from the data in the others. Therefore, the adversarial examples generated by the inner-maximization of adversarial training tend to be highly biased to each local distribution.
% , yielding \textcolor{red}{the radical optimization}. 
Previous study~\citep{li2018federated,li2019convergence} indicated the local training in federated learning exhibits the optimization bias under the data heterogeneity among clients. The adversarial data generated by the biased local model even exacerbate the heterogeneity in federated optimization, making it more difficult to converge to a robust optimum. %Note that, this issue is different from the natural data heterogeneity~\citep{mcmahan2017communication,li2019convergence} that previous heterogeneous optimization methods \textit{e.g.,} FedProx~\citep{li2018federated} and Scaffold~\citep{karimireddy2020scaffold} targeted, and our proposed method is orthogonal to and compatible with these works.

To deal with the above challenge in the combination of adversarial training and federated learning, we propose a novel learning framework based on an $\alpha$-slack mechanism, namely, \textit{Slack Federated Adversarial Training} (SFAT). In the high level, we relax the inner-maximization objective of adversarial training~\citep{Madry_adversarial_training} into a lower bound by an $\alpha$-slack mechanism (as Eq.~(\ref{eq:alpha-weighted-loss}) in Section~\ref{sec:theo_analysis}). By doing so, we construct a mediating function that asymptotically approaches the original goal while alleviating the intensified heterogeneity induced by the local adversarial generation. In detail, our SFAT assigns the client-wise slack during aggregation to upweight the clients having the small adversarial training loss (simultaneously downweight the large-loss clients), which reduces the extra exacerbated heterogeneity and alleviates the robustness deterioration (as Figure~\ref{fig1:b}). Theoretically, we analyze the property of our $\alpha$-slack mechanism and its benefit to achieve a better convergence (as Theorem~\ref{theorem:convergence} in Section~\ref{sec:realization}). Empirically, we conduct extensive experiments (as Section~\ref{sec:exp} and Appendix~\ref{app:exp_details}) to provide a comprehensive understanding of the proposed SFAT, and the results of SFAT in the context of different adversarial training and federated optimization methods demonstrate its superiority to improve the model performance. We summarize our main contributions as follows,

%\paragraph{Main Contributions}
\begin{itemize}
    \item We study the critical, yet thus far overlooked robustness deterioration in FAT, and discover that the reason behind this phenomenon may attribute to the intensified data heterogeneity induced by the adversarial generation in local clients (Section~\ref{sec:motivation}).
    % New added.
    \item We derive an $\alpha$-slack mechanism for adversarial training to relax the inner-maximization to a lower bound, which could asymptotically approach the original goal towards adversarial robustness and alleviate the intensified heterogeneity in federated learning (Section~\ref{sec:theo_analysis}).
    %\item We derive an $\alpha$-weighted relaxation for Adversarial Training to relax the inner-maximization by a lower bound, which builds a mediating function to alleviate the potential radical optimization in its straightforward combination with Federated Learning (in Section~\ref{sec:theo_analysis}).
    \item We propose a novel framework, i.e., Slack Federated Adversarial Training (SFAT), to realize the mechanism in FAT via assigning client-wise slack during aggregation, which addresses the data heterogeneity and adversarial vulnerability in a proper manner (Section~\ref{sec:realization}).
    %\item We propose a new learning framework, \textit{i.e.,} $\alpha$-Weighted Federated Adversarial Training ($\alpha$-WFAT), to realize the relaxation of inner-maximization in FAT, which is simple and compatible with various Federated Learning or Adversarial Training methods (in Section~\ref{sec:realization}).
    \item We conduct extensive experiments to comprehensively understand the characteristics of the proposed SFAT (Section~\ref{sec:exp_comp}), as well as to verify its effectiveness on improving the model performance using several representative federated optimization methods (Section~\ref{sec:exp_benchmark}).
    %\item We conduct extensive experiments to comprehensively understand the characteristics of the $\alpha$-WFAT, and confirm its effectiveness on improving the model performance for both IID and Non-IID settings in the context of several federated optimization methods (in Section~\ref{sec:exp}). 
\end{itemize}


%\section{Background}

%In this section, we briefly introduce the preliminary of standard Adversarial Training (AT)~\citep{Madry_adversarial_training} and federated learning as well as FedAvg~\citep{mcmahan2017communication}, and discuss the related work.  

%For the related work, we have thoroughly discussed them and highlighted the distinguishable points in Appendix~\ref{app:related_work}.

%More detailed discussion and the notable differences are highlighted in Appendix~\ref{app:related_work}.

\section{Related Work}

In this section, we briefly introduce the related work with the following aspects. More comprehensive discussions with previous literature and detailed comparison are presented in our Appendix~\ref{app:related_work}.

\paragraph{Federated Learning.}
The representative work in federated learning is FedAvg~\citep{mcmahan2017communication}, which has been proved effective during the distributed training to maintain the data privacy. To further address the heterogeneous issues, several optimization approaches have been proposed \textit{\textit{e.g.,}} FedProx~\citep{li2018federated}, FedNova~\citep{wang2020tackling} and Scaffold~\citep{karimireddy2020scaffold}. FedProx introduced a proximal term for FedAvg to constrain the model drift cause by heterogeneity; Scaffold utilized the control variates to reduce the gradient variance in the local updates and accelerate the convergence. %\citet{reisizadeh2020robust} developed a robust federated learning algorithm to against distribution shifts. 
\citet{mansour2022federated} provides an extended theoretical framework to analyze the aggregation methods and utilize the reweighting to enhance the learning stability and convergence.
Note that, the intensified heterogeneity is different from the natural data heterogeneity~\citep{li2019convergence} that previous methods targeted, and our proposed method is orthogonal to and compatible with them.

%The representative work in federated learning is FedAvg~\citep{mcmahan2017communication}, which has been proved effectiveness during the distributed training to maintain the data privacy. To further address the heterogeneous issues, several optimization approaches have been proposed \textit{\textit{e.g.,}} FedProx~\citep{li2018federated}, FedNova~\citep{wang2020tackling} and Scaffold~\citep{karimireddy2020scaffold}. FedProx introduced a proximal term for FedAvg to constrain the model drift cause by heterogeneity; FedNova proposed a general framework that eliminated the objective inconsistency and preserved the fast convergence; Scaffold utilized the control variates to reduce the gradient variance in the local updates and accelerate the convergence. MOON~\citep{Li_2021_CVPR} alleviated the heterogeneity by maximizing the agreement between the representation of the local model and that of the global model, which helps correct the local training of individual parties. 
%\citet{reisizadeh2020robust} developed a robust federated learning algorithm to against distribution shifts in clients samples. Our $\alpha$-WFAT introduces the relaxation into federated adversarial training, which is orthogonal to and compatible with the previous optimization methods.

\paragraph{Adversarial Training.}
As one of the defensive methods~\citep{papernot2016distillation}, adversarial training~\citep{Madry_adversarial_training} is to improve the robustness of machine learning models. The classical AT~\citep{Madry_adversarial_training} is built upon on a min-max formula to optimize the worst case, \textit{e.g.,} the adversarial example near the natural example~\citep{Goodfellow14_Adversarial_examples}. \citet{Zhang_trades} decomposed the prediction error for adversarial examples as the sum of the natural error and the boundary error, and proposed TRADES to balance the classification performance between the natural and adversarial examples. \citet{wang2020improving_MART} further explored the influence of the misclassified examples on the robustness, and proposed MART that emphasizes the misclassified examples to boost the classic AT. 

%As one of the defensive methods~\citep{papernot2016distillation,gao2021mmd}, adversarial training~\citep{Madry_adversarial_training,Zhang_trades,jiang2020robust,wu2020adversarial,chen2021robust} is to improve the robustness of machine learning models. The classical AT~\citep{Madry_adversarial_training} is built upon on a min-max formula to optimize the worst case, \textit{e.g.,} the adversarial example near the natural example~\citep{Goodfellow14_Adversarial_examples}. \citet{Zhang_trades} decomposed the prediction error for adversarial examples as the sum of the natural error and the boundary error, and proposed TRADES to balance the classification performance between the natural and adversarial examples. \citet{wang2020improving_MART} further explored the influence of the misclassified examples on the robustness, and proposed MART that emphasizes the minimization of the misclassified examples to boost the AT. \citet{zhang2020fat} investigated the ``benign adversarial examples" in AT that could be used to improve the natural performance of robust model. Different from their instance-level granularity, our $\alpha$-WFAT framework leverages the client-level measure to alleviate the heterogeneous issue in the straightforward combination of adversarial training and federated learning. It is compatible to incorporate those centralized adversarial training methods to further improve the model performance.

\paragraph{Federated Adversarial Training.}
Recently, several works have made the exploration on the adversarial training in the context of federated learning. To our best knowledge, ~\citet{zizzo2020fat} takes the first trial to study the feasibility of extending federated learning~\citep{mcmahan2017communication} with the standard AT on both IID and Non-IID settings. Considering the practical situations~\citep{kairouz2019advances}, the challenges of federated adversarial training are mainly from the distributed learning paradigm or the system constraints. From the learning aspect, \citet{zizzo2020fat} found that there was a large performance gap existing between the federated and the centralized adversarial training, especially on the Non-IID data. From the system aspect,  \citet{shah2021adversarial} designed a dynamic schedule for local training to pursue higher robustness under the communication budget. \citet{hong2021federated} explored how to effectively propagate the adversarial robustness when only limited clients in federated learning have the sufficient computational budget to afford AT. 
%More comprehensive discussion about its challenges is provided in Appendixes~\ref{app:related_work} and~\ref{app:impact}. 
Different from above works, we are to solve the robustness deterioration issue induced by the intensified heterogeneity.

%Recently, several works have made the exploration on the adversarial training in the context of federated learning, which consider the data privacy and the robustness in one framework.
%To our best knowledge, ~\citet{zizzo2020fat} takes the first trial to study the feasibility of extending federated learning~\citep{mcmahan2017communication} with the standard AT on both IID and Non-IID settings. Empirically, they found that there was a large performance gap existing between the distributed and the centralized adversarial training, especially on the Non-IID data. \citet{shah2021adversarial} designed a dynamic schedule for the local training to pursue a larger robustness under the constrained communication budget of federated learning. \citet{hong2021federated} explored how to effectively propagate the adversarial robustness when only limited clients in federated learning have the sufficient computational budget to afford AT. ~\citet{zizzo2021certified} studied to defend the malicious clients that poison the global model in federated learning, which also discuss the robustness but actually another research topic compared with the federated adversarial training in this work.
%Different from previous works, we explore to solve the robustness deterioration issue of the straightforward combination between federated learning and adversarial training (as shown in Figure~\ref{fig1:a}).


\section{Preliminaries}

%In this section, we briefly formalize the notations of standard Adversarial Training (AT)~\citep{Madry_adversarial_training} and federated learning as well as FedAvg~\citep{mcmahan2017communication}.

\subsection{Adversarial Training}
Let $(\cX,d_\infty)$ denote the input feature space $\cX$ with the infinity distance metric $d_{\infty}(\bx,\xadv)=\|\bx-\xadv\|_\infty$, and $\epsball[\bx] = \{\xadv \in \cX \mid d_{\infty}(\bx,\xadv)\le\epsilon\}$
be the closed ball of radius $\epsilon>0$ centered at $\bx$ in $\cX$. Given a
dataset $S = \{ ({x}_n, y_n)\}^N_{n=1}$, where ${x}_n \in \cX$ and $y_n \in \cY =  \{0, 1, ..., C-1\}$, the objective function of Adversarial Training (AT)~\citep{Madry_adversarial_training} is a min-max formula defined as follows, $\min_{f_{\theta}\in\cF} \frac{1}{N}\sum_{n=1}^N \max_{\xadv_n\in\epsball[\bx_n]} \ell(f_{\theta}(\xadv_n),y_n)$,
where $\cF$ is the hypothesis space, $\bxtidle_n$ is the \textit{most adversarial data} within the $\epsilon$-ball centered at ${x_n}$, $f_{\theta}(\cdot):\cX\to\bR^C$ is a score function, $\ell:\bR^C\times\cY\to\bR$ is a composition of a base loss $\ell_\textrm{B}:\Delta^{C-1}\times\cY\to\bR$ (\textit{e.g.,} the Cross-Entropy loss) and an inverse link function $\ell_\textrm{L}:\bR^C\to\Delta^{C-1}$ (\textit{e.g.,} the Softmax). Here, $\Delta^{C-1}$ is the corresponding probability simplex that yields $\ell(f_{\theta}(\cdot),y)=\ell_\textrm{B}(\ell_\textrm{L}(f_{\theta}(\cdot)),y)$. 
For the inner-maximization, the multi-step projected gradient descent (PGD)~\citep{Madry_adversarial_training} is usually employed to generate the adversarial samples. Given the natural data ${x}^{(0)} \in \cX$ and a step size $\alpha > 0$, PGD works as follows,
%which are then used for the outer-minimization to gain the adversarial robustness. \textcolor{red}{Add PGD formula} 
%Given a starting point ${x}^{(0)} \in \cX$ and step size $\alpha > 0$, PGD works as follows:
${x}^{(t+1)} = \Pi_{\epsball[{x}^{(0)}]} \big( {x}^{(t)} +\alpha \text{sign} (\nabla_{{x}^{(t)}} \ell(f_{\theta}({x}^{(t)}), y )  )  \big )$,
%until a certain stopping criterion is satisfied. $\ell$ is the loss function; ${x}^{(0)}$ refers to natural data or natural data perturbed by a small Gaussian or uniformly random noise; $y$ is the corresponding label for natural data; 
where $t \in \mathbb{N}$, ${x}^{(t)}$ is the adversarial data at step $t$, $\text{sign}(\cdot)$ is the function that extracts the sign of tensor elements, and $\Pi_{\epsball[{x}^{(0)}]}(\cdot)$ is the projection function that projects the adversarial data back into the $\epsilon$-ball centered at ${x}^{(0)}$ if necessary.

\subsection{Federated Learning}
Let $\cD_{k}$ denote a finite set of samples from the $k$-th client, and in each round, a set of datasets $\{\cD_{k}\}_{k=1}^K$ from $K$ clients are involved into the training. The objective of federated learning is to learn a machine learning model without any exchange of the training data between the clients and the server. The current popular strategy, namely FedAvg, is introduced by~\citet{mcmahan2017communication}, where the clients collaboratively send the locally trained model parameters $\theta_{k}$ to the server for the global average aggregation. Concretely, each client runs on a local copy of the global model (parameterized by $\theta^t$ in the $t$-th round) with its local data to optimize the learning objective. Then, the server receives their updated model parameters $\{\theta^t_k\}_{k=1}^K$ of all clients and performs the following aggregation,
%\vspace{-3mm}
%\begin{align}
%\label{eq:fedavg}
$\theta^{t+1} = \frac{1}{N}\sum^K_{k=1}{N_{k}\theta^{t}_{k}}$,
%\vspace{-3mm}
%\end{align}
where $N_k$ denotes the number of samples in $\cD_k$ and $N=\sum_{k=1}^K N_k$. Then, the parameters $\theta^{t+1}$ for the global model will be sent back to each client for another round of training. After sufficient rounds of such a periodic aggregation, we expect the stationary point of federated learning will approximately approach to or have a small gap with that from the centralized case.


%\subsection{Related Work}

%\textcolor{blue}{To be reorganized here}

%\subsection{Adversarial Training}

%Let $(\cX,d_\infty)$ denote the input feature space $\cX$ with the infinity distance metric $d_{\infty}(\bx,\xadv)=\|\bx-\xadv\|_\infty$, and $\epsball[\bx] = \{\xadv \in \cX \mid d_{\infty}(\bx,\xadv)\le\epsilon\}$ be the closed ball of radius $\epsilon>0$ centered at $\bx$ in $\cX$. Given a dataset $S = \{ ({x}_n, y_n)\}^N_{n=1}$, where ${x}_n \in \cX$ and $y_n \in \cY =  \{0, 1, ..., C-1\}$, the objective function of Adversarial Training (AT)~\citep{Madry_adversarial_training} is a min-max formula defined as follows, $\min_{f_{\theta}\in\cF} \frac{1}{N}\sum_{n=1}^N \max_{\xadv_n\in\epsball[\bx_n]} \ell(f_{\theta}(\xadv_n),y_n)$, where $\cF$ is the hypothesis space, $\bxtidle_n$ is the \textit{most adversarial data} within the $\epsilon$-ball centered at ${x_n}$, $f_{\theta}(\cdot):\cX\to\bR^C$ is a score function, $\ell:\bR^C\times\cY\to\bR$ is a composition of a base loss $\ell_\textrm{B}:\Delta^{C-1}\times\cY\to\bR$ (\textit{e.g.,} the Cross-Entropy loss) and an inverse link function $\ell_\textrm{L}:\bR^C\to\Delta^{C-1}$ (\textit{e.g.,} the Softmax). Here, $\Delta^{C-1}$ is the corresponding probability simplex that yields $\ell(f_{\theta}(\cdot),y)=\ell_\textrm{B}(\ell_\textrm{L}(f_{\theta}(\cdot)),y)$. For the inner-maximization, the multi-step projected gradient descent (PGD)~\citep{Madry_adversarial_training} is usually employed to generate the adversarial samples. Given the natural data ${x}^{(0)} \in \cX$ and a step size $\alpha > 0$, PGD works as follows,
%which are then used for the outer-minimization to gain the adversarial robustness. \textcolor{red}{Add PGD formula} 
%Given a starting point ${x}^{(0)} \in \cX$ and step size $\alpha > 0$, PGD works as follows: ${x}^{(t+1)} = \Pi_{\epsball[{x}^{(0)}]} \big( {x}^{(t)} +\alpha \text{sign} (\nabla_{{x}^{(t)}} \ell(f_{\theta}({x}^{(t)}), y )  )  \big )$,
%until a certain stopping criterion is satisfied. $\ell$ is the loss function; ${x}^{(0)}$ refers to natural data or natural data perturbed by a small Gaussian or uniformly random noise; $y$ is the corresponding label for natural data; where $t \in \mathbb{N}$, ${x}^{(t)}$ is the adversarial data at step $t$, $\text{sign}(\cdot)$ is the function that extracts the sign of tensor elements, and $\Pi_{\epsball[{x}^{(0)}]}(\cdot)$ is the projection function that projects the adversarial data back into the $\epsilon$-ball centered at ${x}^{(0)}$ if necessary.

%\subsection{Adversarial Training}

%As one of the defensive methods~\citep{papernot2016distillation}, adversarial training~\citep{Madry_adversarial_training} is to improve the robustness of machine learning models. The classical AT~\citep{Madry_adversarial_training} is built upon on a min-max formula to optimize the worst case, \textit{e.g.,} the adversarial example near the natural example~\citep{Goodfellow14_Adversarial_examples}. \citet{Zhang_trades} decomposed the prediction error for adversarial examples as the sum of the natural error and the boundary error, and proposed TRADES to balance the classification performance between the natural and adversarial examples. \citet{wang2020improving_MART} further explored the influence of the misclassified examples on the robustness, and proposed MART that emphasizes the minimization of the misclassified examples to boost the classic AT. 

%\subsection{Federated Learning}

%The representative work in federated learning is FedAvg~\citep{mcmahan2017communication}, which has been proved effective during the distributed training to maintain the data privacy. To further address the heterogeneous issues, several optimization approaches have been proposed \textit{\textit{e.g.,}} FedProx~\citep{li2018federated}, FedNova~\citep{wang2020tackling} and Scaffold~\citep{karimireddy2020scaffold}. FedProx introduced a proximal term for FedAvg to constrain the model drift cause by heterogeneity; Scaffold utilized the control variates to reduce the gradient variance in the local updates and accelerate the convergence. %\citet{reisizadeh2020robust} developed a robust federated learning algorithm to against distribution shifts. 
%Note that, the intensified heterogeneity is different from the natural data heterogeneity~\citep{li2019convergence} that previous methods targeted, and our proposed method is orthogonal to and compatible with them.

%Recently, several works have made the exploration on the adversarial training in the context of federated learning.
%To our best knowledge, ~\citet{zizzo2020fat} takes the first trial to study the feasibility of extending federated learning~\citep{mcmahan2017communication} with the standard AT on both IID and Non-IID settings. Empirically, they found that there was a large performance gap existing between the distributed and the centralized adversarial training, especially on the Non-IID data. \citet{shah2021adversarial} designed a dynamic schedule for the local training to pursue higher robustness under the constrained communication budget of federated learning. \citet{hong2021federated} explored how to effectively propagate the adversarial robustness when only limited clients in federated learning have the sufficient computational budget to afford AT. 
% \textcolor{blue}{\citet{luo2021ensemble} utilizes the extra public data to enhance the diversity of training samples on the basis of conventional federated adversarial training.}
%Different from previous works (also summarized in Table~\ref{tab:research_compare}), we explore to solve robustness deterioration issue induced by the intensified heterogeneity.
% of the straightforward combination of federated learning and adversarial training.

\begin{figure*}[!t]
    \centering
    \vspace{-2mm}
    %\includegraphics[scale=0.28]{motivation_figure.pdf}
    %\includegraphics[scale=0.292]{motivation_figure_adv_revised_hard.pdf}
    %\hspace{-0.2in}
    %\includegraphics[scale=0.292]{motivation_figure_adv_process_with_loss.pdf}
    %\includegraphics[scale=0.242]{motivation_figure_direction_with_loss_comp_note.pdf}
    %\includegraphics[scale=0.242]{motivation_figure_adv_smaller_merged.pdf}
    \includegraphics[scale=0.242]{motivation_figure_adv_smaller_merged_cifar10.pdf}
    %\includegraphics[scale=0.22]{diff_alpha_acc.pdf}
    %\hspace{0.05in}
    %\includegraphics[scale=0.22]{diff_alpha_acc.pdf}
    %\includegraphics[scale=0.21]{diff_step_number_center_per.pdf}
    %\includegraphics[scale=0.18]{diff_training_curve.pdf}
    \vspace{-4mm}
    \caption{Left panel: Heterogeneity measure using the client drift~\citep{li2018federated,karimireddy2020scaffold} with different adversarial generation on CIFAR-10 dataset. Right panel: comparison about FAT with our SFAT on aggregating local clients.
    The local adversarial generation would maximize the loss and are observed to exacerbate the heterogeneity (more empirical verification that correlates to robust deterioration can refer to Appendixes~\ref{app:emp} and~\ref{client_drift}). Compared with FAT, SFAT selectively upweights/downweights the client with small/large adversarial training loss to alleviate it during aggregation, which follows our $\alpha$-slack mechanism to relax the original objective into a lower bound. We also compare the client drift of FAT and SFAT in Figures~\ref{fig:justification} and~\ref{fig:client_drift_app} to explain their difference. %The performance deterioration is more significant as the training data being more adversarial, which confirmed the left toy illustration. 
    }
    \label{fig:reason}
    \vspace{-4mm}
\end{figure*}

% \begin{figure}[!t]
% \centering
% %\vspace{2mm}
%     %\hspace{-0.15in}
%     \subfigure[Client drift with different adv. generation]{
%         \includegraphics[scale=0.20]{fed_justification_epsilon_svhn.pdf}
%         \label{fig:just_statistic}
%     }
%     \hspace{0.1in}
%     \subfigure[w/o adv. generation]{
%         \includegraphics[scale=0.22]{ori_just_reason_b.pdf}
%         \label{fig:just_app_a}
%     }
%     \subfigure[w/ adv. generation]{
%         \includegraphics[scale=0.22]{adv_just_reason_b.pdf}
%         \label{fig:just_app_b}
%     }
%     \vspace{-2mm}
%     \caption{ (a): the client drift~\citep{li2018federated} with different adv. generation varied from weak (i.e., $\epsilon=1/255$) to strong (i.e., $\epsilon=4/255$) on SVHN. $||\theta_{k}-\theta_{s}||_2$ indicates the parameter difference between local model and averaged global model. It verified that stronger adv. generation leads to intensified heterogeneity. (b)-(c): The decision boundary of a binary classification task on one local client. The black squares and circles indicate samples of two classes in the client, the light gray ones indicate that of the other client. The red squares and circles indicate the generated adversarial data. It demonstrates the bias exacerbation caused by local adversarial generation, which verifies the illustration in the left of Figure~\ref{fig:reason}. Note that, (b)-(c) are obtained by training the neural networks.}
%     \label{fig:just_reason_app}
%     %\vspace{2mm}
% \end{figure}

\section{Slack Federated Adversarial Training}

In this section, we first discuss the motivation of the problem when directly applying adversarial training into federated learning. Then, we propose $\alpha$-slack mechanism and show some theoretical insights. Finally, we propose our Slack Federated Adversarial Training (SFAT) to realize the $\alpha$-slack mechanism and provide its corresponding convergence analysis and insights.


\subsection{Motivation}
\label{sec:motivation}

Considering federated learning, one of the primary difficulties is the biased optimization caused by the local training with heterogeneous data~\citep{zhao2018federated,li2018federated,lit2020federated}. As for adversarial training, the key distinction from standard training is the use of inner-maximization to generate adversarial data, which pursues the better adversarial robustness. When combining the two learning paradigms, we conjecture that the following issue may arise especially under the Non-IID case,
\vspace{-2mm}
\begin{quote}
\textit{the inner-maximization for pursuing adversarial robustness would exacerbate the data heterogeneity among local clients in federated learning.}
\end{quote}
\vspace{-2mm}
Intuitively, the adversarial data inherits the optimization bias since its generation is on the basis of the biased local model. As the adversarial strength increases, i.e., when adversarial training trying to gain more robustness via stronger adversarial generation, the heterogeneity are observed to be exacerbated (indicated by the client drift in the left of Figure~\ref{fig:reason}). In the right of Figure~\ref{fig:reason}, we illustrate the aggregation procedure with two clients (i.e., Clients A and B). With adversarial generation on local data, the optimization bias of each client is exacerbated, which may result in more severe heterogeneity and the poor convergence. Therefore, a new mechanism is required to prevent the intensified heterogeneity that shows detrimental to convergence in FAT (refer to Figures~\ref{fig:client_drift_reverse} and~\ref{fig:client_drift_app}).

%\textcolor{blue}{The corresponding qualitative analysis is presented in Figure 6(a), where we verify the intensified heterogeneity in the perspective of client drift [1,2]. However, we appreciate the reviewer's challenge about the clarity of the motivation. We will add Figure 6(a) into Figure 2 to better improve the motivation part. Besides, the same quantitative analysis has also been conducted on our SFAT in Figures 4, 10, and 11 to compare with the original FAT, which confirms the rationality of our $\alpha$-slack mechanism and SFAT with $\alpha$-slack indeed alleviates the exacerbated heterogeneity and achieve better robust accuracy. In the corresponding parts, we will add the necessary clarification of the experimental support to facilitate the reviewers and readers to refer to the quantitative analysis. [1] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In ICML, 2020. [2] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith Federated optimization in heterogeneous networks. In MLSys, 2018.}

\subsection{\texorpdfstring{$\alpha$}{a}-Slack Mechanism}
\label{sec:theo_analysis}

As previous analysis, the inner-maximization of adversarial training is incompatible with federated learning due to the intensification of data heterogeneity. To deal with that, one possible way is to build a mediating function that can alleviate the intensified heterogeneity effect and simultaneously approach the goal of the original objective asymptotically to pursue adversarial robustness.
%maintains the original goal while alleviating the effect of adversarial generation which exacerbates the heterogeneity. 
To this intuition, we consider a slack of the inner-maximization to prevent the intensification of the optimization bias as illustrated in the right panel of Figure~\ref{fig:reason}. Formally, we decompose the inner-maximization in adversarial training into the independent $K$ populations that correspond to the $K$ clients in federated learning, and relax it into a lower bound by $\alpha$ as follows\footnote{Note that the intuition here is to find a mechanism to \emph{relax} the original objective like the classical continuous relaxation in the discrete optimization. Pursuing an upper bound does not help but exacerbates the heterogeneity.},
\begin{align} \label{eq:alpha-weighted-loss}
\vspace{-4mm}
\footnotesize
    \begin{split}
        \mathcal{L}_{AT} &= \frac{1}{N}\sum_{n=1}^N \max_{\xadv_n\in\epsball[\bx_n]} \ell(f_\theta(\xadv_n), y_n)
     = \sum_{k=1}^K \frac{N_k}{N}\underbrace{\left(\frac{1}{N_k}\sum_{n=1}^{N_k}\max_{\xadv_n\in\epsball[\bx_n]}\ell(f_\theta(\xadv_n^k), y_n^k)\right)}_{\mathcal{L}_k} \\
        % & = \frac{N_1}{N}\mathcal{L}_1 + \frac{N_2}{N}\mathcal{L}_2 + \dots + \frac{N_K}{N}\mathcal{L}_K \\
        % & = \underbrace{\sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}}_{\text{top}-\widehat{K}~\text{small population losses}} + \underbrace{\sum_{k=\widehat{K}+1}^{K} \frac{N_{\psi(k)}}{N}\mathcal{L}_{\psi(k)}}_{\text{bottom}-(K-\widehat{K})~\text{population losses}} ~\quad\quad \text{s.t.}~\widehat{K}\leq \frac{K}{2} \\
        % & \geq (1+\alpha) \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} + (1-\alpha) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\psi(k)}}{N}\mathcal{L}_{\psi(k)}~\quad\quad \text{s.t.}~\alpha\in\left[0,~1\right.) \\
        & \geq (1+\alpha) \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} + (1-\alpha) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}~\quad \\
        & \doteq \mathcal{L}^\alpha(\widehat{K}),  ~\quad~\quad \text{s.t.}~\alpha\in\left[0,~1\right.),~\widehat{K}\leq \frac{K}{2},
    \end{split}
    \vspace{-6mm}
\end{align}
where $\phi(\cdot)$ is a function which maps the index to the original population sorted by $\{\frac{N_k}{N}\mathcal{L}_k\}$ in an ascending order. Note that, $\phi(\cdot)$ is an auxiliary operation that is non-parametric and does not affect the gradient back-propagation. The intuition is to relax the original objective to alleviate the heterogeneity exacerbation, like the classical continuous relaxation (e.g., Gumbel-SoftMax~\citep{jang2017categorical}) in the discrete optimization. We have also discuss the reverse operation of $\alpha$-slack in experiments (refer to Section~\ref{sec:exp_comp} and Appendix~\ref{app:emp}), which pursues an upper bound but it further exacerbates the heterogeneity.
%\textcolor{blue}{We would like to clarify that our intuition is to relax the original objective to alleviate the heterogeneity exacerbation. Although it is true that minimizing the lower bound does not always mean the minimization of the original objective, the similar optimization strategies also occur in the optimization of discrete variables like Gumbel-SoftMax [1], which is indefinite in terms of the bound relationship. However, it is really effective in the empirical results. We appreciate the advice of the reviewer and will add more discussion about the corresponding parts around Eq.(1).  Empirically, we present the validation in Figures 10, 11, and 12 to show that our SFAT can alleviate the heterogeneity exacerbation and achieve the better robustness by relaxing the objective to a lower bound.~\citep{jang2017categorical}}
The following Theorems~\ref{theorem:characteristic} and~\ref{theorem:convergence} will provide more analysis about the characteristics of this slack mechanism and their complete proofs are given in Appendix~\ref{sec:app_proof_all}.
\begin{theorem} \label{theorem:characteristic}
$\mathcal{L}^\alpha(\widehat{K})$ is monotonically decreasing \textit{w.r.t.} both $\alpha$ and $\widehat{K}$, \textit{i.e.,} $\mathcal{L}^{\alpha_1}(\widehat{K})<\mathcal{L}^{\alpha_2}(\widehat{K})$ if $\alpha_1>\alpha_2$ and $\mathcal{L}^{\alpha}(\widehat{K}_1)<\mathcal{L}^{\alpha}(\widehat{K}_2)$ if $\widehat{K}_1>\widehat{K}_2$. Specifically, $\mathcal{L}^\alpha(\widehat{K})$ recovers $\mathcal{L}$ of adversarial training when $\alpha$ achieves 0, and $\mathcal{L}^\alpha(\widehat{K})$ relaxes $\mathcal{L}$ to a lower bound objective by increasing $\widehat{K}$ and $\alpha$.
\end{theorem}
Based on the above theorem, we can flexibly emphasize the importance of partial populations by setting the proper hyperparameters (i.e., $\widehat{K}$ and $\alpha$), to alleviate the evenly averaging of the harsh heterogeneous updates in FAT as illustrated by the right-most panel of Figure~\ref{fig:reason}.
\begin{theorem}\label{theorem:convergence}
Assume the loss function $\ell(\cdot, \cdot)$ in Eq.~(\ref{eq:alpha-weighted-loss}) satisfies the Lipschitzian smoothness condition \textit{w.r.t.} the model parameter $\theta$ and the training sample $x$, and is $\lambda$-strongly concave for all $x$, and $\mathbb{E}\left[||\nabla_{\theta} \mathcal{L}^\alpha(\widehat{K}) - \nabla_\theta\ell(f_{\theta}(\xadv),y)||^2_2\right]\leq \delta^2$, 
% \textcolor{blue}
{where $\tilde{x}$ is the adversarial example}. Then, 
after the sufficient $T$-step optimization \textit{i.e.,} $T\geq \frac{L\Delta}{\delta^2}$, for the $\alpha$-slack mechanism of decomposed Adversarial Training with the constant stepsize $\sqrt{\frac{\Delta}{LT\sigma^2}}$ in PGD, we have the following convergence property,
\begin{align} \label{eq:convergence}
    \begin{split}
        \frac{1}{T} & \sum_{t=1}^T\mathbb{E}\left[\bigg|\bigg|\nabla \mathcal{L}^\alpha(\widehat{K})\big|_{\theta^t}\bigg|\bigg|^2_2\right]  \leq  \left(1+\alpha\frac{\frac{1}{T}\sum_{t=1}^T\xi^{(t)}}{N}\right) \left(\frac{4L^2_{\theta x}\epsilon}{\lambda}+4\delta\sqrt{\frac{L\Delta}{T}}\right), 
    \end{split}
    %\vspace{-2mm}
\end{align}
where $L=L_{\theta\theta}+\frac{L_{\theta x}L_{x\theta}}{\lambda}$ defined by the Lipschitzian constraints, $\Delta\geq\mathcal{L}^\alpha(\widehat{K})|_{\theta^0}-\inf_\theta\mathcal{L}^\alpha(\widehat{K})$ and $\xi^{(t)}=\sum_{k=1}^{\widehat{K}} N_{\phi(k)}^{(t)} - \sum_{\widehat{K}+1}^{K} N_{\phi(k)}^{(t)}$ meaning the accumulative counting difference of the $t$-th step.
\end{theorem}

The complete notation explanation can be found in Appendix~\ref{sec:app_comp_proof_section42}. Note that, when $\alpha=0$, Eq.~(\ref{eq:alpha-weighted-loss}) recovers the original loss of Adversarial Training, and the first part in the RHS of Eq.~(\ref{eq:convergence}) goes to 1 that recovers the convergence rate of Adversarial Training~\citep{sinha2018certifying}. When $\alpha\rightarrow 1$, Eq.~(\ref{eq:alpha-weighted-loss}) becomes more biased, while simultaneously the straightforward benefit is that we can achieve a faster convergence in Eq.~(\ref{eq:convergence}) if $\frac{1}{T}\sum_{t=1}^T\xi^{(t)}< 0$, \textit{i.e.,} $\left(1+\alpha\frac{\frac{1}{T}\sum_{t=1}^T\xi^{(t)}}{N}\right)< 1$. Actually, this is possible when the sample number is approximately 
similar among all clients and the top-1 choice easily has $-N<\xi^{(t)}= N_{\phi(1)}^{(t)} - \sum_{k=2}^{K} N_{\phi(k)}^{(t)}<0$ in each optimization step. In this case, a larger $\alpha$ has a faster convergence. Therefore, the proposed $\alpha$-slack mechanism of adversarial training provides us a way to acquire the optimization benefits in FAT by introducing the small relaxation to the objective.

\subsection{Realization of Slack Federated Adversarial Training}
\label{sec:realization}

Based on the previous analysis of the $\alpha$-slack mechanism, we propose a \textit{Slack Federated Adversarial Training} to combine adversarial training and federated learning. The intuition is applying the $\alpha$-slack mechanism into the inner-maximization in FAT, which can be formalized as follows,
\begin{align}\label{eq:aWFAT}
\vspace{2mm}
\begin{split}
    \min \mathcal{L}_{\text{SFAT}} 
    % & = \min_{f_{\theta}\in\cF} \frac{1}{\sum_{k=1}^{K} P_k N_k}\sum_{k=1}^{K} P_k N_k\mathcal{L}_k \\
    =  \min_{f_{\theta}\in\cF} \frac{1}{\sum_{k}^K N_k} \sum_{k=1}^{K} P_k N_k \cdot \underbrace{\left( \frac{1}{N_k}\sum_{n=1}^{N_k} \max_{\xadv_n^{k}\in\epsball[\bx_n^{k}]} \ell(f_{\theta}(\xadv^{k}_n),y^{k}_n)\right)}_{\mathcal{L}_k},
\end{split}
\end{align}
\vspace{2mm}
where $P_k$ denotes the weight assigned to the $k$-th client based on the ascending sort of weighted client losses compared with the $\widehat{K}$-th one, which can be $(1+\alpha) \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k \leq \mathcal{L}_{\text{sorted}}[\widehat{K}]) + (1-\alpha) \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k > \mathcal{L}_{\text{sorted}}[\widehat{K}])$ that corresponds to the relaxed loss in Eq.~(\ref{eq:alpha-weighted-loss}). 
For simplicity without loss of generality, we can transform the slack mechanism as the weight adjustment of those selected clients with smaller adversarial training losses, and assign $P_k=((1+\alpha)/(1-\alpha) \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k \leq \mathcal{L}_{\text{sorted}}[\widehat{K}]) + 1 \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k > \mathcal{L}_{\text{sorted}}[\widehat{K}]))/((\sum_{k=1}^K P_k)+2\alpha/(1-\alpha))$ to ensure the lower bound derivation. 
For more details, we summarize the procedure of SFAT in Algorithm~\ref{alg:alpha-WFAT} of Appendix~\ref{app:supp_alg}, which consists of multi-round iterations between the local training on the client side and the global aggregation on the server side.

%\begin{wrapfigure}{r}{0.48\textwidth}
%\begin{minipage}{0.48\textwidth}

% \setlength{\intextsep}{0pt}
% \setlength{\textfloatsep}{10pt}
% \begin{algorithm}[t!]
% %\footnotesize
%   \caption{Slack Federated Adversarial Training}
%   \label{alg:alpha-WFAT}
%   {\bf Input:} client number: $K$, communication rounds: $T$, local training epochs per round: $E$, initial server's model parameter: $\theta^0$, hyper-parameter for aggregation: $\alpha$, number of enhanced clients: $\widehat{K}$; \\
%   {\bf Output:} globally robust model $\theta^{T}$;
% \begin{algorithmic}[1]
%   \FOR{t $= 1$, $\dots$, $T$}
%     \STATE \colorbox{shadecolor}{\textbf{Clients:} [  perform adversarial training]}
%     \FOR{client $k =1$, $\dots$, $K$ }
%     %\State Client download $\theta_{k}$ from the server;
%     \STATE $\theta_{k}^{t}, \mathcal{L}_{k}= $ AT$(\theta_{k}^{t}, E)$~\citep{Madry_adversarial_training}
%   \ENDFOR
%   \STATE \colorbox{shadecolor}{\textbf{Server:} [ performs slacked aggregation]}
% %  \State $\theta^{t+1}=F(\theta_{selected})$
%     \STATE $\mathcal{L}_{all}\gets[\frac{N_1}{N}\mathcal{L}_1,\frac{N_2}{N}\mathcal{L}_2,\dots,\frac{N_K}{N}\mathcal{L}_K]$,  \quad $\mathcal{L}_{\text{sorted}} \gets $ Ascending$\_$Sort($\mathcal{L}_{all}$);
%   \STATE $\forall k,~P_{k} \gets (1+\alpha) \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k \leq \mathcal{L}_{\text{sorted}}[\widehat{K}]) + (1-\alpha) \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k > \mathcal{L}_{\text{sorted}}[\widehat{K}])$;
%   \STATE $\theta^{t+1}=\frac{1}{\sum^{K}_{k=1}P_k N_k}\sum^{K}_{k=1}{P_{k} N_k\theta^t_{k}}$; %\Comment{\colorbox{shadecolor}{$\alpha$-weighted mechanism}}
%  \ENDFOR
% \end{algorithmic}
% \end{algorithm}

%\end{minipage}
%\end{wrapfigure}

% \begin{figure}[!t]
%     \centering
%     %\hspace{-0.2in}
%     %\includegraphics[scale=0.18]{fed_dyn_weight.pdf}
%     \includegraphics[scale=0.18]{fed_dyn_weight_confirm.pdf}
%     %\includegraphics[scale=0.195]{fed_dyn_weight_copy.pdf}
%     \vspace{-2mm}
%     \caption{The index of the top-$\widehat{K}$ clients with the small losses in SFAT ($\alpha=1/6$, $\widehat{K}=1$) in each  communication round on \textit{CIFAR-10} (Non-IID) as well as the total accounts in right. We can see that it is dynamically routing among all clients, which shows there is no dominant client exists.}
%     \label{fig:dyn_tracing}
%     \vspace{-2mm}
% \end{figure}

Concretely, on the client side, after downloading the global model parameter from the server, each client will perform the adversarial training on its local data. At the same time, the client loss on the adversarial examples is also recorded, which acts as the soft-indicator of the local bias induced by the radical adversarial generation. Then, when the training steps reach to the condition, the client will upload its model parameter and the loss to the server. On the server side, after collecting the model parameters $\{\theta_k\}_{k=1}^K$ and the losses $\{\mathcal{L}_k\}_{k=1}^K$ of all clients, it will first sort $\{\frac{N_k}{N}\mathcal{L}_k\}_{k=1}^K$ in an ascending order to find the top-$\widehat{K}$ clients. Based on that, the global model parameters will be aggregated by the $\alpha$-slack mechanism in which the model parameters of the top-$\widehat{K}$ clients are upweighted with $(1+\alpha)/(1-\alpha)$ and the remaining is downweighted. For atypical layers~\citep{li2021fedbn} \textit{e.g.,} BN, it is outside the scope of this paper and we keep the aggregation same as FedAvg. 


\begin{wrapfigure}{r}{0.49\linewidth}
    %\vspace{-1mm}
    \centering
    \hspace{-0.1in}
    \includegraphics[scale=0.142]{fed_justification_100_12.pdf}
    \vspace{-2mm}
    \caption{The averaged client drift~\citep{li2018federated, karimireddy2020scaffold} in each communication round on \textit{CIFAR-10} (Non-IID). SFAT generally achieves a smaller drift compared to FAT, \textit{i.e.,} a less heterogeneous aggregation. More empirical results can refer to Appendixes~\ref{app:emp}, ~\ref{client_drift} and~\ref{app:orthogonal_effect.}.}
    \label{fig:justification}
    \vspace{0mm}
\end{wrapfigure}
In Figure~\ref{fig:justification}, we empirically justify the rationality of our SFAT as illustrated by Figure~\ref{fig:reason}. We employ the averaged client drift~\citep{li2018federated,karimireddy2020scaffold}, i.e., $||\theta_{k}-\theta_{s}||_2$ (the parameter difference between local model and averaged global model), to approximately reflect the effect of data heterogeneity (illustrated as the diverse optimization directions in the right panel of Figure~\ref{fig:reason}). From Figure~\ref{fig:justification}, we can see the client drift of SFAT is smaller than that of FAT in the later stages. This indicates the optimization directions of clients are less diverse, contributing to the alleviation of the intensified heterogeneity. In Figure~\ref{fig:dyn_tracing_app}, we trace the index of the top-weighted client in one experiment and find it dynamically routes among different clients instead of a fixed one. 


In the following, we provide the theoretical analysis of our SFAT on the convergence in the context of federated learning~\citep{li2019convergence}, which is slightly different from the centralized counterpart. 
\setlength{\intextsep}{0pt}
\begin{theorem}
\label{the:awfat-convergence}
Assume the loss function $\ell(\cdot, \cdot)$ in Eq.~(\ref{eq:aWFAT}) is $L$-smooth and $\lambda$-strongly convex \textit{w.r.t.} the model parameter $\theta$, and the expected norm and the variance of the stochastic gradient in each client respectively satisfy $\mathbb{E}\left[||\nabla_\theta\ell(f_{\theta}(\xadv^k), y^k)||^2_2\right]\leq \varsigma^2$ and $\mathbb{E}\left[||\nabla_\theta\ell(f_{\theta}(\xadv^k), y^k)-\nabla_\theta \mathcal{L}_k||^2_2\right]\leq \delta^2_k$. Let $\kappa=\frac{L}{\lambda}$, $\gamma=\max\{8\kappa, E\}$ where $E$ is the iteration number of the local adversarial training with the learning rate $\eta_{t}=\frac{2}{\lambda(\gamma+t)}$. Then, after the sufficient $T$-step communication rounds for SFAT, we have the following asymptotics to the optimal,
\begin{align} \label{eq:awfat-convergence}
\vspace{-3mm}
    \begin{split}
        \mathbb{E}[\mathcal{L}&_{\text{SFAT}}]-\mathcal{L}^{*} \leq\frac{\kappa}{\gamma+T-1}\left(\frac{2B}{\lambda}+\frac{\lambda\gamma}{2}\mathbb{E}\left[||\theta^0-\theta^{*}||^2\right]\right),
    \end{split}
\end{align}
%where $\mathcal{L}^{*}$ is the minimum value of $\mathcal{L}_{\alpha-WFAT}$, $\theta^*$ is the optimal model parameter, and $$B=\sum_k^K \left(\frac{P_k^{(T)} }{1+\alpha\frac{\xi^{(T)}}{N} }\right)^2\left(\frac{N_k}{N}\delta_k\right)^2 + 6L\left(\mathcal{L}^{*}-\sum_k^K \frac{P_k^{(T)} }{1+\alpha\frac{\xi^{(T)}}{N}}\frac{N_k}{N}\mathcal{L}_k^*\right) + 8(E-1)^2\varsigma^2.$$
where $\mathcal{L}^{*}$ is the minimum value of $\mathcal{L}_{\text{SFAT}}$, $\theta^*$ is the optimal model parameter, and 
\begin{align}\begin{split} B = &\sum_{k=1}^K \left(\frac{P_k^{(T)} }{1+\alpha\frac{\xi^{(T)}}{N} }\right)^2\left(\frac{N_k}{N}\delta_k\right)^2 +  6L\left(\mathcal{L}^{*}-\sum_k^K \frac{P_k^{(T)} }{1+\alpha\frac{\xi^{(T)}}{N}}\frac{N_k}{N}\mathcal{L}_k^*\right) + 8(E-1)^2\varsigma^2. \nonumber
\end{split}
\end{align}
\vspace{-3mm}
\end{theorem}
When $\alpha=0$, we have 
% $\frac{P_k^{(T)} }{1+\alpha\frac{\xi^{(T)}}{N} }=1$ 
$P_k^{(T)}\slash(1+\alpha\frac{\xi^{(T)}}{N})=1$
and Eq.~(\ref{eq:awfat-convergence}) becomes the convergence rate of FedAvg on Non-IID data~\citep{li2019convergence}. Different from Theorem~\ref{theorem:convergence} that concludes in the centralized training setting, when $\alpha\rightarrow1$, the convergence is indefinite compared to the standard FAT, since the emerging terms in $B$, \textit{i.e.,} $\left(P_k^{(T)}\slash(1+\alpha\frac{\xi^{(T)}}{N})\right)^2$ and $P_k^{(T)}\slash(1+\alpha\frac{\xi^{(T)}}{N})$, are acted as the scalar timing by the personalized variance bound $\delta_k^2$ and the local optimum $\mathcal{L}^*_k$ of each client. One possible case is when the optimization approaches to the optimal parameter $\theta^*$, $\delta_k^2$ can be in a smaller scale relative to the scale of $\mathcal{L}^*_k$. In this case, the increment of the first term of $B$ can be totally counteracted by the loss of the second term of $B$ so that in sum $B$ becomes smaller. Then, we can have a tighter upper bound for SFAT in Eq.~(\ref{eq:awfat-convergence}) to achieve a faster convergence than FAT. The completed proof of Theorem~\ref{the:awfat-convergence} is given in Appendix~\ref{sec:app_comp_proof_section43} and the empirical verification is presented in Appendix~\ref{app:theo_empirical}. The following section will comprehensively confirm that SFAT can reach to a more robust optimum. Note that, the theorem we deduce here follows the same assupmitions~\citep{li2019convergence} and is mainly to compare the difference with the early convergence analysis in federated learning. However, some relaxation on the assumptions could be further improved by considering more practical SGD theories~\citep{nguyen2018sgd}, which is beyond the scope of this paper and we leave in the future works.



\section{Experiments}
\label{sec:exp}

In this section, we provide a comprehensive analysis of SFAT and empirically verify its effectiveness compared with the current methods on a range of benchmarked datasets and a real-world dataset. The source code is publicly available at: \url{https://github.com/ZFancy/SFAT}.

\textbf{Setups.}  We conduct the experiments on three benchmark datasets, \textit{i.e.,} \textit{CIFAR-10}, \textit{CIFAR-100}~\citep{krizhevsky2009learning_cifar10}, \textit{SVHN}~\citep{netzer2011reading_SVHN} as well as a real-world dataset \textit{CelebA}~\citep{caldas2018leaf} for federated adversarial training. For the IID scenario, we just randomly and evenly distribute the samples to each client. For the Non-IID scenario, we follow~\citet{mcmahan2017communication,shah2021adversarial} to 
partition the training data based on their labels. To be specific, a skew parameter $s$ is utilized in the data partition introduced by~\citet{shah2021adversarial}, which enables $K$ clients to get a majority of the data samples from a subset of classes. We denote the set of all classes in a dataset as $\cY$ and create $\cY_{k}$ by dividing all the class labels equally among $K$ clients. Accordingly, we split the data across $K$ clients that each client has $(100-(K-1)\times s)\%$ of data for the class in $\cY_k$ and $s\%$ of data in other split sets. In the test phase, we evaluate the model's standard performance using natural test data and its robust performance using adversarial test data generated by FGSM~\citep{Goodfellow14_Adversarial_examples}, PGD-20, CW$_\infty$~\citep{Carlini017_CW} and AutoAttack~\citep{croce2020reliable} (termed as AA) to evaluate its robust performance. More detailed settings are provided in Appendix~\ref{app:exp_details}.

\subsection{Ablation Study}
\label{sec:exp_comp}

In this subsection, we conduct various experiments on \textit{CIFAR-10} with the Non-IID setting to visualize the characteristics of our proposed SFAT. More comprehensive results are provided in Appendix~\ref{app:exp_details}.


\textbf{Non-AT vs. AT.} In the left two panels of Figure~\ref{fig:comp_part1}, we respectively apply our $\alpha$-slack mechanism to Federated Standard Training (SFST) and Federated Adversarial Training (SFAT) under $\widehat{K}=1$. We also consider both FedAvg and FedProx in this experiment to guarantee the universality. From the curves, we can see that SFST has the negative effect on the natural accuracy, while SFAT consistently improves the robust accuracy based on FedAvg and FedProx. This indicates our $\alpha$-slack mechanism is tailored for the inner-maximization of Federated Adversarial Training instead of the outer-minimization considered by other federated optimization methods. In addition, we also verify the orthogonal effects of SFAT with FedProx on reducing client drift in Appendix~\ref{app:orthogonal_effect.} and strengthen the hyper-parameter of FedProx to demonstrate the consistent effectiveness of our SFAT.


\textbf{Re-SFAT vs. SFAT.} In the middle panel of Figure~\ref{fig:comp_part1}, we conversely apply our $\alpha$-slack mechanism in Federated Adversarial Training (Re-SFAT) where we upweight the client with large adversarial training loss. Note that the Re-SFAT share a similar spirit with the Agnostic Federated Learning (AFL)~\citep{mohri2019agnostic}, which seeks to improve the generalization in standard federated learning through a loss-maximization reweighting. Through its comparison with FAT and SFAT, we can see enlarging the inner-maximization during aggregation could severely exacerbate heterogeneity which results in the worse performance, while our SFAT improves the performance through relaxing it into a lower bound. We also confirm the rationality of SFAT on other datasets in Appendix~\ref{app:emp}. 


\begin{figure*}[t!]
\vspace{-2mm}
    \centering
    \hspace{-0.15in}
    \includegraphics[scale=0.14]{fedst_vs_fedat_st.pdf}
    %\hspace{0.05in}
    \includegraphics[scale=0.14]{fedst_vs_fedat_at.pdf}
    %\hspace{0.1in}
    \includegraphics[scale=0.14]{diff_alpha_acc.pdf}
    \includegraphics[scale=0.14]{diff_alpha.pdf}
    \includegraphics[scale=0.14]{diff_client_number.pdf}
    %\vspace{-1mm}
    \caption{Ablation study on SFAT.  Left two panels: comparison between federated standard training and federated adversarial training respectively in combination with the $\alpha$-slack mechanism, \textit{i.e.,} SFST vs. SFAT ($\alpha=1/11$). Middle panel: comparison between FAT, SFAT and Re-SFAT (the reverse operation which upweights the clients with large adversarial training loss). Right two panels: the natural accuracy and the robust accuracy of SFAT with different $\alpha$ and different $\widehat{K}$ on CIFAR-10.}
    \label{fig:comp_part1}
    \vspace{-2mm}
\end{figure*}


\begin{table}[t!]
 \begin{minipage}[t]{0.48\textwidth}
  \centering
     \makeatletter\def\@captype{table}\makeatother\caption{Test accuracy on \textit{CIFAR-10} (Non-IID) partition with different client numbers.}
     \label{table:exp_diff_client_main_text}
       \resizebox{\textwidth}{!}{
       \renewcommand\arraystretch{1.1}
\begin{tabular}{c|c|c|c|c}
\toprule[1.5pt]
Client Number & Methods & Natural & PGD-20 & CW$_{\infty}$ \\
\midrule[0.6pt]
\midrule[0.6pt]
%AT  & 57 & 66.47\% & 47.68\% & 38.18\% & 37.04\% & - \\
\multirow{2}*{10} & FAT & 56.62\% & 31.24\% & 29.82\% \\
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{56.67\%} & \cellcolor{greyL}\textbf{33.31\%} & \cellcolor{greyL}\textbf{31.58\%} \\
\multirow{2}*{20} & FAT & 60.55\% & 32.67\% & 31.07\% \\
~ &\textbf{SFAT} & \cellcolor{greyL}\textbf{62.24\%} & \cellcolor{greyL}\textbf{35.66\%} & \cellcolor{greyL}\textbf{33.21\%} \\
\multirow{2}*{25} & FAT & 58.97\%& 32.98\% & 31.14\% \\
~ &\textbf{SFAT} & \cellcolor{greyL}\textbf{62.73\%} & \cellcolor{greyL}\textbf{35.75\%} & \cellcolor{greyL}\textbf{33.16\%} \\
\multirow{2}*{50} & FAT & 56.74\% & 32.91\% & 30.50\% \\
~& \textbf{SFAT}  & \cellcolor{greyL}\textbf{57.21\%} & \cellcolor{greyL}\textbf{34.35\%} & \cellcolor{greyL}\textbf{31.75\%} \\

\bottomrule[1.5pt]
\end{tabular}}
  \end{minipage}
  \hspace{0.1in}
  \begin{minipage}[t]{0.48\textwidth}
   \centering
        \makeatletter\def\@captype{table}\makeatother\caption{Test accuracy on \textit{CIFAR-10} (Non-IID) with different local adversarial training methods.}
        \label{table:exp_diff_methods}
         \resizebox{\textwidth}{!}{
         \renewcommand\arraystretch{1.0}
\begin{tabular}{c|c|c|c|c}
\toprule[1.5pt]
\multicolumn{2}{c|}{Methods}  & Natural & PGD-20 & CW$_{\infty}$  \\
\midrule[0.6pt]
\midrule[0.6pt]
%AT  & 57 & 66.47\% & 47.68\% & 38.18\% & 37.04\% & - \\
\multirow{2}*{AT} & FAT & 57.45\% & 32.58\% & 30.52\%  \\
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{62.34\%} & \cellcolor{greyL}\textbf{35.59\%} & \cellcolor{greyL}\textbf{33.06\%}  \\
\midrule[0.6pt]
\midrule[0.6pt]
%TRADES  &  - & - & - & - & - & - \\
\multirow{2}*{TRADES} & FAT & 64.00\% & 31.64\% & 28.95\%  \\
~ &\textbf{SFAT} & \cellcolor{greyL}\textbf{65.26\%} & \cellcolor{greyL}\textbf{35.10\%} & \cellcolor{greyL}\textbf{31.80\%}  \\
\midrule[0.6pt]
\midrule[0.6pt]
%MART  &  - & - & - & - & - & - \\
\multirow{2}*{MART} & FAT & 56.29\% & 36.27\% & 32.41\%  \\
~& \textbf{SFAT}  & \cellcolor{greyL}\textbf{58.41\%} & \cellcolor{greyL}\textbf{38.90\%} & \cellcolor{greyL}\textbf{34.67\%} \\
\bottomrule[1.5pt]
\end{tabular}}
   \end{minipage}
\vspace{-4mm}
\end{table}


\textbf{Impact of $\alpha$ and $\widehat{K}$.} To study the effect of hyperparameters in SFAT, we conduct several ablation experiments to verify the model performance. Regarding the experiments of $\alpha$, we set the client number $K=5$ and $\widehat{K}=1$ to upweight/downweight the client models in each communication round. The right middle panel of Figure~\ref{fig:comp_part1} shows that $\alpha \in (0, 1/6]$ can significantly improve the robust accuracy and the natural accuracy, while a larger $\alpha$ might be inappropriate to the natural accuracy. We also conduct a comprehensive ablation to show the effects of $\alpha$ during training in Appendix~\ref{client_drift}. Regarding the choice of $\widehat{K}$, we specially set $K=8$ in this experiment to span the range of $\widehat{K}$ due to the constraint $\widehat{K}<=K/2$. The right panel of Figure~\ref{fig:comp_part1} tracks the accuracy of SFAT with increasing $\widehat{K}$.
As can be seen, both natural accuracy and robust accuracy are improved even with larger $\widehat{K}$, which shows the effect of $\widehat{K}$ on the slack of inner-maximization. For other basic experimental setting, e.g., the local epochs, we explore the effectiveness under different setups in Appendix~\ref{app:local_ep}.

%\textcolor{blue}{The experiment in the second figure of Figure 5 ($1+\alpha/1-\alpha=1.2$) is to show the improvement of SFAT over FedAvg and FedProx, and does not incorporate a better $\alpha$ setting, different from that in Figure 1 (b) ($1+\alpha/1-\alpha=1.6$). In Figure 1 (b), we adopted a stronger $\alpha$-slack with a larger $\alpha$ value. We will add the corresponding experimental setup in the appropriate position to avoid this confusion. For the ablation study on $\alpha$ in our experiments, please refer to Figure 11, where we conduct a comprehensive ablation to show the effects of $\alpha$.}

\textbf{Different client numbers.} In Table~\ref{table:exp_diff_client_main_text}, we validate our SFAT on training with different client numbers, where we set $\alpha=1/11$ (i.e., $\frac{1+\alpha}{1-\alpha}=1.2$) and $\widehat{K}=K/5$. The results show that with the client number varying from 10 to 50, our SFAT can consistently gain better natural and robust performance than FAT. We also confirm the scalability of using other datasets (in Appendix~\ref{app:more_clients}), the performance on unequal data splits in the different clients (in Appendix~\ref{app:unequal_data_split}), as well as the effectiveness in a practical situation where only a subset of clients participate in the aggregation (in Appendix~\ref{app:real_celeba}).



\textbf{Different adversarial training methods.} In Table~\ref{table:exp_diff_methods}, we validate the combination of $\alpha$-slack mechanism and different adversarial training methods (\textit{i.e.,} AT~\citep{Madry_adversarial_training}, TRADES~\citep{Zhang_trades} and MART~\citep{wang2020improving_MART}), where we switch different local adversarial training methods on the client side. Through the comparison with FAT, the results show that SFAT can consistently boost both the natural performance and the robust performance, and is applicable to other state-of-the-art adversarial training methods under the federated learning scenarios.

\subsection{Performance Evaluation}
\label{sec:exp_benchmark}


Next, we compare SFAT with FAT on various benchmark datasets to verify its effectiveness. Specifically, we validate it with three representative federated optimization methods, \textit{i.e.,} FedAvg, FedProx and Scalffold. Considering the sensitivity of data selection in Non-IID setting, we report the results with Mean $\pm$ Std values in Table~\ref{table:exp_robust_eval_non-iid_rebuttal} after running multiple times. For the completeness of experiments, we also demonstrate the efficacy of SFAT on the IID setting and a real-world dataset. The overall results for comparison (with the centralized counterparts) are presented in Appendixs~\ref{app:real_celeba} and~\ref{app:overall_results}.


\begin{table*}[t!]
\renewcommand\arraystretch{0.93}
\centering
\caption{Performance on Non-IID settings with different federated optimization methods (Mean$\pm$Std).}
\vspace{-2mm}
\footnotesize
\label{table:exp_robust_eval_non-iid_rebuttal}
\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{2}{c|}{Setting} & \multicolumn{5}{c}{Non-IID} \\
\midrule[0.6pt]
\multicolumn{2}{c|}{CIFAR-10} & Natural & FGSM & PGD-20 & CW$_{\infty}$ & AA\\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{2}*{FedAvg} & FAT & 58.13$\pm$0.68\% & 40.06$\pm$0.62\% & 32.56$\pm$0.01\% & 30.88$\pm$0.37\% & 29.17$\pm$0.03\%   \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{63.36$\pm$0.07\%} & \cellcolor{greyL}\textbf{44.82$\pm$0.32\%} & \cellcolor{greyL}\textbf{37.14$\pm$0.03\%} & \cellcolor{greyL}\textbf{33.39$\pm$0.61\%} & \cellcolor{greyL}\textbf{31.66$\pm$0.70\%}  \\
\midrule[0.6pt]
\multirow{2}*{FedProx} & FAT & 59.95$\pm$0.45\% & 41.44$\pm$0.15\% & 33.83$\pm$0.01\% & 31.65$\pm$0.36\% & 30.11$\pm$0.09\%  \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{62.04$\pm$0.47\%} & \cellcolor{greyL}\textbf{44.21$\pm$0.08\%} & \cellcolor{greyL}\textbf{36.64$\pm$0.11\%} & \cellcolor{greyL}\textbf{32.62$\pm$0.20\%} & \cellcolor{greyL}\textbf{31.83$\pm$0.15\%}  \\
\midrule[0.6pt]
\multirow{2}*{Scaffold} & FAT & 61.44$\pm$1.37\% & 42.85$\pm$0.76\% & 34.08$\pm$0.05\% & 32.56$\pm$0.02\% & 31.03$\pm$0.08\%  \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{63.16$\pm$0.96\%} & \cellcolor{greyL}\textbf{45.55$\pm$0.50\%} & \cellcolor{greyL}\textbf{37.33$\pm$0.02\%} & \cellcolor{greyL}\textbf{34.82$\pm$0.04\%} & \cellcolor{greyL} \textbf{33.32$\pm$0.01\%} \\

\midrule[0.6pt]
\midrule[0.6pt]
\multicolumn{2}{c|}{CIFAR-100}  & Natural & FGSM & PGD-20 & CW$_{\infty}$ & AA \\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{2}*{FedAvg} & FAT & 34.63$\pm$0.56\% & 19.92$\pm$0.28\% & 15.40$\pm$0.20\% & 13.23$\pm$0.03\% & 12.23$\pm$0.01\%  \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{35.65$\pm$0.54\%} & \cellcolor{greyL}\textbf{20.23$\pm$0.44\%} & \cellcolor{greyL}\textbf{16.24$\pm$0.16\%} & \cellcolor{greyL}\textbf{13.53$\pm$0.02\%} & \cellcolor{greyL}\textbf{12.45$\pm$0.03\%} \\
\midrule[0.6pt]
\multirow{2}*{FedProx} & FAT & 31.93$\pm$0.43\% & 19.06$\pm$0.17\% & 15.30$\pm$0.08\% & 12.93$\pm$0.02\% & 12.01$\pm$0.04\%  \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{34.87$\pm$0.24\%} & \cellcolor{greyL}\textbf{20.54$\pm$0.08\%} & \cellcolor{greyL}\textbf{16.09$\pm$0.10\%} & \cellcolor{greyL}\textbf{13.35$\pm$0.12\%} & \cellcolor{greyL}\textbf{12.44$\pm$0.20\%} \\
\midrule[0.6pt]
\multirow{2}*{Scaffold} & FAT & 39.98$\pm$0.02\% & 24.30$\pm$0.04\% & 19.34$\pm$0.07\% & 16.49$\pm$0.12\% & 15.29$\pm$0.08\% \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{44.13$\pm$0.05\%} & \cellcolor{greyL}\textbf{25.32$\pm$0.94\%} & \cellcolor{greyL}\textbf{20.22$\pm$0.07\%} & \cellcolor{greyL}\textbf{16.96$\pm$0.17\%} & \cellcolor{greyL} \textbf{15.80$\pm$0.10\%} \\

\midrule[0.6pt]
\midrule[0.6pt]
\multicolumn{2}{c|}{SVHN} & Natural & FGSM & PGD-20 & CW$_{\infty}$ & AA  \\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{2}*{FedAvg} & FAT & \textbf{91.52$\pm$0.28\%} & 88.13$\pm$0.18\% & 68.98$\pm$0.11\% & 68.04$\pm$0.15\% & 66.59$\pm$0.04\%  \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}91.26$\pm$0.01\% & \cellcolor{greyL}\textbf{88.27$\pm$0.02\%} & \cellcolor{greyL}\textbf{72.04$\pm$0.32\%} & \cellcolor{greyL}\textbf{69.96$\pm$0.16\%} & \cellcolor{greyL}\textbf{68.89$\pm$0.27\%} \\
\midrule[0.6pt]
\multirow{2}*{FedProx} & FAT & 91.00$\pm$0.08\% & 87.65$\pm$0.15\% & 68.48$\pm$0.04\% & 67.16$\pm$0.02\% & 65.76$\pm$0.18\% \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{91.19$\pm$0.06\%} & \cellcolor{greyL}\textbf{88.15$\pm$0.01\%} & \cellcolor{greyL}\textbf{71.84$\pm$0.30\%} & \cellcolor{greyL}\textbf{69.88$\pm$0.35\%} & \cellcolor{greyL}\textbf{68.84$\pm$0.37\%} \\
\midrule[0.6pt]
\multirow{2}*{Scaffold} & FAT & 90.82$\pm$0.87\% & 87.89$\pm$0.66\% & 69.51$\pm$0.84\% & 68.12$\pm$0.88\% & 67.19$\pm$0.54\% \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{90.93$\pm$0.76\%} & \cellcolor{greyL}\textbf{88.27$\pm$0.45\%} & \cellcolor{greyL}\textbf{71.77$\pm$0.38\%} & \cellcolor{greyL}\textbf{69.49$\pm$0.67\%} & \cellcolor{greyL} \textbf{68.37$\pm$0.48\%}  \\

\bottomrule[1.5pt]
\end{tabular}}
\vspace{-4mm}
\end{table*}


According to Table~\ref{table:exp_robust_eval_non-iid_rebuttal} on \textit{CIFAR-10}, we can find that our SFAT significantly outperforms FAT on the Non-IID data in terms of both the natural accuracy ($\sim$2\%-6\%) and the robust accuracy ($\sim$2\%-5\%). As for FedProx and Scaffold which are specifically designed to handle the heterogeneous issues in federated learning, employing them in FAT can indeed improve the model performance compared with that based on FedAvg. Our SFAT further boosts the performance by alleviating the extra heterogeneity from adversarial training. On \textit{CIFAR-100} and \textit{SVHN}, we can find the similar improvement in Table~\ref{table:exp_robust_eval_non-iid_rebuttal} as that of \textit{CIFAR-10} under three types of federated optimization methods. 
\iffalse
\begin{wraptable}{r}{0.48\linewidth}
\vspace{3mm}
%\renewcommand\arraystretch{1.2}
\centering
\caption{Performance on Non-IID settings using a real-world large-scale dataset \textit{CelebA}.}
%\footnotesize
\scriptsize
\renewcommand\arraystretch{0.8}
\label{table:exp_robust_eval_non-iid_celeba}
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{c|c|c|c|c}
\toprule[1.5pt]
\midrule[0.6pt]
\multicolumn{2}{c|}{CelebA} & Natural & PGD-20 & CW$_{\infty}$\\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{2}*{FedAvg} & FAT &  57.62\%  &    22.20\%  &  21.67\%   \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{58.50\%} &
\cellcolor{greyL}\textbf{24.14\%} &
\cellcolor{greyL}\textbf{23.52\%}\\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{2}*{FedProx} & FAT &  57.70\%  &   22.29\%  &  21.50\%   \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{58.51\%} &
\cellcolor{greyL}\textbf{24.21\%} &
\cellcolor{greyL}\textbf{23.61\%}\\
%\midrule[0.6pt]
%\midrule[0.6pt]
%\multirow{2}*{Scaffold} & FAT &  -  &  -  &  -  &  -   \\
%\cline{2-12}
%~ & \textbf{$\alpha$-WFAT}  & \cellcolor{greyL}\textbf{-} &
%\cellcolor{greyL}\textbf{-} &
%\cellcolor{greyL}\textbf{-} &
%\cellcolor{greyL}\textbf{-}\\
\bottomrule[1.5pt]
\end{tabular}}
%\vspace{-2mm}
\end{wraptable}
In particular, our largest improvement in natural accuracy can reach to 4\% on \textit{CIFAR-100} dataset. Through these different experiments, our SFAT has been verified to be consistently effective.


In Table~\ref{table:exp_robust_eval_non-iid_celeba}, we confirm the efficiency of our SFAT using a real-world large-scale dataset \textit{CelebA} with 455 clients. Except Scaffold that fails to converge in FAT and thus is not reported, our SFAT again gains significantly better natural and robust accuracies than FAT under FedAvg and FedProx.
\fi

\section{Conclusion}

In this work, we investigated the issue of robustness deterioration when combining adversarial training with federated learning, and revealed that it may attribute to the intensified heterogeneity induced by local adversarial generation. To alleviate it, we introduce an $\alpha$-slack decomposed mechanism into adversarial training to relax the overall inner-maximization. Based on this, we propose a new framework, i.e., Slack Federated Adversarial Training (SFAT). We provide both the theoretical analysis and empirical evidences to understand the proposed method. The experimental results under various settings confirm the consistent effectiveness of our proposed SFAT. Nevertheless, we only move a small step on the intensified heterogeneous issue in the combination of two learning paradigms, federated adversarial training still suffers from the other challenges of systems or algorithms. Beyond the empirical conjecture in the problem focused on this work, more theoretical understanding on the dynamical heterogeneous issue under federated learning is worthwhile to explore in the future. 

%\textcolor{blue}{federated adversarial training still suffer from the system-level challenges like limited local computation capacity or communication budget, or learning-level challenges like heterogeneous data and different kinds of adversarial vulnerability considering the practical requirement in the real-world applications. More issues in this direction are worthwhile to further explored in the future.} 
%and more issues in their cross field could be further explored in the future.Like communication arounds 

%Nevertheless, we only move a small step on the heterogeneous issue in the combination of two paradigms and more issues in their cross field could be further explored.

\clearpage

\section*{Acknowledgement}

JNZ and BH were supported by NSFC Young Scientists Fund No. 62006202, Guangdong Basic and Applied Basic Research Foundation No. 2022A1515011652, RGC Early Career Scheme No. 22200720, RGC Research Matching Grant Scheme No. RMGS20221102, No. RMGS20221306 and No. RMGS20221309. BH was also supported by CAAI-Huawei MindSpore Open Fund and HKBU CSD Departmental Incentive Grant. TLL was partially supported by Australian Research Council Projects IC-190100031, LP-220100527, DP-220102121, and FT-220100318. JLX was partially supported by Hong Kong RGC Grants 12202221 and  C2004-21GF.

\section*{Ethics Statement}
This paper does not raise any ethics concerns. This study does not involve any human subjects, practices to data set releases, potentially harmful insights, methodologies and applications, potential conflicts of interest and sponsorship, discrimination/bias/fairness concerns, privacy and security issues, legal compliance, and research integrity issues.

%\section*{Reproducibility Statement}


\bibliography{main}
\bibliographystyle{iclr2023_conference}

\clearpage
\appendix
\section*{Appendix}
The Appendix is organized as follows. In Appendix~\ref{app:related_work}, we detailedly discuss the related work and highlighted our distinguishable point compared with previous work. In Appendix~\ref{sec:app_proof_all}, we formally prove the aforementioned Equations and Theorems. In Appendix~\ref{app:just_figure_reason}, we demonstrate the issue of bias exacerbation (as illustrated in Figure~\ref{fig:reason}) using a binary classification experiment. In Appendix~\ref{app:supp_alg}, we provide illustration of the learning framework for our SFAT. In Appendix~\ref{app:exp_details}, we present our experimental details and more quantitative results about understanding our proposed SFAT.

%\section*{Reproducibility Statement}
%To ensure the reproducibility of experimental results, we will provide the anonymous repository about our source codes in the discussing phase. The experimental setups for training and evaluation as well as the hyperparamters are detailedly described in Section~\ref{sec:exp} and Appendix~\ref{app:exp_details}.

%in \url{https://anonymous.4open.science/r/SFAT-678C}.


\section{Detailed Discussion and Comparison about Related work}
\label{app:related_work}

In this section, we detailedly discuss the related work in federated learning, adversarial training as well as the federated adversarial training. At the end of each part, we also highlight our distinguishable points compared with the previous work, either from conceptual or technical perspectives.

\paragraph{Federated Learning.}
The representative work in federated learning is FedAvg~\citep{mcmahan2017communication}, which has been proved effective during the distributed training to maintain the data privacy. To further address the heterogeneous issues, several optimization approaches have been proposed \textit{\textit{e.g.,}} FedProx~\citep{li2018federated}, FedNova~\citep{wang2020tackling} and Scaffold~\citep{karimireddy2020scaffold}. FedProx introduced a proximal term for FedAvg to constrain the model drift cause by heterogeneity; FedNova proposed a general framework that eliminated the objective inconsistency and preserved the fast convergence; Scaffold utilized the control variates to reduce the gradient variance in the local updates and accelerate the convergence. MOON~\citep{Li_2021_CVPR} alleviated the heterogeneity by maximizing the agreement between the representations of the local and global models, which helps the local training of individual parties. 
\citet{reisizadeh2020robust} developed a robust federated learning algorithm to against distribution shifts in client samples.
% \textcolor{blue}{\citet{mohri2019agnostic} proposed agnostic federated learning to improve the fairness and generalization to different data distribution.%(The proposed reweighing loss seems to be a special case of agnostic federated learning (Mohri, et al., 2019). Mohri, et al., 2019 show that a proper loss-maximization reweighting can improve fairness and generalize to unseen data distributions. In contrast to (Mohri, et al., 2019), I am afraid the proposed method may negatively impact the generalization of the trained model by focusing on easy clients (with lower losses). The authors may provide some discussions on the difference to agnostic federated learning.)
% } 
\citet{mohri2019agnostic} proposed Agnostic Federated Learning (AFL) to improve the fairness and generalization to different data distribution through a loss-maximization reweighting. However, it is not suitable to the problem of FAT and actually opposite to our relaxation. We show AFL performs even worse than FAT in Appendix~\ref{app:emp}. Our SFAT introduces the $\alpha$-slack mechanism to combat intensified heterogeneity in federated adversarial training, which is orthogonal to and compatible with the most previous methods. 

One concurrent work~\citep{mansour2022federated} recently provide an extended theoretical framework to analyze the general aggregation methods in federated learning, it also utilizes the reweighting mechanism and propose the FedSoftBetter. However, our proposed SFAT and FedSoftBetter have both different motivations and underlying principles. On the one hand, we introduce $\alpha$-slack mechanism to alleviate the exacerbated heterogeneity, while \citet{mansour2022federated} employs reweighting to enhance the stability and convergence of original FedAvg. On the other hand, SFAT focuses on federated adversarial training and origins from our $\alpha$-slack mechanism, while FedSoftBetter focuses on ordinary federated learning and originates as a specific strategy for federated aggregation from the theoretical analysis on convergence bound. Different from FedSoftBetter, as empirically verified in "Non-AT v.s. AT" of Section~\ref{sec:exp_comp}, our SFAT is not for ordinary federated learning but tailored for federated adversarial training.  In practice, the technical forms of two weighting mechanisms are also different. SFAT directly ranks the losses of all clients and constructs the weights, while the weights of FedSoftbetter build upon the gap between the client loss and the client optimal loss. We also provide an empirical comparison of the two methods in our Appendix~\ref{app:schedule}.


\paragraph{Adversarial Training.}
As one of the defensive methods~\citep{papernot2016distillation}, adversarial training~\citep{Madry_adversarial_training,Zhang_trades,jiang2020robust,chen2021robust,zhang2021geometryaware} is to improve the robustness of machine learning models. The classical AT~\citep{Madry_adversarial_training} is built upon on a min-max formula to optimize the worst case, \textit{e.g.,} the adversarial example near the natural example~\citep{Goodfellow14_Adversarial_examples}. \citet{Zhang_trades} decomposed the prediction error for adversarial examples as the sum of the natural error and the boundary error, and proposed TRADES to balance the classification performance between the natural and adversarial examples. \citet{wang2020improving_MART} further explored the influence of the misclassified examples on the robustness, and proposed MART that emphasizes the minimization of the misclassified examples to boost the AT. \citet{zhang2020fat,sanyal2020benign} investigated the instance-level difficulties in AT and designed different training strategies to improve the model performance. Different from their instance-level granularity, our SFAT framework leverages the client-level measure to alleviate the heterogeneous issue in the straightforward combination of adversarial training and federated learning. It is compatible to incorporate those centralized adversarial training methods (as shown in Table~\ref{table:exp_diff_methods} of Section~\ref{sec:exp_comp}) in the updates of local clients to further improve the model performance or address some special issues.

\paragraph{Federated Adversarial Training.}
Recently, several works have made the exploration on the adversarial training in the context of federated learning, which consider the data privacy and the robustness in one framework.
To our best knowledge, ~\citet{zizzo2020fat} takes the first trial to study the feasibility of extending federated learning~\citep{mcmahan2017communication} with the standard AT on both IID and Non-IID settings. Empirically, they found that there was a large performance gap existing between the distributed and the centralized adversarial training, especially on the Non-IID data. \citet{shah2021adversarial} designed a dynamic schedule for the local training to pursue a larger robustness under the constrained communication budget of federated learning. \citet{hong2021federated} explored how to effectively propagate the adversarial robustness when only limited clients in federated learning have the sufficient computational budget to afford AT. 
% \textcolor{blue}{\citet{luo2021ensemble} utilizes the extra public data to enhance the diversity of training samples on the basis of conventional federated adversarial training.}
~\citet{zhang2020defending,zizzo2021certified} studied to defend the malicious clients that poison the global model in federated learning, which also discuss the robustness but actually another research topic compared with the federated adversarial training in this work.
Different from previous works (in Table~\ref{tab:research_compare}), we explore to solve the robustness deterioration issue (as shown in Figure~\ref{fig1:a}) induced by the intensified heterogeneity (as illustrated in Figure~\ref{fig:reason}) of the direct combination of federated learning and adversarial training.

\vspace{3mm}
\begin{table}[ht]
    \centering
    \footnotesize
    \caption{
    % \textcolor{blue}{Brief comparison with some related work in federated adversarial training}
    Brief comparison with some related work in federated adversarial training
    }
    %\vspace{2mm}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{c|c|c|c}
    \toprule[1.5pt]
    Research work & adopt FAT & Other research topic & Notable differences with ours \\
    \midrule[0.6pt]
    \midrule[0.6pt]
    \cite{shah2021adversarial} & \checkmark & & focus on limited constrained communication budget\\
     \midrule[0.6pt]
    \cite{hong2021federated} & \checkmark & & assumes some client can not perform AT locally\\
    \midrule[0.6pt]
    %\cite{luo2021ensemble}  & \checkmark & & requires utilizing shared public data\\
    %\midrule[0.6pt]
    \cite{zhang2020defending} & & \checkmark & focus on poisoning defense\\
    \midrule[0.6pt]
    \cite{zizzo2021certified} & & \checkmark & focus on poisoning defense\\
    \bottomrule[1.5pt]
    \end{tabular}
    }
    \label{tab:research_compare}
    \vspace{4mm}
\end{table}

Considering the practical requirement in the real-world applications~\citep{kairouz2019advances}, federated adversarial training still faces various challenges. In general, these challenges mainly come from perspectives of the distributed systems~\citep{lit2020federated} and the unique learning paradigm~\citep{kairouz2019advances}. From the perspective of distributed systems, the major issue for federated adversarial training is its characteristic of high computational-cost~\citep{Madry_adversarial_training}. It is well known in conventional adversarial training as the local adversarial generation always require multiple times of optimization to better optimize the inner-maximization, which is to pursue the better empirical adversarial robustness~\citep{Goodfellow14_Adversarial_examples}. In federated setting, we also need to consider the heterogeneous devices~\citep{kairouz2019advances} in practical situation like the previous work~\citep{hong2021federated} focused on. The clients with low computational capacity not only affect the synchronous aggregation but also may not affordable for the local adversarial training. Such issues in hardware also results in severe problem for the distributed learning. From the perspective of the learning paradigm, the issues is more about the training data and inference threaten for federated adversarial training. Except for the intensified heterogeneity discussed in our work, the heterogeneity data itself is also a severe problem for federated adversarial training. More conventional issues about learning data like the class-imbalanced data~\citep{kovashka2016crowdsourcing}, label noised data~\citep{natarajan2013learning} or out-of-distributed data~\citep{hendrycks2016baseline} need further investigated in federated adversarial training. As for the inference threaten, one practical scenario is that different client may face different kinds of adversarial attacks~\citep{Carlini017_CW,xiao2018spatially}, whether federated adversarial training can help for gaining various type of robustness on different clients is still under explored.


\section{Proof}
\label{sec:app_proof_all}

\subsection{Proof of Eq.~(\ref{eq:alpha-weighted-loss}) and Theorem~\ref{theorem:characteristic}}
\label{sec:app_comp_proof_section41}

We proof the Eq.~(\ref{eq:alpha-weighted-loss}) and Theorem~\ref{theorem:characteristic} in this section.

Recall the $\alpha$-slack mechanism for the inner-maximization objective decomposition with $K$ independent populations as follows,
\begin{align} \label{eq:alpha-weighted-loss-app}
    \begin{split}
        \mathcal{L}_{AT} & = \frac{1}{N}\sum_{n=1}^N \max_{\xadv_n\in\epsball[\bx_n]} \ell(f(\xadv_n), y_n) = \sum_{k=1}^K \frac{N_k}{N}\underbrace{\left(\frac{1}{N_k}\sum_{n=1}^{N_k}\max_{\xadv_n\in\epsball[\bx_n]}\ell(f(\xadv_n^k), y_n^k)\right)}_{\mathcal{L}_k} \\
        % & = \frac{N_1}{N}\mathcal{L}_1 + \frac{N_2}{N}\mathcal{L}_2 + \dots + \frac{N_K}{N}\mathcal{L}_K \\
        % & = \underbrace{\sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}}_{\text{top}-\widehat{K}~\text{small population losses}} + \underbrace{\sum_{k=\widehat{K}+1}^{K} \frac{N_{\psi(k)}}{N}\mathcal{L}_{\psi(k)}}_{\text{bottom}-(K-\widehat{K})~\text{population losses}} ~\quad\quad \text{s.t.}~\widehat{K}\leq \frac{K}{2} \\
        % & \geq (1+\alpha) \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} + (1-\alpha) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\psi(k)}}{N}\mathcal{L}_{\psi(k)}~\quad\quad \text{s.t.}~\alpha\in\left[0,~1\right.) \\
        & \geq (1+\alpha) \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} + (1-\alpha) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}~\quad \text{s.t.}~\alpha\in\left[0,~1\right.),~\widehat{K}\leq \frac{K}{2}\\
        & \doteq \mathcal{L}^\alpha(\widehat{K}), 
    \end{split}
\end{align}
where $\phi(\cdot)$ is a function which maps the index to the original population group sorted by $\{\frac{N_k}{N}\mathcal{L}_k\}$ in an ascending order. Here $\phi(\cdot)$ is to bind the terms before and after the sort and does not affect the normal gradient back-propagation, since each gradient path of samples is traceable..

\begin{proof}[proof of Eq.~(\ref{eq:alpha-weighted-loss})]
The deduction of the inequality in Eq.~(\ref{eq:alpha-weighted-loss-app}) can be formulated in the following. Given $\alpha\in\left[0,1)\right.$ and $\widehat{K}\leq \frac{K}{2}$ with the population sorted by $\{\frac{N_k}{N}\mathcal{L}_k\}$ in an ascending order, we have $\sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} \leq \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}$. Then, we have the following relationship by subtraction,
\begin{align}
\label{eq:proof-alpha-weighted-loss-app}
        & \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} +\sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} - (1+\alpha)  \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} - (1-\alpha) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} \nonumber \\ 
        & = \alpha \cdot \left( \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}-\sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}\right) \geq 0 .
\end{align}
%This gives the proof of the $\alpha$-weighted relaxation for the decomposed Adversarial Training.
\end{proof}


\begin{proof}[proof of Theorem~\ref{theorem:characteristic}]
It can be naturally proved by Eq.~(\ref{eq:proof-alpha-weighted-loss-app}). If $\alpha_1>\alpha_2$, then we have,
\begin{align}
    \mathcal{L}^{\alpha_1}(\widehat{K}) - \mathcal{L}^{\alpha_2}(\widehat{K}) = (1+\alpha_1)  \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} + (1-\alpha_1) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}\nonumber\\
    -(1+\alpha_2)  \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} - (1-\alpha_2) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}\\
    = (\alpha_1-\alpha_2) \left (\sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)} - \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}}{N}\mathcal{L}_{\phi(k)}\right ) \leq 0 \nonumber 
\end{align}
Similarly, we can prove $\mathcal{L}^{\alpha}(\widehat{K}_1)<\mathcal{L}^{\alpha}(\widehat{K}_2)$ if $\widehat{K}_1>\widehat{K}_2$.
\end{proof}

\subsection{Proof of Theorem~\ref{theorem:convergence}}
\label{sec:app_comp_proof_section42}

Based on the convergence of Adversarial Training~\citep{sinha2018certifying}, we proof Theorem~\ref{theorem:convergence} in this section. Following~\citep{sinha2018certifying}, we firstly make some required Assumptions~\ref{app:assump_32_0}and~\ref{app:assump_32_1} and provide the corresponding Lemma~\ref{app:lemma_32_1} that defines the Lipschitzan condition in Theorem~\ref{theorem:convergence}.

\begin{assumption}
\label{app:assump_32_0}
The function $c: \cX\times\cX\rightarrow\mathbb{R}_{+}$ is continuous. For each $x_0\in\cX$, $c(\cdot, x_0)$ is $l$-strongly convex with respect to the norm $||\cdot||$.
\end{assumption}

\begin{assumption}
\label{app:assump_32_1}
Let $||\cdot||_{*}$ is the dual norm to $||\cdot||$, the loss $\ell:\Theta\times\cX\rightarrow\mathbb{R}$ satisfies the Lipschitzian smoothness conditions
\begin{center}
    $||\nabla_\theta \ell(\theta; x)-\nabla_\theta \ell(\theta'; x)||_{*}\leq L_{\theta\theta}||\theta - \theta'||,\quad ||\nabla_x \ell(\theta; x)-\nabla_x \ell(\theta; x')||_{*}\leq L_{xx}||x - x'||,$
\end{center}
\begin{center}
    $||\nabla_\theta \ell(\theta; x)-\nabla_\theta \ell(\theta; x')||_{*}\leq L_{\theta x}||x - x'||,\quad ||\nabla_x \ell(\theta; x)-\nabla_x \ell(\theta'; x)||_{*}\leq L_{x\theta}||\theta - \theta'||.$
\end{center}

\end{assumption}

\begin{lemma}
\label{app:lemma_32_1}
Let $f:\Theta\times\cX\rightarrow\mathbb{R}$ be differentiable and $\lambda$-strongly concave in $x$ with respect to the norm $||\cdot||$, and define $\Bar{f}(\theta)=\sup_{x\in\cX}f(\theta, x)$. Let $g_\theta(\theta,x) = \nabla_{\theta}f(\theta, x)$ and $g_x(\theta,x) = \nabla_{x}f(\theta, x)$ and assume $g_\theta$ and $g_x$ satisfy Assumption~\ref{app:assump_32_1} with $\ell(\theta, x)$ replaced with $f(\theta, x)$. Then $\Bar{f}$ is differentiable, and letting $x^*(\theta) = \arg\max_{x\in\cX}f(\theta, x)$, we have $\nabla\Bar{f}(\theta)=g_\theta(\theta, x^*(\theta)).$ Moreover,
\begin{center}
    $||x^*(\theta_1)-x^*(\theta_2)||\leq \frac{L_{x\theta}}{\lambda}||\theta_1-\theta_2||$ and $||\nabla\Bar{f}(\theta)-\nabla\Bar{f}(\theta')||_{*}\leq(L_{\theta\theta}+\frac{L_{\theta x}L_{x \theta}}{\lambda}||\theta-\theta'||).$
\end{center}

\end{lemma}

\begin{proof}[proof of Theorem~\ref{theorem:convergence}] 
Let $c:\mathcal{X}\times\mathcal{X}\rightarrow\mathbb{R}_{+} \cup \{\infty\}$, where $c(x,x_0)$ is the ``cost'' for an adversary to perturb $x_0$ to $x$.
Let $f(\theta,x;x_0)=\ell(\theta;x)-\gamma c(x,x_0)$, noting that the gradient steps is preformed as $g^t=\nabla_{\theta}f(\theta^t,\hat{x};x^t)$, where $\hat{x}$ is an approximate maximizer of $f(\theta,x;x^t)$ in $x$, and $\theta^{t+1}=\theta^t-\mu_t g^t$. We assume $\mu_t\leq\frac{1}{L_{\psi}}$ in the rest of the proof, which is satisfied for the constant step size $\mu=\sqrt{\frac{\Delta_{\mathcal{L}}}{L_{\psi}T\delta^2}}$ and $T\geq\frac{L_{\psi}\Delta_{\mathcal{L}}}{\delta^2}$. By a Taylor expansion using the $L_{\psi}$-smoothness of the objective $\mathcal{L}_k$ for $k$-th client, we have
\begin{align}
    \mathcal{L}_k\big|_{\theta^{t+1}}&\leq\mathcal{L}_k\big|_{\theta^t}+\left\langle\nabla\mathcal{L}_k\big|_{\theta^t},\theta^{t+1}-\theta^{t}\right\rangle+\frac{L_{\psi}}{2}||\theta^{t+1}-\theta^{t}||_2^2\\
    &= \mathcal{L}_k\big|_{\theta^t}-\mu_t||\nabla\mathcal{L}_k\big|_{\theta^t}||_2^2+\frac{L_{\psi}\mu^2}{2}||g^t||_2^2+\mu_t\left\langle\nabla\mathcal{L}_k\big|_{\theta^t},\nabla\mathcal{L}_k\big|_{\theta^t}-g^t\right\rangle\nonumber\\
    &= \mathcal{L}_k\big|_{\theta^t}-\mu_t\left(1-\frac{1}{2}L_{\psi}\mu^2\right)||\nabla\mathcal{L}_k\big|_{\theta^t}||_2^2\nonumber\\
    &+\mu_t(1-L_{\psi}\mu)\left\langle\nabla\mathcal{L}_k\big|_{\theta^t},\nabla\mathcal{L}_k\big|_{\theta^t}-g^t \right\rangle+\frac{L_{\psi}\mu^2}{2}||g^t-\nabla\mathcal{L}_k\big|_{\theta^t}||_2^2 \nonumber
\end{align}
Consider the function $\phi_{\gamma}(\theta;x_0)=\sup_{x\in \mathbb{Z}}f(\theta,x;x_0)$, we define the potentially biased errors $\zeta^t=g^t-\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t)$. Then we have the following relationship,
\begin{align}
    \mathcal{L}_k\big|_{\theta^{t+1}}\leq&\mathcal{L}_k\big|_{\theta^{t}}-\mu_t\left(1-\frac{1}{2}L_{\psi}\mu^2\right)||\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2\\
    &+\mu_t(1-L_{\psi}\mu)\left\langle\nabla\mathcal{L}_k\big|_{\theta^{t}},\nabla\mathcal{L}_k\big|_{\theta^{t}}-\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t) \right\rangle\nonumber\\
    &-\mu_t(1-L_{\psi}\mu_t)\left\langle \nabla\mathcal{L}_k\big|_{\theta^{t}},\zeta^t \right\rangle +\frac{L_{\psi}\mu^2}{2}||\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t)+\zeta^2-\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2 \nonumber\\
    &=\mathcal{L}_k\big|_{\theta^{t}} -\mu_t\left(1-\frac{1}{2}L_{\psi}\mu^2\right)||\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2 \nonumber\\
    &+\mu_t(1-L_{\psi}\mu)\left\langle\nabla\mathcal{L}_k\big|_{\theta^{t}},\nabla\mathcal{L}_k\big|_{\theta^{t}}-\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t) \right\rangle\nonumber\\
    &-\mu_t(1-L_{\psi}\mu_t)\left\langle \nabla\mathcal{L}_k\big|_{\theta^{t}},\zeta^t \right\rangle \nonumber\\
    &+\frac{L_{\psi}\mu_t^2}{2}\left( ||\zeta^t||_2^2+||\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t)-\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2+2\left\langle \nabla_{\theta}\phi_{\gamma}(\theta^t;x^t)-\nabla\mathcal{L}_k\big|_{\theta^{t}},\zeta^t \right\rangle \right). \nonumber    
\end{align}
Since $\pm\langle a,b\rangle\leq\frac{1}{2}\left(||a||_2^2+||b||_2^2\right)$, we have
\begin{align}
\label{eq:mid_bound}
    \mathcal{L}_k\big|_{\theta^{t+1}}\leq&\mathcal{L}_k\big|_{\theta^{t}}-\frac{\mu_t}{2}||\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2+\mu_t((1-L_{\psi}\alpha))\left\langle\nabla\mathcal{L}_k\big|_{\theta^{t}},\nabla\mathcal{L}_k\big|_{\theta^{t}}-\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t) \right\rangle\\
    & +\frac{\mu_t((1+L_{\psi}\mu))}{2}||\zeta||_2^2+L_{\psi}\mu_t^2||\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t)-\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2. \nonumber
\end{align}
Then, letting $x_{*}^t=\arg\max_{x}f(\theta^t,x;x^t)$, the error $\zeta^t$ satisfies,
\begin{align}
    ||\zeta||_2^2=&||\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t)-\nabla f(\theta,\hat{x}^t;x^t)||_2^2=||\nabla_{\theta}\ell(\theta,x_{*}^t)-\nabla_{\theta}\ell(\theta,\hat{x}^t)||_2^2\\
    &\leq L_{\theta_{x}}||\hat{x}^t-x_{*}^t||_2^2\leq \frac{2L_{\theta_{x}}^2}{\lambda}\epsilon,
\end{align}
where the final inequality utilize the $\lambda=\gamma-L_{xx}$ strong-concavity of $x\mapsto f(\theta,x;x_0)$. For convenience, let $\hat{\epsilon}=\frac{2L_{\theta_{x}}^2}{\gamma-L_{xx}}\epsilon$. Taking conditional expectations in Eq.~(\ref{eq:mid_bound}) and using $\mathbb{E}\left[\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t)|\theta^t\right]=\nabla\mathcal{L}_k\big|_{\theta^{t}}$, we have,
\begin{align}
    \mathbb{E}\left[\mathcal{L}_k\big|_{\theta^{t+1}}-\mathcal{L}_k\big|_{\theta^{t}}|\theta^t\right]&\leq -\frac{\mu_t}{2}||\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2+\frac{\mu_t((1+L_{\psi}\mu))}{2}\hat{\epsilon}+L_{\psi}\mu_t^2||\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t)-\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2\\
    &\leq -\frac{\mu_t}{2}||\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2+\mu_t\hat{\epsilon}+L_{\psi}\mu_t^2||\nabla_{\theta}\phi_{\gamma}(\theta^t;x^t)-\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2 \nonumber
\end{align}
Since $\mu_t\leq \frac{1}{L_{\psi}}$, taking a fixed step size $\mu$, we have,
\begin{align}
    \mathbb{E}\left[||\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2\right]-2\hat{\epsilon}\leq \frac{2}{\mu}\mathbb{E}\left[\mathcal{L}_k\big|_{\theta^{t}}-\mathcal{L}_k\big|_{\theta^{t+1}}\right]+2L_{\psi}\mu\delta^2
\end{align}
Because $\mathbb{E}\left[||\nabla_{\theta}\phi_{\gamma}(\theta;Z)-\nabla\mathcal{L}_k\big|_{\theta}||_2^2\right]\leq \delta^2$, summing over $t$, we have,
\begin{align}
    \frac{1}{T}\sum_{t=1}^{T}\mathbb{E}\left[||\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2\right]-2\hat{\epsilon}&\leq\frac{2}{\mu T}(\mathcal{L}_k\big|_{\theta^{0}}-\mathbb{E}[\mathcal{L}_k\big|_{\theta^{T}}])+2L_{\psi}\mu\delta^2\nonumber\\
    &\leq \frac{2\Delta}{\mu T} + 2L_{\psi}\mu\delta^2
\end{align}
Since $\mu=\sqrt{\frac{Delta}{L_{\psi}T\delta^2}}$, and $\lambda=\gamma-L_{xx}$, we can get the following result,
\begin{align}
    \frac{1}{T}\sum_{t=1}^{T}\mathbb{E}\left[||\nabla\mathcal{L}_k\big|_{\theta^{t}}||_2^2\right]\leq \frac{4L_{\theta x}^2\epsilon}{\lambda}+4\delta\sqrt{\frac{L\Delta}{T}}
\end{align}
Adopting our $\alpha$-slack mechanism, we have,
\begin{align}
\begin{split}
& \frac{1}{T}\sum_{t=1}^T\mathbb{E}\left[\bigg|\bigg|\nabla \mathcal{L}^\alpha(\widehat{K})\big|_{\theta^t}\bigg|\bigg|^2_2\right] \\
& = \frac{1}{T}\sum_{t=1}^T\mathbb{E}\left[\bigg|\bigg|(1+\alpha) \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}^{(t)}}{N}\nabla\mathcal{L}_{\phi(k)}\big|_{\theta^t} + (1-\alpha) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}^{(t)}}{N}\nabla\mathcal{L}_{\phi(k)}\big|_{\theta^t}\bigg|\bigg|^2_2\right] \\  
& \leq \frac{1}{T}\sum_{t=1}^T\left((1+\alpha) \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}^{(t)}}{N}\mathbb{E}\left[\bigg|\bigg|\nabla\mathcal{L}_{\phi(k)}\big|_{\theta^t}\bigg|\bigg|^2_2\right] + (1-\alpha) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}^{(t)}}{N}\mathbb{E}\left[\bigg|\bigg|\nabla\mathcal{L}_{\phi(k)}\big|_{\theta^t}\bigg|\bigg|^2_2\right]\right) \\
& \leq \frac{1}{T}\sum_{t=1}^T\left((1+\alpha) \sum_{k=1}^{\widehat{K}} \frac{N_{\phi(k)}^{(t)}}{N} + (1-\alpha) \sum_{k=\widehat{K}+1}^{K} \frac{N_{\phi(k)}^{(t)}}{N}\right)\left(\frac{4L^2_{\theta x}\epsilon}{\lambda}+4\delta\sqrt{\frac{L\Delta}{T}}\right)\\
& =  \frac{1}{T}\sum_{t=1}^T\left(1+\alpha  \frac{\sum_{k=1}^{\widehat{K}} N_{\phi(k)}^{(t)} - \sum_{k=\widehat{K}+1}^{K}N_{\phi(k)}^{(t)}}{N}\right)\left(\frac{4L^2_{\theta x}\epsilon}{\lambda}+4\delta\sqrt{\frac{L\Delta}{T}}\right)\\
& =  \left(1+\alpha\frac{\frac{1}{T}\sum_{t=1}^T\xi^{(t)}}{N}\right) \left(\frac{4L^2_{\theta x}\epsilon}{\lambda}+4\delta\sqrt{\frac{L\Delta}{T}}\right),   
\end{split}
\end{align}
where $\xi^{(t)}=\sum_{k=1}^{\widehat{K}} N_{\phi(k)}^{(t)} - \sum_{k=\widehat{K}+1}^{K}N_{\phi(k)}^{(t)}$ to simplify the notations.
\end{proof}



\subsection{Proof of Theorem~\ref{the:awfat-convergence}}
\label{sec:app_comp_proof_section43}

Based on the convergence of FedAvg~\citep{li2019convergence}, we proof Theorem~\ref{the:awfat-convergence} in this section.

First, we make the following assumptions and present some useful lemmas. Specifically, we make the following assumptions. Assumption~\ref{app:assump_1} and~\ref{app:assump_2} are standard (typical examples are the $\ell_2$-norm regularized linear regression, logistic regression, or softmax classifier). Assumption~\ref{app:assump_3} and~\ref{app:assump_4} have been made by the previous works~\citep{zhang2013communication,li2019convergence}.

\begin{assumption}
\label{app:assump_1}
$\mathcal{L}_1$, $\dots$, $\mathcal{L}_{K}$ are all L-smooth: for all $v$ and $w$, $\mathcal{L}_k(v)\leq \mathcal{L}_k(w)+(v-w)^T\nabla \mathcal{L}_k(w)+\frac{L}{2}||v-w||_2^2$.
\end{assumption}

\begin{assumption}
\label{app:assump_2}
$\mathcal{L}_1$, $\dots$, $\mathcal{L}_{K}$ are all $\lambda$-strongly convex: for all $v$ and $w$, $\mathcal{L}_k(v)\geq \mathcal{L}_k(w)+(v-w)^T\nabla \mathcal{L}_k(w)+\frac{\lambda}{2}||v-w||_2^2$.
\end{assumption}

\begin{assumption}
\label{app:assump_3}
Let $\xi_t^k$ be sampled from the $k$-th device's local data uniformly at random. The variance of stochastic gradients in each device is bounded: $\mathbb{E}||\nabla \mathcal{L}_k(w_t^k,\xi_t^k)-\nabla \mathcal{L}_k(w_t^k)||^2\leq\delta_k^2$ for $k=1, \cdots, K$.
\end{assumption}

\begin{assumption}
\label{app:assump_4}
The expected squared norm of stochastic gradients is uniformly bounded, i.e., $\mathbb{E}||\nabla \mathcal{L}_k(w_t^k,\xi_t^k)||^2\leq \varsigma^2$ for all $k=1, \cdots, K$ and $t=1, \cdots, T-1$.
\end{assumption}
We use the following lemmas proved by~\citet{li2019convergence}. Let $\theta_t^k$ denotes the model parameter maintained in the $k$-th client at $t$-th step, $\Theta$ represents an immediate result of one step SGD update from $\theta_t^k$. For convenience, we define $\Bar{\Theta}_t=\sum_{k=1}^K\frac{N_k}{N}\Theta_t$, $\Bar{\theta}_t==\sum_{k=1}^K\frac{N_k}{N}\theta_t$, $\Bar{g}_t=\sum_{k=1}^K\frac{N_k}{N}\nabla \mathcal{L}_k(\theta_t^k)$ and $g_t = \sum_{k=1}^K\frac{N_k}{N}\nabla \mathcal{L}_k(\theta_t^k,\xi_t^k)$. Therefore, $\mathbb{E}g_t=\Bar{g}_t$.
\begin{lemma}[Results of one step SGD]
\label{app:lemma_1}
Assume Assumption~\ref{app:assump_1} and~\ref{app:assump_2}. If $\eta_t\leq\frac{1}{4L}$, we have
\begin{align}
    \mathbb{E}||\Bar{\Theta}_{t+1}-\theta^*||^2&\leq(1-\eta_t\lambda)\mathbb{E}||\Bar{\theta}_t-\theta^*||^2\\
    &+\eta_t^2\mathbb{E}||g_t-\Bar{g}_t||^2+6L\eta_t^2\Gamma+2\mathbb{E}\sum_{k=1}^K\frac{N_k}{N} ||\Bar{\theta}_t-\theta_t^k||^2,\nonumber
\end{align}
where $\Gamma=\mathcal{L}^{*}-\sum_k^K \mathbb{E}_t\frac{N_k}{N}\mathcal{L}_k^*\geq0$
\end{lemma}

\begin{lemma}[Bounding the variance]
\label{app:lemma_2}
Assume Assumption~\ref{app:assump_3}. It follows that
\begin{align}
    \mathbb{E}||g_t-\Bar{g}_t||^2 \leq \sum_{k=1}^K \left(\frac{N_k}{N}\right)^2 \delta_k^2,
\end{align}
\end{lemma}

\begin{lemma}[Bounding the divergence of {$\theta_t^k$}]
\label{app:lemma_3}
Assume Assumption~\ref{app:assump_4}, that $\eta_t$ is non-increasing and $\eta\leq2\eta_{t+E}$ for all $t>0$. It follows that
\begin{align}
    \mathbb{E}\left[\sum_{k=1}^K\frac{N_k}{N} ||\Bar{\theta}_t-\theta_t^k||^2\right]\leq 4\eta_t^2(E-1)^2\varsigma^2
\end{align}
\end{lemma}

\begin{proof}[proof of Theorem~\ref{the:awfat-convergence}]
Let $\Delta_t=\mathbb{E}||\theta_t-\theta^*||^2$. From Lemma~\ref{app:lemma_1}, Lemma~\ref{app:lemma_2} and Lemma~\ref{app:lemma_3}, it follows that
\begin{align}
    \Delta_{t+1}\leq (1-\eta_t\lambda)\Delta_t+\eta_t^2B,
\end{align}
where,
\begin{align}
    B=\sum_{k=1}^K \left(\frac{P_k^{(T)} }{1+\alpha\frac{\xi^{(T)}}{N} }\right)^2\left(\frac{N_k}{N}\delta_k\right)^2 + 6L\left(\mathcal{L}^{*}-\sum_{k=1}^K \frac{P_k^{(T)} }{1+\alpha\frac{\xi^{(T)}}{N}}\frac{N_k}{N}\mathcal{L}_k^*\right) + 8(E-1)^2\varsigma^2,
\end{align}
and $\left(\frac{P_k^{(T)} }{1+\alpha\frac{\xi^{(T)}}{N} }\right)^2$ and $\frac{P_k^{(T)} }{1+\alpha\frac{\xi^{(T)}}{N}}$, are acted as the scalar timing by the personalized variance bound $\delta_k^2$ and the local optimum $\mathcal{L}^*_k$ of each client.

For a diminishing stepsize, $\eta_t=\frac{\beta}{\gamma+t}$ for some $\beta>\frac{1}{\lambda}$ and $\gamma>0$ such that $\eta_1\leq\min\{\frac{1}{\lambda},\frac{1}{4L}\}=\frac{1}{4L}$ and $\eta_t\leq 2\eta_{t+E}$. We will prove that $\Delta_t\leq\frac{\nu}{\gamma+t}$, where $\nu=\max\{\frac{\beta^2B}{\beta\lambda-1},(\gamma+1)\Delta_1\}$.
The above can be proved by induction. Firstly, the definition of $\nu$ ensures that it holds for $t=1$. Assume the conclusion holds for some $t$, it follows that,
\begin{align}
\begin{split}
    \Delta_{t+1} &\leq (1-\eta_t\lambda)\Delta_t +\eta_t^2B\\
    &\leq (1-\frac{\beta\lambda}{t+\gamma})\frac{\nu}{t+\gamma}+\frac{\beta^2B}{(t+\gamma)^2}\\
    & = \frac{t+\gamma-1}{(t+\gamma)^2}\nu + [\frac{\beta^2B}{(t+\gamma)^2}-\frac{\beta\lambda-1}{(t+\gamma)^2} \nu]\\
    &\leq \frac{\nu}{t+\gamma+1}.
\end{split}
\end{align}
Then by the L-smoothness of $\mathcal{L}$($\cdot$),
\begin{align}
    \mathbb{E}[\mathcal{L}_{t}]-\mathcal{L}^*\leq \frac{L}{2}\Delta_t\leq\frac{L}{2}\frac{\nu}{\gamma+t}
\end{align}
Specifically, if we choose $\beta=\frac{2}{\lambda},\gamma=\max\{8\frac{L}{\lambda},E\}-1$ and denote $\kappa=\frac{L}{\lambda}$, then $\eta_t=\frac{2}{\lambda}\frac{1}{\gamma+t}$. One can verify that the choice of $\eta_t$ satisfies $\eta_t\leq2\eta_{t+E}$ for $t\geq1$. Then we have
\begin{align}
    \nu = \max\left\{\frac{\beta^2B}{\beta\lambda-1},(\gamma+1)\Delta_1\right\}\leq\frac{\beta^2B}{\beta\lambda-1}+(\gamma+1)\Delta_1\leq \frac{4B}{\lambda^2}+(\gamma+1)\Delta_1,
\end{align}
and
\begin{align}
    \mathbb{E}[\mathcal{L}_{t}]-\mathcal{L}^*&\leq\frac{L}{2}\frac{\nu}{\gamma+t}\leq\frac{\kappa}{\gamma+t}\left(\frac{2B}{\lambda}+\frac{\lambda(\gamma+1)}{2}\Delta_1\right)
    %&
    %\leq\frac{\kappa}{\gamma+T-1}\left(\frac{2B}{\lambda}+\frac{\lambda\gamma}{2}\mathbb{E}\left[||\theta^{0}-\theta^{*}||^2\right]\right)\nonumber
\end{align}
\end{proof}
%\clearpage

\section{Further discussion about Figure~\ref{fig:reason}}
\label{app:just_figure_reason}

\begin{figure}[htp]
\centering
\vspace{2mm}
    %\hspace{-0.15in}
    \subfigure[Client drift with different adv. generation]{
        \includegraphics[scale=0.20]{fed_justification_epsilon_svhn.pdf}
        \label{fig:just_statistic}
    }
    \hspace{0.1in}
    \subfigure[w/o adv. generation]{
        \includegraphics[scale=0.22]{ori_just_reason_b.pdf}
        \label{fig:just_app_a}
    }
    \subfigure[w/ adv. generation]{
        \includegraphics[scale=0.22]{adv_just_reason_b.pdf}
        \label{fig:just_app_b}
    }
    %\vspace{2mm}
    \caption{ (a): the client drift~\citep{li2018federated} with different adv. generation varied from weak (i.e., $\epsilon=1/255$) to strong (i.e., $\epsilon=4/255$) on SVHN. $||\theta_{k}-\theta_{s}||_2$ indicates the parameter difference between local model and averaged global model. It verified that stronger adv. generation leads to intensified heterogeneity. (b)-(c): The decision boundary of a binary classification task on one local client. The black squares and circles indicate samples of two classes in the client, the light gray ones indicate that of the other client. The red squares and circles indicate the generated adversarial data. It serves as a potential explanation for the bias exacerbation caused by local adversarial generation. Note that, (b)-(c) are obtained by training the neural networks.}
    \label{fig:just_reason_app}
    \vspace{2mm}
\end{figure}



In this section, we provide a verification about intensified heterogeneity using the real dataset, i.e., SVHN~\citep{netzer2011reading_SVHN} (in Figure~\ref{fig:just_statistic}), and provide a two-dimensional result (in Figures~\ref{fig:just_app_a} and~\ref{fig:just_app_b}) to explain the exacerbated optimization bias induced by the local adversarial generation.

First, we conduct the experiments under Non-IID setting to verify the relationship of intensified heterogeneity with adversarial generation in the SVHN dataset, which is for the multi-classification task. To be specific, we compare the FAT on 5 clients using different adversarial strength to show the effect of adversarial generation on local clients. Other setups keep the same with that of Table~\ref{table:exp_robust_eval_non-iid_rebuttal}.

In Figure~\ref{fig:just_statistic}, we conduct FAT using the adversarial generation of different $\epsilon$-ball (from weak $1/255$ to strong $4/255$) and check the client drift, which has been formally defined in~\cite{karimireddy2020scaffold} to show the optimization bias in federated learning. The client drift is widely adopted in federated learning literature~\citep{smith2017federated,li2018federated,li2021fedbn,karimireddy2020scaffold}] to reflect the degree of heterogeneity~\citep{zhao2018federated,li2019convergence}. The statics of client drift with different adversarial generation can indicate the relationship between inner-maximization with the intensified heterogeneity. Through the results, we can find that as adversarial strength increases, the heterogeneity is also exacerbated along with training. The similar trend can be also found in the experiments with other dataset in Figure~\ref{fig:client_drift_app} of Appendix~\ref{client_drift}, where we also present the corresponding robust accuracy. This verifies the issue discussed in our motivation part (in Section~\ref{sec:motivation}) using the real classification task, and it is also consistent with our binary illustration. 

Second, we conduct the experiments on a synthetic dataset to present the potential explanation about the heterogeneity exacerbation. To be specific, we conduct basic federated learning and FAT using two clients on the synthetic dataset and check the decision boundary in a two-dimensional plane. It shows how the adversarial generation on local clients can exacerbate the heterogeneity.

As for the experiments on the synthetic dataset, we create its training data randomly using Numpy and train using a neural network with one hidden layer and one Relu activation layer for each clients.

In Figures~\ref{fig:just_app_a} and~\ref{fig:just_app_b}, we plot the decision boundary of the training results on a synthetic dataset for FAT using two clients. The Figure~\ref{fig:just_app_a} shows standard training (using the natural data) on the client's local data while the Figure~\ref{fig:just_app_b} shows adversarial training (generating the adversarial data) on the client's local data. Note that, without the training data of other clients, the adversarial generation on the current biased model is highly biased to the local distribution, which even exacerbated the optimization bias and would result in a large client drift or variance, e.g., $\delta^2$ in our theorems. More empirical evidence on CIFAR-10 dataset can also refer to Appendixes~\ref{client_drift} and~\ref{app:gradient_variance} which show the statics corresponding the accuracy during the training process.


\vspace{2mm}
\begin{table}[ht]
%\renewcommand\arraystretch{0.65}
\centering 
\caption{Robust deterioration w.r.t adversarial training strength in FAT.}
\footnotesize
\label{table:robust_deter_adv}
%\resizebox{\linewidth}{!}{
\begin{tabular}{c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{2}{c|}{Setting} & \multicolumn{3}{c}{Performance gap between best and last epoch} \\

\midrule[0.6pt]
\multicolumn{2}{c|}{Dataset/Adv. Strength} & 2/255 & 4/255 & 8/255  \\
\midrule[0.6pt]
\midrule[0.6pt]
%AT  & 57 & 66.47\% & 47.68\% & 38.18\% & 37.04\% & - \\
CIFAR-10 & FAT & 6.33 & 11.16 & \textbf{13.06}  \\
\midrule[0.6pt]
\multicolumn{2}{c|}{Dataset/Adv. Strength} & 1/255 & 2/255 & 4/255  \\
\midrule[0.6pt]
SVHN & FAT & 4.65 & 5.63 & \textbf{6.43} \\
%TRADES  &  - & - & - & - & - & - \\
\bottomrule[1.5pt]
\end{tabular}
%}
\end{table}
\vspace{3mm}


% For the left illustration of Figure 2, it maybe one possible explanation to the exacerbated process of adversarial generation. However, the heterogeneity exacerbation which indicated by the increasing client drift is free of specified data distribution (as shown in our toy example of Figure 2) and observed in the experiments with the robustness deterioration (refer to Figure 11). According to the verification on Figure 6(a), the heterogeneity exacerbation is indeed induced by adversarial generation. 
%We will replace the left panel of Figure 2 with Figure 6(a) that is more empirically verified, and revise the corresponding explanation with the proper description. Following the suggestion, we conducted the extra experiments to investigate the classification difference between the baseline and the SFAT. However, it is hard to draw and understand the characteristics from the raw data level regarding those non-overlapped examples. 
% Since it is a distributed learning paradigm, the information from those examples conveys complex reflection to analyze. Comparing our SFAT with the original FAT, we have trace the client drift during training with the robust performance dynamics in Figure 10 and Figure 11. It shows our SFAT alleviates the heterogeneity exacerbation and achieves higher robust accuracy. 
To better support our conjecture, we compare and robust deterioration in FAT with different adversarial training strength (using the same robust evaluation strength) and summarized the results in Table~\ref{table:robust_deter_adv}. The results show that more stronger adversarial generation (i.e., the larger inner-maximization) lead to severe robustness deterioration (indicated by the large accuracy gap between the best and last stage). It confirms the rationality of our derived lower bound by $\alpha$-slack mechanism to pursue the adversarial robustness and alleviate the heterogeneity exacerbation. In our Appendix~\ref{client_drift}, we also provide more empirical verification that quantitatively measure the intensified heterogeneity, which show that our SFAT indeed alleviate the intensified heterogeneity and achieve the better robust accuracy.


%\clearpage
\section{Detailed Algorithm and Learning Framework}
\label{app:supp_alg}


\begin{figure}[htp]
\centering
\vspace{4mm}
    %\hspace{-0.15in}
    \includegraphics[scale=0.34]{method_figure_revise.pdf}
    \caption{A brief illustration of our Slack Federated Adversarial Training (SFAT) framework. On the client-side, each client will conduct adversarial training on its local data and update the optimized model parameter (\textit{i.e.,} $\theta_{k}$) with the adversarial training loss (\textit{i.e.,} $\frac{N_k}{N}\mathcal{L}_k)$). On the server-side, after collecting the model parameters and the loss value (information about the training status), the server will conduct an ascending sort and aggregate the global model with a weighted average (denoted by $\odot$) which upweights the top populations of the small-loss client's model parameters with $\alpha$. }
    \label{fig:realization_illustration_app}
    \vspace{6mm}
\end{figure}

In this section, we provide the detailed algorithm (i.e., Algorithm~\ref{alg:alpha-WFAT}) for our Slack Federated Adversarial Training (SFAT) and an intuitive illustration of our proposed SFAT in Figure~\ref{fig:realization_illustration_app}. 

\vspace{2mm}
\begin{algorithm}[ht]
%\footnotesize
  \caption{Slack Federated Adversarial Training}
  \label{alg:alpha-WFAT}
  {\bf Input:} client number: $K$, communication rounds: $T$, local training epochs per round: $E$, initial server's model parameter: $\theta^0$, hyper-parameter for aggregation: $\alpha$, number of enhanced clients: $\widehat{K}$; \\
  {\bf Output:} globally robust model $\theta^{T}$;
\begin{algorithmic}[1]
  \FOR{t $= 1$, $\dots$, $T$}
    \STATE \colorbox{shadecolor}{\textbf{Clients:} [  perform adversarial training]}
    \FOR{client $k =1$, $\dots$, $K$ }
    %\State Client download $\theta_{k}$ from the server;
    \STATE $\theta_{k}^{t}, \mathcal{L}_{k}= $ AT$(\theta_{k}^{t}, E)$~\citep{Madry_adversarial_training}
  \ENDFOR
  \STATE \colorbox{shadecolor}{\textbf{Server:} [ performs slacked aggregation]}
%  \State $\theta^{t+1}=F(\theta_{selected})$
    \STATE $\mathcal{L}_{all}\gets[\frac{N_1}{N}\mathcal{L}_1,\frac{N_2}{N}\mathcal{L}_2,\dots,\frac{N_K}{N}\mathcal{L}_K]$,  \quad $\mathcal{L}_{\text{sorted}} \gets $ Ascending$\_$Sort($\mathcal{L}_{all}$);
  \STATE $\forall k,~P_k=(\frac{1+\alpha}{1-\alpha} \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k \leq \mathcal{L}_{\text{sorted}}[\widehat{K}]) + 1 \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k > \mathcal{L}_{\text{sorted}}[\widehat{K}]))/((\sum_{k=1}^K P_k)+\frac{2\alpha}{1-\alpha})$;
  \STATE $\theta^{t+1}=\frac{1}{\sum^{K}_{k=1} N_k}\sum^{K}_{k=1}{P_{k} N_k\theta^t_{k}}$; %\Comment{\colorbox{shadecolor}{$\alpha$-weighted mechanism}}
 \ENDFOR
\end{algorithmic}
\end{algorithm}
\vspace{3mm}

For simplifying the practical use and adaptation, we can mainly assign higher weights for the client having smaller adversarial training losses to realize the relative weighting illustrated in Figure~\ref{fig:realization_illustration_app}. To be specific, we can set the normalized $P_k=((1+\alpha)/(1-\alpha) \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k \leq \mathcal{L}_{\text{sorted}}[\widehat{K}]) + 1 \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k > \mathcal{L}_{\text{sorted}}[\widehat{K}]))/((\sum_{k=1}^K P_k)+2\alpha/(1-\alpha))$ in the aggregation to ensure the expected lower bound.

% where $P_k$ denotes the weight assigned to the $k$-th client based on the ascending sort of weighted client losses compared with the $\widehat{K}$-th one, which can be $(1+\alpha) \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k \leq \mathcal{L}_{\text{sorted}}[\widehat{K}]) + (1-\alpha) \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k > \mathcal{L}_{\text{sorted}}[\widehat{K}])$ that corresponds to the relaxed loss in Eq.~(\ref{eq:alpha-weighted-loss}). 
% \textcolor{orange}{For simplicity and flexibility, we can transform the slack mechanism by mainly adjusting the weights of those selected clients with smaller adversarial training losses, and assign $P_k=((1+\alpha)/(1-\alpha) \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k \leq \mathcal{L}_{\text{sorted}}[\widehat{K}]) + 1 \cdot \mathds{1}(\frac{N_k}{N}\mathcal{L}_k > \mathcal{L}_{\text{sorted}}[\widehat{K}]))/((\sum_{k=1}^K P_k)-1)$ to ensure the lower bound derivation.} 

Based on the $\alpha$-slack mechanism, we provide a new framework for the combination of adversarial training with federated learning. It is orthogonal to a variety of different adversarial training~\citep{Zhang_trades,DeepMind_useto,wang2020once,jiang2020robust,chen2021robust,carmon2019unlabeled,Madry_adversarial_training, chen2020adversarial, ding2020mma, li2021neural,chen2021robust,chen2022sparsity} methods and federated optimization algorithms~\citep{mcmahan2017communication,li2018federated,li2021fedbn,kairouz2019advances} which pursue the adversarial robustness or alleviate the data heterogeneity as well as other specific issues on the client side, and for the specific practical challenge for federated settings~\citep{shah2021adversarial,hong2021federated}. Those all can be flexibly adopted into our framework or extend to fit other training constraints~\citep{kairouz2019advances} of federated learning.


%\clearpage
\section{Experimental Details and More Comprehensive Results}
\label{app:exp_details}

In this section, we first provide the details about our experimental setups for dataset, training and evaluation. Then we provide more comprehensive results for better understanding the characteristics of our SFAT and the performance verification in different settings. In Appendix~\ref{app:tracing}, we tracing and discuss the dynamics of our SFAT on choosing the upweighted clients. In Appendix~\ref{app:local_ep}, we present the results of training with different local epochs. In Appendix~\ref{app:emp}, we present and discuss the comparison of Re-SFAT v.s. SFAT. In Appendixes~\ref{client_drift} and~\ref{app:gradient_variance}, we report the client drift and variance with the corresponding robust accuracy during training. In Appendix~\ref{app:orthogonal_effect.}, we discuss the orthogonal effects of SFAT on intensified heterogeneity. In Appendix~\ref{app:more_clients}, we verify SFAT using more clients. In Appendix~\ref{app:unequal_data_split}, we verify SFAT using unequal data splits under Non-IID setting. In Appendix~\ref{app:real_celeba}, we verify SFAT in a more practical real-world situation. In Appendix~\ref{app:overall_results}, we report the performance results on both Non-IID and IID setting across the three benchmarked datasets.

\paragraph{Dataset.}
We conduct the experiments on three benchmark datasets, \textit{i.e.,} \textit{SVHN}~\citep{netzer2011reading_SVHN}, \textit{CIFAR-10} and \textit{CIFAR-100}~\citep{krizhevsky2009learning_cifar10} as well as a real-world dataset \textit{CelebA}~\citep{caldas2018leaf} for federated adversarial training. For the IID scenario, we randomly distribute these datasets to each client. For simulating the Non-IID scenario, we follow~\citet{mcmahan2017communication,shah2021adversarial} to distribute the training data based on their labels. To be specific, a skew parameter $s$ is utilized in the data partition introduced by~\citet{shah2021adversarial}, which enables $K$ clients to get a majority of the data samples from a subset of classes. We denote the set of all classes in a dataset as $\cY$ and create $\cY_{k}$ by dividing all the class labels equally among $K$ clients. Accordingly, we split the data across $K$ clients that each client has $(100-(K-1)\times s)\%$ of data for the class in $\cY_k$ and $s\%$ of data in other split sets. In most experiments, we set $s=2$ for simulating the Non-IID partition with $5$ clients as~\citet{shah2021adversarial} recommended.  
\vspace{3mm}
\begin{table}[ht]
    \centering
    \caption{Brief summary of the basic experimental details about SFAT}
    %\vspace{1mm}
    \begin{tabular}{l|l|c|c|c}
    \toprule[1.5pt]
    Dataset & Network & Local epochs & $K$ & $\widehat{K}$ \\
    \midrule[0.6pt]
    \midrule[0.6pt]
     \textit{CIFAR-10} & NIN~\citep{shah2021adversarial} & 10 & 5 & 1 \\
     \midrule[0.6pt]
     \textit{CIFAR-100} & ResNet-18~\citep{chen2021robust} & 3 & 20 & 4 \\
    \midrule[0.6pt]
     \textit{SVHN} & SmallCNN~\citep{Zhang_trades} & 2 & 5 & 1 \\
    \midrule[0.6pt]
    \bottomrule[1.5pt]
    \end{tabular}
    \label{tab:exp_set}
\end{table}
\paragraph{Training and evaluation.} In the experiments, we follow the previous works~\citep{Zhang_trades,shah2021adversarial} to leverage the same architectures, \textit{i.e.,} \textit{NIN}~\citep{lin2014network} for \textit{CIFAR-10}, \textit{ResNet-18}~\citep{he2016deep} for \textit{CIFAR-100} and \textit{Small CNN}~\citep{Zhang_trades} for \textit{SVHN}. 

For the local training batch size, we set $32$ for \textit{CIFAR-10}, $128$ for \textit{CIFAR-100} and \textit{SVHN}. For the training schedule, SGD is adopted with 0.9 momentum for 100 communication rounds under $5$ clients as in~\citep{hong2021federated,shah2021adversarial}, and the weight decay = $0.0001$. For adversarial training, we set the configurations of PGD respectively~\citep{Madry_adversarial_training} for different datasets. On \textit{CIFAR-10/CIFAR-100}, we set the perturbation bound $\epsilon = 8/255$, the PGD step size $2/255$ and 
set the PGD step number $10$. On \textit{SVHN}, we set the perturbation bound $\epsilon = 4/255$, the PGD step size $1/255$. The PGD generation for all the datasets keep the same step number $10$.


Regarding the evaluation, the accuracy for the natural test data and that for the adversarial test data are computed following~\citet{Madry_adversarial_training,Zhang_trades}. Note that, the adversarial test data are generated by FGSM, PGD-20, C\&W
~\citep{Carlini017_CW} attack with the same perturbation bound and step size as the training. All the adversarial generations have a random start, i.e, the uniformly random perturbation of $[-\epsilon,\epsilon]$ added to the natural data before attacking iterations. Besides, we also report the robustness under a stronger AutoAttack, termed as AA for simplicity. All the experiments are conducted for multiple times using NVIDIA Tesla V100-SXM2.


As for our SFAT, different training tasks adopt different $\alpha$-slack mechanism considering different characteristic of local training data, specifically, we set $\alpha=1/6$ (\textit{i.e.,} $\frac{1+\alpha}{1-\alpha}=1.4$) for the experiments on \textit{CIFAR-10}, and $\alpha=1/11$ (\textit{i.e.,} $\frac{1+\alpha}{1-\alpha}=1.2$) for the experiments on \textit{CIFAR-100} and $\alpha=1/11$ (\textit{i.e.,} $\frac{1+\alpha}{1-\alpha}=1.2$) for the experiments on \textit{SVHN}. As for FedProx, we set its original hyper-parameter $\mu=0.01$ for each dataset and the $\alpha$ for our $\alpha$-slack mechanism are $1/11$, $1/11$, and $1/11$. As for Scaffold, the $\alpha$ adopted for previous datasets are $1/11$, $3/23$ and $1/11$ correspondingly.

As for the choice of the hyper-parameter $\alpha$, one useful way to set it might be progressively probing its effect in a value-growth manner. When the $\alpha$ is very small, the objective will approximately degenerate the original objective of FAT, so does the performance with no harm. Slightly enlarging $\alpha$ can improve the performance due to the benefit on alleviating the intensified heterogeneity during aggregation, and then make a stop in one point where the performance becomes drop.


%\subsection{Tracing the Dynamic of $\alpha$-WFAT}

%\begin{figure*}[htp]
%    \centering
%    \hspace{-0.2in}
%    \includegraphics[scale=0.22]{fed_dyn_weight.pdf}
%    \vspace{-1mm}
%    \caption{The index of the top-$\widehat{K}$ clients with the small losses in $\alpha$-WFAT ($\alpha=1/6$, $\widehat{K}=1$) in each  communication round on CIFAR-10. We can see that it is dynamically routing among all clients.}
%    \label{fig:dyn_tracing_appendix}
%    \vspace{-3mm}
%\end{figure*}

\subsection{The Dynamic of SFAT}
\label{app:tracing}

In this part, we present the dynamics of our SFAT about the critical $\alpha$-slack mechanism. To be specific, we visualize the selected clients in each communication rounds for our slack aggregation.

\vspace{4mm}
\begin{figure}[htp]
    \centering
    %\vspace{-2mm}
    %\hspace{-0.2in}
    %\includegraphics[scale=0.18]{fed_dyn_weight.pdf}
    \includegraphics[scale=0.18]{fed_dyn_weight_confirm.pdf}
    %\includegraphics[scale=0.195]{fed_dyn_weight_copy.pdf}
    \caption{The index of the top-$\widehat{K}$ clients with the small losses in SFAT ($\alpha=1/6$, $\widehat{K}=1$) in each  communication round on \textit{CIFAR-10} (Non-IID) as well as the total account. We can see that it is dynamically routing among all clients instead of fixed, and each client has similar assignments.}
    \label{fig:dyn_tracing_app}
\end{figure}
\vspace{2mm}



In one experiment on \textit{CIFAR-10} (Non-IID), we trace the index of top client (i.e., the selected client that is upweighted in our mechanism) and find the top weight dynamically routes among different clients instead of the single or a subset of 5 clients. The empirical results confirmed there is no dominant client exists during the training. To further check whether our SFAT will result in unfair attention to different clients, we investigate the difference of client's training accuracy, the accuracy gap ($32.40\%$) of the best client with the worst client is comparable with that ($32.23\%$) in SFAT. Intuitively, since the large adversarial training loss can automatically balance the client-wise aggregation weight, there is no unfair attention to exacerbate the performance difference among clients in our experiments, which are verified by the above gap and the similar assignments for the weighting index.  

\paragraph{Robust performance on each client.}
In Figure~\ref{fig:dyn_tracing_app}, we can find there is no dominant client exists, which means that all clients are ever chose to be up-weighted/down-weighted during the training. Thus, our SFAT explores to help all clients to be better. Besides, the global model is redistributed to each client in each communication round of federated learning, which can also avoid the bias accumulation for each single client.
% There are no significant empirical evidence that shows our SFAT would down-weighted some specific clients to induce some unfairness issue. Since the global model will be redistributed to clients for further training, intuitively it will not induce worse performance on those downweighted local clients.
To verify each client performance in our experiments, we report the robust training accuracy of each client in our experiments and summarize in Table~\ref{table:each_client_robust_app}. The results show the training performance of each client is not worse than the original FAT.

\vspace{2mm}
\begin{table}[ht]
%\renewcommand\arraystretch{0.65}
\centering 
\caption{Robust training accuracy on each client w.r.t. different methods.}
\scriptsize
\label{table:each_client_robust_app}
%\resizebox{\linewidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{2}{c|}{Setting} & \multicolumn{5}{c}{Client} \\

\midrule[0.6pt]
\multicolumn{2}{c|}{Method/Client} & 1 & 2 & 3 & 4 & 5 \\
\midrule[0.6pt]
\midrule[0.6pt]
%AT  & 57 & 66.47\% & 47.68\% & 38.18\% & 37.04\% & - \\
\multirow{2}*{CIFAR-10} & FAT & 59.35 & 65.97 & 75.96 & 77.12 & 80.37 \\
~ & \textbf{SFAT} & 60.05 & 66.57 & 77.17 & 78.79 & 83.23 \\
\midrule[0.6pt]
\multirow{2}*{SVHN} & FAT & 89.50 & 82.12 & 89.60 & 81.96 & 87.88 \\
~ & \textbf{SFAT} & 91.69 & 85.58 & 91.93 & 85.31 & 90.35 \\
%TRADES  &  - & - & - & - & - & - \\
\bottomrule[1.5pt]
\end{tabular}
%}
\end{table}
\vspace{3mm}

To further check the generalization performance on each client, we also conduct an extra experiment where we split a small part of local data in each client to serve as the local test data and evaluate their training and test performance using FAT and the proposed SFAT on SVHN dataset. According to the summarized results in Table~\ref{table:each_client_robust_gap_app}, the generalization performance (indicated by the gap of robust training and test accuracy) of our SFAT are also generally better than FAT in SVHN dataset.

\vspace{2mm}
\begin{table}[ht]
%\renewcommand\arraystretch{0.65}
\centering 
\caption{Robust performance gap on each client w.r.t. different methods.}
\scriptsize
\label{table:each_client_robust_gap_app}
%\resizebox{\linewidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{3}{c|}{Setting} & \multicolumn{5}{c}{Client} \\

\midrule[0.6pt]
\multicolumn{3}{c|}{Method/Client} & 1 & 2 & 3 & 4 & 5 \\
\midrule[0.6pt]
\midrule[0.6pt]
%AT  & 57 & 66.47\% & 47.68\% & 38.18\% & 37.04\% & - \\
\multirow{6}*{SVHN} & \multirow{3}*{FAT} & Train & 87.51 & 88.19 & 85.91 & 78.99 & 79.17 \\
~ & ~ & Test & 72.96 & 70.64 & 64.30 & 61.97 & 66.57 \\
~ & ~& Gap & 14.55 & 17.55 & 21.61 & 17.02 & 12.65 \\
\cmidrule{2-8}
~ & \multirow{3}*{SFAT} & Train & 87.59 & 88.41 & 85.97 & 79.27 & 79.04 \\
~ & ~ & Test & 73.65 & 71.46 & 65.80 & 63.48 & 66.62 \\
~ & ~&Gap  & 13.94 & 16.95 & 20.17 & 15.79 & 12.42 \\
%TRADES  &  - & - & - & - & - & - \\
\bottomrule[1.5pt]
\end{tabular}
%}
\end{table}
\vspace{3mm}


\subsection{Experiments with Different Local Training Epochs}
\label{app:local_ep}

\begin{figure}[ht]
    \vspace{2mm}
    \centering
    %\hspace{-1mm}
    \subfigure[Local training epoch: 10]{
    \includegraphics[scale=0.20]{afat_fat_100.pdf}
    \label{fig:local_10}
    }
    \hspace{0.2in}
    \subfigure[Local training epoch: 5]{
    \includegraphics[scale=0.20]{afat_fat_200.pdf}
    \label{fig:local_5}
    }
    \hspace{0.1in}
    \subfigure[Local training epoch: 1]{
    \includegraphics[scale=0.20]{afat_fat_1000_long.pdf}
    \label{fig:local_1}
    }
    \vspace{-2mm}
    \caption{Comparison between FAT and SFAT with different local training epochs. All the experiments are conducted on \textit{CIFAR-10} dataset (Non-IID) with $5$ clients, and use PGD-20~\citep{Madry_adversarial_training} to evaluate the robust accuracy.}
    \label{fig:local_epoch_app}
\end{figure}

In this part, we first report the robust test curve on \textit{CIFAR-10} dataset to compare the FAT and SFAT using different local training epoch in each client. Then we focus on a extreme setup, i.e., 1 local epoch for each client in both \textit{CIFAR-10} and \textit{SVHN} datasets and report the performance comparison, although using 1 local epoch is not practical considering the heavy communication cost it introduced in real-world application~\citep{mcmahan2017communication}.

In Figure~\ref{fig:local_epoch_app}, we conduct the experiments on \textit{CIFAR-10} with different local training epochs. We find FAT exhibits robust deterioration across different settings that impedes further progress towards adversarial robustness of the federated system, and simply changing the local training epoch can not achieve the significantly higher robust accuracy as the dashed black line denoted. In comparison, our SFAT can consistently achieve a higher robust accuracy than FAT by alleviating the deterioration.

Even on the extreme setup, i.e., using 1 local epoch for each client, we can find the intensified heterogeneity also exist since the adversarial generation will be conducted in each optimization step, and can be further mitigate by our SFAT. Reducing the local epoch indeed can alleviate the robustness deterioration since it can reducing the original client drift~\citep{mcmahan2017communication,li2018federated}. As the original client drift is alleviated, the adversarial generation will inherit and exacerbate less heterogeneity. However, it does not achieve the nature of this issue and this experimental setup adjustment has similar essence with those federated optimization methods~\citep{li2018federated,karimireddy2020scaffold}. The results help us to better understand the effects of the proposed SFAT on combating the intensified heterogeneity via relaxing the inner-maximization to a lower bound. 

\vspace{4mm}
\begin{table}[ht]
%\renewcommand\arraystretch{1.2}
\centering
\caption{Comparison using FedAvg on CIFAR-10 and SVHN datasets using different local epochs.}
%\footnotesize
\label{table:exp_appendix_additional_results_local_epochs}
%\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c}
\toprule[1.5pt]
Dataset & Local epochs & Methods & Natural & FGSM & PGD-20 & CW$_{\infty}$ \\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{4}*{CIFAR-10} & \multirow{2}*{10 (in Table~\ref{table:exp_robust_eval_non-iid_rebuttal})} & FAT & 57.45\% & 39.44\% & 32.58\% & 30.52\% \\
~ &~& \textbf{SFAT}  & \cellcolor{greyL}\textbf{63.44\%} & \cellcolor{greyL}\textbf{45.13\%} & \cellcolor{greyL}\textbf{37.17\%} & \cellcolor{greyL}\textbf{33.99\%}\\
\cmidrule{2-7}
~ & \multirow{2}*{1} & FAT & 57.61\% & 40.27\% & 33.18\% & 32.16\% \\
~ &~& \textbf{SFAT}  & \cellcolor{greyL}\textbf{64.85\%} & \cellcolor{greyL}\textbf{45.55\%} & \cellcolor{greyL}\textbf{37.04\%} & \cellcolor{greyL}\textbf{34.84\%}\\
\midrule[0.6pt]
\multirow{4}*{SVHN} &\multirow{2}*{2 (in Table~\ref{table:exp_robust_eval_non-iid_rebuttal})} &  FAT & 91.24\% & 87.95\% & 68.87\% & 67.39\% \\
~ &~& \textbf{SFAT}  & \cellcolor{greyL}\textbf{91.25\%} & \cellcolor{greyL}\textbf{88.28\%} & \cellcolor{greyL}\textbf{71.72\%} & \cellcolor{greyL}\textbf{69.79\%}\\
\cmidrule{2-7}
~ &\multirow{2}*{1} &  FAT & 91.21\% & 87.99\% & 69.35\% & 68.28\% \\
~ &~& \textbf{SFAT}  & \cellcolor{greyL}\textbf{91.98\%} & \cellcolor{greyL}\textbf{88.99\%} & \cellcolor{greyL}\textbf{72.34\%} & \cellcolor{greyL}\textbf{71.05\%}\\
\bottomrule[1.5pt]
\end{tabular}%}
\vskip1ex%
\vskip -0ex%
\end{table}
\vspace{3mm}

In Table~\ref{table:exp_appendix_additional_results_local_epochs}, we report and compare the results under the 1-epoch local training compared with our previous results under multiple epochs used in Table~\ref{table:exp_robust_eval_non-iid_rebuttal}. The results verify the consistent effectiveness of SFAT. Reducing the local epochs to 1 indeed can improve the performance ($~$0.5\%) of the baseline FAT, but might not be very practical due to the resulting large cost of the communication in federated learning~\citep{mcmahan2017communication}. Even on the 1-epoch setting, as shown in Figure~\ref{fig:local_epoch_app}, the FAT still suffer from the robust deterioration. The results in Table~\ref{table:exp_appendix_additional_results_local_epochs} demonstrate that the intensified heterogeneity could be better alleviated by our SFAT. It is similar to our discussion (in Appendix~\ref{app:orthogonal_effect.}) about the orthogonal effects with federated optimization methods~\citep{li2018federated}.



\subsection{SFAT vs. Re-SFAT}
\label{app:emp}

\begin{table}[ht]
%\renewcommand\arraystretch{1.2}
\centering
\vspace{2mm}
\caption{Comparison with emphasize/de-emphasize the client with smallest loss.}
%\footnotesize
\label{table:exp_small_large_appendix}
%\resizebox{\textwidth}{!}{
\begin{tabular}{c|r|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{3}{c|}{Setting} & \multicolumn{4}{c}{Non-IID} \\
\midrule[0.6pt]
\multicolumn{3}{c|}{CIFAR-10} & Natural & FGSM & PGD-20 & CW$_{\infty}$\\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{5}*{FedAvg} & \textbf{SFAT: $\frac{1+\alpha}{1-\alpha}=1.4$} & emphasize & \textbf{63.44\%} & \textbf{45.13\%} & \textbf{36.17\%} & \textbf{33.99\%} \\
~ & \textbf{SFAT: $\frac{1+\alpha}{1-\alpha}=1.2$} & emphasize  & 62.26\% & 44.08\% & 35.83\% & 33.31\% \\
~ & FAT: $\frac{1+\alpha}{1-\alpha}=1.0$ & original & 57.45\% & 39.44\% & 32.58\% & 30.52\%  \\
~ & \textbf{Re-SFAT: $\frac{1+\alpha}{1-\alpha}=0.8$} & de-emphasize  & 50.45\% & 34.34\% & 27.86\% & 26.62\% \\
~ & \textbf{Re-SFAT: $\frac{1+\alpha}{1-\alpha}=0.6$} & de-emphasize & 40.47\% & 28.81\% & 24.36\% & 23.19\% \\
\midrule[0.6pt]
\multicolumn{3}{c|}{SVHN} & Natural & FGSM & PGD-20 & CW$_{\infty}$\\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{5}*{FedAvg} & \textbf{SFAT: $\frac{1+\alpha}{1-\alpha}=1.4$} & emphasize & 90.60\% & 87.75\% & \textbf{73.12\%} & \textbf{70.51\%} \\
~ & \textbf{SFAT: $\frac{1+\alpha}{1-\alpha}=1.2$} & emphasize  & \textbf{91.25\%}&\textbf{88.28\%}&71.72\%&69.79\% \\
~ & FAT: $\frac{1+\alpha}{1-\alpha}=1.0$ & original & 91.24\% &87.95\%&68.87\%&67.89\% \\
~ & \textbf{Re-SFAT: $\frac{1+\alpha}{1-\alpha}=0.8$} & de-emphasize  & 90.03\% & 86.12\% & 64.35\% & 64.32\% \\
~ & \textbf{Re-SFAT: $\frac{1+\alpha}{1-\alpha}=0.6$} & de-emphasize & 89.46\%&84.80\%&58.64\%&58.96\% \\
\bottomrule[1.5pt]
\end{tabular}%}
\vskip1ex%
\vskip -0ex%
\end{table}
\vspace{2mm}


\begin{figure}[ht]
    \centering
    %\hspace{-1mm}
    \subfigure[Robust accuracy]{
        \includegraphics[scale=0.15]{fed_justification_80_reverse_acc.pdf}
        \label{fig:robust_acc_alpha_reverse}
    }
    \subfigure[Client drift]{
    \includegraphics[scale=0.15]{fed_justification_80_reverse.pdf}
    \label{fig:client_drift_reverse_results}
    }
    \subfigure[Zoom-in Client drift]{
    \includegraphics[scale=0.15]{fed_justification_80_reverse_zoomin.pdf}
    \label{fig:client_drift_reverse_zoomin}
    }    
    %\vspace{-2mm}
    \caption{The robust accuracy w.r.t. the client drift~\citep{li2018federated} of Re-SFAT, FAT, and SFAT during training. It shows that Re-SFAT further enhances the intensified heterogeneity as well as the robustness deterioration via emphasizing the client with larger adversarial loss, which is reversed to the operation of our SFAT. This verifies the rationality of SFAT that slack the original objective.}
    \label{fig:client_drift_reverse}
\end{figure}

In this part, we start with the experiments about comparing the performance of oppositely using the $\alpha$-slack mechanism, i.e., Re-SFAT, with our original SFAT. Then we discuss its underlying reason as well as the relationship of loss and the intensified heterogeneity. 

In Table~\ref{table:exp_small_large_appendix}, we conduct an empirical comparison between FAT, SFAT (which \textit{emphasizes} the client model with the smallest adversarial training loss) and Re-SFAT (which is a contrary variant of SFAT that \textit{de-emphasizes} the client model with the smallest adversarial training loss). Here the Re-SFAT share the same spirit with the AFL~\citep{mohri2019agnostic}, which seeks to improve the fairness and generalization through a loss-maximization reweighting. The experimental setups keep the same as Table~\ref{table:exp_robust_eval_non-iid_rebuttal} using $5$ clients. Both SFAT and Re-SFAT keep the $\widehat{K}=1$ in all the trails.

Through the results across two benchmarked datasets (i.e., \textit{CIFAR-10} and \textit{SVHN}), We find that de-emphasizing the client with smallest adversarial loss (relatively emphasize those with larger adversarial loss) consistently harm the model performance across these evaluations, which shows the spirit of loss-maximization in Re-SFAT and AFL is contrary to the correct way. In contrast, emphasizing the client with smallest adversarial loss indeed improve the model performance in terms of both natural and robust accuracies. It confirms the rationality of SFAT to alleviating intensified heterogeneity by relaxing the inner-maximization of adversarial generation during aggregation. 

Note that the generalization focus by AFL is under the standard federated learning instead of federated adversarial training, and the empirical results also confirm the loss-maximization actually trigger the intensified heterogeneity and lead to lower accuracies (in Table~\ref{table:exp_small_large_appendix}). Since it is out of the scope of this work on handling the intensified heterogeneity, we leave it to our future work.

With respect to the experiments with standard training (in the left of Figure~\ref{fig:comp_part1}), there is no inner-maximization in Eq.(\ref{eq:aWFAT}). Thus, there is no intensified heterogeneity to handle but only positive training signals from the standard training. In this case, adding the inequality with slack in Eq.(\ref{eq:aWFAT}) only induces the extra objective bias to the standard federated learning. Correspondingly, as shown in the left-most panel of Figure~\ref{fig:comp_part1}, such an operation instead degenerates the model performance.

\textbf{Discussion about the loss and the intensified heterogeneity. } It is the learning dynamic of Eq.~\ref{eq:aWFAT} that upweights the client model with the smaller losses and downweights the client model with the larger losses to slack the overall objective. Possibly, the optimization bias (or termed as client drift more rigorously) may result in a smaller loss and sometimes the smaller loss may not absolutely indicate the smaller optimization bias. We have verified that when the opposite does not hold and the larger loss is preferred in the selection in the middle panel of Figure~\ref{fig:comp_part1} (see Re-SFAT v.s. SFAT) and the above Table~\ref{table:exp_small_large_appendix} (see Re-SFAT v.s. SFAT). The Re-SFAT is actually construct an upper bound of the FAT objective, which is different from SFAT that relax to the lower bound of the FAT objective. The results empirically verify the failure of this case that prefers the larger loss. Here we discuss the connection between the slack mechanism and the intensified heterogeneity (or roughly call intensified optimization bias). To alleviate the intensified heterogeneity, our slack mechanism naturally relaxes the overall objective and constructs a mediating function that asymptotically approaches the original goal and reducing the negative impact of the intensified heterogeneity on the training. Our reasonable analysis and comprehensive evidence from both theoretical (e.g., Theorems~\ref{theorem:convergence} and~\ref{the:awfat-convergence}) and empirical (e.g., Figures~\ref{fig:justification}, ~\ref{fig:client_drift_app}, and~\ref{fig:variance_app}) views have demonstrated its rationality. In Tables~\ref{table:exp_robust_eval_non-iid_rebuttal} and~\ref{table:exp_robust_eval_non-iid_rebuttal_celeba}, the multiple experimental results with random non-iid data distribution as well as the real-world datasets demonstrates the empirical superiority of our proposed SFAT over the original FAT.

\subsection{SFAT Corresponding to Client Drift}
\label{client_drift}

\vspace{3mm}
\begin{figure}[ht]
    \centering
    %\hspace{-1mm}
    \subfigure[Client drift]{
    \includegraphics[scale=0.22]{fed_justification_100_all.pdf}
    \label{fig:client_drift}
    }
    \hspace{0.2in}
    \subfigure[Robust accuracy]{
    \includegraphics[scale=0.22]{fed_justification_100_all_acc.pdf}
    \label{fig:robust_acc_alpha}
    }
    %\vspace{-2mm}
    \caption{The client drift corresponding to the robust accuracy of FAT and our SFAT during training.}
    \label{fig:client_drift_app}
\end{figure}
\vspace{4mm}


In this part, we present more results about the client drift during training using FAT and our SFAT than Figure~\ref{fig:justification}. The corresponding curve during training can be more clearly to show how SFAT alleviate the intensified heterogeneity and achieve the higher robust accuracy.

We conduct more experiments about the client drift of FAT and our SFAT on \textit{CIFAR-10} (Non-IID) in Figure~\ref{fig:client_drift_app}. As the $\alpha$ increasing, our SFAT can further alleviate the intensified heterogeneity (having smaller client drift value as shown in Figure~\ref{fig:client_drift}) of FAT at the later stage which corresponds to the robustness deterioration (exhibiting less obvious deterioration while achieving higher robust accuracy as shown in Figure~\ref{fig:robust_acc_alpha}). Unlike FAT that hindered by the intensified heterogeneity, our SFAT can improve the robust accuracy by combating the issue of intensified heterogeneity.

\subsection{Additional discussion on the \texorpdfstring{$\alpha$}{a}-slack mechanism}
\label{app:schedule}


Here, we first empirically verify the difference between FedSoftBetter and our SFAT, we conduct the experiments on CIFAR-10 and SVHN to compare their performance in the following table. The results show that its empirical performance is slightly better than FedAvg but not better than SFAT.

% Conceptually, it is novel since our $\alpha$-slack mechanism is naturally based on that the local adversarial generation induces the intensified heterogeneity, which is not considered or discovered in previous literature including [1]. It has a different motivation from [1]. To be specific, the $\alpha$-slack mechanism introduced in our SFAT is to relax the original objective of federated adversarial training to a lower bound for combating the exacerbated heterogeneity, while the latter is to develop an extended mathematical analysis of aggregation strategies that specifically focus on the tradeoff among accuracy and convergence speed in federated learning.

% 2) Technically, the reweighted aggregation follows a unique underlying principle that tailored for the exacerbated heterogeneity induced by local adversarial generation, not for ordinary federated learning.
% , it is the learning dynamics of Eq.(3) that upweights the client model with the smaller losses and downweights the client model with larger losses to slack the overall objective to a lower bound. 
% The proposed mechanism has been empirically verified to be effective to alleviate the heterogeneity exacerbation (please kindly refer to Figure 4, 10, 11, and 12). 
% In contrast, [1] propose FedSoftBetter as the variant of FedBetter to better enhance the efficiency and stability of federated learning following its extended mathematical analysis. The significant difference on the underlying principle of each method results in different coefficient considered in the reweighted aggregation.

% Our conjecture is that since the coefficients of different clients in FedSoftBetter gradually become same along with the training due to its dynamic setups, it may not be able to combat with the exacerbated heterogeneity that exist through the whole process.

\vspace{2mm}
\begin{table}[ht]
%\renewcommand\arraystretch{1.2}
\centering
\caption{Comparison of different methods on CIFAR-10 and SVHN datasets.}
\footnotesize
\label{table:exp_appendix_additional_results_1000}
%\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c}
\toprule[1.5pt]
Dataset & Methods & Natural & FGSM & PGD-20 & CW$_{\infty}$ \\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{3}*{CIFAR-10} & FAT & 57.45\% & 39.44\% & 32.58\% & 30.52\% \\
~ & FedSoftBetter & 58.86\% & 40.23\% & 32.78\% & 30.76\% \\
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{63.44\%} & \cellcolor{greyL}\textbf{45.13\%} & \cellcolor{greyL}\textbf{37.17\%} & \cellcolor{greyL}\textbf{33.99\%}\\
\midrule[0.6pt]
\multirow{3}*{SVHN}&  FAT & 91.24\% & 87.95\% & 68.87\% & 67.39\% \\
~ & FedSoftBetter & \textbf{91.64\%} & \textbf{88.53\%} & 69.07\% & 67.83\% \\
~ &\textbf{SFAT}  & \cellcolor{greyL} 91.25\% & \cellcolor{greyL}88.28\% & \cellcolor{greyL}\textbf{71.72\%} & \cellcolor{greyL}\textbf{69.79\%}\\
\bottomrule[1.5pt]
\end{tabular}%}
\vskip1ex%
\vskip -0ex%
\end{table}
\vspace{2mm}



In the following, we present the experiments that progressively anneal the coefficient to vanilla federated adversarial training during the training and compare with SFAT on CIFAR-10 and SVHN. According to the results in Table~\ref{table:exp_schedule_alpha}, gradually annealing-$\alpha$ SFAT achieves slightly lower robust accuracy than the constant-$\alpha$ SFAT and sometimes may introduces the large drop of natural accuracy (e.g., on CIFAR-10). It indicates that keeping a consistent $\alpha$ for the $\alpha$-slack maybe a better choice. On the other hand, it also confirms the intuition that using a gradually decreased alpha is empirically contrary to the observation of robustness deterioration (or the heterogeneity exacerbation as shown in Figure~\ref{fig:client_drift_app}) at the later stage of training.

% a dynamic $\alpha$ for SFAT. To be specific, we compare the trails with constant $\alpha$ with gradually decreased $\alpha$ in CIFAR-10 and SVHN datasets. We report the robust accuracy of those trails in the following table. The results show that gradually decreasing the $\alpha$ during FL achieves slightly lower robust accuracy than our original SFAT. It indicates that keeping a consistent $\alpha$ for the $\alpha$-slack maybe better to alleviate the exacerbated heterogeneity and combat the robustness deterioration. On the other hand, it also confirm the intuition that using a gradually decreased alpha is empirically contrary to the observation of robustness deterioration (or the heterogeneity exacerbation) at the later stage of training.

\vspace{2mm}
\begin{table}[ht]
%\renewcommand\arraystretch{1.2}
\centering
\caption{Comparison on CIFAR-10 and SVHN datasets using different $\alpha$ schedule.}
\footnotesize
\label{table:exp_schedule_alpha}
%\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c}
\toprule[1.5pt]
Dataset & $\alpha$-slack & Methods & Natural & FGSM & PGD-20 & CW$_{\infty}$ \\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{4}*{CIFAR-10} & - & FAT & 57.45\% & 39.44\% & 32.58\% & 30.52\% \\
~ & $\frac{1+\alpha}{1-\alpha}:1.4$ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{63.44\%} & \cellcolor{greyL}\textbf{45.13\%} & \cellcolor{greyL}\textbf{37.17\%} & \cellcolor{greyL}\textbf{33.99\%}\\
~ & $\frac{1+\alpha}{1-\alpha}:1.4\rightarrow1.0$ & \textbf{SFAT}  & \cellcolor{greyL}60.63\% & \cellcolor{greyL}43.53\% & \cellcolor{greyL}36.23\% & \cellcolor{greyL}33.22\%\\
\midrule[0.6pt]
\multirow{4}*{SVHN} & - &  FAT & 91.24\% & 87.95\% & 68.87\% & 67.39\% \\
~ & $\frac{1+\alpha}{1-\alpha}:1.2$ & \textbf{SFAT}  & \cellcolor{greyL}91.25\% & \cellcolor{greyL}88.28\% & \cellcolor{greyL}\textbf{71.72\%} & \cellcolor{greyL}\textbf{69.79\%}\\
~ & $\frac{1+\alpha}{1-\alpha}:1.2\rightarrow1.0$ & \textbf{SFAT}  & \cellcolor{greyL} \textbf{91.68\%} & \cellcolor{greyL}\textbf{88.55\%} & \cellcolor{greyL} 71.44\% & \cellcolor{greyL} 69.76\%\\
\bottomrule[1.5pt]
\end{tabular}%}
\vskip1ex%
\vskip -0ex%
\end{table}
\vspace{3mm}

\subsection{SFAT Corresponding to Gradient Variance}
\label{app:gradient_variance}

\vspace{3mm}
\begin{figure}[ht]
    \centering
    %\hspace{-1mm}
    \subfigure[Gradient Variance]{
    \includegraphics[scale=0.22]{fed_justification_100_all_variance.pdf}
    \label{fig:client_variance}
    }
    \hspace{0.2in}
    \subfigure[Robust accuracy]{
    \includegraphics[scale=0.22]{fed_justification_100_all_acc_variance.pdf}
    \label{fig:robust_acc_variance}
    }
    %\vspace{-2mm}
    \caption{The gradient variance corresponding to the robust accuracy of FAT and our SFAT.}
    \label{fig:variance_app}
\end{figure}
\vspace{2mm}

To further factorize how the inner maximization affects the intensified heterogeneity of the local data, we add the experiments about the variance of the client's gradients (calculated by parameters difference). We find the similar trend with the empirical results about client drift in Figure~\ref{fig:variance_app}, i.e., SFAT prevents exacerbated gradients variance in FAT, and results in better performance on robustness. 

\subsection{Empirical verification about our theoretical analysis.}
\label{app:theo_empirical}
\vspace{3mm}
\begin{figure}[ht]
    \centering
    %\hspace{-1mm}
    %\includegraphics[scale=0.18]{fed_svhn_acc_value_avg_each_client_gap.pdf}
    \includegraphics[scale=0.20]{fed_cifar10_loss_value_avg.pdf}
    \hspace{0.17in}
    %\includegraphics[scale=0.15]{fed_svhn_loss_value_avg_each_client.pdf}
    %\hspace{0.15in}
    \includegraphics[scale=0.20]{fed_svhn_loss_value_avg_each_client_gap.pdf}
    %\vspace{-2mm}
    \caption{Empirical verification of our theoretical analyze. Left panel: Empirical estimation about $\mathbb{E}|\cdot|$ in Theorem~\ref{theorem:convergence} of the original and our slacked objective using CIFAR10 dataset. Right panel: Empirical estimation about  $\mathbb{E}|\mathcal{L}_{\text{SFAT}}|-\mathcal{L}^{*}$ in Theorem~\ref{the:awfat-convergence} of FAT and our SFAT using SVHN dataset. The overall results confirm the benefit on convergence from our proposed $\alpha$-slack mechanism.}
    \label{fig:theo_empirical_app}
\end{figure}
\vspace{3mm}

Here, we provide the empirical verification about the theoretical claim in Theorem~\ref{theorem:convergence} and Theorem~\ref{the:awfat-convergence} via tracing the training loss on CIFAR-10 and SVHN datasets. In Figure~\ref{fig:theo_empirical_app}, we present the empirical estimation of the RHS of Eq.~(\ref{eq:convergence}) and Eq.~(\ref{eq:awfat-convergence}) via tracing the training loss. The results show that our our $\alpha$-slack mechanism can achieve a faster convergence compared with the original objective for the convergence of adversarial training in Theorem~\ref{theorem:convergence} and the federated case in Theorem~\ref{the:awfat-convergence}.

%as the training loss quickly achieves to stable than FAT during the same training epochs.}


% [1] Madry, Aleksander, et al. "Towards Deep Learning Models Resistant to Adversarial Attacks." International Conference on Learning Representations. 2018.

% [2] Raghunathan, Aditi, Jacob Steinhardt, and Percy Liang. "Certified Defenses against Adversarial Examples." International Conference on Learning Representations. 2018.

% [3] Cohen, Jeremy, Elan Rosenfeld, and Zico Kolter. "Certified adversarial robustness via randomized smoothing." International Conference on Machine Learning. PMLR, 2019.


\subsection{Experiments about the Orthogonal Effects of SFAT on Client Dirft.}
\label{app:orthogonal_effect.}

In this part, we start with the discussion about the orthogonal effects of SFAT from the conceptual perspective, and then present the orthogonal effects of SFAT on combating the intensified heterogeneity via tracing the client drift from the experimental perspective. 

From the problem view, our slack mechanism is targeted for the intensified heterogeneity. However, similar to other techniques in federated learning literature, FedProx~\citep{li2018federated} is designed for the original heterogeneous data instead of considering the intensified process. The two problems are discussed in our Appendix~\ref{app:related_work}. Although intensified heterogeneity and the ordinary heterogeneity (i.e., without the inner-maximization) both induce the client drift, the effects and extent are different. To be specific, the intensified heterogeneity will result in more diverged models and exacerbate the difference among client models compared with the ordinary heterogeneity. This intensification process is not considered in FedProx or other related work~\citep{mcmahan2017communication, karimireddy2020scaffold}, and SFAT is orthogonal to them further incorporates a slack mechanism to avoid its influence.

\vspace{3mm}
\begin{table}[ht]
%\renewcommand\arraystretch{0.65}
\centering 
\caption{Client drift w.r.t Epochs on CIFAR-10 in Figure~\ref{fig:justification}. }
\footnotesize
\label{table:exp_client_drift_figure4}
\resizebox{\linewidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{2}{c|}{Setting} & \multicolumn{10}{c}{Client drift $\downarrow$} \\

\midrule[0.6pt]
\multicolumn{2}{c|}{Method / Epoch} & 10 & 20 & 30 & 40 & 50 & 60 & 70 & 80 & 90 & 100 \\
\midrule[0.6pt]
\midrule[0.6pt]
%AT  & 57 & 66.47\% & 47.68\% & 38.18\% & 37.04\% & - \\
\multirow{2}*{FedAvg} & FAT & \textbf{11.56} & 13.10 & 15.04 & 17.30 & 19.22 & 20.66 & 21.72 & 22.47 & 23.02 & 23.49 \\
~ & \textbf{SFAT} & \cellcolor{greyL}12.21 & \cellcolor{greyL}\textbf{13.08} & \cellcolor{greyL}\textbf{14.37} & \cellcolor{greyL}\textbf{15.95} & \cellcolor{greyL}\textbf{17.68} & \cellcolor{greyL}\textbf{19.04} & \cellcolor{greyL}\textbf{20.16} & \cellcolor{greyL}\textbf{20.92} & \cellcolor{greyL}\textbf{21.50} & \cellcolor{greyL}\textbf{21.86}  \\
\midrule[0.6pt]
%TRADES  &  - & - & - & - & - & - \\
\multirow{2}*{FedProx} & FAT & \textbf{4.71} & \textbf{4.58} & 5.98 & 6.54 & 7.83 & 8.26 & 9.12 & 10.23 & 11.71 & 12.61 \\
~ &\textbf{SFAT} & \cellcolor{greyL}5.89 & \cellcolor{greyL}5.27 & \cellcolor{greyL}\textbf{5.67} & \cellcolor{greyL}\textbf{6.02} & \cellcolor{greyL}\textbf{6.87} & \cellcolor{greyL}\textbf{7.34} & \cellcolor{greyL}\textbf{7.98} & \cellcolor{greyL}\textbf{8.77} & \cellcolor{greyL}\textbf{9.65} & \cellcolor{greyL}\textbf{10.81}  \\
\bottomrule[1.5pt]
\end{tabular}}
%}
\vspace{3mm}
\end{table}
\vspace{3mm}

\begin{table}[ht]
%\renewcommand\arraystretch{0.65}
\centering 
\caption{Client drift w.r.t Epochs on CIFAR-10 in the setting of unequal splits with 5 clients.}
\footnotesize
\label{table:exp_client_drift_other_experiments}
\resizebox{\linewidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{2}{c|}{Setting} & \multicolumn{10}{c}{Client drift $\downarrow$} \\

\midrule[0.6pt]
\multicolumn{2}{c|}{Method / Epoch} & 10 & 20 & 30 & 40 & 50 & 60 & 70 & 80 & 90 & 100 \\
\midrule[0.6pt]
\midrule[0.6pt]
%AT  & 57 & 66.47\% & 47.68\% & 38.18\% & 37.04\% & - \\
\multirow{2}*{FedAvg} & FAT & \textbf{13.96} & 16.91 & 19.89 & 22.52 & 24.40 & 25.75 & 26.76 & 27.64 & 28.13 & 28.53 \\
~ & \textbf{SFAT} & \cellcolor{greyL}14.15 & \cellcolor{greyL}\textbf{16.71} & \cellcolor{greyL}\textbf{19.37} & \cellcolor{greyL}\textbf{21.68} & \cellcolor{greyL}\textbf{23.33} & \cellcolor{greyL}\textbf{24.24} & \cellcolor{greyL}\textbf{25.39} & \cellcolor{greyL}\textbf{26.11} & \cellcolor{greyL}\textbf{26.75} & \cellcolor{greyL}\textbf{26.93}  \\
\midrule[0.6pt]
%TRADES  &  - & - & - & - & - & - \\
\multirow{2}*{FedProx} & FAT & \textbf{5.36} & \textbf{5.89} & 6.82 & 7.96 & 9.36 & 10.89 & 12.52 & 14.03 & 15.41 & 16.47 \\
~ &\textbf{SFAT} & \cellcolor{greyL}6.28 & \cellcolor{greyL}6.27 & \cellcolor{greyL}\textbf{6.59} & \cellcolor{greyL}\textbf{7.10} & \cellcolor{greyL}\textbf{7.68} & \cellcolor{greyL}\textbf{8.10} & \cellcolor{greyL}\textbf{9.06} & \cellcolor{greyL}\textbf{9.80} & \cellcolor{greyL}\textbf{10.60} & \cellcolor{greyL}\textbf{11.14}  \\
\bottomrule[1.5pt]
\end{tabular}}
%}
\end{table}
\vspace{3mm}

From the experimental view, we also provide the comparison between SFAT and FedProx (actually they are orthogonal and combinable). We show the results of client drift w.r.t different methods in the Tables~\ref{table:exp_client_drift_figure4} and~\ref{table:exp_client_drift_other_experiments}. According to the results, FAT under the backbone FedProx can indeed catch up with our SFAT on basis of FedAvg since the FedProx is designed for reducing the client drift. However, when adopting FedProx as the backbone of SFAT, the intensified client drift can be further reduced, which verified the orthogonal effects (as stated in our Appendix~\ref{app:related_work}) on reducing intensified heterogeneity in the critical issue of federated adversarial training. Note that, we are not focus on the relationship of normal heterogeneity~\citep{li2018federated} (e.g., the value of client drift) with the robust performance in federated adversarial training. Instead, our proposed SFAT actually focus on the robust deterioration caused by the intensified heterogeneity (e.g., the increasing trend of client drift). It is orthogonal and compatible to those previous federated optimization methods.

\vspace{3mm}
\begin{table}[ht]
%\renewcommand\arraystretch{1.2}
\centering
\vspace{3mm}
\caption{Comparison of SFAT and FAT using FedProx with different paramter $\mu$.}
\footnotesize
\label{table:exp_fedprox_svhn_diff_mu}
%\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c}
\toprule[1.5pt]
FedProx: $\mu$ & Methods & Natural & PGD-20 & CW$_{\infty}$ \\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{2}*{0.01} & FAT & 90.92\% & 68.44\% & 67.18\% \\
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{91.25\%} & \cellcolor{greyL}\textbf{71.54\%} & \cellcolor{greyL}\textbf{69.53\%} \\
\multirow{2}*{0.05} & FAT & 90.25\% & 68.07\% & 66.88\% \\
~ &\textbf{SFAT} & \cellcolor{greyL}\textbf{91.37\%} & \cellcolor{greyL}\textbf{70.58\%} & \cellcolor{greyL}\textbf{68.93\%} \\
\multirow{2}*{0.1} & FAT & 89.98\% & 67.15\% &65.94\%\\
~ &\textbf{SFAT} & \cellcolor{greyL}\textbf{90.95\%} & \cellcolor{greyL}\textbf{71.89\%} & \cellcolor{greyL}\textbf{69.98\%} \\
\bottomrule[1.5pt]
\end{tabular}%}
\vskip1ex%
\vskip -0ex%
\end{table}
\vspace{3mm}

Except the previous results, we further strength the hyper-parameter $\mu$ of the proposed proximal term i.e., $\frac{\mu}{2}||w-w^t||_{2}$ in FedProx to verify the improvement of using our SFAT on SVHN dataset. We summarize the results in Table~\ref{table:exp_fedprox_svhn_diff_mu}. The results show that increasing the $\mu$ from 0.01 (adopted in our experiments and following the recommendation of FedProx) to 0.1, the robust performance even worse while our SFAT can still reach the better performance. The reason may be that too large $\mu$ also has the potentially negative influence on the convergence of the training by forcing the updates to be close to the starting point, which has been discussed in previous literature~\citep{karimireddy2020scaffold}.


\subsection{Experiments with More Clients}
\label{app:more_clients}

\vspace{3mm}
\begin{table}[ht]
\centering  
\caption{Comparison about FAT with SFAT on Non-IID data partition with different client numbers}
\label{table:exp_diff_client_number}
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{3}{c|}{Setting} & \multicolumn{9}{c}{Non-IID} \\
\midrule[0.6pt]
\multicolumn{3}{c|}{\multirow{2}*{Client Number / Method}} & \multicolumn{3}{c|}{CIFAR-10} & \multicolumn{3}{c}{SVHN} & \multicolumn{3}{|c}{CIFAR-100}\\
\cmidrule{4-12}
\multicolumn{3}{c|}{~} & Natural & PGD-20 & CW$_{\infty}$ & Natural & PGD-20 & CW$_{\infty}$  & Natural & PGD-20 & CW$_{\infty}$\\
\midrule[0.6pt]
\midrule[0.6pt]
%AT  & 57 & 66.47\% & 47.68\% & 38.18\% & 37.04\% & - \\
\multirow{9}*{FedAvg} & \multirow{2}*{10} & FAT & 56.62\% & 31.24\% & 29.82\% & 91.42\% & 69.65\% & 68.52\% & 33.27\% & 16.81\% & 14.12\%\\
~ & ~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{56.67\%} & \cellcolor{greyL}\textbf{33.31\%} & \cellcolor{greyL}\textbf{31.58\%} & \cellcolor{greyL}\textbf{91.84\%} & \cellcolor{greyL}\textbf{72.59\%} & \cellcolor{greyL}\textbf{70.71\%} &
\cellcolor{greyL}\textbf{34.17\%} &
\cellcolor{greyL}\textbf{17.66\%} &
\cellcolor{greyL}\textbf{14.25\%}\\

~ & \multirow{2}*{20} & FAT & 60.55\% & 32.67\% & 31.07\% & 92.14\% & 70.32\% & 69.48\% &31.49\%&15.35\%&13.18\%\\
~ & ~ &\textbf{SFAT} & \cellcolor{greyL}\textbf{62.24\%} & \cellcolor{greyL}\textbf{35.66\%} & \cellcolor{greyL}\textbf{33.21\%} & \cellcolor{greyL}\textbf{92.75\%} & \cellcolor{greyL}\textbf{72.06\%} & \cellcolor{greyL}\textbf{71.14\%} &
\cellcolor{greyL}\textbf{34.04\%} &
\cellcolor{greyL}\textbf{16.05\%} &
\cellcolor{greyL}\textbf{13.70\%}\\

%MART  &  - & - & - & - & - & - \\
%TRADES  &  - & - & - & - & - & - \\
~ & \multirow{2}*{25} & FAT & 58.97\%& 32.98\% & 31.14\% & 92.32\% & 70.54\% & 69.84\%  &32.64\%&15.82\%&13.23\%\\
~ & ~ &\textbf{SFAT} & \cellcolor{greyL}\textbf{62.73\%} & \cellcolor{greyL}\textbf{35.75\%} & \cellcolor{greyL}\textbf{33.16\%} & \cellcolor{greyL}\textbf{92.33\%} & \cellcolor{greyL}\textbf{71.99\%} & \cellcolor{greyL}\textbf{71.06\%} &
\cellcolor{greyL}\textbf{34.19\%} &
\cellcolor{greyL}\textbf{16.37\%} &
\cellcolor{greyL}\textbf{13.63\%}\\

%MART  &  - & - & - & - & - & - \\
~ & \multirow{2}*{50} & FAT & 56.74\% & 32.91\% & 30.50\% & 91.97\% & 70.84\% & 69.42\%  &34.46\%&15.97\%&13.59\%\\
~ & ~& \textbf{SFAT}  & \cellcolor{greyL}\textbf{57.21\%} & \cellcolor{greyL}\textbf{34.35\%} & \cellcolor{greyL}\textbf{31.75\%}  & \cellcolor{greyL}\textbf{91.99\%} & \cellcolor{greyL}\textbf{71.87\%} & \cellcolor{greyL}\textbf{70.74\%} &
\cellcolor{greyL}\textbf{34.82\%} &
\cellcolor{greyL}\textbf{16.34\%} &
\cellcolor{greyL}\textbf{13.93\%}\\

\bottomrule[1.5pt]
\end{tabular}}
\end{table}
\vspace{4mm}

In this part, we verify SFAT using more clients under the Non-IID data partition with the three benchmarked datasets, i.e., \textit{CIFAR-10}, \textit{SVHN} and \textit{CIFAR-100}. 

In Table~\ref{table:exp_diff_client_number}, we change the client number from 10 to 50 to investigate the scalability of our SFAT. For each client setting, we conduct FAT and SFAT to compare their performance on both natural test data and adversarial test data. In the experiments, we set $\widehat{K}=K/5$ and $\alpha=1/11$ for our SFAT and keep the other basic setups as the same with previous experiments. We can find that the results further confirm the effectiveness of SFAT on improving both natural and robust performance when training with different client numbers.


\subsection{Experiments on The Unequal Data Splits.}
\label{app:unequal_data_split}


\begin{table}[ht]
%\renewcommand\arraystretch{1.2}
\centering
\vspace{3mm}
\caption{Performance on the setting with unequal data splits among clients.}
\footnotesize
\label{table:exp_unequal_appendix}
%\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{5}{c|}{Setting} & \multicolumn{4}{c}{Non-IID} \\
\midrule[0.6pt]
Dataset & Client & Sample & Opt. & Method & Natural & FGSM & PGD-20 & CW$_{\infty}$\\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{8}*{CIFAR-10} & \multirow{4}*{5} & \multirow{4}*{6000-13000} & \multirow{2}*{FedAvg} & FAT & 59.98\% & 40.57\% & 31.50\% & 29.57\% \\
~ & ~ & ~  & ~& SFAT & \cellcolor{greyL}\textbf{61.70\%} & \cellcolor{greyL}\textbf{42.81\%} & \cellcolor{greyL}\textbf{33.87\%} & \cellcolor{greyL}\textbf{30.99\%} \\
~ & ~ & ~ & \multirow{2}*{FedProx} & FAT &  60.36\% & 40.36\% & 31.90\% & 29.00\% \\
~ & ~ & ~ & ~& SFAT & \cellcolor{greyL}\textbf{60.65\%} & \cellcolor{greyL}\textbf{42.38\%} & \cellcolor{greyL}\textbf{35.16\%} & \cellcolor{greyL}\textbf{30.93\%} \\
\cmidrule{2-9}
~ & \multirow{4}*{10} & \multirow{4}*{1000-8000} & \multirow{2}*{FedAvg} & FAT & 61.67\% & 42.69\% & 33.17\% & 30.58\% \\
~ & ~ & ~  & ~& SFAT & \cellcolor{greyL}\textbf{62.57\%} & \cellcolor{greyL}\textbf{44.85\%} & \cellcolor{greyL}\textbf{36.42\%} & \cellcolor{greyL}\textbf{32.65\%} \\
~ & ~ & ~ & \multirow{2}*{FedProx} & FAT & 60.24\% & 41.25\% & 33.21\% & 30.98\% \\
~ & ~ & ~ & ~& SFAT &  \cellcolor{greyL}\textbf{60.78\%} & \cellcolor{greyL}\textbf{43.73\%} & \cellcolor{greyL}\textbf{36.76\%} & \cellcolor{greyL}\textbf{32.44\%} \\
\midrule[0.6pt]
Dataset & Client & Sample & Opt. & Method & Natural & FGSM & PGD-20 & CW$_{\infty}$\\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{8}*{SVHN} & \multirow{4}*{5} & \multirow{4}*{5860-26370}&\multirow{2}*{FedAvg} & FAT & 89.42\% & 85.93\% & 68.35\% & 67.03\% \\
~ & ~ & ~  & ~& SFAT & \cellcolor{greyL}\textbf{90.57\%} & \cellcolor{greyL}\textbf{87.53\%} & \cellcolor{greyL}\textbf{70.56\%} & \cellcolor{greyL}\textbf{68.67\%} \\
~ & ~ & ~ & \multirow{2}*{FedProx} & FAT & 90.15\% & 86.59\% & 68.02\% & 66.22\% \\
~ & ~ & ~ & ~& SFAT & \cellcolor{greyL}\textbf{90.55\%} & \cellcolor{greyL}\textbf{87.45\%} & \cellcolor{greyL}\textbf{71.19\%} & \cellcolor{greyL}\textbf{69.00\%} \\
\cmidrule{2-9}
~ & \multirow{4}*{10} & \multirow{4}*{1465-13185}&\multirow{2}*{FedAvg} & FAT & \textbf{91.84\%} & 88.80\% & 70.66\% & 68.90\% \\
~ & ~ & ~  & ~& SFAT & \cellcolor{greyL}91.55\% & \cellcolor{greyL}\textbf{88.91\%} & \cellcolor{greyL}\textbf{72.29\%} & \cellcolor{greyL}\textbf{70.30\%} \\
~ & ~ & ~ & \multirow{2}*{FedProx} & FAT & 90.95\% & 87.77\% & 69.80\% & 68.20\% \\
~ & ~ & ~ & ~& SFAT &\cellcolor{greyL}\textbf{91.61\%} & \cellcolor{greyL}\textbf{88.83\%} & \cellcolor{greyL}\textbf{72.45\%} & \cellcolor{greyL}\textbf{70.29\%} \\

\bottomrule[1.5pt]
\end{tabular}%}
\vskip1ex%
\vskip -0ex%
\end{table}
\vspace{3mm}

\begin{table}[ht]
%\renewcommand\arraystretch{1.2}
\centering
\vspace{3mm}
\caption{Performance on the setting with severe unequal splits among clients on SVHN dataset.}
\footnotesize
\label{table:exp_unequal_appendix_additional_results}
%\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{5}{c|}{Setting} & \multicolumn{4}{c}{Non-IID} \\
\midrule[0.6pt]
Dataset & Client & Sample & Opt. & Method & Natural & FGSM & PGD-20 & CW$_{\infty}$\\
\midrule[0.6pt]
\multirow{8}*{SVHN} & \multirow{4}*{10} & \multirow{4}*{1465-13185}&\multirow{2}*{FedAvg} & FAT & \textbf{91.84\%} & 88.80\% & 70.66\% & 68.90\% \\
~ & ~ & ~  & ~& SFAT & \cellcolor{greyL}91.55\% & \cellcolor{greyL}\textbf{88.91\%} & \cellcolor{greyL}\textbf{72.29\%} & \cellcolor{greyL}\textbf{70.30\%} \\
~ & ~ & ~ & \multirow{2}*{FedProx} & FAT & 90.95\% & 87.77\% & 69.80\% & 68.20\% \\
~ & ~ & ~ & ~& SFAT &\cellcolor{greyL}\textbf{91.61\%} & \cellcolor{greyL}\textbf{88.83\%} & \cellcolor{greyL}\textbf{72.45\%} & \cellcolor{greyL}\textbf{70.29\%} \\
\cmidrule{2-9}
~ & \multirow{4}*{10} & \multirow{4}*{50-16700}&\multirow{2}*{FedAvg} & FAT & 93.14\% & 90.23\% & 72.09\% & 71.01\% \\
~ & ~ & ~  & ~& SFAT &\cellcolor{greyL}\textbf{92.78\%} & \cellcolor{greyL}\textbf{90.07\%} & \cellcolor{greyL}\textbf{73.85\%} & \cellcolor{greyL}\textbf{72.08\%} \\
~ & ~ & ~ & \multirow{2}*{FedProx} & FAT & 93.06\% & 90.37\% & 72.03\% & 70.90\% \\
~ & ~ & ~ & ~& SFAT  &\cellcolor{greyL}\textbf{93.14\%} & \cellcolor{greyL}\textbf{90.51\%} & \cellcolor{greyL}\textbf{73.87\%} & \cellcolor{greyL}\textbf{72.35\%} \\
\bottomrule[1.5pt]
\end{tabular}%}
\vskip1ex%
\vskip -0ex%
\end{table}
\vspace{4mm}

To complete our experimental verification on those unequal data splits, we conduct the experiments on \textit{CIFAR-10} and \textit{SVHN} datasets with different client numbers. We summarize the results in Table~\ref{table:exp_unequal_appendix}. In addition, we also add Table~\ref{table:exp_unequal_appendix_additional_results} to explore the more severe unequal splits in different clients.

In such setups, the sample numbers of different client are also a critical factor to the optimization. More samples the client has, larger weights the local model has in the aggregation phase. In comparison with our $\alpha$, it follows the support of the statistical sample proportion while our $\alpha$ utilizes the clues of the local loss related to the adversarial training. According to the results, we can see that SFAT is approximately orthogonal to the sample number effect and still more effective than FAT.

From the algorithm level, our algorithm (refer to Algorithm~\ref{alg:alpha-WFAT}) and the framework (refer to Figure~\ref{fig:realization_illustration_app}) has taken the numbers of local data into consideration. To be specific, when we conduct the slack selection, all the adversarial training loss are normalized by the local data number.

\subsection{Experiments on The Real-world Scenarios}
\label{app:real_celeba}

\begin{table}[ht]
%\renewcommand\arraystretch{1.2}
\centering
\vspace{4mm}
\caption{Performance on Non-IID settings using the real-world dataset, i.e., \textit{CelebA}}
\vspace{2mm}
\footnotesize
\label{table:exp_robust_eval_non-iid_rebuttal_celeba}

\begin{tabular}{c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{2}{c|}{Setting} & \multicolumn{4}{c}{Non-IID} \\
\midrule[0.6pt]
\multicolumn{2}{c|}{CelebA} & Natural & FGSM & PGD-20 & CW$_{\infty}$\\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{2}*{FedAvg} & FAT &  57.62\%  &  42.20\%  &  22.20\%  &  21.67\%   \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{58.50\%} &
\cellcolor{greyL}\textbf{43.44\%} &
\cellcolor{greyL}\textbf{24.14\%} &
\cellcolor{greyL}\textbf{23.52\%}\\
\midrule[0.6pt]
\midrule[0.6pt]
\multirow{2}*{FedProx} & FAT &  57.70\%  &  41.85\%  &  22.29\%  &  21.50\%   \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{58.50\%} &
\cellcolor{greyL}\textbf{43.08\%} &
\cellcolor{greyL}\textbf{24.14\%} &
\cellcolor{greyL}\textbf{23.61\%}\\
%\midrule[0.6pt]
%\midrule[0.6pt]
%\multirow{2}*{Scaffold} & FAT &  -  &  -  &  -  &  -   \\
%\cline{2-12}
%~ & \textbf{$\alpha$-WFAT}  & \cellcolor{greyL}\textbf{-} &
%\cellcolor{greyL}\textbf{-} &
%\cellcolor{greyL}\textbf{-} &
%\cellcolor{greyL}\textbf{-}\\
\bottomrule[1.5pt]
\end{tabular}
\vskip1ex%
\vskip -0ex%
\vspace{3mm}
\end{table}
\vspace{2mm}

To verify the effectiveness of our SFAT in more practical situation, we conduct the experiments using a real-world dataset \textit{CelebA} in the benchmark of federated learning, i.e., LEAF~\citep{caldas2018leaf}, with hundreds (455) of clients in Table~\ref{table:exp_robust_eval_non-iid_rebuttal_celeba}. We follow the most settings in LEAF to perform our experiments using different federated optimization methods, and we set $\widehat{K}=2*K/5$ and $\alpha=1/6$ for all the experiments of our SFAT. 


In Table~\ref{table:exp_robust_eval_non-iid_rebuttal_celeba}, we confirm the effectiveness of our SFAT using a real-world large-scale dataset \textit{CelebA} with 455 clients. Except Scaffold that fails to converge in FAT and thus is not reported, our SFAT again gains significantly better natural and robust accuracies than FAT under FedAvg and FedProx. 

\begin{table}[ht]
%\renewcommand\arraystretch{0.65}
\centering 
\vspace{4mm}
\caption{Test accuracy (\%) on \textit{SVHN} with different participation ratio. }
\vspace{1mm}
\footnotesize
\label{table:exp_diff_subset}
%\resizebox{\linewidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{2}{c|}{Setting} & \multicolumn{5}{c}{Non-IID} \\

\midrule[0.6pt]
\multicolumn{2}{c|}{Accuracy / Participation Ratio} & 0.2 & 0.4 & 0.6 & 0.8 & 1.0 \\
\midrule[0.6pt]
\midrule[0.6pt]
%AT  & 57 & 66.47\% & 47.68\% & 38.18\% & 37.04\% & - \\
\multirow{2}*{Natural} & FAT & \textbf{91.93\%} & 91.39\% & 92.19\% & 92.31\%  & 92.14\%  \\
~ & \textbf{SFAT} & \cellcolor{greyL}91.61\%  & \cellcolor{greyL}\textbf{92.51\%} & \cellcolor{greyL}\textbf{92.30\%} & \cellcolor{greyL}\textbf{92.53\%} & \cellcolor{greyL}\textbf{92.75\%}  \\
\midrule[0.6pt]
%TRADES  &  - & - & - & - & - & - \\
\multirow{2}*{PGD-20} & FAT & 69.63\% & 69.97\% & 70.25\% & 70.24\% & 70.32\%  \\
~ &\textbf{SFAT} & \cellcolor{greyL}\textbf{72.37\%} & \cellcolor{greyL}\textbf{73.01\%} & \cellcolor{greyL}\textbf{72.85\%} & \cellcolor{greyL}\textbf{72.59\%} & \cellcolor{greyL}\textbf{72.06\%}  \\
\bottomrule[1.5pt]
\end{tabular}
%}
\end{table}
\vspace{4mm}

In addition, we also consider the practical situation where only a subset of clients participates in each round. Following the same settings as previous section, we add the experiments on \textit{SVHN} dataset in Table~\ref{table:exp_diff_subset} with 20 clients. The results show that the lower participation ratio leads to lower natural and PGD-20 accuracy while our SFAT can consistently outperform FAT on the robustness.



\subsection{Overall Results on Both Non-IID and IID Settings}
\label{app:overall_results}

\begin{table*}[ht]
\renewcommand\arraystretch{1.0}
\centering
\vspace{4mm}
\caption{Performance on three benchmark datasets under different federated optimization methods (Non-IID \& IID).}
\vspace{-1mm}
\label{table:exp_robust_eval_all_backup}
\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c}
\toprule[1.5pt]
\rowcolor{greyC} \multicolumn{2}{c|}{Setting} & \multicolumn{5}{c|}{Non-IID} &\multicolumn{5}{c}{IID} \\
\midrule[0.6pt]
\multicolumn{2}{c|}{CIFAR-10} & Natural & FGSM & PGD-20 & CW$_{\infty}$ & AA & Natural & FGSM & PGD-20 & CW$_{\infty}$ & AA \\
\midrule[0.6pt]
\midrule[0.6pt]
\multicolumn{2}{c|}{Centralized AT} & - & - & - & - & - & 66.47\% & 47.68\% & 38.18\% & 37.04\% & 34.48\% \\
\midrule[0.6pt]
\multirow{2}*{FedAvg} & FAT & 57.45\% & 39.44\% & 32.58\% & 30.52\% & 29.20\% & \textbf{69.35\%} & 48.45\% & 37.43\% & 35.72\% & 33.96\% \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{63.44\%} & \cellcolor{greyL}\textbf{45.13\%} & \cellcolor{greyL}\textbf{37.17\%} & \cellcolor{greyL}\textbf{33.99\%} & \cellcolor{greyL}\textbf{32.36\%} & \cellcolor{greyL}67.43\% & \cellcolor{greyL}\textbf{50.33\%} & \cellcolor{greyL}\textbf{42.78\%} & \cellcolor{greyL}\textbf{37.91\%} & \cellcolor{greyL}\textbf{36.20\%} \\
\midrule[0.6pt]
\multirow{2}*{FedProx} & FAT & 60.44\% & 41.59\% & 33.84\% & 31.29\% & 30.02\% & 66.91\% & 46.70\% & 37.14\% & 34.54\% & 32.68\% \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{62.51\%} & \cellcolor{greyL}\textbf{44.29\%} & \cellcolor{greyL}\textbf{36.75\%} & \cellcolor{greyL}\textbf{33.82\%} & \cellcolor{greyL}\textbf{31,98\%} & \cellcolor{greyL}\textbf{68.31\%} & \cellcolor{greyL}\textbf{48.40\%} & \cellcolor{greyL}\textbf{42.41\%} & \cellcolor{greyL}\textbf{37.25\%} & \cellcolor{greyL}\textbf{35.97\%} \\
\midrule[0.6pt]
\multirow{2}*{Scaffold} & FAT & 62.81\% & 43.61\% & 34.13\% & 32.53\% & 30.95\% & 68.27\% & 49.25\% & 39.33\% & 37.31\% & 35.30\% \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{64.12\%} & \cellcolor{greyL}\textbf{46.05\%} & \cellcolor{greyL}\textbf{37.35\%} & \cellcolor{greyL}\textbf{34.78\%} & \cellcolor{greyL}\textbf{33.32\%} & \cellcolor{greyL}\textbf{71.36\%} & \cellcolor{greyL}\textbf{50.42\%} & \cellcolor{greyL}\textbf{43.83\%} & \cellcolor{greyL}\textbf{39.12\%} & \cellcolor{greyL}\textbf{35.47\%} \\

%FedNovaAT & FAT & 57.30\% & 39.81\% & 32.72\% & 30.65\% & 29.22\% & 68.46\% & 47.85\% & 37.66\% & 35.65\% & 33.50\% \\

\midrule[0.6pt]
\midrule[0.6pt]

\multicolumn{2}{c|}{CIFAR-100}  & Natural & FGSM & PGD-20 & CW$_{\infty}$ & AA & Natural & FGSM & PGD-20 & CW$_{\infty}$ & AA \\
\midrule[0.6pt]
\midrule[0.6pt]
\multicolumn{2}{c|}{Centralized AT} & - & - & - & - & - & 35.81\% & 23.09\% & 18.64\% & 16.48\% & 15.42\% \\
\midrule[0.6pt]
\multirow{2}*{FedAvg} & FAT  & 35.19\% & 20.20\% & 15.60\% & 13.26\% & 12.22\% & 32.65\% & 20.44\% & 16.47\% & 14.10\% & 12.99\% \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{36.18\%} & \cellcolor{greyL}\textbf{20.70\%} & \cellcolor{greyL}\textbf{16.40\%} & \cellcolor{greyL}\textbf{13.55\%} & \cellcolor{greyL}\textbf{12.42\%} & \cellcolor{greyL}\textbf{38.36\%} & \cellcolor{greyL}\textbf{21.86\%} & \cellcolor{greyL}\textbf{17.10\%} & \cellcolor{greyL}\textbf{14.36\%} & \cellcolor{greyL}\textbf{13.42\%} \\
\midrule[0.6pt]
\multirow{2}*{FedProx} & FAT & 32.36\% & 19.22\% & 15.37\% & 12.91\% & 12.05\% & 34.78\% & 20.71\% & 16.37\% & 14.28\% & 13.09\% \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{35.11\%} & \cellcolor{greyL}\textbf{20.62\%} & \cellcolor{greyL}\textbf{16.19\%} & \cellcolor{greyL}\textbf{13.47\%} & \cellcolor{greyL}\textbf{12.63\%} & \cellcolor{greyL}\textbf{37.58\%} & \cellcolor{greyL}\textbf{21.74\%} & \cellcolor{greyL}\textbf{17.03\%} & \cellcolor{greyL}\textbf{14.46\%} & \cellcolor{greyL}\textbf{13.50\%} \\
\midrule[0.6pt]
\multirow{2}*{Scaffold} & FAT & 39.96\% & 24.26\% & 19.41\% & 16.60\% & 15.37\% & 43.80\% & 26.25\% & 20.76\% & 18.39\% & 17.20\% \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{44.08\%} & \cellcolor{greyL}\textbf{24.38\%} & \cellcolor{greyL}\textbf{20.29\%} & \cellcolor{greyL}\textbf{16.79\%} & \cellcolor{greyL}\textbf{15.90\%} & \cellcolor{greyL}\textbf{44.36\%} & \cellcolor{greyL}\textbf{28.65\%} & \cellcolor{greyL}\textbf{23.14\%} & \cellcolor{greyL}\textbf{20.11\%} & \cellcolor{greyL}\textbf{18.39\%} \\
%FedNovaAT & 33.80\% & 20.31\% & 16.26\% & 13.75\% & 12.71\% & 38.19\%  & 23.42\% & 18.51\% & 16.66\% & 15.53\% \\

\midrule[0.6pt]
\midrule[0.6pt]

\multicolumn{2}{c|}{SVHN} & Natural & FGSM & PGD-20 & CW$_{\infty}$ & AA & Natural & FGSM & PGD-20 & CW$_{\infty}$ & AA \\
\midrule[0.6pt]
\midrule[0.6pt]
\multicolumn{2}{c|}{Centralized AT} & - & - & - & - & - & 92.39\% & 89.75\% & 72.73\% & 72.31\% & 70.93\% \\
\midrule[0.6pt]
\multirow{2}*{FedAvg} & FAT & 91.24\% & 87.95\% & 68.87\% & 67.89\% & 66.54\%  & \textbf{93.52\%} & \textbf{90.68\%} & 72.24\% & 71.22\% & 70.08\%  \\
%\cline{2-12}
~ & \textbf{SFAT}  & \cellcolor{greyL}\textbf{91.25\%} & \cellcolor{greyL}\textbf{88.28\%} & \cellcolor{greyL}\textbf{71.72\%} & \cellcolor{greyL}\textbf{69.79\%} & \cellcolor{greyL}\textbf{68.62\%} & \cellcolor{greyL}92.75\% & \cellcolor{greyL}90.06\% & \cellcolor{greyL}\textbf{74.37\%} & \cellcolor{greyL}\textbf{72.34\%} & \cellcolor{greyL}\textbf{71.27\%}  \\
\midrule[0.6pt]
\multirow{2}*{FedProx} & FAT & 90.92\% & 87.50\% & 68.44\% & 67.18\% & 65.94\%  & 93.54\% & 90.66\% & 72.53\% & 71.42\% & 70.21\%  \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{91.25\%} & \cellcolor{greyL}\textbf{88.15\%} & \cellcolor{greyL}\textbf{71.54\%} & \cellcolor{greyL}\textbf{69.53\%} & \cellcolor{greyL}\textbf{68.47\%}  & \cellcolor{greyL}\textbf{93.59\%} & \cellcolor{greyL}\textbf{90.80\%} & \cellcolor{greyL}\textbf{74.66\%}& \cellcolor{greyL}\textbf{72.67\%} & \cellcolor{greyL}\textbf{71.48\%} \\
\midrule[0.6pt]
\multirow{2}*{Scaffold} & FAT & 89.95\% & 87.23\% & 68.66\% & 67.23\% & 66.65\% & 93.80\% & 91.00\% & 73.26\% & 72.05\% & 70.80\%  \\
%\cline{2-12}
~ & \textbf{SFAT} & \cellcolor{greyL}\textbf{90.20\%} & \cellcolor{greyL}\textbf{87.81\%} & \cellcolor{greyL}\textbf{71.39\%} & \cellcolor{greyL}\textbf{68.81\%} & \cellcolor{greyL} \textbf{67.88\%}  & \cellcolor{greyL}\textbf{93.92\%} & \cellcolor{greyL}\textbf{91.28\%} & \cellcolor{greyL}\textbf{75.96\%} & \cellcolor{greyL}\textbf{74.05\%} & \cellcolor{greyL}\textbf{72.88\%} \\

%FedNovaAT & \textbf{92.16\%} & \textbf{89.04\%} & 69.91\% & 69.01\% & 67.77\% & \textbf{93.58\%} & \textbf{90.88\%} & 73.98\% & 72.39\% & 71.43\% \\

\bottomrule[1.5pt]
\end{tabular}}
\vskip1ex%
\vskip -0ex%
\end{table*}
\vspace{4mm}

Here we provide the overall results for comparison on both Non-IID and IID settings in Table~\ref{table:exp_robust_eval_all_backup}.

For the Non-IID data, our SFAT gain consistently improvement across the various of evaluation metrics and datasets. For the IID data, our method acquires a similar improvement on the robust accuracy without the deterioration of the natural accuracy. The reason might be that even the data is IID, adversarial training can still drive the independently-initialized overparameterized network~\citep{allen2020towards} on each client side towards at the robust overfitting of different directions, yielding the model heterogeneity. Thus, the proper slack to the inner-maximization makes adversarial training more compatible with federated learning. Another interesting observation is that Federated Adversarial Training shows better performance than centralized adversarial training in the IID setting. This gain could be from the distributed training paradigm that helps adversarial training converge to the more robust optimum by the divide-and-conquer mechanism. This might enlighten the more explore in adversarial training to improve the robustness via federated learning.


\section{Further Discussion}
\label{app:impact}

Adversarial robustness is an important topic in the centralized machine learning. The adversarial training are confirmed to be one of the most effective empirical defenses against the adversarial attack, which is critical especially for those safety-critical areas like medicine and finance. In federated settings, how to train an adversarially robust model is a challenging but practical task for the increasing concern about data privacy. In this work, we observe and explore to combat the intensified heterogeneity in federated adversarial training. Different from the conventional FAT adopted by previous works, we propose a new learning framework, i.e., SFAT, which relaxes the exacerbated heterogeneous effect and is compatible with the various adversarial training~\citep{Madry_adversarial_training,Zhang_trades} and federated optimization methods~\citep{li2018federated,karimireddy2020scaffold}.  

Although we take a step forward in FAT, it is not the end of this direction since there are still many problems to be addressed to further enhance the practicality of federated adversarial training.

From the perspective of adversarial robustness, adversarial attacks can be very complex, especially in a decentralized environment, while the adversarial robustness discussed in this paper mainly focuses on common adversarial attacks (e.g., $L_\infty$-bounded attack)~\citep{Goodfellow14_Adversarial_examples}. More practical situation which contains different kind of adversarial attack (e.g., mixed types of attack with $L_\infty$-bounded attack, Spatially transformed attack~\citep{xiao2018spatially}), even only considering the inference phase, may also happened since there are different clients may meet different threaten~\citep{kairouz2019advances,yao2022edge}. Besides, the federated adversarial training that requires multiple local runs~\citep{Madry_adversarial_training,Zhang_trades} also introduces the extra computation to the low-capacity devices, which is computational bottleneck and requires some lightweight techniques. Except for the empirical defense strategy focused by our work, the certifiable robustness~\citep{cohen2019certified,zizzo2021certified,alfarra2022certified} which can give the theoretical guarantees is also important.

From the perspective of federated learning, our SFAT shares the similar spirit of the conventional federated adversarial training. The first part of challenges comes from the distributed learning paradigm~\citep{mcmahan2017communication,kairouz2019advances,lit2020federated} of federated setting, which brings the hardware constraint that considers the computational capacity of local clients and communication cost between clients and server~\citep{hong2021federated}. Once these conditions do not satisfy, both FAT and SFAT would not work well. The second may from the algorithm design for some special training or inference issues, like dealing with heterogeneous data~\citep{li2018federated,zhao2018federated}, class-imbalance data or even some out-of-distribution data at inference time. On the other hand, the decentralized structure of the learning paradigm also introduces various issues on information transferring for server and clients.
The current federated adversarial training still needs large improvement considering the practical cases that may happened in the federated setting. For the intensified heterogeneity, it can also be recognized as an dynamical heterogeneous issue existing in federated learning, which may result from the special learning algorithm adapted in the distributed framework or other data manipulation scenarios. More robust issues, like robust distillation~\citep{goldblum2020adversarially,zhu2022reliable}, train-test distribution shift~\citep{jiang2023testtime}, out-of-distribution detection~\citep{yu2023turning}, under the federated framework can be further explored in the future.



%There is still a certain gap between the conventional federated adversarial training framework with the more practical scenarios in the real-world.

%In addition, if the datasets contain the overwhelming label noise, SFAT may not work well, since the optimization possibly approaches to the overfitting phase of the noisy training data, which then generalizes poorly on the clean test set. These cases can be overcome or alleviated by combining with previous explorations in the corresponding areas. 

%\textcolor{blue}{ Adversarial training is important to enhance the robustness of machine learning models against adversarial attack, especially for some safety-critical areas like medicine and finance. In these area, there are also the increasing concern about the data privacy. Hence, it raise a significant and practical challenge about training the adversarially robust model in federated settings. As for the challenges in federated adversarial training, it comes from various aspects. Most generally, we provide the discussion from two perspectives. The first is the distributed learning paradigm of federated setting, which brings the hardware constraint that considers the computational capacity of local clients and communication cost between clients and server. In this perspective, adversarial training introduces extra computation cost to those local clients, which is computational bottleneck and requires the lightweight techniques to improve it. The second is from the algorithm design for some special training or inference issues in both federated setting and adversarial training, like dealing with the heterogeneous data, class-imbalance data or even some out-of-distribution data at inference time. There is still a certain gap between the conventional federated adversarial training framework with the more practical scenarios in the real-world. }

% \newpage
% test

\clearpage




\end{document}

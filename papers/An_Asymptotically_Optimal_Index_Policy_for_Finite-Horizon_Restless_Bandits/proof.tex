\section{Proof of Asymptotic Optimality}\label{sec:pf}
Our index policy $\hat{\allp}$ achieves asymptotic optimality when we let the number of sub-processes $K$ go to infinity, while holding $\alpha = \frac{m}{K}$ constant.
Let $Z(\allp,m,K)$ to denote the expected reward of the original MDP obtained by policy $\allp$, to emphasize the dependency of this quantity on $K$ and $m$.
We use $\allpset_{m,K}$ to denote the set of all feasible Markov policies for the original MDP with $K$ sub-processes and a budget of $m$ activations per period. Lastly, it should be understood that whenever we use $\hat{\allp}$ to denote our index policy there is a dependency of $\hat{\allp}$ on $m$ and $K$ that is not explicitly stated. 
We are now ready to state the main result of this paper, which shows that the per arm gap between the upper bound and the index policy goes to zero under the limit assumption.:
\begin{theorem}\label{th:asp}
For any $\alpha\in(0,1)$, 
\begin{equation}
\lim_{K\rightarrow\infty}\frac{1}{K}\left(Z(\hat{\allp},\lfloor \alpha K\rfloor,K) - \max_{\allp\in\allpset_{\lfloor \alpha K\rfloor,K}}Z(\allp,\lfloor \alpha K\rfloor,K)\right) = 0.
\end{equation}
\end{theorem}

To formalize the notations that will be used throughout the proofs, we augment $P(\lambdav)$ to $P(\lambdav,m,K)$ to indicate the values of $m$ and $K$ assumed in the Lagrangian relaxation. We use $\lambdav^*$ to denote one and any element in $\arg\inf_{\lambdav}P(K,\alpha K,\lambdav)$ and let $\pi^{**}$ be the optimal policy constructed in \eqref{df:rho} using $m=\alpha K$, which satisfies $\mathbb{E}^{\pi^{**}}(A_t)=\alpha$. Note $\lambdav^*$ and $\pi^{**}$ depend on only $\alpha$ (not on $K$).

% Define $P_t(s)$ as the probability of being in state $s$ at time $t$ under $\pi^{**}$. 
% We observe the following relation between $P_t(s)$, occupation measure $\rho$ and $\pi^{**}$:
% $$\rho(s,a,t)=P_t(s)*\pi^{**}(s,a,t)$$ for all $s,a,t$. 

As before, we let $N_t(s)$ be the number of sub-processes in state $s$ at time $t$ under $\hat{\allp}$.  
We additionally define $M_t(\substate)$ to be the number of sub-processes in state $s$ at time $t$ that are set active by $\hat{\allp}$. These quantities depend on $K$ and $m$, but for simplicity we do not include this dependence in the notation: they always assume $m=\lfloor \alpha K \rfloor$ and we rely on context to make clear the value of $K$ assumed.
We also define $V_t(\substate)$ to be the set of states with the same index value as $s$, including $s$, and $U_t(s)$ to be the set of states with index value greater than that of $s$, for each time $t$.  These quantities depend on $\alpha$ but not on $K$ or $m$.


We prove Theorem \ref{th:asp} by first demonstrating below in Theorem~\ref{th:conv} that for each time $t$,
the proportion of the sub-processes that are in state $s$ under our index policy $\hat{\allp}$,
$\frac{N_t(s)}{K}$, approaches $P_t(s)$ as $K\rightarrow \infty$. 
In other words, our index policy $\hat{\subp}$ recreates the behavior of $\subp^{**}$ in the large $K$ limit.
\begin{theorem}\label{th:conv}
For every $s\in\substates$ and $1\leq t\leq T$,
\begin{equation}\label{conv1}
\lim_{K\rightarrow\infty}\frac{N_t(s)}{K} = P_t(s), \hspace{2mm} P^{\hat{\allp}}-a.s.,
\end{equation}
and
\begin{equation}\label{conv2}
\lim_{K\rightarrow\infty}\frac{M_t(s)}{K} = P_t(s)*\subp^{**}(s,1,t), \hspace{2mm} P^{\hat{\allp}}-a.s., 
\end{equation}
\end{theorem}
Before proving Theorem \ref{th:conv}, we first present two intermediate results, whose proofs are given in Appendix \ref{ap:eq} and \ref{ap:p1}.
\begin{lemma}\label{th:eq}
At time $1\leq t\leq T$, for all $\substate\in\substates$ , we have
\begin{enumerate}[(1)]
    \item If $\beta_t(\substate)>\lambda^*_t$, then $\subp^{**}(\substate,1,t) = 1$.
    \item If $\beta_t(\substate)<\lambda^*_t$, then $\subp^{**}(\substate,1,t) = 0$.
\end{enumerate}
\end{lemma}

\begin{lemma}\label{th:p1}
For any state $s\in\substates$ and time $1\leq t\leq T$, 
\begin{enumerate}[(1)]
\item If $\alpha-\sum_{s'\in U_{t}(s)\cup V_{t}(s)}P_{t}(s')\geq 0$, then $\subp^{**}(s,1,t) = 1.$
\item If $\alpha-\sum_{s'\in U_{t}(s)}P_{t}(s') \leq 0$, then $\subp^{**}(s,1,t) = 0.$
\end{enumerate}

\end{lemma}


We will also require the following technical result in the proof of Theorem~\ref{th:conv}. Again the proof is offered in Appendix \ref{ap:bino}


Now we are ready to prove Theorem \ref{th:conv}.
\begin{proof}{}
We prove \eqref{conv1} and \eqref{conv2} simultaneously via induction over the time periods.

When $t=1$, all sub-processes starts in state $s_1$, and we have
\begin{align*}
\lim_{K\rightarrow \infty}\frac{N_1(s)}{K} = \lim_{K\rightarrow \infty}\frac{K}{K} = 1 = P_1(s) \; \text{if }s = s_1,\\
\lim_{K\rightarrow \infty}\frac{N_1(s)}{K} = \lim_{K\rightarrow \infty}\frac{0}{K} = 0 = P_1(s) \; \text{otherwise}.
\end{align*}
By the set-up of the original MDP, $M_1(s)=\lfloor\alpha * K\rfloor$, and we have
\begin{align*}
&\lim_{K\rightarrow \infty}\frac{M_1(s)}{K} = \lim_{K\rightarrow \infty}\frac{\lfloor\alpha*K\rfloor}{K} = \alpha = \subp^{**}(s,1,t) =  P_1(s)*\subp^{**}(s,1,t) , \; \text{if }s = s_1,\\
&\lim_{K\rightarrow \infty}\frac{M_1(s)}{K} = \frac{0}{K} = 0 = P_1(s)*\subp^{**}(s,1,t), \; \text{otherwise},
\end{align*} 
so we have proved the base case of the induction. 

Now assume \eqref{conv1} and \eqref{conv2} hold up until time $t$. 
Fix a state $s\in \substates$ and time $1\leq t\leq T$, define $Y_t(s',s)$ to be the number of sub-processes set active by $\hat{\allp}$ in $s'$ at time $t$ which transition to state $s$ at time $t+1$, and $X_t(s',s)$ to be the number of sub-processes set inactive by $\hat{\allp}$ in $s'$ at time $t$ which transition to $s$ at time $t+1$. Note that $Y_t(s',s)$ and $X_t(s',s)$ also depend on $K$. 
We can subsequently express $N_{t+1}(s)$ as
\begin{align*}
&N_{t+1}(s) = \sum_{s'\in \substates} Y_t(s',s) + X_t(s',s).
\end{align*}
Dividing both sides by $K$, and taking $K$ to a limit, we get 
\begin{equation}\label{n1}
\lim_{K\rightarrow \infty}\frac{N_{t+1}(s)}{K} = \lim_{K\rightarrow \infty}\sum_{s'\in \substates} \frac{1}{K} Y_t(s',s) + \lim_{K\rightarrow \infty}\sum_{s'\in \substates}\frac{1}{K} X_t(s',s) 
\end{equation}
Note $Y_t(s',s)$ is a binomial random variable with $M_t(s')$ trials and success probability $\subpr^{1}(s',s)$
Similarly, $X_t(s',s)$ is a binomial random variable with $N_t(s')-M_t(s')$ trials and success probability $\subpr^{0}(s',s)$. 
We can rewrite the RHS of \eqref{n1} by applying Lemma \ref{th:bino}, which is stated at the end of the section:
\begin{align}
\lim_{K\rightarrow\infty}\frac{N_{t+1}(s)}{K} &= \sum_{s'\in\substates}\lim_{K\rightarrow\infty}\frac{M_t(s')}{K}*\subpr^1(s',s) + \sum_{s'\in\substates}\lim_{K\rightarrow\infty}\frac{N_t(s')-M_t(s')}{K}*\mathbb{P}_x^0(s',s)\nonumber\\
& = \sum_{s'\in \substates} P_t(s')*\subp^{**}(s',1,t+1)*\subpr^1(s',s)\\
&\;\;\;\;+\sum_{s'\in \substates}
P_t(s')(1-\subp^{**}(s',1,t+1))*\mathbb{P}_x^0(s',s)\hspace{2mm}a.s.\nonumber\\ 
&=P_{t+1}(s).\hspace{2mm}a.s. \label{ntlimit} 
\end{align}
The last equality follows as we have exhausted all the ways of getting to $s$ at time $t+1$. Hence we have shown (\ref{conv1}) holds for time $t+1$. 

To show (\ref{conv2}) holds for time $t+1$, define sets $\Pv_t = \{P_t(s):s\in\substates\}$, and $\Nv_t=\{N_t(s):s\in\substates\}$. We use notation $\frac{\Nv_{t}}{K}$ for the set which consists of all elements in $\Nv_t$ divided by $K$. Define function $f_s(\Nv_t,\lfloor\alpha K\rfloor)$ to represent the number of sub-processes set active at time $t$ in state $s$, that is,
\begin{align}
f_s(\Nv_t,\lfloor\alpha K\rfloor,H_1,H_2) =& \mathlarger{\mathlarger{\mathbbm{1}_{([\lfloor\alpha K\rfloor-\sum_{s'\in U_{t}(s)}N_{t}(s')]^+ \geq \sum_{s'\in V_{t}(s)}N_{t}(s'))}}}
*N_{t}(s)\nonumber\\
&+\mathlarger{\mathlarger{\mathbbm{1}_{([\lfloor\alpha K\rfloor-\sum_{s'\in U_{t}(s)}N_{t}(s')]^+ < \sum_{s'\in V_{t}(s)}N_{t}(s'))}}}*\nonumber\\
&\hspace{4mm}\mathlarger{\mathlarger{\mathbbm{1}_{(\lfloor\alpha K\rfloor-\sum_{s'\in U_{t}(s)}N_{t}(s')>0)}}}b_s(\Nv_t,\lfloor\alpha K\rfloor), 
\end{align}
where $b_s(\Nv_t,\lfloor\alpha K\rfloor)$ represent the number of sub-processes set active when tie-breaking is needed, that is,
\begin{align}
b_s(\Nv_t,\lfloor\alpha K\rfloor) = & \mathlarger{\mathlarger{\mathbbm{1}_{(\sum_{s'\in V_{t}(s)}\rho(s',1,t)>0)}}} * \nonumber\\
&\hspace{4mm}\left(\min\Big\{\Big\lfloor (\lfloor\alpha K\rfloor-\sum_{s'\in U_{t}(s)}N_{t}(s'))\frac{\rho(s,1,t)}{\sum_{s'\in V_{t}(s)}\rho(s',1,t)}\Big\rfloor,N_{t}(s)\Big\}+H_1\right)\nonumber\\
& + \mathlarger{\mathlarger{\mathbbm{1}_{(\sum_{s'\in V_{t}(s)}\rho(s',1,t)=0)}}}\left(\Big\lfloor (\lfloor\alpha K\rfloor-\sum_{s'\in U_{t}(s)}N_{t}(s'))\frac{N_{t}(s)}{\sum_{s'\in V_{t}(s)}N_{t}(s')}\Big\rfloor+H_2\right),
\end{align}
where $H_1$ and $H_2$ are random variables due to the rounding rules in Algorithm \ref{ag:tiebreak}, and are dependent on $K$.
We also define function
\begin{equation}
g_s(\Pv_t) = 
\begin{cases}
\min\{P_t(s),[\alpha - \sum_{s'\in U_t(s)}P_t(s')]^+\frac{\rho(s,1,t)}{\sum_{s'\in V_{t}(s)}\rho(s',1,t)}\} \;\;\; \text{if } \sum_{s'\in V_{t}(s)}\rho(s',1,t) >0 \\
\min\{P_t(s),[\alpha - \sum_{s'\in U_t(s)}P_t(s')]^+\frac{P_t(s)}{\sum_{s'\in V_{t}(s)}P_t(s')}\} \;\;\; \text{if } \sum_{s'\in V_{t}(s)}\rho(s',1,t) =0 ,
\end{cases}
\end{equation}
This proof will be accomplished by the following three lemmas, whose proof is given in Appendix \ref{ap:movein},\ref{ap:equiv},\ref{ap:ppi}
\begin{lemma}\label{th:movein}
$$\lim_{K\rightarrow\infty}f_s(\frac{\Nv_{t+1}}{K},\frac{\lfloor\alpha K\rfloor}{K}) = f_s(\Pv_{t+1},\alpha), a.s$$.
\end{lemma}
\begin{lemma}\label{th:equiv}
$$f_s(\Pv_t,\alpha) = g_s(\Pv_t)$$
\end{lemma}
\begin{lemma}\label{th:ppi}
$$g_s(\Pv_t) = P_t(s)\pi^{**}(s,1,t)$$
\end{lemma}
Combining the three lemmas above we have  $$\lim_{K\rightarrow\infty}\frac{M_{t+1}(s)}{K}=\lim_{K\rightarrow\infty}f_s(\frac{\Nv_{t+1}}{K},\frac{\lfloor\alpha K\rfloor}{K}) =g_s(\Pv_{t+1})=P_{t+1}(s)\pi^{**}(s,1,t+1).$$ 
$\square$
\end{proof}

Finally, we prove Theorem \ref{th:asp} by leveraging the results from Theorem \ref{th:conv}.
\begin{proof}{Proof of Theorem \ref{th:asp}}
$\hat{\allp} \in \allpset_{\lfloor \alpha K\rfloor,K}$ implies $Z(\hat{\allp},\lfloor \alpha K\rfloor,K) \leq \max_{\allp\in\allpset_{\lfloor \alpha K\rfloor,K}}Z(\allp,\lfloor \alpha K\rfloor,K)$.  Thus,
\begin{equation*}
\lim_{K\rightarrow\infty}\frac{1}{K}Z(\hat{\allp},\lfloor \alpha K\rfloor,K) \leq  \lim_{K\rightarrow\infty}\frac{1}{K}\sup_{\allp\in\allpset_{\lfloor \alpha K\rfloor,K}}Z(\allp,\lfloor \alpha K\rfloor,K).
\end{equation*}
On the other hand,
\begin{align*}
\lim_{K\rightarrow\infty}\frac{1}{K}Z(\hat{\allp},\lfloor \alpha K\rfloor,K) 
=&\lim_{K\rightarrow\infty}\frac{1}{K}\Eb^{\hat{\allp}}\left[\sum_{t=1}^{T}\sum_{s\in\substates}r_t(s,1) M_{t}(s)+r_t(s,0) (N_{t}(s)-M_{t}(s))\right]\\
=&\sum_{t=1}^{T}\sum_{s\in\substates}r_t(s,1) \lim_{K\rightarrow\infty}\frac{1}{K}\Eb^{\hat{\allp}}\left[M_{t}(s)\right]+r_t(s,0) \lim_{K\rightarrow\infty}\frac{1}{K}\Eb^{\hat{\allp}}\left[N_{t}(s)-M_{t}(s)\right]\\
=&\sum_{t=1}^{T}\sum_{s\in \substates}\left[r_t(s,1) \rho(s,1,t)+r_t(s,0) \rho(s,0,t) \right]\\
=&\sum_{t=1}^{T}\sum_{s\in \substates}\left[r_t(s,1) \rho(s,1,t)+r_t(s,0) \rho(s,0,t) \right] - \mathbb{E}^{\subp^{**}}\left[\sum_{t}\lambda_t \left(A_t-\alpha\right)\right]\\
=& Q(\lambdav^*)+\alpha \sum\lambda^*_t\\
=& \lim_{K\rightarrow\infty}\frac{1}{K}(KQ(\lambdav^*)+\lfloor \alpha K \rfloor\sum\lambda^*_t)\\
=& \lim_{K\rightarrow\infty}\frac{1}{K} P(\lambdav^*,\lfloor \alpha K \rfloor, K)\\
\geq& \lim_{K\rightarrow\infty}\frac{1}{K}\sup_{\allp\in\allpset_{\lfloor \alpha K\rfloor,K}}Z(\allp,\lfloor \alpha K\rfloor,K).
\end{align*}
Here, the third line follows by Theorem \ref{th:conv} and the fact that both $N_t(s)$ and $M_t(s)$ are bounded and hence uniformly integrable random variables (for uniformly integrable random variables, convergence almost surely implies convergence in expectation). The fourth line holds because $\subp^{**}$ takes the active action at each time with probability $\alpha$. 
The fifth line follows from Lemma~\ref{th:decom}, where we have augmented the notation for $P$ to include the values of $m$ and $K$ assumed.
The sixth line follows from Lemma~\ref{th:up}.

Finally, sandwiching the two inequalities gives the desired result.
$\square$
\end{proof}
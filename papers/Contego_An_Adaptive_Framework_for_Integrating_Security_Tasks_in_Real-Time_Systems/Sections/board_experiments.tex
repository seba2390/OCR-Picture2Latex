 \documentclass[../rt_server_main.tex]{subfiles}

 \begin{document}




\subsection{Experiment with Security Applications in an Embedded Platform} \label{subsec:implementation_BBB}

%\subsubsection{Prototype Implementation}
To observe the performance of the proposed scheme in a practical setup, we implemented \coolname on an embedded platform. %\remove[MH]{For this, we use a BeagleBone Black (BBB) development board \cite{bbb} (1 GHz ARM Cortex-A8 single-core processor, 512 MB RAM) as our experimental platform.} 
Our experimental platform \cite{bbb} was configured with 1 GHz ARM Cortex-A8 single-core processor and 512 MB RAM. We used Linux as the operating system -- that allowed us to utilize the existing Linux-based IDSes (refer to Section \ref{subsubsec:sec_task}) for the evaluation. Since the vanilla Linux kernel is  unsuitable for hard real-time scheduling, we enabled the real-time capabilities with the Xenomai \cite{xenomai} 2.6.3 real-time patch (kernel version 3.8.13-r72) on top of an embedded Debian Linux console image. 

We measured the WCET of the real-time and security tasks using ARM cycle counter registers (\eg CCNT), giving us nanosecond-level precision. Since these registers are not enabled by default, we developed a Linux kernel module to access the registers from our application codes.
Our prototype implementation was developed in C and uses a fixed-priority scheduler powered by the Xenomai real-time patch. Sporadic real-time and security tasks in the system were defined by Xenomai $\mathtt{rt\_task\_create()}$ function and were 
suspended after the completion of corresponding instances using the $\mathtt{rt\_task\_wait\_period()}$ function.




\subsubsection{Real-time Tasks}

For a real-time application, we considered a UAV control system (refer to Table \ref{table:rt_task_param}). %in Appendix~\ref{appsec:task_param}). 
We implemented it using an open-source UAV model \cite{khan-drone}. 
The original application codes were based on the STM32F4  micro-controller (ARM Cortex M4) and developed for FreeRTOS \cite{free_rtos}. Because of differences in library support and execution semantics, we updated the source codes accordingly and ported them to Linux.

\subfile{Sections/rt_task_table}
%\input{Sections/rt_task_table}

\subsubsection{Security Tasks}
\label{subsubsec:sec_task}

To integrate security in the aforesaid control system, we included additional security tasks. For the security tasks, we considered two lightweight open-source intrusion detection mechanisms, \ci Tripwire \cite{tripwire}, that detects integrity violations by storing clean system state during initialization and using it later to detect intrusions by comparing the current system state against the stored clean values,  and \cii Bro \cite{bro} that monitors anomalies in network traffic. As Table \ref{table:rtos} shows, %(refer to Appendix~\ref{appsec:task_param}), 
we consider several security tasks in both modes, \eg  \textit{protecting security task's own binary files}, \textit{protecting system binary and library files}, \textit{monitoring network traffic}.~%We measure the WCET of the security tasks using ARM cycle counter registers (\eg CCNT) that gives us nanosecond-level precision. 
In each mode, we set the desired and maximum allowable periods of the security tasks such that utilization of the security tasks did not exceed $50\%$ of the total system utilization. %$0.40$.

\subfile{Sections/se_task_table}


\subsubsection{Experience and Evaluation}



\paragraph{Performance Impact in Different Modes}



 \begin{figure}[!t]
%\begin{wrapfigure}{r}{0.49\columnwidth}
%\vspace{-1.3\baselineskip}
%\centering
\centering
\includegraphics[width=2.9in]{cpu_usage}
\caption{The CPU load when the security tasks executed in \pve (top) and \ave (bottom) mode, respectively. The dotted line represents average load over the observation duration (500 s).}
\label{fig:cpu_usage}
\vspace{-1.0\baselineskip}
%\end{wrapfigure}
 \end{figure}


In the first set of experiments, we measured the average CPU load when the security tasks were executing in \pve and \ave modes. For that, we executed the security tasks independently for $500~\mathrm{s}$ in \pve and \ave modes and observed the CPU load using $\mathtt{/proc/stat}$ interface (represents the y-axis of Fig.~\ref{fig:cpu_usage}). As Fig.~\ref{fig:cpu_usage} shows, running security tasks in \ave mode increased the average CPU load compared to running them in \pve mode. This is because \ave mode contains more security tasks (\eg 4 compared to 2, refer to %Appendix \ref{appsec:task_param}
Table \ref{table:rtos}) and they execute more frequently than in \pve mode. Because of the nature of applications, most RTS prefer predictability over performance. The overhead of running security tasks in \ave mode comes with increased security guarantees that will suffice for many RTS.



% \begin{figure}[!htbp]
%   \centering
%   \begin{minipage}[b]{0.48\textwidth}
%   \centering
%     \includegraphics[width=2.9in]{cpu_usage}
% \caption{The CPU load when the security tasks are running in \pve (top) and \ave (bottom) mode, respectively. The dotted line represents average load over the observation duration (500\textit{s}).}
% \label{fig:cpu_usage}
%   \end{minipage}
%   \hfill
%   \begin{minipage}[b]{0.48\textwidth}
%   \centering
%     \includegraphics[width=2.9in]{fig_mode_trace_color}
% \caption{The empirical distribution of time to detect the intrusions when mode change is allowed vs when is the security tasks running only in \pve mode. We use ARM cycle counter registers to measure the detection time. Total 50 individual experiment instances are examined to obtain the timing traces.}
% \label{fig:mode_trace}
%   \end{minipage}
% \end{figure}

\paragraph{Impact on Detection Time}

To study the detection performance we injected malicious code into the system that mimics anomalous behaviors.  We assumed that an attacker can take over\footnote{One way to override a task could be to use an approach similar to one presented in the literature \cite{cy_side_channel} that exploits the deterministic behavior of the real-time scheduling.} one of the low-priority real-time tasks (referred to as the victim task) and is able to insert malicious code that can execute with a privilege similar to that of legitimate tasks.
We launched the attack at both the \textit{network} and \textit{host}-level. We defined network-level DoS attacks as too many rejected usernames and passwords submitted from a single address and used a real FTP DoS trace \cite{bro_dos} to demonstrate the attack. Malware (such as LRK, tOrn, Adore, \etc) in general-purpose Linux environments causes damage to the system by modifying or overwriting the system binary \cite[Ch. 5]{linux_hack}. Thus we follow a similar approach to demonstrate a host-level attack, \viz we injected ARM shellcode \cite{arm_shellcode} to override the victim task's code and launched the attack by modifying the contents in the file-system binary. %(\eg $\mathtt{/}$). 

We obtained the periods of the security tasks in both modes by solving the period adaptation problem (Algorithm \ref{alg:sec_schd}) and set it as the period of security tasks (by using the Xenomai $\mathtt{rt\_task\_set\_periodic()}$ function). For each of the experiments, the work-flow was as follows. We started with a clean (\eg uncompromised) system state, launched the DoS attack at any random time of the program execution and then injected the shellcode after a random interval, and finally logged the time required by security tasks  to detect the attacks. Initially the security tasks ran in \pve mode. When the network-level attack was suspected by the security task (\eg Bro), a mode change request was placed and the control was switched to \ave mode with the corresponding \ave mode tasks (see Table \ref{table:rtos}).  %in Appendix \ref{appsec:task_param}). 
As mentioned in Section \ref{subsec:timeshield_overview}, our focus is \textit{not} on the effectiveness of a particular IDS here but on the effectiveness of integration of the IDSes into RTS. Therefore  we controlled the experimental environment so that the results were not affected by the false positive/negative rates of the IDS used in the evaluation. In particular, both of the launched attacks were detectable by the respective IDSes used in the evaluation. Detection times were measured using ARM cycle counter registers (CCNT). To ensure the accuracy of the detection time measurements, we disabled all the frequency scaling features in the kernel (by using the $\mathtt{cpufrequtils}$ utility) and allowed the platform to execute with a constant frequency (\eg 1 GHz, the maximum frequency of our experimental platform).

   \begin{figure}[!t]
%\begin{wrapfigure}{l}{0.5\columnwidth}
%\vspace{-1.0\baselineskip}
\centering
\includegraphics[width=2.9in]{fig_mode_trace_color}
\caption{The empirical distribution of time to detect the intrusions when mode change was allowed vs when security tasks were run only in \pve mode. We used ARM cycle counter registers to measure the detection time. A total of $50$ individual experiment instances were examined to obtain the timing traces.}
\label{fig:mode_trace}
\vspace{-1.0\baselineskip}
%\end{wrapfigure}
 \end{figure}

We compared the performance of \coolname with that of an earlier approach \cite{mhasan_rtss16} that has no provision for mode changes and in which the security tasks are run with the lowest priority (similar to the \pve mode of operation in \coolname). Specifically, we measured the time to detect both the host and network-level intrusions, and plot the empirical cumulative distribution function (CDF) of those detection times in Fig.~\ref{fig:mode_trace}. The x-axis in  Fig.~\ref{fig:mode_trace} represents the detection time (in cycle count) and the y-axis represents the probability that the attack would be detected by that time.  The empirical CDF is defined as $\widehat{F}_\alpha(\jmath) = \frac{1}{\alpha} \displaystyle \sum_{i=1}^\alpha \mathbb{I}_{[\zeta_i \leq \jmath]}$, where $\alpha$ is the total number of experimental observations, ${\zeta}_i$ is the time taken to detect the attack in the $i$-th experimental observation, and $\jmath$  represents the $x$-axis values (\viz the detection times in cycle count) in Fig.~\ref{fig:mode_trace}. The indicator function $\mathbb{I}_{[\cdot]}$ outputs $1$ if the condition $[\cdot]$ is satisfied and $0$ otherwise.



From Fig.~\ref{fig:mode_trace} we can see that \coolname provides better detection time (\ie fewer cycle counts required to detect the intrusions). From our experiments we find that \textit{on average} \coolname detects attacks $27.29\%$ faster than the reference scheme does. The approach from the literature \cite{mhasan_rtss16} allows the security tasks to run only when other real-time tasks are not running, leading to more interference (\eg higher response times), and does not provide any mechanisms to adapt against abnormal behaviors (\eg the DoS attack in the experiments). In contrast, \coolname allows quick response to anomalies (by switching to \ave mode when a DoS attack is suspected). Since \ave security tasks can run with higher priority and less interference without impacting the timeliness constraints of real-time tasks, \coolname had a superior detection rate in general for most of the experiments  without impacting safety. 

 \end{document}
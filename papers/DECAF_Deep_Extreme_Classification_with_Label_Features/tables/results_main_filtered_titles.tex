\begin{table}[ht]
    \caption{Results on publicly available short-text datasets. \alg was found to be 2--6\% more accurate, as well as an order of magnitude faster at prediction compared to other deep learning based approaches. Algorithms marked with a `-' were unable to scale on the given dataset within available resources and timeout period. Prediction times for \alg within parenthesis indicate those obtained on a CPU whereas those outside parentheses are times on a GPU.}
    \label{tab:baelines_eval}
      \centering
      \resizebox{\linewidth}{!}{
        \begin{tabular}{@{}l|cc|cc|c@{}}
        \toprule
        \textbf{Method} & \textbf{PSP@1} & \textbf{PSP@5} &  \textbf{P@1} & \textbf{P@5} &  \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Prediction}\\ \textbf{Time (ms)}\end{tabular}} \\
        \midrule
      \multicolumn{6}{c}{LF-AmazonTitles-131K}\\ \midrule					
\alg	 & \textbf{30.85}	 & \textbf{41.42}	 & \textbf{38.4}	 & \textbf{18.65}	 & \textbf{0.1} (1.15)\\
Astec	 & 29.22	 & 39.49	 & 37.12	 & 18.24	 & 2.34\\
AttentionXML	 & 23.97	 & 32.57	 & 32.25	 & 15.61	 & 5.19\\
MACH	 & 24.97	 & 34.72	 & 33.49	 & 16.45	 & 0.23\\
X-Transformer	 & 21.72	 & 27.09	 & 29.95	 & 13.07	 & 15.38\\
Siamese	 & 13.3	 & 13.36	 & 13.81	 & 5.81	 & 0.2\\
Parabel	 & 23.27	 & 32.14	 & 32.6	 & 15.61	 & 0.69\\
Bonsai	 & 24.75	 & 34.86	 & 34.11	 & 16.63	 & 7.49\\
DiSMEC	 & 25.86	 & 36.97	 & 35.14	 & 17.24	 & 5.53\\
PfastreXML	 & 26.81	 & 34.24	 & 32.56	 & 16.05	 & 2.32\\
XT	 & 22.37	 & 31.64	 & 31.41	 & 15.48	 & 9.12\\
Slice	 & 23.08	 & 31.89	 & 30.43	 & 14.84	 & 1.58\\
AnneXML	 & 19.23	 & 32.26	 & 30.05	 & 16.02	 & 0.11\\
\midrule
\multicolumn{6}{c}{LF-WikiSeeAlsoTitles-320K}\\ \midrule					
\alg	 & \textbf{16.73}	 & \textbf{21.01}	 & \textbf{25.14}	 & \textbf{12.86}	 & \textbf{0.09} (0.97)\\
Astec	 & 13.69	 & 17.5	 & 22.72	 & 11.43	 & 2.67\\
AttentionXML	 & 9.45	 & 11.73	 & 17.56	 & 8.52	 & 7.08\\
MACH	 & 9.68	 & 12.53	 & 18.06	 & 8.99	 & 0.52\\
X-Transformer	 & -	 & -	 & -	 & -	 & -\\
Siamese	 & 10.1	 & 9.59	 & 10.69	 & 4.51	 & 0.17\\
Parabel	 & 9.24	 & 11.8	 & 17.68	 & 8.59	 & 0.8\\
Bonsai	 & 10.69	 & 13.79	 & 19.31	 & 9.55	 & 14.82\\
DiSMEC	 & 10.56	 & 14.82	 & 19.12	 & 9.87	 & 11.02\\
PfastreXML	 & 12.15	 & 13.26	 & 17.1	 & 8.35	 & 2.59\\
XT	 & 8.99	 & 11.82	 & 17.04	 & 8.6	 & 12.86\\
Slice	 & 11.24	 & 15.2	 & 18.55	 & 9.68	 & 1.85\\
AnneXML	 & 7.24	 & 11.75	 & 16.3	 & 8.84	 & 0.13\\
\midrule
\multicolumn{6}{c}{LF-AmazonTitles-1.3M}\\ \midrule					
\alg	 & 22.07	 & 29.3	 & \textbf{50.67}	 & \textbf{40.35}	 & 0.16 (1.73)\\
Astec	 & 21.47	 & 27.86	 & 48.82	 & 38.44	 & 2.61\\
AttentionXML	 & 15.97	 & 22.54	 & 45.04	 & 36.25	 & 29.53\\
MACH	 & 9.32	 & 13.26	 & 35.68	 & 28.35	 & 2.09\\
X-Transformer	 & -	 & -	 & -	 & -	 & -\\
Siamese	 & -	 & -	 & -	 & -	 & -\\
Parabel	 & 16.94	 & 24.13	 & 46.79	 & 37.65	 & 0.89\\
Bonsai	 & 18.48	 & 25.95	 & 47.87	 & 38.34	 & 39.03\\
DiSMEC	 & -	 & -	 & -	 & -	 & -\\
PfastreXML	 & \textbf{28.71}	 & \textbf{32.51}	 & 37.08	 & 31.43	 & 23.64\\
XT	 & 13.67	 & 19.06	 & 40.6	 & 32.01	 & 5.94\\
Slice	 & 13.8	 & 18.89	 & 34.8	 & 27.71	 & 1.45\\
AnneXML	 & 15.42	 & 21.91	 & 47.79	 & 36.91	 & \textbf{0.12}\\
        \bottomrule
    \end{tabular}}
\end{table}

\begin{table}
    \caption{Augmenting existing BoW-based XML methods by incorporating label metadata leads to $1.5\%$ increase in the accuracy as compared to base method. However, \alg could be up to $7\%$ more accurate compared to even these.}
    \label{tab:bowmeta}
      \centering
      %\resizebox{\linewidth}{!}{
        \begin{tabular}{@{}l|cc|cc@{}}
        \toprule
         \textbf{Method} & \textbf{PSP@1}  & \textbf{PSP@5} & \textbf{P@1}  & \textbf{P@5} \\
        \midrule
        \multicolumn{5}{c}{LF-AmazonTitles-131K}\\ \midrule					
\alg	 & \textbf{30.85}	 & \textbf{41.42}	 & \textbf{38.4}	 & \textbf{18.65} \\
\midrule
Parabel	 & 23.27	 & 32.14	 & 32.6	 & 15.61 \\
Parabel + metadata	 & 25.89	 & 34.83	 & 33.6	 & 15.84 \\
\midrule
Bonsai	 & 24.75	 & 34.86	 & 34.11	 & 16.63 \\
Bonsai + metadata	 & 26.82	 & 36.63	 & 34.83	 & 16.67 \\
\midrule
DiSMEC	 & 26.25	 & 37.15	 & 35.14	 & 17.24 \\
DiSMEC + metadata	 & 27.19	 & 38.17	 & 35.52	 & 17.52 \\
    \midrule 
    \multicolumn{5}{c}{LF-WikiSeeAlsoTitles-320K}\\ \midrule					
\alg	 & \textbf{16.73}	 & \textbf{21.01}	 & \textbf{25.14}	 & \textbf{12.86} \\
\midrule
Parabel	 & 9.24	 & 11.8	 & 17.68	 & 8.59	 \\
Parabel + metadata	 & 12.96	 & 16.77	 & 20.69	 & 10.24 \\
\midrule
Bonsai	 & 10.69	 & 13.79	 & 19.31	 & 9.55	 \\
Bonsai + metadata	 & 13.63	 & 17.54	 & 21.61	 & 10.72 \\
\midrule
DiSMEC	 & 10.56	 & 14.82	 & 19.12	 & 9.87	\\
DiSMEC + metadata	 & 12.46	 & 15.9	 & 20.74	 & 10.29\\
\bottomrule
    \end{tabular}
		%}
\end{table}


\begin{table}
\caption{Using strategies used by existing XML algorithms for shortlisting labels instead of $\cS$ hurts both both shortlist recall (R@20) and final prediction accuracy (P@k, PSP@k).}
    \label{tab:sub:xmlclass}
    \centering
    \begin{tabular}{@{}l|cc|cc|c@{}}
        \toprule
        \textbf{Method}
        & \textbf{PSP@1}  & \textbf{PSP@5} & \textbf{P@1}  & \textbf{P@5} &\textbf{R@20}\\
        \midrule
\multicolumn{6}{c}{LF-AmazonTitles-131K}\\ \midrule					
\alg	 & \textbf{30.85}	 & \textbf{41.42}	 & \textbf{38.4}	 & \textbf{18.65}	 & \textbf{55.86} \\
\midrule
+ HNSW Shortlist	 & 29.55	 & 39.17	 & 36.7	 & 17.78	 & 48.82 \\
+ Parabel Shortlist	 & 24.88	 & 31.21	 & 32.13	 & 14.73	 & 39.36 \\
\midrule
\multicolumn{6}{c}{LF-WikiSeeAlsoTitles-320K}\\ \midrule			
\alg	 & \textbf{16.73}	 & \textbf{21.01}	 & \textbf{25.14}	 & \textbf{12.86}	 & \textbf{37.53} \\
\midrule
+ HNSW Shortlist	 & 15.68	 & 19.38	 & 23.84	 & 12.11	 & 30.26 \\
+ Parabel Shortlist	 & 13.17	 & 15.09	 & 21.18	 & 10.05	 & 23.91 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}
    \caption{Analyzing the impact for alternative design and algorithmic choices for DECAFâ€™s components.}
    \label{tab:combouv}
      \centering
      \resizebox{\linewidth}{!}{
        \begin{tabular}{@{}l|cc|cc|c@{}}
        \toprule
        Component & \textbf{PSP@1}  & \textbf{PSP@5} & \textbf{P@1}  & \textbf{P@5} & \textbf{R@20} \\
        \midrule
\multicolumn{6}{c}{LF-AmazonTitles-131K}\\ \midrule					
\alg	 & \textbf{30.85}	 & \textbf{41.42}	 & \textbf{38.4}	 & \textbf{18.65}	 & \textbf{55.86} \\
\alg-FFT	 & 25.5	 & 33.38	 & 32.42	 & 15.43	 & 47.23 \\
\alg-8K	 & 29.07	 & 38.7	 & 36.29	 & 17.52	 & 51.65 \\
\alg-no-init	 & 29.86	 & 41.04	 & 37.79	 & 18.57	 & 55.75 \\
\alg-$\hat\vz^1$	 & 28.02	 & 38.38	 & 33.5	 & 17.09	 & 53.83 \\
\alg-$\hat\vz^2$	 & 27.32	 & 38.05	 & 36	 & 17.65	 & 52.2 \\
\algl	 & 29.75	 & 40.36	 & 37.26	 & 18.29	 & 55.25 \\
        \midrule
        \multicolumn{6}{c}{LF-WikiSeeAlsoTitles-320K}\\ \midrule					
\alg	 & 16.73	 & 21.01	 & \textbf{25.14}	 & \textbf{12.86}	 & \textbf{37.53} \\
\alg-FFT	 & 13.91	 & 17.3	 & 21.72	 & 11	 & 32.58 \\
\alg-8K	 & 14.55	 & 17.38	 & 22.41	 & 10.96	 & 30.21 \\
\alg-no-init	 & 15.09	 & 19.47	 & 23.81	 & 12.25	 & 36.18 \\
\alg-$\hat\vz^1$	 & \textbf{18.04}	 & \textbf{21.48}	 & 24.54	 & 12.55	 & 37.33 \\
\alg-$\hat\vz^2$	 & 11.55	 & 15.24	 & 20.82	 & 10.53	 & 29.72 \\
\algl	 & 16.59	 & 20.84	 & 24.87	 & 12.78	 & 37.24 \\
\bottomrule
        \end{tabular}}
\end{table}

\begin{table}[h]
\caption{\alg is more accurate on all evaluation metrics, and a order of magnitude faster in prediction as compared to deep learning based approaches.}
    \label{tab:sup:baelines_eval_unfilters}
    \centering
    \resizebox{\textwidth}{!}{
    \begin{tabular}{@{}c|l|ccccc|ccccc@{}}
    \toprule
    \textbf{Dataset} & \textbf{Method} & \textbf{P@1=N@1} & \textbf{P@3} & \textbf{P@5} & \textbf{N@3} & \textbf{N@5} & \textbf{PSP@1}=\textbf{PSN@1} & \textbf{PSP@5} & \textbf{PSN@5} \\
    \midrule
  \multirow{10}{*}{\textbf{\rotatebox{90}{AmazonTitles-300K}}}	 & \alg(T=3)	 & \textbf{58.39}	 & \textbf{30.19}	 & \textbf{49.71}	 & \textbf{48.31}	 & \textbf{45.15}	 & \textbf{45.62} \\
	 & \alg -uni (T=3)	 & 57.02	 & 29.48	 & 48.53	 & 46.68	 & 43.69	 & 44.1 \\
	 & DeepXML	 & 36.01	 & 23.03	 & 35.16	 & 26.45	 & 32.65	 & 29.77 \\
	 & AttentionXML	 & 28.38	 & 17.27	 & 26.21	 & 18.15	 & 22.38	 & 19.89 \\
	 & XT (T=3)	 & 32.6	 & 20.89	 & 31.65	 & 21.05	 & 27.77	 & 24.68 \\
	 & MACH	 & 33.66	 & 21.25	 & 32.54	 & 21.96	 & 28.39	 & 25.64 \\
	 & Slice+Fasttext	 & 33.08	 & 21.17	 & 32.29	 & 22.7	 & 29.36	 & 26.53 \\
	 & ParabelOld	 & 33.72	 & 20.84	 & 31.86	 & 21.84	 & 27.75	 & 24.92 \\
	 & DiSMEC	 & 34.86	 & 22.45	 & 34.29	 & 22.82	 & 30.63	 & 27.53 \\
	 & AnnexML	 & 29.05	 & 19.5	 & 28.78	 & 16.2	 & 24.44	 & 20.64 \\
	 \midrule
	 \multirow{10}{*}{\textbf{\rotatebox{90}{WikiSeeAlsoTitles-350K}}}	 & \alg(T=3)	 & 21.15	 & \textbf{14.66}	 & \textbf{25.58}	 & 11.54	 & \textbf{20.37}	 & \textbf{18.51} \\
	 & \alg -uni (T=3)	 & 21.04	 & 14.16	 & 24.89	 & 11.25	 & 19.18	 & 17.61 \\
	 & DeepXML	 & \textbf{21.97}	 & 12.56	 & 22.53	 & \textbf{12.46}	 & 17.34	 & 16.08 \\
	 & AttentionXML	 & 14.91	 & 7.23	 & 13.68	 & 6.15	 & 7.39	 & 7.1 \\
	 & XT (T=3)	 & 17.85	 & 10.02	 & 18.21	 & 8.69	 & 12.23	 & 11.39 \\
	 & MACH	 & 16.04	 & 8.13	 & 15.69	 & 7.5	 & 9.36	 & 9.37 \\
	 & Slice+Fasttext	 & 20.17	 & 11.83	 & 20.95	 & 10.56	 & 15.75	 & 14.27 \\
	 & ParabelOld	 & 18.61	 & 10.04	 & 18.44	 & 8.93	 & 12.17	 & 11.41 \\
	 & DiSMEC	 & 16.61	 & 9.14	 & 16.72	 & 7.75	 & 10.96	 & 10.24 \\
	 & AnnexML	 & 15.74	 & 8.99	 & 16.04	 & 6.37	 & 10.22	 & 9.07 \\
	 \midrule
	 \multirow{10}{*}{\textbf{\rotatebox{90}{WikiTitles-500K}}}	 & \alg(T=3)	 & \textbf{47.34}	 & \textbf{18.54}	 & \textbf{33.7}	 & 19.79	 & \textbf{19.93}	 & \textbf{23.06} \\
	 & \alg -uni (T=3)	 & 47.24	 & 18.49	 & 33.66	 & \textbf{19.89}	 & 19.77	 & 22.98 \\
	 & DeepXML	 & -	 & -	 & -	 & -	 & -	 & - \\
	 & AttentionXML	 & 42.59	 & 15.61	 & 28.53	 & 14.98	 & 13.9	 & 16.44 \\
	 & XT (T=3)	 & 40.09	 & 15.6	 & 28.17	 & 15.44	 & 15.57	 & 17.92 \\
	 & MACH	 & 33.68	 & 10.43	 & 20.81	 & 11.37	 & 8.37	 & 11.28 \\
	 & Slice+Fasttext	 & 28.17	 & 12.34	 & 22.94	 & 15.17	 & 15.41	 & 17.75 \\
	 & ParabelOld	 & 42.45	 & 16.17	 & 29.4	 & 16.5	 & 16.12	 & 18.72 \\
	 & DiSMEC	 & 39.89	 & 14.96	 & 27.31	 & 15.97	 & 15.46	 & 17.9 \\
	 & AnnexML	 & 39.47	 & 14.33	 & 26.52	 & 13.92	 & 13.29	 & 15.65 \\
	 \midrule
	 \multirow{10}{*}{\textbf{\rotatebox{90}{AmazonTitles-1.6M}}}	 & \alg(T=3)	 & \textbf{48.1}	 & \textbf{42.99}	 & \textbf{44.66}	 & \textbf{13.81}	 & \textbf{18.02}	 & \textbf{16.7} \\
	 & \alg -uni (T=3)	 & 45.53	 & 40.5	 & 42.13	 & 13.76	 & 17.58	 & 16.37 \\
	 & DeepXML	 & -	 & -	 & -	 & -	 & -	 & - \\
	 & AttentionXML	 & -	 & -	 & -	 & -	 & -	 & - \\
	 & XT (T=3)	 & -	 & -	 & -	 & -	 & -	 & - \\
	 & MACH	 & -	 & -	 & -	 & -	 & -	 & - \\
	 & Slice+Fasttext	 & 35.29	 & 31.7	 & 32.9	 & 10.97	 & 14.47	 & 13.38 \\
	 & ParabelOld	 & 46.52	 & 41.73	 & 43.32	 & 12.53	 & 16.88	 & 15.55 \\
	 & DiSMEC	 & -	 & -	 & -	 & -	 & -	 & - \\
	 & AnnexML	 & 47.43	 & 42.14	 & 43.74	 & 11.11	 & 15.69	 & 14.25 \\
    \bottomrule
    \end{tabular}
    }
\end{table}
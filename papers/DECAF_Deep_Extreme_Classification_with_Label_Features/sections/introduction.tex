\section{Introduction}
\label{sec:intro}

\textbf{Objective}: Extreme multi-label classification (XML) refers to the task of tagging data points with a relevant subset of labels from an extremely large label set. This paper demonstrates that XML algorithms stand to gain significantly by incorporating label metadata. The \alg algorithm is proposed, which could be up to 2-6\% more accurate than leading XML methods such as Astec~\citep{Dahiya21}, MACH~\cite{Medini2019}, Bonsai~\citep{Khandagale19}, AttentionXML~\citep{You18}, \etc, while offering predictions within a fraction of a millisecond, which makes it suitable for high-volume and time-critical applications.

\textbf{Short-text applications}: Applications such as predicting related products given a retail product's name \cite{Medini2019}, or predicting related webpages given a webpage title, or related searches \cite{Jain19}, all involve short texts, with the product name, webpage title, or search query having just 3-10 words on average. In addition to the statistical and computational challenges posed by a large set of labels, short-text tasks are particularly challenging as only a few words are available per data point. This paper focuses on short-text applications such as related product and webpage recommendation.

\textbf{Label metadata}: Metadata for labels can be available in various forms: textual representations, label hierarchies, label taxonomies \cite{Kanagal12, menon11, sachdeva19}, or label correlation graphs, and can capture semantic relations between labels. For instance, the Amazon products (that serve as labels in a product-to-product recommendation task) ``Panzer Dragoon", and ``Panzer Dragoon Orta" do not share any common training point but are semantically related. Label metadata can allow collaborative learning, which especially benefits \emph{tail} labels. Tail labels are those for which very few training points are available and form the majority of labels in XML applications~\citep{Jain16, Babbar17, Babbar19}. For instance, just 14 documents are tagged with the label ``Panzer Dragoon Orta" while 23 documents are tagged with the label ``Panzer Dragoon" in the LF-AmazonTitles-131K dataset. In this paper, we will focus on utilizing label text as a form of label metadata.

\textbf{\alg}: \alg learns a separate linear classifier per label based on the 1-vs-All approach. These classifiers critically utilize label metadata and require careful initialization since random initialization~\citep{Glorot2010} leads to inferior performance at extreme scales. \alg proposes using a \emph{shortlister} with large fanout to cut down training and prediction time drastically. Specifically, given a training set of $N$ examples, $L$ labels, and $D$ dimensional embeddings being learnt, the use of the shortlister brings training time down from $\bigO{NDL}$ to $\bigO{ND\log L}$ (by training only on the $\bigO{\log L}$ most confusing negative labels for every training point), and prediction time down from $\bigO{DL}$ to $\bigO{D\log L}$ (by evaluating classifiers corresponding to only the $\bigO{\log L}$ most likely labels). An efficient and scalable two-stage strategy is proposed to train the shortlister.

\textbf{Comparison with state-of-the-art}: Experiments conducted on publicly available benchmark datasets revealed that \alg could be 5\% more accurate than the leading approaches such as DiSMEC~\citep{Babbar17}, Parabel~\citep{Prabhu18b}, Bonsai~\cite{Khandagale19} AnnexML~\citep{Tagami17}, \etc, which utilize pre-computed features. \alg was also found to be 2-6\% more accurate than leading deep learning-based approaches such as Astec~\citep{Dahiya21}, AttentionXML~\citep{You18} and MACH~\citep{Medini2019} that jointly learn feature representations and classifiers. Furthermore, \alg could be up to 22$\times$ faster at prediction than deep learning methods such as MACH and AttentionXML.

\textbf{Contributions}: This paper presents \alg, a scalable deep learning architecture for XML applications that effectively utilize label metadata. Specific contributions are made in designing a shortlister with a large fanout and a two-stage training strategy. \alg also introduces a novel initialization strategy for classifiers that leads to accuracy gains, more prominently on data-scarce tail labels. \alg scales to XML tasks with millions of labels and makes predictions significantly more accurate than state-of-the-art XML methods. Even on datasets with more than a million labels, \alg can make predictions in a fraction of a millisecond, thereby making it suitable for real-time applications.
